# 04-BANKS_AND_PAYROLLS_ESM

Unified Bank + Payroll roadmap with ESM-oriented code snippets and repository-safe migration numbering.
# Implementation Baseline

Base repository currently has migrations through `m030`.
This roadmap starts new migration keys from `m031_*` and follows repository-native ESM conventions.
Migration snippets should use `key`, `description`, and `async up(connection)` with `connection.execute(...)`.

## Start Here (Execution Guide)

Use this file as an implementation roadmap, but not every snippet is equally authoritative.

Follow this order:

1. Read `Bank Adoption Baseline` first (repo compatibility rules).
2. Use `Recommended Implementation Order (After Adoption)` for the first bank PRs.
3. Implement one PR at a time from the full `# PR-*` sections.
4. Treat later `H*` sections as cross-cutting follow-ups after core Bank/Payroll flows are stable.

Working rule:

- Adoption/baseline sections define repo conventions.
- `# PR-*` sections define execution steps and acceptance criteria.
- Chat-style lines (for example, `Perfect - here is ...`) are historical drafting noise and can be ignored.

## Canonical Conventions (Resolve Ambiguities Before Coding)

This file contains mixed drafts. Use these conventions consistently when implementing:

1. Module format: ESM only (`import` / `export default`)
2. Migration keys: continue from `m031_*` onward
3. Frontend routes: `/app/...` only (no parallel `/bank/...`)
4. Backend route files: prefer `*.routes.js` naming for new modules
5. Scope safety: bank/payroll domain tables must be tenant-scoped and legal-entity-scoped unless explicitly tenant-global
6. Permissions: use one permission naming style per module and keep it consistent in routes, seed, frontend guards, and sidebar

Permission naming note (important):

- This file shows both `bank.account.*` and `bank.accounts.*` in different places.
- Pick one style before PR-B01 and use it everywhere in implementation.
- Recommended for consistency with the detailed PR snippets: `bank.accounts.*` (plural).

## Execution Tracker (Update As You Implement)

- [x] PR-B01 Bank Foundation (implemented)
- [x] PR-B02 Statement Import Foundation (implemented)
- [x] PR-B03 Reconciliation Core (implemented)
- [x] PR-B04 Generic Payment Batch Engine (implemented)
- [x] PR-P01 Payroll Import Foundation (implemented)
- [x] PR-P02 Payroll Accrual Posting + Component Mapping (implemented)
- [x] PR-P03 Payroll Liability Breakdown + Payment Batch Prep (implemented)
- [x] PR-P04 Payroll Payment Settlement Sync (implemented)
- [x] PR-P05 Payroll Corrections (implemented)
- [x] PR-P06 Partial Settlement + Manual Override (implemented)
- [x] PR-B05 Bank Connectivity Adapter (implemented)
- [x] PR-B06 Payment File Export + Bank Ack Import (implemented)
- [x] PR-B07 Reconciliation Rules + Exception Queue (implemented)
- [x] PR-B08-A Auto-Posting Templates (implemented)
- [x] PR-B08-B Returns / Rejections / FX Difference (implemented)
- [x] PR-B09 Bank Approvals / SoD / Thresholds (implemented)
- [x] PR-P07 Beneficiary Bank Master + Immutable Snapshots (implemented)
- [x] PR-P08 Payroll Close Controls + Locks (implemented)
- [x] PR-P09 Provider-Specific Payroll Adapters (implemented)
- [x] PR-H01..PR-H09 Cross-cutting hardening and release gates (implemented)
- [x] PR-H01 Sensitive Data Security (implemented)
- [x] PR-H02 Jobs + Retry Engine (implemented)
- [x] PR-H03 Performance + Indexing + Pagination Hardening (implemented)
- [x] PR-H04 Unified Approval Policy Engine (Thresholds, SoD, Multi-step) (implemented)
- [x] PR-H05 Operations Dashboard APIs (KPIs, SLAs, Health) (implemented)
- [x] PR-H06 Unified Exception Workbench (Bank + Payroll Settlement Exceptions) (implemented)
- [x] PR-H07 Data Retention, Archival, and Export Snapshots (implemented)
- [x] PR-H08 Release Gate + End-to-End Regression Pack (Bank + Payroll) (implemented: bank-flow, payroll-flow, and cross-flow release-gate stages pass end-to-end with real smoke assertions)
- [x] PR-H09 Tenant/Entity Isolation Hardening (implemented)

---
## Roadmap Content

---

## Bank Adoption Baseline

# Bank Roadmap Adoption Baseline (Before Implementation)

Date: 2026-02-25
Scope: Adapt the original Bank roadmap into this repository's real architecture and conventions before any Bank PR code starts.

## Why This Is Required

The original Bank roadmap contains useful functional goals, but the sample code is not drop-in compatible with this repo.

Hard incompatibilities:

1. Migration numbering conflict
- Bank doc starts at `m021_*`.
- This repo already has `m001..m030`.
- Bank/Payroll roadmap migrations must start from `m031_*`.

2. Module format mismatch
- Bank doc examples are mostly CommonJS (`module.exports`).
- This repo is ESM (`import` / `export default`).

3. Guardrail mismatch (tenant/legal-entity safety)
- Bank doc table/API samples do not consistently follow this repo's tenant/legal-entity scoping and RBAC resolution model.
- All Bank entities must be tenant-scoped and legal-entity-scoped where relevant.

4. Frontend auth API mismatch
- Use `RequirePermission anyOf={[...]} / allOf={[...]}` for frontend route guards.
- This repo uses `RequirePermission` with `anyOf`/`allOf`.

5. Frontend route convention mismatch
- Bank doc uses `/bank/...`.
- This repo renders feature pages inside `/app/...` with sidebar-driven permissions and i18n by route path.

## Repository Rules Bank Must Follow

## Backend

1. Migration format
- Use ESM migration objects with `key`, `description`, `up(connection)`.
- Keep idempotent checks (`information_schema`) where applicable.

2. Scope model
- Include `tenant_id` and `legal_entity_id` on bank domain tables unless the table is truly tenant-global.
- Enforce scope in routes/services with existing RBAC helpers (`requirePermission`, `assertScopeAccess`, `buildScopeFilter`) and tenant guards.

3. Validation style
- Use route validators that parse/normalize fields and throw `badRequest(...)` on contract violations.
- Reuse existing common parsers in `cash.validators.common.js` where possible.

4. Service style
- Keep business rules in services.
- Keep routes thin: parse input -> service call -> standardized JSON response.

5. Router registration
- Mount routers in `backend/src/index.js` with `requireAuth`.

## Frontend

1. App route pattern
- Implement pages in `frontend/src/App.jsx` under `/app/...`.
- Wrap with `RequirePermission anyOf={[...]}` semantics through existing route guard pattern.

2. Sidebar pattern
- Use `requiredPermissions` arrays and `implemented: true` in `frontend/src/layouts/sidebarConfig.js`.

3. i18n pattern
- Add labels in `frontend/src/i18n/messages.js` `sidebar.byPath` for both TR and EN maps.

4. API client pattern
- Use `frontend/src/api/client.js` helper style, not custom fetch wrappers.

## Test/quality

1. Add dedicated scripts per Bank PR in `backend/scripts`.
2. Add npm aliases in `backend/package.json`.
3. Keep Bank gate separate at first; wire into release gate later as optional extension (same pattern used for contracts/revenue).

## Adopted Mapping: Original -> Repo-Native

## PR-B01 (Bank Foundation)

Original intent: bank master data + strict GL link.

Repo-native adoption:

- Migration file:
  - `backend/src/migrations/m031_bank_foundation.js`
- Suggested table:
  - `bank_accounts`
  - Required columns: `id`, `tenant_id`, `legal_entity_id`, `code`, `name`, `currency_code`, `gl_account_id`, `is_active`, `created_by_user_id`, timestamps.
- Required constraints/indexes:
  - Unique `(tenant_id, legal_entity_id, code)`
  - Unique `(tenant_id, legal_entity_id, gl_account_id)` for v1 one-to-one GL-bank link per legal entity
  - FK `(tenant_id, legal_entity_id)` -> `legal_entities`
  - FK `currency_code` -> `currencies(code)`
  - FK `created_by_user_id` -> `users(id)`
  - FK `gl_account_id` -> `accounts(id)` plus service-level tenant/legal-entity compatibility checks using tenant guards
- Router/validator/service:
  - `backend/src/routes/bank.accounts.routes.js`
  - `backend/src/routes/bank.accounts.validators.js`
  - `backend/src/services/bank.accounts.service.js`
- Mount:
  - `app.use("/api/v1/bank/accounts", requireAuth, bankAccountsRoutes);`
- Permissions to add:
  - `bank.accounts.read`
  - `bank.accounts.write` (use for create/update/activate/deactivate in v1)
- Frontend:
  - `frontend/src/api/bankAccounts.js`
  - `frontend/src/pages/bank/BankAccountsPage.jsx`
  - Route under `/app/...` (see routing note below)
- Test:
  - `backend/scripts/test-bank-prb01-foundation.js`
  - npm: `test:bank-prb01`

## PR-B02 (Statement Import Foundation)

Original intent: import + line queue, no recon matching.

Repo-native adoption:

- Migration file:
  - `backend/src/migrations/m032_bank_statement_imports.js`
- Tables:
  - `bank_statement_imports` (tenant-scoped, legal-entity-scoped)
  - `bank_statement_lines` (tenant-scoped, legal-entity-scoped, `recon_status`)
- APIs under:
  - `/api/v1/bank/statements/*`
- Permissions:
  - `bank.statement.import`
  - `bank.statement.read`
- Test:
  - `backend/scripts/test-bank-prb02-import-foundation.js`
  - npm: `test:bank-prb02`

## PR-B03 (Reconciliation Core)

Original intent: queue, suggestions, match/unmatch/ignore, audit.

Repo-native adoption:

- Migration file:
  - `backend/src/migrations/m033_bank_reconciliation.js`
- Tables:
  - `bank_reconciliation_matches`
  - `bank_reconciliation_audit`
- APIs under:
  - `/api/v1/bank/reconciliation/*`
- Permissions:
  - `bank.reconcile.read`
  - `bank.reconcile.write`
- Test:
  - `backend/scripts/test-bank-prb03-reconciliation-core.js`
  - npm: `test:bank-prb03`

## PR-B04 (Generic Payment Batch Engine)

Original intent: reusable payment batch with approval/export/post.

Repo-native adoption:

- Migration file:
  - `backend/src/migrations/m034_payment_batches.js`
- Tables:
  - `payment_batches`
  - `payment_batch_lines`
  - `payment_batch_exports`
- APIs under:
  - `/api/v1/payments/*`
- Permissions:
  - `payments.batch.read`
  - `payments.batch.create`
  - `payments.batch.approve`
  - `payments.batch.export`
  - `payments.batch.post`
  - `payments.batch.cancel`
- Test:
  - `backend/scripts/test-payments-prb04-batch-engine.js`
  - npm: `test:payments-prb04`

## Frontend Routing Adoption Notes (Mandatory)

Do not introduce a parallel top-level `/bank/...` frontend namespace.
Use `/app/...` routes to stay consistent with current app layout and guards.

Adopted path plan:

- PR-B01 page:
  - Canonical: `/app/banka-tanimla` (reuse existing placeholder)
  - Optional alias: `/app/banka-hesaplari` -> redirect to canonical
- PR-B02 pages:
  - `/app/banka-ekstre-ice-aktar`
  - `/app/banka-ekstre-kuyrugu`
- PR-B03 page:
  - `/app/banka-mutabakat`
- PR-B04 pages:
  - `/app/odeme-batchleri`
  - `/app/odeme-batchleri/:id`

## Release Gate Adoption

Do not immediately hard-wire Bank into the final release gate.

Adopt staged scripts:

1. `test:bank-gate` (new chain for B01..B03 or B04 when ready)
2. Keep release gate extension optional by env flag, same strategy used for contracts/revenue.

Example target after bank stabilizes:

- `test:release-gate:core` (existing)
- optional extension call from release orchestrator:
  - skip env e.g. `RELEASE_GATE_SKIP_BANK=1`

## Recommended Implementation Order (After Adoption)

1. PR-B01 only (bank accounts foundation)
2. PR-B02 (statement import queue)
3. PR-B03 (reconciliation core)
4. PR-B04 (generic payment batches)

## "Definition of Ready" For Starting PR-B01

Before coding PR-B01:

1. Confirm migration number `m031_*` is reserved.
2. Confirm permission codes and role seed mapping are finalized in design.
3. Confirm canonical frontend route (`/app/banka-tanimla`) for Bank Accounts page.
4. Confirm Bank smoke script name and npm alias.
5. Confirm OpenAPI generation flow includes new endpoints.

---

## Bank PR Steps (Original Draft)

# Bank PR Steps (Original Draft)

> Implementation note (mandatory): do not execute this file directly in this repository.
> First align every Bank PR with `04-BANKS_AND_PAYROLLS_ESM.md`, then implement from the adopted mapping there.

# PR-B01: Bank Foundation (Master Data + GL Link)

    ## Goal

    Introduce **Bank Accounts** as a first-class module with strict GL linkage (no statement import/reconciliation yet).

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m031_bank_foundation.js`
    * `backend/src/routes/bank.accounts.js`
    * `backend/src/routes/bank.accounts.validators.js`
    * `backend/src/services/bank.accounts.service.js`
    * `backend/scripts/test-bank-prb01-foundation.js`

    ### Frontend

    * `frontend/src/api/bankAccounts.js`
    * `frontend/src/pages/bank/BankAccountsPage.jsx`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js` (permissions seed)
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/App.jsx`
    * `frontend/src/layouts/sidebarConfig.js`
    * `frontend/src/i18n/messages.js`

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m031_bank_foundation.js`

    > Assumes MySQL 8 + your migration style (`up/down` with `db.query` or similar). Adjust helper names to your project’s migration runner.

    ```js
    // backend/src/migrations/m031_bank_foundation.js

    export default {
    key: "m031_bank_foundation",
    description: "m031_bank_foundation",
    async up(connection) {
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS bank_accounts (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            code VARCHAR(50) NOT NULL,
            name VARCHAR(255) NOT NULL,
            currency_code CHAR(3) NOT NULL,
            gl_account_id BIGINT UNSIGNED NOT NULL,
            bank_name VARCHAR(255) NULL,
            branch_name VARCHAR(255) NULL,
            iban VARCHAR(64) NULL,
            account_no VARCHAR(64) NULL,
            is_active TINYINT(1) NOT NULL DEFAULT 1,
            created_by BIGINT UNSIGNED NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            UNIQUE KEY uq_bank_accounts_code (code),
            UNIQUE KEY uq_bank_accounts_gl_account_id (gl_account_id),
            KEY idx_bank_accounts_active (is_active),
            KEY idx_bank_accounts_currency (currency_code),
            CONSTRAINT fk_bank_accounts_gl_account
            FOREIGN KEY (gl_account_id) REFERENCES accounts(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);
    },

    async down(connection) {
        await connection.execute(`DROP TABLE IF EXISTS bank_accounts;`);
    },
    };
    ```

    ### Notes

    * `UNIQUE(gl_account_id)` enforces **1 bank account ↔ 1 GL bank account** in v1.
    * `is_active` allows soft lifecycle (don’t delete historical bank accounts).

    ---

    ## 2) Validators — `backend/src/routes/bank.accounts.validators.js`

    > Keep it aligned with your existing validator pattern (`zod`, `joi`, or custom). Here’s a neutral shape.

    ```js
    // backend/src/routes/bank.accounts.validators.js

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function requireCode(code) {
    const v = normalizeString(code);
    if (!v) throw new Error("code is required");
    return v.toUpperCase();
    }

    function requireName(name) {
    const v = normalizeString(name);
    if (!v) throw new Error("name is required");
    return v;
    }

    function requireCurrency(currency) {
    const v = normalizeString(currency);
    if (!v || v.length !== 3) throw new Error("currency_code must be 3 chars");
    return v.toUpperCase();
    }

    function requirePositiveInt(value, fieldName) {
    const n = Number(value);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${fieldName} must be positive integer`);
    return n;
    }

    function validateCreateBankAccount(body = {}) {
    return {
        code: requireCode(body.code),
        name: requireName(body.name),
        currency_code: requireCurrency(body.currency_code),
        gl_account_id: requirePositiveInt(body.gl_account_id, "gl_account_id"),
        bank_name: normalizeString(body.bank_name),
        branch_name: normalizeString(body.branch_name),
        iban: normalizeString(body.iban),
        account_no: normalizeString(body.account_no),
    };
    }

    function validateUpdateBankAccount(body = {}) {
    return {
        name: body.name !== undefined ? requireName(body.name) : undefined,
        currency_code: body.currency_code !== undefined ? requireCurrency(body.currency_code) : undefined,
        gl_account_id: body.gl_account_id !== undefined ? requirePositiveInt(body.gl_account_id, "gl_account_id") : undefined,
        bank_name: body.bank_name !== undefined ? normalizeString(body.bank_name) : undefined,
        branch_name: body.branch_name !== undefined ? normalizeString(body.branch_name) : undefined,
        iban: body.iban !== undefined ? normalizeString(body.iban) : undefined,
        account_no: body.account_no !== undefined ? normalizeString(body.account_no) : undefined,
    };
    }

    function validateIdParam(params = {}) {
    return { id: requirePositiveInt(params.id, "id") };
    }

    export default {
    validateCreateBankAccount,
    validateUpdateBankAccount,
    validateIdParam,
    };
    ```

    ---

    ## 3) Service — `backend/src/services/bank.accounts.service.js`

    > Keep business rules here (GL linkage, uniqueness, active/inactive).

    ```js
    // backend/src/services/bank.accounts.service.js

    async function listBankAccounts(db, { includeInactive = true } = {}) {
    const params = [];
    let sql = `
        SELECT
        b.id, b.code, b.name, b.currency_code, b.gl_account_id,
        b.bank_name, b.branch_name, b.iban, b.account_no,
        b.is_active, b.created_at, b.updated_at,
        a.code AS gl_account_code,
        a.name AS gl_account_name
        FROM bank_accounts b
        LEFT JOIN accounts a ON a.id = b.gl_account_id
    `;
    if (!includeInactive) {
        sql += ` WHERE b.is_active = 1`;
    }
    sql += ` ORDER BY b.code ASC`;

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function getBankAccountById(db, id) {
    const [rows] = await db.query(
        `
        SELECT
        b.id, b.code, b.name, b.currency_code, b.gl_account_id,
        b.bank_name, b.branch_name, b.iban, b.account_no,
        b.is_active, b.created_at, b.updated_at,
        a.code AS gl_account_code,
        a.name AS gl_account_name
        FROM bank_accounts b
        LEFT JOIN accounts a ON a.id = b.gl_account_id
        WHERE b.id = ?
        LIMIT 1
        `,
        [id]
    );
    return rows[0] || null;
    }

    async function assertGlAccountExists(db, glAccountId) {
    const [rows] = await db.query(
        `SELECT id, code, name FROM accounts WHERE id = ? LIMIT 1`,
        [glAccountId]
    );
    if (!rows[0]) {
        const err = new Error("GL account not found");
        err.statusCode = 400;
        throw err;
    }
    }

    async function createBankAccount(db, payload, userId = null) {
    await assertGlAccountExists(db, payload.gl_account_id);

    try {
        const [result] = await db.query(
        `
        INSERT INTO bank_accounts
        (code, name, currency_code, gl_account_id, bank_name, branch_name, iban, account_no, is_active, created_by)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, 1, ?)
        `,
        [
            payload.code,
            payload.name,
            payload.currency_code,
            payload.gl_account_id,
            payload.bank_name,
            payload.branch_name,
            payload.iban,
            payload.account_no,
            userId,
        ]
        );
        return getBankAccountById(db, result.insertId);
    } catch (e) {
        if (e && e.code === "ER_DUP_ENTRY") {
        const err = new Error("Duplicate bank code or GL account link");
        err.statusCode = 409;
        throw err;
        }
        throw e;
    }
    }

    async function updateBankAccount(db, id, patch) {
    const existing = await getBankAccountById(db, id);
    if (!existing) {
        const err = new Error("Bank account not found");
        err.statusCode = 404;
        throw err;
    }

    if (patch.gl_account_id !== undefined) {
        await assertGlAccountExists(db, patch.gl_account_id);
    }

    const next = {
        name: patch.name ?? existing.name,
        currency_code: patch.currency_code ?? existing.currency_code,
        gl_account_id: patch.gl_account_id ?? existing.gl_account_id,
        bank_name: patch.bank_name ?? existing.bank_name,
        branch_name: patch.branch_name ?? existing.branch_name,
        iban: patch.iban ?? existing.iban,
        account_no: patch.account_no ?? existing.account_no,
    };

    try {
        await db.query(
        `
        UPDATE bank_accounts
        SET name = ?, currency_code = ?, gl_account_id = ?,
            bank_name = ?, branch_name = ?, iban = ?, account_no = ?
        WHERE id = ?
        `,
        [
            next.name,
            next.currency_code,
            next.gl_account_id,
            next.bank_name,
            next.branch_name,
            next.iban,
            next.account_no,
            id,
        ]
        );
        return getBankAccountById(db, id);
    } catch (e) {
        if (e && e.code === "ER_DUP_ENTRY") {
        const err = new Error("Duplicate GL account link");
        err.statusCode = 409;
        throw err;
        }
        throw e;
    }
    }

    async function setBankAccountActive(db, id, isActive) {
    const existing = await getBankAccountById(db, id);
    if (!existing) {
        const err = new Error("Bank account not found");
        err.statusCode = 404;
        throw err;
    }

    await db.query(`UPDATE bank_accounts SET is_active = ? WHERE id = ?`, [isActive ? 1 : 0, id]);
    return getBankAccountById(db, id);
    }

    export default {
    listBankAccounts,
    getBankAccountById,
    createBankAccount,
    updateBankAccount,
    setBankAccountActive,
    };
    ```

    ---

    ## 4) Routes — `backend/src/routes/bank.accounts.js`

    > Keep route-level permission checks here (same pattern you use in other modules).

    ```js
    // backend/src/routes/bank.accounts.js

    import express from "express";
    import { validateCreateBankAccount,
    validateUpdateBankAccount,
    validateIdParam, } from "./bank.accounts.validators.js";
    import service from "../services/bank.accounts.service.js";
    // Replace these with your project helpers:
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();

    // GET /api/v1/bank/accounts
    router.get(
    "/accounts",
    requireAuth,
    requirePermission("bank.accounts.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const includeInactive = req.query.include_inactive !== "0";
        const rows = await service.listBankAccounts(db, { includeInactive });
        res.json({ items: rows });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/bank/accounts/:id
    router.get(
    "/accounts/:id",
    requireAuth,
    requirePermission("bank.accounts.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const row = await service.getBankAccountById(db, id);
        if (!row) return res.status(404).json({ error: "Not found" });
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/bank/accounts
    router.post(
    "/accounts",
    requireAuth,
    requirePermission("bank.accounts.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const payload = validateCreateBankAccount(req.body);
        const userId = req.user?.id ?? null;
        const created = await service.createBankAccount(db, payload, userId);
        res.status(201).json(created);
        } catch (err) {
        next(err);
        }
    }
    );

    // PUT /api/v1/bank/accounts/:id
    router.put(
    "/accounts/:id",
    requireAuth,
    requirePermission("bank.accounts.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const patch = validateUpdateBankAccount(req.body);
        const updated = await service.updateBankAccount(db, id, patch);
        res.json(updated);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/bank/accounts/:id/activate
    router.post(
    "/accounts/:id/activate",
    requireAuth,
    requirePermission("bank.accounts.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const row = await service.setBankAccountActive(db, id, true);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/bank/accounts/:id/deactivate
    router.post(
    "/accounts/:id/deactivate",
    requireAuth,
    requirePermission("bank.accounts.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const row = await service.setBankAccountActive(db, id, false);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 5) Mount route — `backend/src/index.js`

    Add the bank router mount (same pattern as your other modules):

    ```js
    // backend/src/index.js
    import bankAccountsRoutes from "./routes/bank.accounts.js";
    // ...
    app.use("/api/v1/bank", bankAccountsRoutes);
    ```

    ---

    ## 6) Migration registry — `backend/src/migrations/index.js`

    Add the migration in order:

    ```js
    // backend/src/migrations/index.js
    import m031_bank_foundation from "./m031_bank_foundation.js";
    export default [
    // ...
    m031_bank_foundation,
    ];
    ```

    ---

    ## 7) Seed permissions — `backend/src/seedCore.js`

    Add permissions so UI/backend can enforce them:

    ```js
    // backend/src/seedCore.js (where you seed permissions)
    const BANK_PERMISSIONS = [
    "bank.accounts.read",
    "bank.accounts.write",
    ];

    // merge with your existing permissions seed list
    ```

    ---

    ## 8) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Add bank endpoints to your spec generation map (shape depends on your script).
    Minimum paths to register:

    * `GET /api/v1/bank/accounts`
    * `GET /api/v1/bank/accounts/{id}`
    * `POST /api/v1/bank/accounts`
    * `PUT /api/v1/bank/accounts/{id}`
    * `POST /api/v1/bank/accounts/{id}/activate`
    * `POST /api/v1/bank/accounts/{id}/deactivate`

    If your script is route-driven, just make sure this router is included.

    ---

    ## 9) Backend smoke test — `backend/scripts/test-bank-prb01-foundation.js`

    > Keep it small and deterministic: create + duplicate check + activate/deactivate + list.

    ```js
    // backend/scripts/test-bank-prb01-foundation.js

    async function main() {
    // Pseudocode: adapt to your test helpers / supertest setup
    // 1) Ensure migration is applied
    // 2) Create/find a GL account to link (use seeded bank-type account if available)
    // 3) POST /api/v1/bank/accounts
    // 4) GET list and assert created row exists
    // 5) POST duplicate code -> expect 409
    // 6) POST same gl_account_id on another code -> expect 409
    // 7) POST deactivate, then activate -> status flips
    console.log("PR-B01 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    If you already use `supertest`, make this a real endpoint test script immediately.

    ---

    ## 10) `backend/package.json` scripts

    Add a smoke test command:

    ```json
    {
    "scripts": {
        "test:bank:prb01": "node backend/scripts/test-bank-prb01-foundation.js"
    }
    }
    ```

    (Adjust path if your `package.json` is inside `/backend` already)

    ---

    # Frontend skeletons

    ## 11) API client — `frontend/src/api/bankAccounts.js`

    Follow your existing API modules style (`fetch`, `request`, axios, etc.). Here’s a generic fetch-based shape:

    ```js
    // frontend/src/api/bankAccounts.js

    import { apiFetch } from "./client.js"; // adapt to your actual client helper

    export function listBankAccounts(params = {}) {
    const q = new URLSearchParams();
    if (params.include_inactive !== undefined) {
        q.set("include_inactive", params.include_inactive ? "1" : "0");
    }
    const qs = q.toString();
    return apiFetch(`/api/v1/bank/accounts${qs ? `?${qs}` : ""}`);
    }

    export function getBankAccount(id) {
    return apiFetch(`/api/v1/bank/accounts/${id}`);
    }

    export function createBankAccount(payload) {
    return apiFetch(`/api/v1/bank/accounts`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function updateBankAccount(id, payload) {
    return apiFetch(`/api/v1/bank/accounts/${id}`, {
        method: "PUT",
        body: JSON.stringify(payload),
    });
    }

    export function activateBankAccount(id) {
    return apiFetch(`/api/v1/bank/accounts/${id}/activate`, {
        method: "POST",
    });
    }

    export function deactivateBankAccount(id) {
    return apiFetch(`/api/v1/bank/accounts/${id}/deactivate`, {
        method: "POST",
    });
    }
    ```

    ---

    ## 12) Page — `frontend/src/pages/bank/BankAccountsPage.jsx`

    > Start simple: table + create form. Edit can be phase 2 on same page or modal later.

    ```jsx
    // frontend/src/pages/bank/BankAccountsPage.jsx

    import { useEffect, useState } from "react";
    import {
    listBankAccounts,
    createBankAccount,
    activateBankAccount,
    deactivateBankAccount,
    } from "../../api/bankAccounts.js";

    const emptyForm = {
    code: "",
    name: "",
    currency_code: "USD",
    gl_account_id: "",
    bank_name: "",
    branch_name: "",
    iban: "",
    account_no: "",
    };

    export default function BankAccountsPage() {
    const [items, setItems] = useState([]);
    const [form, setForm] = useState(emptyForm);
    const [loading, setLoading] = useState(false);
    const [err, setErr] = useState("");

    async function load() {
        setLoading(true);
        setErr("");
        try {
        const res = await listBankAccounts({ include_inactive: true });
        setItems(res.items || []);
        } catch (e) {
        setErr(e.message || "Failed to load bank accounts");
        } finally {
        setLoading(false);
        }
    }

    useEffect(() => {
        load();
    }, []);

    async function onSubmit(e) {
        e.preventDefault();
        setErr("");
        try {
        await createBankAccount({
            ...form,
            gl_account_id: Number(form.gl_account_id),
        });
        setForm(emptyForm);
        await load();
        } catch (e) {
        setErr(e.message || "Create failed");
        }
    }

    async function onToggleActive(row) {
        try {
        if (row.is_active) await deactivateBankAccount(row.id);
        else await activateBankAccount(row.id);
        await load();
        } catch (e) {
        setErr(e.message || "Status update failed");
        }
    }

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <h1 className="text-lg font-semibold mb-3">Bank Accounts</h1>

            {err ? <div className="mb-3 text-sm text-red-600">{err}</div> : null}

            <form className="grid grid-cols-1 md:grid-cols-4 gap-2" onSubmit={onSubmit}>
            <input
                className="border rounded px-2 py-1"
                placeholder="Code"
                value={form.code}
                onChange={(e) => setForm((s) => ({ ...s, code: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="Name"
                value={form.name}
                onChange={(e) => setForm((s) => ({ ...s, name: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="Currency (USD)"
                value={form.currency_code}
                onChange={(e) => setForm((s) => ({ ...s, currency_code: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="GL Account ID"
                value={form.gl_account_id}
                onChange={(e) => setForm((s) => ({ ...s, gl_account_id: e.target.value }))}
            />

            <input
                className="border rounded px-2 py-1"
                placeholder="Bank Name"
                value={form.bank_name}
                onChange={(e) => setForm((s) => ({ ...s, bank_name: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="Branch"
                value={form.branch_name}
                onChange={(e) => setForm((s) => ({ ...s, branch_name: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="IBAN"
                value={form.iban}
                onChange={(e) => setForm((s) => ({ ...s, iban: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="Account No"
                value={form.account_no}
                onChange={(e) => setForm((s) => ({ ...s, account_no: e.target.value }))}
            />

            <div className="md:col-span-4">
                <button className="px-3 py-1 rounded bg-black text-white" type="submit">
                Create Bank Account
                </button>
            </div>
            </form>
        </div>

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">List</h2>

            {loading ? (
            <div>Loading...</div>
            ) : (
            <div className="overflow-auto">
                <table className="min-w-full text-sm border-collapse">
                <thead>
                    <tr className="border-b">
                    <th className="text-left p-2">Code</th>
                    <th className="text-left p-2">Name</th>
                    <th className="text-left p-2">Currency</th>
                    <th className="text-left p-2">GL Link</th>
                    <th className="text-left p-2">Bank</th>
                    <th className="text-left p-2">Active</th>
                    <th className="text-left p-2">Actions</th>
                    </tr>
                </thead>
                <tbody>
                    {items.map((row) => (
                    <tr key={row.id} className="border-b">
                        <td className="p-2">{row.code}</td>
                        <td className="p-2">{row.name}</td>
                        <td className="p-2">{row.currency_code}</td>
                        <td className="p-2">
                        {row.gl_account_code} - {row.gl_account_name}
                        </td>
                        <td className="p-2">{row.bank_name || "-"}</td>
                        <td className="p-2">{row.is_active ? "Yes" : "No"}</td>
                        <td className="p-2">
                        <button
                            className="underline"
                            onClick={() => onToggleActive(row)}
                            type="button"
                        >
                            {row.is_active ? "Deactivate" : "Activate"}
                        </button>
                        </td>
                    </tr>
                    ))}
                    {items.length === 0 && (
                    <tr>
                        <td className="p-2" colSpan={7}>
                        No bank accounts yet.
                        </td>
                    </tr>
                    )}
                </tbody>
                </table>
            </div>
            )}
        </div>
        </div>
    );
    }
    ```

    ---

    ## 13) App route — `frontend/src/App.jsx`

    Add the route (and permission guard if you use `RequirePermission`):

    ```jsx
    // frontend/src/App.jsx
    import BankAccountsPage from "./pages/bank/BankAccountsPage.js";

    // ...
    <Route
    path="/app/banka-tanimla"
    element={
        <RequirePermission anyOf={["bank.accounts.read"]}>
        <BankAccountsPage />
        </RequirePermission>
    }
    />
    ```

    ---

    ## 14) Sidebar — `frontend/src/layouts/sidebarConfig.js`

    Add a Bank section + page item using your canonical permission semantic:

    ```js
    // frontend/src/layouts/sidebarConfig.js
    {
    key: "bank",
    label: "Bank",
    children: [
        {
        key: "bank-accounts",
        label: "Bank Accounts",
        to: "/app/banka-tanimla",
        requiredPermissions: ["bank.accounts.read"],
        },
    ],
    }
    ```

    ---

    ## 15) i18n — `frontend/src/i18n/messages.js`

    Add minimal labels (or Turkish equivalents if you’re using tr-first):

    ```js
    // frontend/src/i18n/messages.js
    export default {
    // ...
    "sidebar.bank": "Bank",
    "sidebar.bankAccounts": "Bank Accounts",
    };
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ Can create bank account only with a valid `gl_account_id`.
    * ✅ Duplicate `code` is blocked.
    * ✅ Duplicate `gl_account_id` link is blocked (v1 one-to-one rule).
    * ✅ Bank account can be activated/deactivated.
    * ✅ Inactive accounts are still listable.
    * ✅ Route + UI permission checks use `bank.accounts.read/write`.
    * ✅ OpenAPI is updated for all new endpoints.
    * ✅ Smoke test script exists and runs.

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:bank:prb01`

    Should verify at least:

    1. **Create success**

    * POST valid payload → `201`
    * response includes `id`, `code`, `gl_account_id`, `is_active=1`

    2. **List success**

    * GET `/api/v1/bank/accounts` includes created record

    3. **Duplicate code blocked**

    * POST same `code` → `409`

    4. **Duplicate GL link blocked**

    * POST different `code` but same `gl_account_id` → `409`

    5. **Deactivate/activate flow**

    * POST `/deactivate` → `is_active=0`
    * POST `/activate` → `is_active=1`

    6. **Permissions enforced**

    * missing/insufficient permission returns `403` (depending on your auth helper)

    ---

    # Recommended payload examples (for API manual test)

    ## Create

    ```json
    {
    "code": "BNK-KBL-USD-001",
    "name": "Kabul Main USD",
    "currency_code": "USD",
    "gl_account_id": 110201,
    "bank_name": "Azizi Bank",
    "branch_name": "Kabul HQ",
    "iban": "",
    "account_no": "001-23456789"
    }
    ```

    ## Update

    ```json
    {
    "name": "Kabul Main USD Updated",
    "branch_name": "Kabul Branch 1"
    }
    ```

    ---

    # Tiny implementation notes (to avoid future pain)

    * Keep `gl_account_id` unique **for now** (v1 simplicity).
    * Do **not** hard-delete bank accounts.
    * In next PRs, `bank_account_id` will be the anchor for:

    * statement imports
    * payment batches
    * reconciliation queue

    ---

Perfect — here’s **PR-B02 in the same concrete format**.

# PR-B02: Bank Statement Import Foundation (Imports + Lines Queue)

    ## Goal

    Add a **bank statement import pipeline** (CSV v1) and normalized **statement lines queue**.

    * ✅ Import file → create import header
    * ✅ Parse rows → create normalized statement lines
    * ✅ Idempotency by file checksum
    * ✅ Line-level dedupe by deterministic hash
    * ❌ No reconciliation matching yet (that’s PR-B03)

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m032_bank_statement_imports.js`
    * `backend/src/routes/bank.statements.js`
    * `backend/src/routes/bank.statements.validators.js`
    * `backend/src/services/bank.statements.service.js`
    * `backend/src/services/bank.parsers.csv.js`
    * `backend/scripts/test-bank-prb02-statement-import.js`

    ### Frontend

    * `frontend/src/api/bankStatements.js`
    * `frontend/src/pages/bank/BankStatementImportPage.jsx`
    * `frontend/src/pages/bank/BankStatementQueuePage.jsx`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js` (permissions)
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/App.jsx`
    * `frontend/src/layouts/sidebarConfig.js`
    * `frontend/src/i18n/messages.js`

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m032_bank_statement_imports.js`

    ```js
    // backend/src/migrations/m032_bank_statement_imports.js

    export default {
    key: "m032_bank_statement_imports",
    description: "m032_bank_statement_imports",
    async up(connection) {
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS bank_statement_imports (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            bank_account_id BIGINT UNSIGNED NOT NULL,
            import_source VARCHAR(20) NOT NULL DEFAULT 'CSV',
            original_filename VARCHAR(255) NOT NULL,
            file_checksum CHAR(64) NOT NULL,
            period_start DATE NULL,
            period_end DATE NULL,
            status VARCHAR(20) NOT NULL DEFAULT 'IMPORTED',
            line_count_total INT UNSIGNED NOT NULL DEFAULT 0,
            line_count_inserted INT UNSIGNED NOT NULL DEFAULT 0,
            line_count_duplicates INT UNSIGNED NOT NULL DEFAULT 0,
            raw_meta_json JSON NULL,
            imported_by BIGINT UNSIGNED NULL,
            imported_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            UNIQUE KEY uq_bank_statement_import_checksum (bank_account_id, file_checksum),
            KEY idx_bank_statement_imports_bank_account (bank_account_id),
            KEY idx_bank_statement_imports_status (status),
            KEY idx_bank_statement_imports_imported_at (imported_at),
            CONSTRAINT fk_bank_statement_imports_bank_account
            FOREIGN KEY (bank_account_id) REFERENCES bank_accounts(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS bank_statement_lines (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            import_id BIGINT UNSIGNED NOT NULL,
            bank_account_id BIGINT UNSIGNED NOT NULL,
            line_no INT UNSIGNED NOT NULL,
            txn_date DATE NOT NULL,
            value_date DATE NULL,
            description VARCHAR(500) NOT NULL,
            reference_no VARCHAR(255) NULL,
            amount DECIMAL(18,2) NOT NULL,
            currency_code CHAR(3) NOT NULL,
            balance_after DECIMAL(18,2) NULL,
            line_hash CHAR(64) NOT NULL,
            recon_status VARCHAR(20) NOT NULL DEFAULT 'UNMATCHED',
            raw_row_json JSON NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            UNIQUE KEY uq_bank_statement_line_hash (bank_account_id, line_hash),
            UNIQUE KEY uq_bank_statement_line_import_lineno (import_id, line_no),
            KEY idx_bank_statement_lines_import (import_id),
            KEY idx_bank_statement_lines_bank_account (bank_account_id),
            KEY idx_bank_statement_lines_recon_status (recon_status),
            KEY idx_bank_statement_lines_txn_date (txn_date),
            CONSTRAINT fk_bank_statement_lines_import
            FOREIGN KEY (import_id) REFERENCES bank_statement_imports(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,
            CONSTRAINT fk_bank_statement_lines_bank_account
            FOREIGN KEY (bank_account_id) REFERENCES bank_accounts(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);
    },

    async down(connection) {
        await connection.execute(`DROP TABLE IF EXISTS bank_statement_lines;`);
        await connection.execute(`DROP TABLE IF EXISTS bank_statement_imports;`);
    },
    };
    ```

    ---

    ## 2) CSV parser — `backend/src/services/bank.parsers.csv.js`

    > v1 assumes a fixed CSV header shape (easy to support/export from banks):
    >
    > `txn_date,value_date,description,reference_no,amount,currency_code,balance_after`

    ```js
    // backend/src/services/bank.parsers.csv.js

    function parseCsvLine(line) {
    // Minimal CSV parser with quote support (good enough for v1)
    const out = [];
    let cur = "";
    let inQuotes = false;

    for (let i = 0; i < line.length; i += 1) {
        const ch = line[i];

        if (ch === '"') {
        if (inQuotes && line[i + 1] === '"') {
            cur += '"';
            i += 1;
        } else {
            inQuotes = !inQuotes;
        }
        continue;
        }

        if (ch === "," && !inQuotes) {
        out.push(cur);
        cur = "";
        continue;
        }

        cur += ch;
    }

    out.push(cur);
    return out.map((s) => s.trim());
    }

    function parseDate(value, fieldName) {
    if (!value) return null;
    const s = String(value).trim();
    // Expect YYYY-MM-DD in v1
    if (!/^\d{4}-\d{2}-\d{2}$/.test(s)) {
        throw new Error(`${fieldName} must be YYYY-MM-DD`);
    }
    return s;
    }

    function parseDecimal(value, fieldName) {
    const n = Number(String(value).replace(/,/g, ""));
    if (!Number.isFinite(n)) throw new Error(`${fieldName} is invalid number`);
    return Number(n.toFixed(2));
    }

    function parseStatementCsv(csvText) {
    const text = String(csvText || "").replace(/\r\n/g, "\n").trim();
    if (!text) throw new Error("CSV is empty");

    const lines = text.split("\n").filter(Boolean);
    if (lines.length < 2) throw new Error("CSV must include header and at least one row");

    const header = parseCsvLine(lines[0]).map((h) => h.toLowerCase());
    const required = [
        "txn_date",
        "value_date",
        "description",
        "reference_no",
        "amount",
        "currency_code",
        "balance_after",
    ];

    for (const key of required) {
        if (!header.includes(key)) {
        throw new Error(`Missing CSV column: ${key}`);
        }
    }

    const idx = Object.fromEntries(required.map((k) => [k, header.indexOf(k)]));

    const rows = [];
    for (let i = 1; i < lines.length; i += 1) {
        const cols = parseCsvLine(lines[i]);
        if (cols.every((c) => c === "")) continue;

        const raw = {
        txn_date: cols[idx.txn_date] ?? "",
        value_date: cols[idx.value_date] ?? "",
        description: cols[idx.description] ?? "",
        reference_no: cols[idx.reference_no] ?? "",
        amount: cols[idx.amount] ?? "",
        currency_code: cols[idx.currency_code] ?? "",
        balance_after: cols[idx.balance_after] ?? "",
        };

        const description = String(raw.description || "").trim();
        if (!description) throw new Error(`Row ${i + 1}: description is required`);

        const currency = String(raw.currency_code || "").trim().toUpperCase();
        if (!/^[A-Z]{3}$/.test(currency)) {
        throw new Error(`Row ${i + 1}: currency_code must be 3-letter code`);
        }

        rows.push({
        line_no: i, // data row no (1-based excluding header)
        txn_date: parseDate(raw.txn_date, `Row ${i + 1} txn_date`),
        value_date: parseDate(raw.value_date, `Row ${i + 1} value_date`),
        description,
        reference_no: String(raw.reference_no || "").trim() || null,
        amount: parseDecimal(raw.amount, `Row ${i + 1} amount`),
        currency_code: currency,
        balance_after:
            String(raw.balance_after || "").trim() === ""
            ? null
            : parseDecimal(raw.balance_after, `Row ${i + 1} balance_after`),
        raw_row_json: raw,
        });
    }

    if (rows.length === 0) throw new Error("CSV has no valid data rows");
    return rows;
    }

    export default {
    parseStatementCsv,
    };
    ```

    ---

    ## 3) Validators — `backend/src/routes/bank.statements.validators.js`

    ```js
    // backend/src/routes/bank.statements.validators.js

    function requirePositiveInt(value, fieldName) {
    const n = Number(value);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${fieldName} must be positive integer`);
    return n;
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    // v1 route accepts multipart file OR raw csv_text fallback
    function validateImportRequest(req) {
    const bank_account_id = requirePositiveInt(req.body?.bank_account_id, "bank_account_id");
    const import_source = "CSV";
    const original_filename =
        req.file?.originalname || normalizeString(req.body?.original_filename) || "statement.csv";

    const csvText =
        req.file?.buffer?.toString("utf8") ||
        (typeof req.body?.csv_text === "string" ? req.body.csv_text : null);

    if (!csvText) {
        throw new Error("CSV file or csv_text is required");
    }

    return {
        bank_account_id,
        import_source,
        original_filename,
        csv_text: csvText,
    };
    }

    function validateIdParam(params = {}) {
    return { id: requirePositiveInt(params.id, "id") };
    }

    function validateListLinesQuery(query = {}) {
    return {
        import_id: query.import_id ? requirePositiveInt(query.import_id, "import_id") : null,
        bank_account_id: query.bank_account_id ? requirePositiveInt(query.bank_account_id, "bank_account_id") : null,
        recon_status: query.recon_status ? String(query.recon_status).trim().toUpperCase() : null,
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 500) : 100,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    function validateListImportsQuery(query = {}) {
    return {
        bank_account_id: query.bank_account_id ? requirePositiveInt(query.bank_account_id, "bank_account_id") : null,
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 200) : 50,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    export default {
    validateImportRequest,
    validateIdParam,
    validateListLinesQuery,
    validateListImportsQuery,
    };
    ```

    ---

    ## 4) Service — `backend/src/services/bank.statements.service.js`

    ```js
    // backend/src/services/bank.statements.service.js

    import crypto from "crypto";
    import { parseStatementCsv } from "./bank.parsers.csv.js";
    function sha256(input) {
    return crypto.createHash("sha256").update(input).digest("hex");
    }

    function normalizeHashPart(v) {
    if (v === null || v === undefined) return "";
    return String(v).trim().toUpperCase();
    }

    function buildStatementLineHash(bankAccountId, row) {
    // Intentionally excludes import_id / line_no for cross-import dedupe
    const key = [
        bankAccountId,
        normalizeHashPart(row.txn_date),
        normalizeHashPart(row.value_date),
        normalizeHashPart(row.currency_code),
        normalizeHashPart(Number(row.amount).toFixed(2)),
        normalizeHashPart(row.balance_after == null ? "" : Number(row.balance_after).toFixed(2)),
        normalizeHashPart(row.reference_no),
        normalizeHashPart(row.description),
    ].join("|");
    return sha256(key);
    }

    async function assertBankAccountExists(db, bankAccountId) {
    const [rows] = await db.query(
        `SELECT id, code, name, currency_code, is_active FROM bank_accounts WHERE id = ? LIMIT 1`,
        [bankAccountId]
    );
    if (!rows[0]) {
        const err = new Error("Bank account not found");
        err.statusCode = 400;
        throw err;
    }
    return rows[0];
    }

    async function getImportById(db, id) {
    const [rows] = await db.query(
        `
        SELECT
        i.*,
        b.code AS bank_account_code,
        b.name AS bank_account_name
        FROM bank_statement_imports i
        JOIN bank_accounts b ON b.id = i.bank_account_id
        WHERE i.id = ?
        LIMIT 1
        `,
        [id]
    );
    return rows[0] || null;
    }

    async function listImports(db, { bank_account_id = null, limit = 50, offset = 0 } = {}) {
    const where = [];
    const params = [];

    if (bank_account_id) {
        where.push("i.bank_account_id = ?");
        params.push(bank_account_id);
    }

    let sql = `
        SELECT
        i.id, i.bank_account_id, i.import_source, i.original_filename, i.file_checksum,
        i.period_start, i.period_end, i.status,
        i.line_count_total, i.line_count_inserted, i.line_count_duplicates,
        i.imported_at, i.imported_by,
        b.code AS bank_account_code, b.name AS bank_account_name
        FROM bank_statement_imports i
        JOIN bank_accounts b ON b.id = i.bank_account_id
    `;

    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY i.id DESC LIMIT ? OFFSET ?`;
    params.push(limit, offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function listStatementLines(db, query) {
    const where = [];
    const params = [];

    if (query.import_id) {
        where.push("l.import_id = ?");
        params.push(query.import_id);
    }
    if (query.bank_account_id) {
        where.push("l.bank_account_id = ?");
        params.push(query.bank_account_id);
    }
    if (query.recon_status) {
        where.push("l.recon_status = ?");
        params.push(query.recon_status);
    }

    let sql = `
        SELECT
        l.id, l.import_id, l.bank_account_id, l.line_no, l.txn_date, l.value_date,
        l.description, l.reference_no, l.amount, l.currency_code, l.balance_after,
        l.recon_status, l.created_at,
        i.original_filename,
        b.code AS bank_account_code, b.name AS bank_account_name
        FROM bank_statement_lines l
        JOIN bank_statement_imports i ON i.id = l.import_id
        JOIN bank_accounts b ON b.id = l.bank_account_id
    `;

    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY l.txn_date DESC, l.id DESC LIMIT ? OFFSET ?`;
    params.push(query.limit, query.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function getStatementLineById(db, id) {
    const [rows] = await db.query(
        `
        SELECT
        l.*,
        i.original_filename,
        b.code AS bank_account_code, b.name AS bank_account_name
        FROM bank_statement_lines l
        JOIN bank_statement_imports i ON i.id = l.import_id
        JOIN bank_accounts b ON b.id = l.bank_account_id
        WHERE l.id = ?
        LIMIT 1
        `,
        [id]
    );
    return rows[0] || null;
    }

    async function importStatementCsv(db, payload, userId = null) {
    const bank = await assertBankAccountExists(db, payload.bank_account_id);

    const fileChecksum = sha256(payload.csv_text);
    const [dupImportRows] = await db.query(
        `SELECT id FROM bank_statement_imports WHERE bank_account_id = ? AND file_checksum = ? LIMIT 1`,
        [payload.bank_account_id, fileChecksum]
    );
    if (dupImportRows[0]) {
        const err = new Error("This statement file was already imported for the selected bank account");
        err.statusCode = 409;
        throw err;
    }

    const parsedRows = parseStatementCsv(payload.csv_text);

    // Optional safeguard: require row currency to match bank account currency in v1
    const badCurrency = parsedRows.find((r) => r.currency_code !== bank.currency_code);
    if (badCurrency) {
        const err = new Error(
        `Statement currency mismatch. Bank account currency=${bank.currency_code}, row currency=${badCurrency.currency_code}`
        );
        err.statusCode = 400;
        throw err;
    }

    const txn = await db.getConnection ? await db.getConnection() : null;
    const q = txn || db;

    try {
        if (txn) await txn.beginTransaction();

        const dates = parsedRows.map((r) => r.txn_date).sort();
        const period_start = dates[0] || null;
        const period_end = dates[dates.length - 1] || null;

        const [insImport] = await q.query(
        `
        INSERT INTO bank_statement_imports
        (bank_account_id, import_source, original_filename, file_checksum, period_start, period_end, status, raw_meta_json, imported_by)
        VALUES (?, ?, ?, ?, ?, ?, 'IMPORTED', ?, ?)
        `,
        [
            payload.bank_account_id,
            "CSV",
            payload.original_filename,
            fileChecksum,
            period_start,
            period_end,
            JSON.stringify({ parser: "csv-v1" }),
            userId,
        ]
        );

        const importId = insImport.insertId;
        let inserted = 0;
        let duplicates = 0;

        for (const row of parsedRows) {
        const lineHash = buildStatementLineHash(payload.bank_account_id, row);

        try {
            await q.query(
            `
            INSERT INTO bank_statement_lines
            (import_id, bank_account_id, line_no, txn_date, value_date, description, reference_no,
            amount, currency_code, balance_after, line_hash, recon_status, raw_row_json)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'UNMATCHED', ?)
            `,
            [
                importId,
                payload.bank_account_id,
                row.line_no,
                row.txn_date,
                row.value_date,
                row.description,
                row.reference_no,
                row.amount,
                row.currency_code,
                row.balance_after,
                lineHash,
                JSON.stringify(row.raw_row_json || null),
            ]
            );
            inserted += 1;
        } catch (e) {
            if (e && e.code === "ER_DUP_ENTRY") {
            duplicates += 1;
            continue;
            }
            throw e;
        }
        }

        await q.query(
        `
        UPDATE bank_statement_imports
        SET line_count_total = ?, line_count_inserted = ?, line_count_duplicates = ?,
            raw_meta_json = JSON_SET(COALESCE(raw_meta_json, JSON_OBJECT()),
                '$.inserted', ?, '$.duplicates', ?, '$.bank_account_code', ?)
        WHERE id = ?
        `,
        [parsedRows.length, inserted, duplicates, inserted, duplicates, bank.code, importId]
        );

        if (txn) await txn.commit();

        return getImportById(db, importId);
    } catch (err) {
        if (txn) {
        try {
            await txn.rollback();
        } catch (_) {}
        }
        throw err;
    } finally {
        if (txn) txn.release();
    }
    }

    export default {
    importStatementCsv,
    listImports,
    getImportById,
    listStatementLines,
    getStatementLineById,
    };
    ```

    ---

    ## 5) Routes — `backend/src/routes/bank.statements.js`

    > Uses `multer` for multipart upload. If you already have an upload helper, swap it in.

    ```js
    // backend/src/routes/bank.statements.js

    import express from "express";
    import multer from "multer";
    import { validateImportRequest,
    validateIdParam,
    validateListLinesQuery,
    validateListImportsQuery, } from "./bank.statements.validators.js";
    import service from "../services/bank.statements.service.js";
    // Replace with your project helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();
    const upload = multer({ storage: multer.memoryStorage() });

    // POST /api/v1/bank/statements/import
    router.post(
    "/statements/import",
    requireAuth,
    requirePermission("bank.statements.import"),
    upload.single("file"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const payload = validateImportRequest(req);
        const userId = req.user?.id ?? null;
        const result = await service.importStatementCsv(db, payload, userId);
        res.status(201).json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/bank/statements/imports
    router.get(
    "/statements/imports",
    requireAuth,
    requirePermission("bank.statements.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateListImportsQuery(req.query);
        const items = await service.listImports(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/bank/statements/imports/:id
    router.get(
    "/statements/imports/:id",
    requireAuth,
    requirePermission("bank.statements.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const row = await service.getImportById(db, id);
        if (!row) return res.status(404).json({ error: "Not found" });
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/bank/statements/lines
    router.get(
    "/statements/lines",
    requireAuth,
    requirePermission("bank.statements.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateListLinesQuery(req.query);
        const items = await service.listStatementLines(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/bank/statements/lines/:id
    router.get(
    "/statements/lines/:id",
    requireAuth,
    requirePermission("bank.statements.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const row = await service.getStatementLineById(db, id);
        if (!row) return res.status(404).json({ error: "Not found" });
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 6) Mount route — `backend/src/index.js`

    ```js
    // backend/src/index.js
    import bankStatementsRoutes from "./routes/bank.statements.js";
    // ...
    app.use("/api/v1/bank", bankStatementsRoutes);
    ```

    ---

    ## 7) Migration registry — `backend/src/migrations/index.js`

    ```js
    // backend/src/migrations/index.js
    import m032_bank_statement_imports from "./m032_bank_statement_imports.js";
    export default [
    // ...
    m032_bank_statement_imports,
    ];
    ```

    ---

    ## 8) Seed permissions — `backend/src/seedCore.js`

    ```js
    // backend/src/seedCore.js
    const BANK_STATEMENT_PERMISSIONS = [
    "bank.statements.import",
    "bank.statements.read",
    ];

    // merge into your permissions seed list
    ```

    ---

    ## 9) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Register these paths:

    * `POST /api/v1/bank/statements/import`
    * `GET /api/v1/bank/statements/imports`
    * `GET /api/v1/bank/statements/imports/{id}`
    * `GET /api/v1/bank/statements/lines`
    * `GET /api/v1/bank/statements/lines/{id}`

    If your generator is route-driven, just ensure `bank.statements.js` is loaded.

    ---

    ## 10) Backend smoke test — `backend/scripts/test-bank-prb02-statement-import.js`

    > You can make this a real `supertest` script. Here’s the exact behavior to test.

    ```js
    // backend/scripts/test-bank-prb02-statement-import.js

    async function main() {
    // Pseudocode:
    // 1) Ensure a bank account exists (from PR-B01)
    // 2) Build a CSV string with 3 rows (same currency as bank account)
    // 3) POST /api/v1/bank/statements/import with bank_account_id + csv_text (or multipart file)
    // 4) Assert 201 and counts (total=3, inserted=3, duplicates=0)
    // 5) GET /api/v1/bank/statements/imports and assert import row exists
    // 6) GET /api/v1/bank/statements/lines?import_id=:id and assert 3 lines, recon_status=UNMATCHED
    // 7) Re-import same CSV for same bank account -> expect 409 (checksum idempotency)
    // 8) Import different CSV containing one duplicate line + one new line -> inserted/new counts reflect dedupe
    console.log("PR-B02 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    ---

    ## 11) `backend/package.json` updates

    Add smoke test + dependencies (if you don’t already have them):

    ```json
    {
    "scripts": {
        "test:bank:prb02": "node backend/scripts/test-bank-prb02-statement-import.js"
    },
    "dependencies": {
        "multer": "^1.4.5-lts.1"
    }
    }
    ```

    (If your `package.json` is already in `/backend`, use `node scripts/test-bank-prb02-statement-import.js`)

    ---

    # Frontend skeletons

    ## 12) API client — `frontend/src/api/bankStatements.js`

    ```js
    // frontend/src/api/bankStatements.js

    import { apiFetch } from "./client.js"; // adapt to your actual helper

    export function importBankStatementCsv({ bank_account_id, file, csv_text }) {
    // Supports multipart file upload or raw csv_text fallback
    if (file) {
        const form = new FormData();
        form.append("bank_account_id", String(bank_account_id));
        form.append("file", file);

        return apiFetch(`/api/v1/bank/statements/import`, {
        method: "POST",
        body: form,
        // important: do NOT set Content-Type manually for FormData
        });
    }

    return apiFetch(`/api/v1/bank/statements/import`, {
        method: "POST",
        body: JSON.stringify({ bank_account_id, csv_text, original_filename: "manual.csv" }),
    });
    }

    export function listBankStatementImports(params = {}) {
    const q = new URLSearchParams();
    if (params.bank_account_id) q.set("bank_account_id", String(params.bank_account_id));
    const qs = q.toString();
    return apiFetch(`/api/v1/bank/statements/imports${qs ? `?${qs}` : ""}`);
    }

    export function getBankStatementImport(id) {
    return apiFetch(`/api/v1/bank/statements/imports/${id}`);
    }

    export function listBankStatementLines(params = {}) {
    const q = new URLSearchParams();
    if (params.import_id) q.set("import_id", String(params.import_id));
    if (params.bank_account_id) q.set("bank_account_id", String(params.bank_account_id));
    if (params.recon_status) q.set("recon_status", String(params.recon_status));
    const qs = q.toString();
    return apiFetch(`/api/v1/bank/statements/lines${qs ? `?${qs}` : ""}`);
    }

    export function getBankStatementLine(id) {
    return apiFetch(`/api/v1/bank/statements/lines/${id}`);
    }
    ```

    ---

    ## 13) Import page — `frontend/src/pages/bank/BankStatementImportPage.jsx`

    > Simple v1 UI: choose bank account ID + file upload.

    ```jsx
    // frontend/src/pages/bank/BankStatementImportPage.jsx

    import { useState } from "react";
    import { importBankStatementCsv } from "../../api/bankStatements.js";

    export default function BankStatementImportPage() {
    const [bankAccountId, setBankAccountId] = useState("");
    const [file, setFile] = useState(null);
    const [result, setResult] = useState(null);
    const [err, setErr] = useState("");
    const [submitting, setSubmitting] = useState(false);

    async function onSubmit(e) {
        e.preventDefault();
        setErr("");
        setResult(null);

        try {
        if (!bankAccountId) throw new Error("Bank account ID is required");
        if (!file) throw new Error("CSV file is required");

        setSubmitting(true);
        const res = await importBankStatementCsv({
            bank_account_id: Number(bankAccountId),
            file,
        });
        setResult(res);
        } catch (e) {
        setErr(e.message || "Import failed");
        } finally {
        setSubmitting(false);
        }
    }

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <h1 className="text-lg font-semibold mb-3">Bank Statement Import</h1>

            {err ? <div className="mb-3 text-sm text-red-600">{err}</div> : null}

            <form className="space-y-3" onSubmit={onSubmit}>
            <input
                className="border rounded px-2 py-1 w-full md:w-64"
                placeholder="Bank Account ID"
                value={bankAccountId}
                onChange={(e) => setBankAccountId(e.target.value)}
            />

            <input
                className="block"
                type="file"
                accept=".csv,text/csv"
                onChange={(e) => setFile(e.target.files?.[0] || null)}
            />

            <button
                className="px-3 py-1 rounded bg-black text-white disabled:opacity-50"
                type="submit"
                disabled={submitting}
            >
                {submitting ? "Importing..." : "Import CSV"}
            </button>
            </form>
        </div>

        {result ? (
            <div className="rounded border bg-white p-4 text-sm">
            <div className="font-medium mb-2">Import Result</div>
            <div>ID: {result.id}</div>
            <div>File: {result.original_filename}</div>
            <div>Status: {result.status}</div>
            <div>Total Rows: {result.line_count_total}</div>
            <div>Inserted: {result.line_count_inserted}</div>
            <div>Duplicates: {result.line_count_duplicates}</div>
            </div>
        ) : null}
        </div>
    );
    }
    ```

    ---

    ## 14) Queue page — `frontend/src/pages/bank/BankStatementQueuePage.jsx`

    ```jsx
    // frontend/src/pages/bank/BankStatementQueuePage.jsx

    import { useEffect, useState } from "react";
    import { listBankStatementLines } from "../../api/bankStatements.js";

    export default function BankStatementQueuePage() {
    const [items, setItems] = useState([]);
    const [err, setErr] = useState("");
    const [loading, setLoading] = useState(false);
    const [bankAccountId, setBankAccountId] = useState("");

    async function load() {
        setLoading(true);
        setErr("");
        try {
        const res = await listBankStatementLines({
            bank_account_id: bankAccountId ? Number(bankAccountId) : undefined,
            recon_status: "UNMATCHED",
        });
        setItems(res.items || []);
        } catch (e) {
        setErr(e.message || "Failed to load queue");
        } finally {
        setLoading(false);
        }
    }

    useEffect(() => {
        load();
    }, []);

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <h1 className="text-lg font-semibold mb-3">Statement Queue</h1>

            <div className="flex items-center gap-2 mb-3">
            <input
                className="border rounded px-2 py-1 w-56"
                placeholder="Filter Bank Account ID"
                value={bankAccountId}
                onChange={(e) => setBankAccountId(e.target.value)}
            />
            <button className="px-3 py-1 rounded border" onClick={load} type="button">
                Refresh
            </button>
            </div>

            {err ? <div className="mb-3 text-sm text-red-600">{err}</div> : null}

            {loading ? (
            <div>Loading...</div>
            ) : (
            <div className="overflow-auto">
                <table className="min-w-full text-sm border-collapse">
                <thead>
                    <tr className="border-b">
                    <th className="text-left p-2">Date</th>
                    <th className="text-left p-2">Bank</th>
                    <th className="text-left p-2">Description</th>
                    <th className="text-left p-2">Ref</th>
                    <th className="text-left p-2">Amount</th>
                    <th className="text-left p-2">Currency</th>
                    <th className="text-left p-2">Status</th>
                    </tr>
                </thead>
                <tbody>
                    {items.map((row) => (
                    <tr key={row.id} className="border-b">
                        <td className="p-2">{row.txn_date}</td>
                        <td className="p-2">{row.bank_account_code}</td>
                        <td className="p-2">{row.description}</td>
                        <td className="p-2">{row.reference_no || "-"}</td>
                        <td className="p-2">{row.amount}</td>
                        <td className="p-2">{row.currency_code}</td>
                        <td className="p-2">{row.recon_status}</td>
                    </tr>
                    ))}
                    {items.length === 0 && (
                    <tr>
                        <td className="p-2" colSpan={7}>
                        No statement lines in queue.
                        </td>
                    </tr>
                    )}
                </tbody>
                </table>
            </div>
            )}
        </div>
        </div>
    );
    }
    ```

    ---

    ## 15) App routes — `frontend/src/App.jsx`

    ```jsx
    // frontend/src/App.jsx
    import BankStatementImportPage from "./pages/bank/BankStatementImportPage.js";
    import BankStatementQueuePage from "./pages/bank/BankStatementQueuePage.js";

    // ...
    <Route
    path="/app/banka-ekstre-ice-aktar"
    element={
        <RequirePermission anyOf={["bank.statements.import"]}>
        <BankStatementImportPage />
        </RequirePermission>
    }
    />

    <Route
    path="/app/banka-ekstre-kuyrugu"
    element={
        <RequirePermission anyOf={["bank.statements.read"]}>
        <BankStatementQueuePage />
        </RequirePermission>
    }
    />
    ```

    ---

    ## 16) Sidebar — `frontend/src/layouts/sidebarConfig.js`

    Add to your existing Bank section:

    ```js
    // frontend/src/layouts/sidebarConfig.js
    {
    key: "bank",
    label: "Bank",
    children: [
        // existing: Bank Accounts
        {
        key: "bank-statements-import",
        label: "Statement Import",
        to: "/app/banka-ekstre-ice-aktar",
        requiredPermissions: ["bank.statements.import"],
        },
        {
        key: "bank-statements-queue",
        label: "Statement Queue",
        to: "/app/banka-ekstre-kuyrugu",
        requiredPermissions: ["bank.statements.read"],
        },
    ],
    }
    ```

    ---

    ## 17) i18n — `frontend/src/i18n/messages.js`

    ```js
    // frontend/src/i18n/messages.js
    export default {
    // ...
    "sidebar.bankStatementImport": "Statement Import",
    "sidebar.bankStatementQueue": "Statement Queue",
    };
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ CSV import creates `bank_statement_imports` header + `bank_statement_lines`
    * ✅ Re-importing same file for same bank account is blocked by checksum (idempotent)
    * ✅ Duplicate statement rows are safely deduped by `line_hash` and counted
    * ✅ Imported rows default to `recon_status = UNMATCHED`
    * ✅ List endpoints return imports + lines for queue UI
    * ✅ Route + UI permission checks use `bank.statements.import/read`
    * ✅ OpenAPI is updated
    * ✅ Smoke test script exists and runs

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:bank:prb02`

    Should verify at least:

    1. **Import success**

    * POST valid CSV → `201`
    * response includes `id`, `status=IMPORTED`
    * `line_count_total`, `line_count_inserted`, `line_count_duplicates`

    2. **Imports list**

    * GET `/api/v1/bank/statements/imports` includes created import row

    3. **Lines list**

    * GET `/api/v1/bank/statements/lines?import_id=:id` returns rows
    * all rows have `recon_status=UNMATCHED`

    4. **Checksum idempotency**

    * Re-import same file for same bank account → `409`

    5. **Line-level dedupe**

    * Import new file with one repeated row + one new row
    * import succeeds
    * duplicate count increments
    * only new line inserted

    6. **Permission enforcement**

    * import/read routes require proper permissions (`403` if missing)

    ---

    # CSV format for manual testing (v1)

    Use this exact header:

    ```csv
    txn_date,value_date,description,reference_no,amount,currency_code,balance_after
    2026-02-01,2026-02-01,Payroll Batch Jan,PAY-2026-01,-12500.00,USD,87500.00
    2026-02-02,2026-02-02,Customer Receipt,RCPT-1001,4200.00,USD,91700.00
    2026-02-03,2026-02-03,Bank Fee,FEE-02,-15.50,USD,91684.50
    ```

    ---

    # Tiny implementation notes (important)

    * **Keep `amount` signed** in v1 (simpler than separate debit/credit columns).
    * **Line hash excludes import_id/line_no** on purpose, so duplicates across files are caught.
    * **Don’t do reconciliation logic yet** in this PR — only queue population.
    * In PR-B03, your matcher will operate on `bank_statement_lines` where `recon_status='UNMATCHED'`.

Perfect — here’s **PR-B03 in the same concrete format**.

# PR-B03: Bank Reconciliation Core (Manual + Suggested Match)

    ## Goal

    Turn imported statement lines into a **real reconciliation queue**:

    * ✅ Queue of `UNMATCHED / PARTIAL / IGNORED`
    * ✅ Suggestions (v1: journal-based; payment batch support ready for PR-B04)
    * ✅ Manual match / unmatch
    * ✅ Ignore line (exception handling)
    * ✅ Full audit trail for reconciliation actions

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m033_bank_reconciliation.js`
    * `backend/src/routes/bank.reconciliation.js`
    * `backend/src/routes/bank.reconciliation.validators.js`
    * `backend/src/services/bank.reconciliation.service.js`
    * `backend/scripts/test-bank-prb03-reconciliation.js`

    ### Frontend

    * `frontend/src/api/bankReconciliation.js`
    * `frontend/src/pages/bank/BankReconciliationPage.jsx`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js` (permissions)
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/App.jsx`
    * `frontend/src/layouts/sidebarConfig.js`
    * `frontend/src/i18n/messages.js`

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m033_bank_reconciliation.js`

    ```js
    // backend/src/migrations/m033_bank_reconciliation.js

    export default {
    key: "m033_bank_reconciliation",
    description: "m033_bank_reconciliation",
    async up(connection) {
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS bank_reconciliation_matches (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            statement_line_id BIGINT UNSIGNED NOT NULL,
            match_type VARCHAR(30) NOT NULL DEFAULT 'MANUAL',
            matched_entity_type VARCHAR(30) NOT NULL, -- JOURNAL, PAYMENT_BATCH, CASH_TXN, MANUAL_ADJUSTMENT
            matched_entity_id BIGINT UNSIGNED NOT NULL,
            matched_amount DECIMAL(18,2) NOT NULL,
            status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE', -- ACTIVE, REVERSED
            notes VARCHAR(500) NULL,
            matched_by BIGINT UNSIGNED NULL,
            matched_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            reversed_by BIGINT UNSIGNED NULL,
            reversed_at DATETIME NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            KEY idx_bank_recon_matches_line (statement_line_id),
            KEY idx_bank_recon_matches_entity (matched_entity_type, matched_entity_id),
            KEY idx_bank_recon_matches_status (status),
            CONSTRAINT fk_bank_recon_matches_line
            FOREIGN KEY (statement_line_id) REFERENCES bank_statement_lines(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS bank_reconciliation_audit (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            statement_line_id BIGINT UNSIGNED NOT NULL,
            action VARCHAR(30) NOT NULL, -- SUGGESTED, MATCHED, UNMATCHED, IGNORE, UNIGNORE, AUTO_STATUS
            payload_json JSON NULL,
            acted_by BIGINT UNSIGNED NULL,
            acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            KEY idx_bank_recon_audit_line (statement_line_id),
            KEY idx_bank_recon_audit_action (action),
            KEY idx_bank_recon_audit_acted_at (acted_at),
            CONSTRAINT fk_bank_recon_audit_line
            FOREIGN KEY (statement_line_id) REFERENCES bank_statement_lines(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);
    },

    async down(connection) {
        await connection.execute(`DROP TABLE IF EXISTS bank_reconciliation_audit;`);
        await connection.execute(`DROP TABLE IF EXISTS bank_reconciliation_matches;`);
    },
    };
    ```

    ---

    ## 2) Validators — `backend/src/routes/bank.reconciliation.validators.js`

    ```js
    // backend/src/routes/bank.reconciliation.validators.js

    function requirePositiveInt(value, fieldName) {
    const n = Number(value);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${fieldName} must be positive integer`);
    return n;
    }

    function requireAmount(value, fieldName) {
    const n = Number(value);
    if (!Number.isFinite(n) || n <= 0) throw new Error(`${fieldName} must be positive number`);
    return Number(n.toFixed(2));
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function validateLineIdParam(params = {}) {
    return { lineId: requirePositiveInt(params.lineId, "lineId") };
    }

    function validateQueueQuery(query = {}) {
    return {
        bank_account_id: query.bank_account_id ? requirePositiveInt(query.bank_account_id, "bank_account_id") : null,
        recon_status: query.recon_status ? String(query.recon_status).trim().toUpperCase() : null,
        q: normalizeString(query.q),
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 500) : 100,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    function validateAuditQuery(query = {}) {
    return {
        statement_line_id: query.statement_line_id ? requirePositiveInt(query.statement_line_id, "statement_line_id") : null,
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 500) : 100,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    function validateMatchBody(body = {}) {
    const matched_entity_type = String(body.matched_entity_type || "").trim().toUpperCase();
    const allowedEntityTypes = ["JOURNAL", "PAYMENT_BATCH", "CASH_TXN", "MANUAL_ADJUSTMENT"];
    if (!allowedEntityTypes.includes(matched_entity_type)) {
        throw new Error(`matched_entity_type must be one of ${allowedEntityTypes.join(", ")}`);
    }

    return {
        match_type: String(body.match_type || "MANUAL").trim().toUpperCase(),
        matched_entity_type,
        matched_entity_id: requirePositiveInt(body.matched_entity_id, "matched_entity_id"),
        matched_amount: requireAmount(body.matched_amount, "matched_amount"),
        notes: normalizeString(body.notes),
    };
    }

    function validateUnmatchBody(body = {}) {
    return {
        match_id: body.match_id ? requirePositiveInt(body.match_id, "match_id") : null,
        notes: normalizeString(body.notes),
    };
    }

    function validateIgnoreBody(body = {}) {
    return {
        reason: normalizeString(body.reason),
    };
    }

    export default {
    validateLineIdParam,
    validateQueueQuery,
    validateAuditQuery,
    validateMatchBody,
    validateUnmatchBody,
    validateIgnoreBody,
    };
    ```

    ---

    ## 3) Service — `backend/src/services/bank.reconciliation.service.js`

    > **Important:** suggestions use a **journal query skeleton**.
    > Replace table names/columns with your actual GL schema if different (e.g. `journal_entries`, `journal_lines`, `posted_at`, `status`).

    ```js
    // backend/src/services/bank.reconciliation.service.js

    async function getStatementLineCore(db, lineId) {
    const [rows] = await db.query(
        `
        SELECT
        l.id, l.import_id, l.bank_account_id, l.txn_date, l.value_date, l.description, l.reference_no,
        l.amount, l.currency_code, l.balance_after, l.recon_status,
        b.gl_account_id, b.code AS bank_account_code, b.name AS bank_account_name
        FROM bank_statement_lines l
        JOIN bank_accounts b ON b.id = l.bank_account_id
        WHERE l.id = ?
        LIMIT 1
        `,
        [lineId]
    );
    return rows[0] || null;
    }

    async function getActiveMatchesForLine(db, lineId) {
    const [rows] = await db.query(
        `
        SELECT id, matched_entity_type, matched_entity_id, matched_amount, status, notes, matched_at
        FROM bank_reconciliation_matches
        WHERE statement_line_id = ? AND status = 'ACTIVE'
        ORDER BY id ASC
        `,
        [lineId]
    );
    return rows;
    }

    async function writeAudit(db, { statementLineId, action, payload = null, userId = null }) {
    await db.query(
        `
        INSERT INTO bank_reconciliation_audit
        (statement_line_id, action, payload_json, acted_by)
        VALUES (?, ?, ?, ?)
        `,
        [statementLineId, action, payload ? JSON.stringify(payload) : null, userId]
    );
    }

    async function recomputeLineReconStatus(db, lineId, userId = null) {
    const line = await getStatementLineCore(db, lineId);
    if (!line) {
        const err = new Error("Statement line not found");
        err.statusCode = 404;
        throw err;
    }

    if (line.recon_status === "IGNORED") {
        return line; // keep ignored until explicitly unignored (not in v1)
    }

    const [aggRows] = await db.query(
        `
        SELECT COALESCE(SUM(matched_amount), 0) AS matched_total
        FROM bank_reconciliation_matches
        WHERE statement_line_id = ? AND status = 'ACTIVE'
        `,
        [lineId]
    );

    const matchedTotal = Number(aggRows[0]?.matched_total || 0);
    const target = Math.abs(Number(line.amount));

    let nextStatus = "UNMATCHED";
    if (matchedTotal > 0 && Math.abs(matchedTotal - target) < 0.005) nextStatus = "MATCHED";
    else if (matchedTotal > 0) nextStatus = "PARTIAL";

    if (nextStatus !== line.recon_status) {
        await db.query(`UPDATE bank_statement_lines SET recon_status = ? WHERE id = ?`, [nextStatus, lineId]);
        await writeAudit(db, {
        statementLineId: lineId,
        action: "AUTO_STATUS",
        payload: { from: line.recon_status, to: nextStatus, matched_total: matchedTotal, target_amount: target },
        userId,
        });
    }

    return getStatementLineCore(db, lineId);
    }

    async function listReconciliationQueue(db, query) {
    const where = [];
    const params = [];

    if (query.bank_account_id) {
        where.push("l.bank_account_id = ?");
        params.push(query.bank_account_id);
    }
    if (query.recon_status) {
        where.push("l.recon_status = ?");
        params.push(query.recon_status);
    } else {
        // queue default: show actionable + exceptions
        where.push(`l.recon_status IN ('UNMATCHED', 'PARTIAL', 'IGNORED')`);
    }
    if (query.q) {
        where.push(`(l.description LIKE ? OR l.reference_no LIKE ?)`);
        params.push(`%${query.q}%`, `%${query.q}%`);
    }

    let sql = `
        SELECT
        l.id, l.bank_account_id, l.import_id, l.txn_date, l.value_date,
        l.description, l.reference_no, l.amount, l.currency_code, l.balance_after,
        l.recon_status, l.created_at,
        b.code AS bank_account_code, b.name AS bank_account_name,
        i.original_filename,
        COALESCE(m.active_match_count, 0) AS active_match_count,
        COALESCE(m.active_matched_total, 0) AS active_matched_total
        FROM bank_statement_lines l
        JOIN bank_accounts b ON b.id = l.bank_account_id
        JOIN bank_statement_imports i ON i.id = l.import_id
        LEFT JOIN (
        SELECT
            statement_line_id,
            COUNT(*) AS active_match_count,
            COALESCE(SUM(matched_amount), 0) AS active_matched_total
        FROM bank_reconciliation_matches
        WHERE status = 'ACTIVE'
        GROUP BY statement_line_id
        ) m ON m.statement_line_id = l.id
    `;

    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY l.txn_date DESC, l.id DESC LIMIT ? OFFSET ?`;
    params.push(query.limit, query.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function getSuggestionsForLine(db, lineId, userId = null) {
    const line = await getStatementLineCore(db, lineId);
    if (!line) {
        const err = new Error("Statement line not found");
        err.statusCode = 404;
        throw err;
    }

    // v1 journal suggestion skeleton:
    // - same amount on bank GL line
    // - date window +/- 7 days
    // - posted status
    // - optional ref/description text scoring
    //
    // Replace `journal_entries` / `journal_entry_lines` names if your schema differs.
    const [rows] = await db.query(
        `
        SELECT
        je.id AS journal_id,
        je.journal_no,
        je.posted_at,
        je.memo,
        ABS(jl.amount) AS bank_line_amount,
        CASE
            WHEN ABS(ABS(jl.amount) - ABS(?)) < 0.005 THEN 100
            ELSE 60
        END
        + CASE WHEN DATE(je.posted_at) = ? THEN 20 ELSE 0 END
        + CASE
            WHEN ? IS NOT NULL AND ? <> '' AND (
                je.memo LIKE CONCAT('%', ?, '%')
                OR je.journal_no LIKE CONCAT('%', ?, '%')
            ) THEN 10
            ELSE 0
            END AS score
        FROM journal_entries je
        JOIN journal_entry_lines jl ON jl.journal_entry_id = je.id
        WHERE je.status = 'POSTED'
        AND jl.account_id = ?
        AND ABS(ABS(jl.amount) - ABS(?)) <= 0.01
        AND DATE(je.posted_at) BETWEEN DATE_SUB(?, INTERVAL 7 DAY) AND DATE_ADD(?, INTERVAL 7 DAY)
        ORDER BY score DESC, je.posted_at DESC
        LIMIT 20
        `,
        [
        line.amount,
        line.txn_date,
        line.reference_no,
        line.reference_no,
        line.reference_no,
        line.reference_no,
        line.gl_account_id,
        line.amount,
        line.txn_date,
        line.txn_date,
        ]
    );

    const suggestions = rows.map((r) => ({
        suggestion_type: "JOURNAL",
        matched_entity_type: "JOURNAL",
        matched_entity_id: r.journal_id,
        display_ref: r.journal_no,
        display_text: r.memo || r.journal_no,
        suggested_amount: Math.abs(Number(line.amount)),
        score: Number(r.score || 0),
        posted_at: r.posted_at,
    }));

    await writeAudit(db, {
        statementLineId: lineId,
        action: "SUGGESTED",
        payload: { suggestion_count: suggestions.length, engine: "journal-v1" },
        userId,
    });

    return {
        line,
        suggestions,
    };
    }

    async function assertMatchTargetExists(db, matchBody) {
    // v1: JOURNAL supported concretely, others are reserved for next PRs.
    if (matchBody.matched_entity_type === "JOURNAL") {
        const [rows] = await db.query(
        `SELECT id, status FROM journal_entries WHERE id = ? LIMIT 1`,
        [matchBody.matched_entity_id]
        );
        if (!rows[0]) {
        const err = new Error("Journal not found");
        err.statusCode = 400;
        throw err;
        }
        if (rows[0].status !== "POSTED") {
        const err = new Error("Only POSTED journals can be reconciled");
        err.statusCode = 400;
        throw err;
        }
        return;
    }

    // Keep explicit for now so users don't think it silently works before PR-B04.
    if (matchBody.matched_entity_type === "PAYMENT_BATCH") {
        const err = new Error("PAYMENT_BATCH reconciliation is enabled in PR-B04");
        err.statusCode = 400;
        throw err;
    }

    // CASH_TXN / MANUAL_ADJUSTMENT can be enabled later similarly
    const err = new Error(`${matchBody.matched_entity_type} matching is not enabled yet`);
    err.statusCode = 400;
    throw err;
    }

    async function matchStatementLine(db, lineId, matchBody, userId = null) {
    const line = await getStatementLineCore(db, lineId);
    if (!line) {
        const err = new Error("Statement line not found");
        err.statusCode = 404;
        throw err;
    }
    if (line.recon_status === "IGNORED") {
        const err = new Error("Ignored line cannot be matched (unignore flow not implemented yet)");
        err.statusCode = 400;
        throw err;
    }

    const target = Math.abs(Number(line.amount));
    const [aggRows] = await db.query(
        `
        SELECT COALESCE(SUM(matched_amount), 0) AS matched_total
        FROM bank_reconciliation_matches
        WHERE statement_line_id = ? AND status = 'ACTIVE'
        `,
        [lineId]
    );
    const existingMatched = Number(aggRows[0]?.matched_total || 0);
    if (existingMatched + Number(matchBody.matched_amount) - target > 0.005) {
        const err = new Error("Matched amount exceeds statement line amount");
        err.statusCode = 400;
        throw err;
    }

    await assertMatchTargetExists(db, matchBody);

    const [ins] = await db.query(
        `
        INSERT INTO bank_reconciliation_matches
        (statement_line_id, match_type, matched_entity_type, matched_entity_id, matched_amount, status, notes, matched_by)
        VALUES (?, ?, ?, ?, ?, 'ACTIVE', ?, ?)
        `,
        [
        lineId,
        matchBody.match_type || "MANUAL",
        matchBody.matched_entity_type,
        matchBody.matched_entity_id,
        matchBody.matched_amount,
        matchBody.notes || null,
        userId,
        ]
    );

    await writeAudit(db, {
        statementLineId: lineId,
        action: "MATCHED",
        payload: {
        match_id: ins.insertId,
        matched_entity_type: matchBody.matched_entity_type,
        matched_entity_id: matchBody.matched_entity_id,
        matched_amount: matchBody.matched_amount,
        },
        userId,
    });

    const updatedLine = await recomputeLineReconStatus(db, lineId, userId);
    const activeMatches = await getActiveMatchesForLine(db, lineId);

    return { line: updatedLine, matches: activeMatches };
    }

    async function unmatchStatementLine(db, lineId, body, userId = null) {
    const line = await getStatementLineCore(db, lineId);
    if (!line) {
        const err = new Error("Statement line not found");
        err.statusCode = 404;
        throw err;
    }

    let sql = `
        UPDATE bank_reconciliation_matches
        SET status = 'REVERSED', reversed_by = ?, reversed_at = NOW()
        WHERE statement_line_id = ? AND status = 'ACTIVE'
    `;
    const params = [userId, lineId];

    if (body.match_id) {
        sql += ` AND id = ?`;
        params.push(body.match_id);
    }

    const [result] = await db.query(sql, params);
    if (!result.affectedRows) {
        const err = new Error("No active match found to unmatch");
        err.statusCode = 400;
        throw err;
    }

    await writeAudit(db, {
        statementLineId: lineId,
        action: "UNMATCHED",
        payload: { match_id: body.match_id || null, reversed_count: result.affectedRows, notes: body.notes || null },
        userId,
    });

    // If line was ignored before, keep ignored; otherwise recompute
    if (line.recon_status !== "IGNORED") {
        await recomputeLineReconStatus(db, lineId, userId);
    }

    return {
        line: await getStatementLineCore(db, lineId),
        matches: await getActiveMatchesForLine(db, lineId),
    };
    }

    async function ignoreStatementLine(db, lineId, body, userId = null) {
    const line = await getStatementLineCore(db, lineId);
    if (!line) {
        const err = new Error("Statement line not found");
        err.statusCode = 404;
        throw err;
    }

    const [activeRows] = await db.query(
        `SELECT COUNT(*) AS c FROM bank_reconciliation_matches WHERE statement_line_id = ? AND status = 'ACTIVE'`,
        [lineId]
    );
    if (Number(activeRows[0]?.c || 0) > 0) {
        const err = new Error("Cannot ignore a line with active matches. Unmatch first.");
        err.statusCode = 400;
        throw err;
    }

    if (line.recon_status !== "IGNORED") {
        await db.query(`UPDATE bank_statement_lines SET recon_status = 'IGNORED' WHERE id = ?`, [lineId]);
    }

    await writeAudit(db, {
        statementLineId: lineId,
        action: "IGNORE",
        payload: { reason: body.reason || null },
        userId,
    });

    return getStatementLineCore(db, lineId);
    }

    async function listReconciliationAudit(db, query) {
    const where = [];
    const params = [];

    if (query.statement_line_id) {
        where.push(`a.statement_line_id = ?`);
        params.push(query.statement_line_id);
    }

    let sql = `
        SELECT
        a.id, a.statement_line_id, a.action, a.payload_json, a.acted_by, a.acted_at,
        l.txn_date, l.description, l.amount, l.currency_code,
        b.code AS bank_account_code
        FROM bank_reconciliation_audit a
        JOIN bank_statement_lines l ON l.id = a.statement_line_id
        JOIN bank_accounts b ON b.id = l.bank_account_id
    `;

    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY a.id DESC LIMIT ? OFFSET ?`;
    params.push(query.limit, query.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    export default {
    listReconciliationQueue,
    getSuggestionsForLine,
    matchStatementLine,
    unmatchStatementLine,
    ignoreStatementLine,
    listReconciliationAudit,
    };
    ```

    ---

    ## 4) Routes — `backend/src/routes/bank.reconciliation.js`

    ```js
    // backend/src/routes/bank.reconciliation.js

    import express from "express";
    import { validateLineIdParam,
    validateQueueQuery,
    validateAuditQuery,
    validateMatchBody,
    validateUnmatchBody,
    validateIgnoreBody, } from "./bank.reconciliation.validators.js";
    import service from "../services/bank.reconciliation.service.js";
    // Replace with your actual helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();

    // GET /api/v1/bank/reconciliation/queue
    router.get(
    "/reconciliation/queue",
    requireAuth,
    requirePermission("bank.reconcile.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateQueueQuery(req.query);
        const items = await service.listReconciliationQueue(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/bank/reconciliation/queue/:lineId/suggestions
    router.get(
    "/reconciliation/queue/:lineId/suggestions",
    requireAuth,
    requirePermission("bank.reconcile.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { lineId } = validateLineIdParam(req.params);
        const userId = req.user?.id ?? null;
        const result = await service.getSuggestionsForLine(db, lineId, userId);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/bank/reconciliation/queue/:lineId/match
    router.post(
    "/reconciliation/queue/:lineId/match",
    requireAuth,
    requirePermission("bank.reconcile.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { lineId } = validateLineIdParam(req.params);
        const body = validateMatchBody(req.body);
        const userId = req.user?.id ?? null;
        const result = await service.matchStatementLine(db, lineId, body, userId);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/bank/reconciliation/queue/:lineId/unmatch
    router.post(
    "/reconciliation/queue/:lineId/unmatch",
    requireAuth,
    requirePermission("bank.reconcile.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { lineId } = validateLineIdParam(req.params);
        const body = validateUnmatchBody(req.body);
        const userId = req.user?.id ?? null;
        const result = await service.unmatchStatementLine(db, lineId, body, userId);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/bank/reconciliation/queue/:lineId/ignore
    router.post(
    "/reconciliation/queue/:lineId/ignore",
    requireAuth,
    requirePermission("bank.reconcile.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { lineId } = validateLineIdParam(req.params);
        const body = validateIgnoreBody(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.ignoreStatementLine(db, lineId, body, userId);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/bank/reconciliation/audit
    router.get(
    "/reconciliation/audit",
    requireAuth,
    requirePermission("bank.reconcile.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateAuditQuery(req.query);
        const items = await service.listReconciliationAudit(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 5) Mount route — `backend/src/index.js`

    ```js
    // backend/src/index.js
    import bankReconciliationRoutes from "./routes/bank.reconciliation.js";
    // ...
    app.use("/api/v1/bank", bankReconciliationRoutes);
    ```

    ---

    ## 6) Migration registry — `backend/src/migrations/index.js`

    ```js
    // backend/src/migrations/index.js
    import m033_bank_reconciliation from "./m033_bank_reconciliation.js";
    export default [
    // ...
    m033_bank_reconciliation,
    ];
    ```

    ---

    ## 7) Seed permissions — `backend/src/seedCore.js`

    ```js
    // backend/src/seedCore.js
    const BANK_RECON_PERMISSIONS = [
    "bank.reconcile.read",
    "bank.reconcile.write",
    ];

    // merge into your permission seed list
    ```

    ---

    ## 8) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Register these paths:

    * `GET /api/v1/bank/reconciliation/queue`
    * `GET /api/v1/bank/reconciliation/queue/{lineId}/suggestions`
    * `POST /api/v1/bank/reconciliation/queue/{lineId}/match`
    * `POST /api/v1/bank/reconciliation/queue/{lineId}/unmatch`
    * `POST /api/v1/bank/reconciliation/queue/{lineId}/ignore`
    * `GET /api/v1/bank/reconciliation/audit`

    ---

    ## 9) Backend smoke test — `backend/scripts/test-bank-prb03-reconciliation.js`

    > This should be a real script with your existing test helpers (supertest / app bootstrap).
    > The key is **behavior**, not exact framework.

    ```js
    // backend/scripts/test-bank-prb03-reconciliation.js

    async function main() {
    // Pseudocode:
    //
    // Preconditions:
    // - PR-B01 bank account exists (linked to a bank GL account)
    // - PR-B02 statement import exists (at least 1 UNMATCHED line)
    // - Create a POSTED journal in GL hitting the same bank GL account and same amount/date
    //
    // Test flow:
    // 1) GET /api/v1/bank/reconciliation/queue -> line appears as UNMATCHED
    // 2) GET /api/v1/bank/reconciliation/queue/:lineId/suggestions -> journal suggestion returned
    // 3) POST /match with JOURNAL + exact amount -> line becomes MATCHED
    // 4) GET /audit -> MATCHED and AUTO_STATUS rows exist
    // 5) POST /unmatch -> line returns UNMATCHED
    // 6) POST /ignore -> line becomes IGNORED
    // 7) POST /match on IGNORED line -> should fail (400)
    // 8) Permission checks -> 403 without bank.reconcile.read/write
    //
    console.log("PR-B03 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    ---

    ## 10) `backend/package.json` updates

    ```json
    {
    "scripts": {
        "test:bank:prb03": "node backend/scripts/test-bank-prb03-reconciliation.js"
    }
    }
    ```

    (Adjust path if your `package.json` is inside `/backend`)

    ---

    # Frontend skeletons

    ## 11) API client — `frontend/src/api/bankReconciliation.js`

    ```js
    // frontend/src/api/bankReconciliation.js

    import { apiFetch } from "./client.js"; // adapt to your helper

    export function listReconciliationQueue(params = {}) {
    const q = new URLSearchParams();
    if (params.bank_account_id) q.set("bank_account_id", String(params.bank_account_id));
    if (params.recon_status) q.set("recon_status", String(params.recon_status));
    if (params.q) q.set("q", String(params.q));
    const qs = q.toString();
    return apiFetch(`/api/v1/bank/reconciliation/queue${qs ? `?${qs}` : ""}`);
    }

    export function getReconciliationSuggestions(lineId) {
    return apiFetch(`/api/v1/bank/reconciliation/queue/${lineId}/suggestions`);
    }

    export function matchReconciliationLine(lineId, payload) {
    return apiFetch(`/api/v1/bank/reconciliation/queue/${lineId}/match`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function unmatchReconciliationLine(lineId, payload = {}) {
    return apiFetch(`/api/v1/bank/reconciliation/queue/${lineId}/unmatch`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function ignoreReconciliationLine(lineId, payload = {}) {
    return apiFetch(`/api/v1/bank/reconciliation/queue/${lineId}/ignore`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function listReconciliationAudit(params = {}) {
    const q = new URLSearchParams();
    if (params.statement_line_id) q.set("statement_line_id", String(params.statement_line_id));
    const qs = q.toString();
    return apiFetch(`/api/v1/bank/reconciliation/audit${qs ? `?${qs}` : ""}`);
    }
    ```

    ---

    ## 12) Page — `frontend/src/pages/bank/BankReconciliationPage.jsx`

    > Simple but useful v1:
    >
    > * queue table
    > * “Suggestions” per line
    > * one-click exact match from suggestion
    > * unmatch / ignore
    > * audit drawer-ish panel (basic)

    ```jsx
    // frontend/src/pages/bank/BankReconciliationPage.jsx

    import { useEffect, useState } from "react";
    import {
    listReconciliationQueue,
    getReconciliationSuggestions,
    matchReconciliationLine,
    unmatchReconciliationLine,
    ignoreReconciliationLine,
    listReconciliationAudit,
    } from "../../api/bankReconciliation.js";

    export default function BankReconciliationPage() {
    const [items, setItems] = useState([]);
    const [bankAccountId, setBankAccountId] = useState("");
    const [loading, setLoading] = useState(false);
    const [err, setErr] = useState("");

    const [selectedLine, setSelectedLine] = useState(null);
    const [suggestions, setSuggestions] = useState([]);
    const [auditItems, setAuditItems] = useState([]);

    async function loadQueue() {
        setLoading(true);
        setErr("");
        try {
        const res = await listReconciliationQueue({
            bank_account_id: bankAccountId ? Number(bankAccountId) : undefined,
        });
        setItems(res.items || []);
        } catch (e) {
        setErr(e.message || "Failed to load reconciliation queue");
        } finally {
        setLoading(false);
        }
    }

    async function openLineActions(line) {
        setSelectedLine(line);
        setErr("");
        try {
        const [sRes, aRes] = await Promise.all([
            getReconciliationSuggestions(line.id),
            listReconciliationAudit({ statement_line_id: line.id }),
        ]);
        setSuggestions(sRes.suggestions || []);
        setAuditItems(aRes.items || []);
        } catch (e) {
        setErr(e.message || "Failed to load line details");
        }
    }

    async function matchSuggestion(line, s) {
        setErr("");
        try {
        await matchReconciliationLine(line.id, {
            matched_entity_type: s.matched_entity_type,
            matched_entity_id: s.matched_entity_id,
            matched_amount: Math.abs(Number(line.amount)),
            match_type: "MANUAL",
        });
        await loadQueue();
        await openLineActions({ ...line });
        } catch (e) {
        setErr(e.message || "Match failed");
        }
    }

    async function unmatchLine(line) {
        setErr("");
        try {
        await unmatchReconciliationLine(line.id, {});
        await loadQueue();
        await openLineActions({ ...line });
        } catch (e) {
        setErr(e.message || "Unmatch failed");
        }
    }

    async function ignoreLine(line) {
        const reason = window.prompt("Ignore reason (optional):", "") || "";
        setErr("");
        try {
        await ignoreReconciliationLine(line.id, { reason });
        await loadQueue();
        await openLineActions({ ...line });
        } catch (e) {
        setErr(e.message || "Ignore failed");
        }
    }

    useEffect(() => {
        loadQueue();
    }, []);

    return (
        <div className="p-4 grid grid-cols-1 lg:grid-cols-3 gap-4">
        <div className="lg:col-span-2 rounded border bg-white p-4">
            <div className="flex items-center gap-2 mb-3">
            <h1 className="text-lg font-semibold">Bank Reconciliation</h1>
            <input
                className="border rounded px-2 py-1 ml-auto w-48"
                placeholder="Bank Account ID"
                value={bankAccountId}
                onChange={(e) => setBankAccountId(e.target.value)}
            />
            <button className="px-3 py-1 rounded border" onClick={loadQueue} type="button">
                Refresh
            </button>
            </div>

            {err ? <div className="text-sm text-red-600 mb-2">{err}</div> : null}

            {loading ? (
            <div>Loading...</div>
            ) : (
            <div className="overflow-auto">
                <table className="min-w-full text-sm border-collapse">
                <thead>
                    <tr className="border-b">
                    <th className="text-left p-2">Date</th>
                    <th className="text-left p-2">Desc</th>
                    <th className="text-left p-2">Ref</th>
                    <th className="text-left p-2">Amount</th>
                    <th className="text-left p-2">Status</th>
                    <th className="text-left p-2">Matched</th>
                    <th className="text-left p-2">Actions</th>
                    </tr>
                </thead>
                <tbody>
                    {items.map((row) => (
                    <tr key={row.id} className="border-b">
                        <td className="p-2">{row.txn_date}</td>
                        <td className="p-2">{row.description}</td>
                        <td className="p-2">{row.reference_no || "-"}</td>
                        <td className="p-2">{row.amount}</td>
                        <td className="p-2">{row.recon_status}</td>
                        <td className="p-2">{row.active_matched_total || 0}</td>
                        <td className="p-2 space-x-2">
                        <button className="underline" type="button" onClick={() => openLineActions(row)}>
                            Details
                        </button>
                        {row.recon_status !== "IGNORED" && (
                            <button className="underline" type="button" onClick={() => ignoreLine(row)}>
                            Ignore
                            </button>
                        )}
                        </td>
                    </tr>
                    ))}
                    {items.length === 0 && (
                    <tr>
                        <td colSpan={7} className="p-2">
                        No reconciliation items.
                        </td>
                    </tr>
                    )}
                </tbody>
                </table>
            </div>
            )}
        </div>

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Line Details</h2>

            {!selectedLine ? (
            <div className="text-sm text-gray-600">Select a line from the queue.</div>
            ) : (
            <div className="space-y-4 text-sm">
                <div>
                <div><b>Date:</b> {selectedLine.txn_date}</div>
                <div><b>Description:</b> {selectedLine.description}</div>
                <div><b>Amount:</b> {selectedLine.amount} {selectedLine.currency_code}</div>
                <div><b>Status:</b> {selectedLine.recon_status}</div>
                </div>

                <div>
                <div className="font-medium mb-1">Suggestions</div>
                {suggestions.length === 0 ? (
                    <div className="text-gray-600">No suggestions.</div>
                ) : (
                    <div className="space-y-2">
                    {suggestions.map((s) => (
                        <div key={`${s.matched_entity_type}-${s.matched_entity_id}`} className="border rounded p-2">
                        <div>{s.display_ref}</div>
                        <div className="text-gray-600">{s.display_text}</div>
                        <div className="text-gray-600">Score: {s.score}</div>
                        <button
                            className="underline mt-1"
                            type="button"
                            onClick={() => matchSuggestion(selectedLine, s)}
                        >
                            Match exact amount
                        </button>
                        </div>
                    ))}
                    </div>
                )}
                </div>

                <div className="space-x-2">
                <button className="px-2 py-1 border rounded" type="button" onClick={() => unmatchLine(selectedLine)}>
                    Unmatch all
                </button>
                </div>

                <div>
                <div className="font-medium mb-1">Audit</div>
                <div className="space-y-1 max-h-64 overflow-auto">
                    {auditItems.map((a) => (
                    <div key={a.id} className="border rounded p-2">
                        <div><b>{a.action}</b> — {a.acted_at}</div>
                        <div className="text-gray-600">{a.bank_account_code}</div>
                    </div>
                    ))}
                    {auditItems.length === 0 && <div className="text-gray-600">No audit rows yet.</div>}
                </div>
                </div>
            </div>
            )}
        </div>
        </div>
    );
    }
    ```

    ---

    ## 13) App route — `frontend/src/App.jsx`

    ```jsx
    // frontend/src/App.jsx
    import BankReconciliationPage from "./pages/bank/BankReconciliationPage.js";

    // ...
    <Route
    path="/app/banka-mutabakat"
    element={
        <RequirePermission anyOf={["bank.reconcile.read"]}>
        <BankReconciliationPage />
        </RequirePermission>
    }
    />
    ```

    ---

    ## 14) Sidebar — `frontend/src/layouts/sidebarConfig.js`

    Add under Bank:

    ```js
    // frontend/src/layouts/sidebarConfig.js
    {
    key: "bank-reconciliation",
    label: "Reconciliation",
    to: "/app/banka-mutabakat",
    requiredPermissions: ["bank.reconcile.read"],
    }
    ```

    ---

    ## 15) i18n — `frontend/src/i18n/messages.js`

    ```js
    // frontend/src/i18n/messages.js
    export default {
    // ...
    "sidebar.bankReconciliation": "Reconciliation",
    };
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ Reconciliation queue lists statement lines with `UNMATCHED / PARTIAL / IGNORED`
    * ✅ Suggestions endpoint returns candidate matches (v1 journal-based)
    * ✅ Manual match creates `bank_reconciliation_matches` row and updates line status
    * ✅ Unmatch reverses active match(es) and recalculates line status
    * ✅ Ignore marks line as `IGNORED` and logs audit action
    * ✅ Every reconciliation action writes audit rows
    * ✅ Permissions enforced (`bank.reconcile.read/write`)
    * ✅ OpenAPI updated
    * ✅ Smoke test script exists and runs

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:bank:prb03`

    Should verify at least:

    1. **Queue load**

    * GET `/api/v1/bank/reconciliation/queue`
    * imported statement line appears with `recon_status=UNMATCHED`

    2. **Suggestions**

    * create a matching posted journal (same bank GL + amount/date)
    * GET `/queue/:lineId/suggestions`
    * receives at least one `JOURNAL` suggestion

    3. **Manual match exact**

    * POST `/queue/:lineId/match` with `JOURNAL`
    * line status becomes `MATCHED`
    * active match total equals statement line absolute amount

    4. **Partial match behavior**

    * on a different line, match less than full amount
    * line status becomes `PARTIAL`

    5. **Unmatch**

    * POST `/queue/:lineId/unmatch`
    * active matches reversed
    * line status recalculates to `UNMATCHED`

    6. **Ignore**

    * POST `/queue/:lineId/ignore`
    * line status becomes `IGNORED`

    7. **Ignore safety**

    * trying to ignore line with active matches returns `400`

    8. **Audit**

    * GET `/api/v1/bank/reconciliation/audit`
    * contains `SUGGESTED`, `MATCHED`, `UNMATCHED`, `IGNORE`, `AUTO_STATUS` events as applicable

    9. **Permissions**

    * read/write endpoints reject users without `bank.reconcile.read/write` (`403`)

    ---

    # Example manual API payloads

    ## Manual match (journal)

    ```json
    {
    "matched_entity_type": "JOURNAL",
    "matched_entity_id": 12345,
    "matched_amount": 12500.00,
    "match_type": "MANUAL",
    "notes": "Matched to payroll settlement JE"
    }
    ```

    ## Unmatch specific match

    ```json
    {
    "match_id": 987,
    "notes": "Wrong journal selected"
    }
    ```

    ## Ignore line

    ```json
    {
    "reason": "Bank fee to be handled in month-end adjustment"
    }
    ```

    ---

    # Tiny implementation notes (important)

    * **B03 supports JOURNAL matching first** (cleanest dependency-wise).
    * `PAYMENT_BATCH` matching is intentionally blocked until **PR-B04** creates that module.
    * Keep `matched_amount` **positive** and compare against `ABS(statement_line.amount)`.
    * Don’t auto-post GL adjustments in this PR; exceptions stay visible in queue.

Perfect — here’s **PR-B04** in the same concrete format.

# PR-B04: Generic Payment Batch Engine (Reusable for Payroll / AP / Tax)

    ## Goal

    Build a **generic payment batch** module that can be reused by:

    * Payroll (later PR-P04)
    * Vendor/AP payments
    * Tax remittances
    * Manual payments

    For this PR, focus on:

    * ✅ Batch header + lines
    * ✅ Maker-checker approval
    * ✅ CSV export (v1)
    * ✅ Posting settlement journal(s): `Dr Payable / Cr Bank`
    * ✅ Idempotent posting
    * ✅ Audit trail

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m034_payment_batches.js`
    * `backend/src/routes/payments.js`
    * `backend/src/routes/payments.validators.js`
    * `backend/src/services/payments.service.js`
    * `backend/scripts/test-payments-prb04-batches.js`

    ### Frontend

    * `frontend/src/api/payments.js`
    * `frontend/src/pages/payments/PaymentBatchListPage.jsx`
    * `frontend/src/pages/payments/PaymentBatchDetailPage.jsx`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js` (permissions)
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/App.jsx`
    * `frontend/src/layouts/sidebarConfig.js`
    * `frontend/src/i18n/messages.js`

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m034_payment_batches.js`

    > This is intentionally generic. `source_type/source_id` let Payroll/AP hook in later.

    ```js
    // backend/src/migrations/m034_payment_batches.js

    export default {
    key: "m034_payment_batches",
    description: "m034_payment_batches",
    async up(connection) {
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payment_batches (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            batch_no VARCHAR(50) NOT NULL,
            source_type VARCHAR(30) NOT NULL, -- PAYROLL, AP, TAX, MANUAL
            source_id BIGINT UNSIGNED NULL,
            bank_account_id BIGINT UNSIGNED NOT NULL,
            currency_code CHAR(3) NOT NULL,
            total_amount DECIMAL(18,2) NOT NULL DEFAULT 0,
            status VARCHAR(20) NOT NULL DEFAULT 'DRAFT', -- DRAFT, APPROVED, EXPORTED, POSTED, FAILED, CANCELLED
            idempotency_key VARCHAR(100) NULL,
            export_file_name VARCHAR(255) NULL,
            export_checksum CHAR(64) NULL,
            posted_journal_entry_id BIGINT UNSIGNED NULL,
            notes VARCHAR(500) NULL,
            created_by BIGINT UNSIGNED NULL,
            approved_by BIGINT UNSIGNED NULL,
            posted_by BIGINT UNSIGNED NULL,
            exported_by BIGINT UNSIGNED NULL,
            approved_at DATETIME NULL,
            posted_at DATETIME NULL,
            exported_at DATETIME NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            UNIQUE KEY uq_payment_batches_batch_no (batch_no),
            UNIQUE KEY uq_payment_batches_idempotency_key (idempotency_key),
            KEY idx_payment_batches_status (status),
            KEY idx_payment_batches_source (source_type, source_id),
            KEY idx_payment_batches_bank (bank_account_id),
            CONSTRAINT fk_payment_batches_bank_account
            FOREIGN KEY (bank_account_id) REFERENCES bank_accounts(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payment_batch_lines (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            batch_id BIGINT UNSIGNED NOT NULL,
            line_no INT UNSIGNED NOT NULL,
            beneficiary_type VARCHAR(30) NOT NULL, -- EMPLOYEE, VENDOR, TAX_AUTHORITY, OTHER
            beneficiary_id BIGINT UNSIGNED NULL,
            beneficiary_name VARCHAR(255) NOT NULL,
            beneficiary_bank_ref VARCHAR(255) NULL,
            payable_entity_type VARCHAR(30) NOT NULL, -- PAYROLL_LIABILITY, AP_INVOICE, TAX_LIABILITY, MANUAL
            payable_entity_id BIGINT UNSIGNED NULL,
            payable_gl_account_id BIGINT UNSIGNED NOT NULL,
            payable_ref VARCHAR(100) NULL,
            amount DECIMAL(18,2) NOT NULL,
            status VARCHAR(20) NOT NULL DEFAULT 'PENDING', -- PENDING, PAID, FAILED, CANCELLED
            external_payment_ref VARCHAR(100) NULL,
            settlement_journal_line_ref VARCHAR(100) NULL,
            notes VARCHAR(500) NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            UNIQUE KEY uq_payment_batch_lines_batch_lineno (batch_id, line_no),
            KEY idx_payment_batch_lines_batch (batch_id),
            KEY idx_payment_batch_lines_payable (payable_entity_type, payable_entity_id),
            KEY idx_payment_batch_lines_status (status),
            CONSTRAINT fk_payment_batch_lines_batch
            FOREIGN KEY (batch_id) REFERENCES payment_batches(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,
            CONSTRAINT fk_payment_batch_lines_payable_gl
            FOREIGN KEY (payable_gl_account_id) REFERENCES accounts(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payment_batch_audit (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            batch_id BIGINT UNSIGNED NOT NULL,
            action VARCHAR(30) NOT NULL, -- CREATED, UPDATED, APPROVED, EXPORTED, POSTED, CANCELLED, FAILED, STATUS
            payload_json JSON NULL,
            acted_by BIGINT UNSIGNED NULL,
            acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            KEY idx_payment_batch_audit_batch (batch_id),
            KEY idx_payment_batch_audit_action (action),
            CONSTRAINT fk_payment_batch_audit_batch
            FOREIGN KEY (batch_id) REFERENCES payment_batches(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);
    },

    async down(connection) {
        await connection.execute(`DROP TABLE IF EXISTS payment_batch_audit;`);
        await connection.execute(`DROP TABLE IF EXISTS payment_batch_lines;`);
        await connection.execute(`DROP TABLE IF EXISTS payment_batches;`);
    },
    };
    ```

    ---

    ## 2) Validators — `backend/src/routes/payments.validators.js`

    ```js
    // backend/src/routes/payments.validators.js

    function requirePositiveInt(value, field) {
    const n = Number(value);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${field} must be positive integer`);
    return n;
    }

    function requirePositiveAmount(value, field) {
    const n = Number(value);
    if (!Number.isFinite(n) || n <= 0) throw new Error(`${field} must be positive number`);
    return Number(n.toFixed(2));
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function requireCurrency(v) {
    const s = String(v || "").trim().toUpperCase();
    if (!/^[A-Z]{3}$/.test(s)) throw new Error("currency_code must be 3 letters");
    return s;
    }

    function validateIdParam(params = {}) {
    return { id: requirePositiveInt(params.id, "id") };
    }

    function validateListBatchesQuery(query = {}) {
    return {
        status: query.status ? String(query.status).trim().toUpperCase() : null,
        source_type: query.source_type ? String(query.source_type).trim().toUpperCase() : null,
        source_id: query.source_id ? requirePositiveInt(query.source_id, "source_id") : null,
        bank_account_id: query.bank_account_id ? requirePositiveInt(query.bank_account_id, "bank_account_id") : null,
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 200) : 50,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    function validateCreateBatch(body = {}) {
    const source_type = String(body.source_type || "").trim().toUpperCase();
    const allowedSourceTypes = ["PAYROLL", "AP", "TAX", "MANUAL"];
    if (!allowedSourceTypes.includes(source_type)) {
        throw new Error(`source_type must be one of ${allowedSourceTypes.join(", ")}`);
    }

    if (!Array.isArray(body.lines) || body.lines.length === 0) {
        throw new Error("lines[] is required");
    }

    const lines = body.lines.map((line, i) => {
        const beneficiary_type = String(line.beneficiary_type || "").trim().toUpperCase();
        const payable_entity_type = String(line.payable_entity_type || "").trim().toUpperCase();
        if (!beneficiary_type) throw new Error(`lines[${i}].beneficiary_type is required`);
        if (!payable_entity_type) throw new Error(`lines[${i}].payable_entity_type is required`);

        return {
        beneficiary_type,
        beneficiary_id: line.beneficiary_id ? requirePositiveInt(line.beneficiary_id, `lines[${i}].beneficiary_id`) : null,
        beneficiary_name: String(line.beneficiary_name || "").trim() || (() => { throw new Error(`lines[${i}].beneficiary_name is required`); })(),
        beneficiary_bank_ref: normalizeString(line.beneficiary_bank_ref),
        payable_entity_type,
        payable_entity_id: line.payable_entity_id ? requirePositiveInt(line.payable_entity_id, `lines[${i}].payable_entity_id`) : null,
        payable_gl_account_id: requirePositiveInt(line.payable_gl_account_id, `lines[${i}].payable_gl_account_id`),
        payable_ref: normalizeString(line.payable_ref),
        amount: requirePositiveAmount(line.amount, `lines[${i}].amount`),
        notes: normalizeString(line.notes),
        };
    });

    return {
        source_type,
        source_id: body.source_id ? requirePositiveInt(body.source_id, "source_id") : null,
        bank_account_id: requirePositiveInt(body.bank_account_id, "bank_account_id"),
        currency_code: requireCurrency(body.currency_code),
        idempotency_key: normalizeString(body.idempotency_key),
        notes: normalizeString(body.notes),
        lines,
    };
    }

    function validateApproveBody(body = {}) {
    return { note: normalizeString(body.note) };
    }

    function validateExportBody(body = {}) {
    return { format: (normalizeString(body.format) || "CSV").toUpperCase() };
    }

    function validatePostBody(body = {}) {
    return {
        note: normalizeString(body.note),
        external_payment_ref_prefix: normalizeString(body.external_payment_ref_prefix),
    };
    }

    function validateCancelBody(body = {}) {
    return { reason: normalizeString(body.reason) };
    }

    export default {
    validateIdParam,
    validateListBatchesQuery,
    validateCreateBatch,
    validateApproveBody,
    validateExportBody,
    validatePostBody,
    validateCancelBody,
    };
    ```

    ---

    ## 3) Service — `backend/src/services/payments.service.js`

    > Replace GL posting table names (`journal_entries`, `journal_entry_lines`) with your actual schema names if needed.

    ```js
    // backend/src/services/payments.service.js

    import crypto from "crypto";
    function sha256(v) {
    return crypto.createHash("sha256").update(String(v)).digest("hex");
    }

    async function writeAudit(db, batchId, action, payload, userId = null) {
    await db.query(
        `INSERT INTO payment_batch_audit (batch_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
        [batchId, action, payload ? JSON.stringify(payload) : null, userId]
    );
    }

    async function getBankAccount(db, bankAccountId) {
    const [rows] = await db.query(
        `
        SELECT b.id, b.code, b.name, b.currency_code, b.gl_account_id, b.is_active
        FROM bank_accounts b
        WHERE b.id = ?
        LIMIT 1
        `,
        [bankAccountId]
    );
    if (!rows[0]) {
        const err = new Error("Bank account not found");
        err.statusCode = 400;
        throw err;
    }
    return rows[0];
    }

    async function assertAccountsExist(db, accountIds) {
    if (!accountIds.length) return;
    const placeholders = accountIds.map(() => "?").join(",");
    const [rows] = await db.query(
        `SELECT id FROM accounts WHERE id IN (${placeholders})`,
        accountIds
    );
    const found = new Set(rows.map((r) => Number(r.id)));
    for (const id of accountIds) {
        if (!found.has(Number(id))) {
        const err = new Error(`GL account not found: ${id}`);
        err.statusCode = 400;
        throw err;
        }
    }
    }

    function computeTotal(lines) {
    return Number(lines.reduce((s, l) => s + Number(l.amount), 0).toFixed(2));
    }

    async function nextBatchNo(db) {
    // Simple deterministic sequence by id count; replace with your numbering service if you have one
    const [rows] = await db.query(`SELECT COALESCE(MAX(id),0) + 1 AS next_id FROM payment_batches`);
    const n = Number(rows[0]?.next_id || 1);
    return `PAY-${String(n).padStart(6, "0")}`;
    }

    async function getBatchById(db, id) {
    const [batches] = await db.query(
        `
        SELECT
        pb.*,
        ba.code AS bank_account_code,
        ba.name AS bank_account_name,
        ba.gl_account_id AS bank_gl_account_id
        FROM payment_batches pb
        JOIN bank_accounts ba ON ba.id = pb.bank_account_id
        WHERE pb.id = ?
        LIMIT 1
        `,
        [id]
    );
    const batch = batches[0];
    if (!batch) return null;

    const [lines] = await db.query(
        `
        SELECT *
        FROM payment_batch_lines
        WHERE batch_id = ?
        ORDER BY line_no ASC
        `,
        [id]
    );

    return { ...batch, lines };
    }

    async function listBatches(db, query) {
    const where = [];
    const params = [];

    if (query.status) {
        where.push(`pb.status = ?`);
        params.push(query.status);
    }
    if (query.source_type) {
        where.push(`pb.source_type = ?`);
        params.push(query.source_type);
    }
    if (query.source_id) {
        where.push(`pb.source_id = ?`);
        params.push(query.source_id);
    }
    if (query.bank_account_id) {
        where.push(`pb.bank_account_id = ?`);
        params.push(query.bank_account_id);
    }

    let sql = `
        SELECT
        pb.id, pb.batch_no, pb.source_type, pb.source_id, pb.bank_account_id,
        pb.currency_code, pb.total_amount, pb.status, pb.created_at, pb.approved_at, pb.posted_at,
        ba.code AS bank_account_code, ba.name AS bank_account_name,
        (SELECT COUNT(*) FROM payment_batch_lines l WHERE l.batch_id = pb.id) AS line_count
        FROM payment_batches pb
        JOIN bank_accounts ba ON ba.id = pb.bank_account_id
    `;
    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY pb.id DESC LIMIT ? OFFSET ?`;
    params.push(query.limit, query.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function createBatch(db, payload, userId = null) {
    const bank = await getBankAccount(db, payload.bank_account_id);
    if (!bank.is_active) {
        const err = new Error("Cannot create payment batch on inactive bank account");
        err.statusCode = 400;
        throw err;
    }
    if (bank.currency_code !== payload.currency_code) {
        const err = new Error(`Currency mismatch. Bank=${bank.currency_code} payload=${payload.currency_code}`);
        err.statusCode = 400;
        throw err;
    }

    const accountIds = [...new Set(payload.lines.map((l) => Number(l.payable_gl_account_id)))];
    await assertAccountsExist(db, accountIds);

    if (payload.idempotency_key) {
        const [dup] = await db.query(
        `SELECT id FROM payment_batches WHERE idempotency_key = ? LIMIT 1`,
        [payload.idempotency_key]
        );
        if (dup[0]) {
        const existing = await getBatchById(db, dup[0].id);
        return existing; // idempotent create returns existing
        }
    }

    // Prevent duplicate open usage of same payable target in active batches (draft/approved/exported)
    for (const line of payload.lines) {
        if (!line.payable_entity_id) continue;
        const [rows] = await db.query(
        `
        SELECT pbl.id, pb.batch_no, pb.status
        FROM payment_batch_lines pbl
        JOIN payment_batches pb ON pb.id = pbl.batch_id
        WHERE pbl.payable_entity_type = ?
            AND pbl.payable_entity_id = ?
            AND pbl.status IN ('PENDING')
            AND pb.status IN ('DRAFT', 'APPROVED', 'EXPORTED', 'POSTED')
        LIMIT 1
        `,
        [line.payable_entity_type, line.payable_entity_id]
        );
        if (rows[0]) {
        const err = new Error(
            `Payable already linked to another active batch (${rows[0].batch_no}, status=${rows[0].status})`
        );
        err.statusCode = 409;
        throw err;
        }
    }

    const total = computeTotal(payload.lines);
    const batchNo = await nextBatchNo(db);

    const conn = db.getConnection ? await db.getConnection() : null;
    const q = conn || db;

    try {
        if (conn) await conn.beginTransaction();

        const [insBatch] = await q.query(
        `
        INSERT INTO payment_batches
        (batch_no, source_type, source_id, bank_account_id, currency_code, total_amount, status, idempotency_key, notes, created_by)
        VALUES (?, ?, ?, ?, ?, ?, 'DRAFT', ?, ?, ?)
        `,
        [
            batchNo,
            payload.source_type,
            payload.source_id,
            payload.bank_account_id,
            payload.currency_code,
            total,
            payload.idempotency_key || null,
            payload.notes || null,
            userId,
        ]
        );

        const batchId = insBatch.insertId;

        let lineNo = 1;
        for (const line of payload.lines) {
        await q.query(
            `
            INSERT INTO payment_batch_lines
            (batch_id, line_no, beneficiary_type, beneficiary_id, beneficiary_name, beneficiary_bank_ref,
            payable_entity_type, payable_entity_id, payable_gl_account_id, payable_ref, amount, status, notes)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'PENDING', ?)
            `,
            [
            batchId,
            lineNo++,
            line.beneficiary_type,
            line.beneficiary_id,
            line.beneficiary_name,
            line.beneficiary_bank_ref,
            line.payable_entity_type,
            line.payable_entity_id,
            line.payable_gl_account_id,
            line.payable_ref,
            line.amount,
            line.notes || null,
            ]
        );
        }

        await writeAudit(q, batchId, "CREATED", { total_amount: total, line_count: payload.lines.length }, userId);

        if (conn) await conn.commit();

        return getBatchById(db, batchId);
    } catch (err) {
        if (conn) {
        try { await conn.rollback(); } catch (_) {}
        }
        throw err;
    } finally {
        if (conn) conn.release();
    }
    }

    async function approveBatch(db, id, userId = null, body = {}) {
    const batch = await getBatchById(db, id);
    if (!batch) {
        const err = new Error("Batch not found");
        err.statusCode = 404;
        throw err;
    }
    if (batch.status !== "DRAFT") {
        const err = new Error("Only DRAFT batches can be approved");
        err.statusCode = 400;
        throw err;
    }
    if (batch.created_by && userId && Number(batch.created_by) === Number(userId)) {
        // Optional maker-checker; keep if you want strict SoD immediately
        const err = new Error("Creator cannot approve the same batch");
        err.statusCode = 403;
        throw err;
    }

    await db.query(
        `UPDATE payment_batches SET status='APPROVED', approved_by=?, approved_at=NOW() WHERE id=?`,
        [userId, id]
    );
    await writeAudit(db, id, "APPROVED", { note: body.note || null }, userId);
    return getBatchById(db, id);
    }

    function buildCsv(batch) {
    const header = [
        "line_no",
        "beneficiary_name",
        "beneficiary_bank_ref",
        "amount",
        "currency_code",
        "payable_entity_type",
        "payable_entity_id",
        "payable_ref",
    ];
    const rows = [header.join(",")];

    for (const line of batch.lines) {
        const vals = [
        line.line_no,
        line.beneficiary_name,
        line.beneficiary_bank_ref || "",
        Number(line.amount).toFixed(2),
        batch.currency_code,
        line.payable_entity_type,
        line.payable_entity_id || "",
        line.payable_ref || "",
        ].map((v) => {
        const s = String(v);
        return /[",\n]/.test(s) ? `"${s.replace(/"/g, '""')}"` : s;
        });
        rows.push(vals.join(","));
    }

    return rows.join("\n");
    }

    async function exportBatch(db, id, userId = null, body = {}) {
    const batch = await getBatchById(db, id);
    if (!batch) {
        const err = new Error("Batch not found");
        err.statusCode = 404;
        throw err;
    }
    if (!["APPROVED", "EXPORTED"].includes(batch.status)) {
        const err = new Error("Only APPROVED/EXPORTED batches can be exported");
        err.statusCode = 400;
        throw err;
    }
    if ((body.format || "CSV") !== "CSV") {
        const err = new Error("Only CSV export is supported in v1");
        err.statusCode = 400;
        throw err;
    }

    const csv = buildCsv(batch);
    const checksum = sha256(csv);
    const fileName = `${batch.batch_no}.csv`;

    await db.query(
        `
        UPDATE payment_batches
        SET status='EXPORTED', export_file_name=?, export_checksum=?, exported_by=?, exported_at=NOW()
        WHERE id=?
        `,
        [fileName, checksum, userId, id]
    );
    await writeAudit(db, id, "EXPORTED", { file_name: fileName, checksum }, userId);

    const fresh = await getBatchById(db, id);
    return { batch: fresh, export: { file_name: fileName, checksum, csv } };
    }

    async function createSettlementJournal(db, batch, userId = null, body = {}) {
    // Adapt these table names/columns to your GL schema.
    // Assumes:
    // - journal_entries(id, journal_no, status, memo, posted_at, created_by)
    // - journal_entry_lines(id, journal_entry_id, line_no, account_id, dr_amount, cr_amount, amount, memo)
    const bankGl = Number(batch.bank_gl_account_id);
    const total = Number(batch.total_amount);

    // Header
    const [jeIns] = await db.query(
        `
        INSERT INTO journal_entries
        (journal_no, status, memo, posted_at, created_by)
        VALUES (?, 'POSTED', ?, NOW(), ?)
        `,
        [
        `PAYSET-${batch.batch_no}`,
        `Payment batch settlement ${batch.batch_no}`,
        userId,
        ]
    );
    const journalId = jeIns.insertId;

    let lineNo = 1;
    // Debit payables per line
    for (const l of batch.lines) {
        const amount = Number(l.amount);
        await db.query(
        `
        INSERT INTO journal_entry_lines
        (journal_entry_id, line_no, account_id, dr_amount, cr_amount, amount, memo)
        VALUES (?, ?, ?, ?, 0, ?, ?)
        `,
        [
            journalId,
            lineNo++,
            Number(l.payable_gl_account_id),
            amount,
            amount,
            `Settlement ${batch.batch_no} line ${l.line_no}`,
        ]
        );
    }

    // Credit bank (single summarized line)
    await db.query(
        `
        INSERT INTO journal_entry_lines
        (journal_entry_id, line_no, account_id, dr_amount, cr_amount, amount, memo)
        VALUES (?, ?, ?, 0, ?, ?, ?)
        `,
        [
        journalId,
        lineNo++,
        bankGl,
        total,
        -total,
        `Settlement ${batch.batch_no} bank credit`,
        ]
    );

    return journalId;
    }

    async function postBatch(db, id, userId = null, body = {}) {
    const batch = await getBatchById(db, id);
    if (!batch) {
        const err = new Error("Batch not found");
        err.statusCode = 404;
        throw err;
    }

    if (batch.status === "POSTED" && batch.posted_journal_entry_id) {
        // idempotent
        return batch;
    }

    if (!["APPROVED", "EXPORTED"].includes(batch.status)) {
        const err = new Error("Only APPROVED/EXPORTED batches can be posted");
        err.statusCode = 400;
        throw err;
    }

    const conn = db.getConnection ? await db.getConnection() : null;
    const q = conn || db;

    try {
        if (conn) await conn.beginTransaction();

        const current = await getBatchById(q, id);
        if (current.status === "POSTED" && current.posted_journal_entry_id) {
        if (conn) await conn.commit();
        return current;
        }

        const journalId = await createSettlementJournal(q, current, userId, body);

        await q.query(
        `
        UPDATE payment_batches
        SET status='POSTED', posted_journal_entry_id=?, posted_by=?, posted_at=NOW()
        WHERE id=?
        `,
        [journalId, userId, id]
        );

        await q.query(
        `
        UPDATE payment_batch_lines
        SET status='PAID',
            external_payment_ref = COALESCE(external_payment_ref, ?)
        WHERE batch_id=? AND status='PENDING'
        `,
        [body.external_payment_ref_prefix ? `${body.external_payment_ref_prefix}-${id}` : `PB-${id}`, id]
        );

        await writeAudit(q, id, "POSTED", { posted_journal_entry_id: journalId, note: body.note || null }, userId);

        if (conn) await conn.commit();
        return getBatchById(db, id);
    } catch (err) {
        if (conn) {
        try { await conn.rollback(); } catch (_) {}
        }
        throw err;
    } finally {
        if (conn) conn.release();
    }
    }

    async function cancelBatch(db, id, userId = null, body = {}) {
    const batch = await getBatchById(db, id);
    if (!batch) {
        const err = new Error("Batch not found");
        err.statusCode = 404;
        throw err;
    }
    if (["POSTED", "CANCELLED"].includes(batch.status)) {
        const err = new Error(`Cannot cancel batch in status ${batch.status}`);
        err.statusCode = 400;
        throw err;
    }

    await db.query(
        `UPDATE payment_batches SET status='CANCELLED' WHERE id=?`,
        [id]
    );
    await db.query(
        `UPDATE payment_batch_lines SET status='CANCELLED' WHERE batch_id=? AND status='PENDING'`,
        [id]
    );
    await writeAudit(db, id, "CANCELLED", { reason: body.reason || null }, userId);

    return getBatchById(db, id);
    }

    async function listBatchAudit(db, batchId) {
    const [rows] = await db.query(
        `
        SELECT id, batch_id, action, payload_json, acted_by, acted_at
        FROM payment_batch_audit
        WHERE batch_id=?
        ORDER BY id DESC
        `,
        [batchId]
    );
    return rows;
    }

    export default {
    listBatches,
    getBatchById,
    createBatch,
    approveBatch,
    exportBatch,
    postBatch,
    cancelBatch,
    listBatchAudit,
    };
    ```

    ---

    ## 4) Routes — `backend/src/routes/payments.js`

    ```js
    // backend/src/routes/payments.js

    import express from "express";
    import { validateIdParam,
    validateListBatchesQuery,
    validateCreateBatch,
    validateApproveBody,
    validateExportBody,
    validatePostBody,
    validateCancelBody, } from "./payments.validators.js";
    import service from "../services/payments.service.js";
    // Replace with your project helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();

    // GET /api/v1/payments/batches
    router.get(
    "/batches",
    requireAuth,
    requirePermission("payments.batch.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateListBatchesQuery(req.query);
        const items = await service.listBatches(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/payments/batches/:id
    router.get(
    "/batches/:id",
    requireAuth,
    requirePermission("payments.batch.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const row = await service.getBatchById(db, id);
        if (!row) return res.status(404).json({ error: "Not found" });
        const audit = await service.listBatchAudit(db, id);
        res.json({ ...row, audit });
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payments/batches
    router.post(
    "/batches",
    requireAuth,
    requirePermission("payments.batch.create"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const body = validateCreateBatch(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.createBatch(db, body, userId);
        res.status(201).json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payments/batches/:id/approve
    router.post(
    "/batches/:id/approve",
    requireAuth,
    requirePermission("payments.batch.approve"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const body = validateApproveBody(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.approveBatch(db, id, userId, body);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payments/batches/:id/export
    router.post(
    "/batches/:id/export",
    requireAuth,
    requirePermission("payments.batch.export"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const body = validateExportBody(req.body);
        const userId = req.user?.id ?? null;
        const result = await service.exportBatch(db, id, userId, body);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payments/batches/:id/post
    router.post(
    "/batches/:id/post",
    requireAuth,
    requirePermission("payments.batch.post"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const body = validatePostBody(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.postBatch(db, id, userId, body);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payments/batches/:id/cancel
    router.post(
    "/batches/:id/cancel",
    requireAuth,
    requirePermission("payments.batch.create"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const body = validateCancelBody(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.cancelBatch(db, id, userId, body);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 5) Mount route — `backend/src/index.js`

    ```js
    // backend/src/index.js
    import paymentsRoutes from "./routes/payments.js";
    // ...
    app.use("/api/v1/payments", paymentsRoutes);
    ```

    ---

    ## 6) Migration registry — `backend/src/migrations/index.js`

    ```js
    // backend/src/migrations/index.js
    import m034_payment_batches from "./m034_payment_batches.js";
    export default [
    // ...
    m034_payment_batches,
    ];
    ```

    ---

    ## 7) Seed permissions — `backend/src/seedCore.js`

    ```js
    // backend/src/seedCore.js
    const PAYMENT_PERMISSIONS = [
    "payments.batch.read",
    "payments.batch.create",
    "payments.batch.approve",
    "payments.batch.export",
    "payments.batch.post",
    ];

    // merge into your permission seed list
    ```

    ---

    ## 8) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Register these paths:

    * `GET /api/v1/payments/batches`
    * `GET /api/v1/payments/batches/{id}`
    * `POST /api/v1/payments/batches`
    * `POST /api/v1/payments/batches/{id}/approve`
    * `POST /api/v1/payments/batches/{id}/export`
    * `POST /api/v1/payments/batches/{id}/post`
    * `POST /api/v1/payments/batches/{id}/cancel`

    ---

    ## 9) Backend smoke test — `backend/scripts/test-payments-prb04-batches.js`

    > This should be a real script with your app bootstrap + supertest.
    > Here’s the exact behavior to validate.

    ```js
    // backend/scripts/test-payments-prb04-batches.js

    async function main() {
    // Preconditions:
    // - PR-B01 bank account exists and is active
    // - Payable GL account(s) exist in accounts
    //
    // Flow:
    // 1) POST /api/v1/payments/batches (MANUAL source) with 2 lines
    //    -> 201, status DRAFT, total_amount = sum(lines)
    // 2) POST create same payload with same idempotency_key
    //    -> returns existing batch (idempotent create)
    // 3) POST /approve
    //    -> status APPROVED
    // 4) POST /export
    //    -> status EXPORTED, CSV returned, checksum present
    // 5) POST /post
    //    -> status POSTED, posted_journal_entry_id exists
    //    -> lines status = PAID
    // 6) POST /post again
    //    -> idempotent (no duplicate JE)
    // 7) GET /batches/:id
    //    -> audit includes CREATED/APPROVED/EXPORTED/POSTED
    // 8) Try create another active batch with same payable_entity target
    //    -> 409 duplicate payable protection
    // 9) Permission checks (read/create/approve/export/post)
    console.log("PR-B04 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    ---

    ## 10) `backend/package.json` updates

    ```json
    {
    "scripts": {
        "test:payments:prb04": "node backend/scripts/test-payments-prb04-batches.js"
    }
    }
    ```

    ---

    # Frontend skeletons

    ## 11) API client — `frontend/src/api/payments.js`

    ```js
    // frontend/src/api/payments.js

    import { apiFetch } from "./client.js"; // adapt

    export function listPaymentBatches(params = {}) {
    const q = new URLSearchParams();
    if (params.status) q.set("status", params.status);
    if (params.source_type) q.set("source_type", params.source_type);
    if (params.source_id) q.set("source_id", String(params.source_id));
    if (params.bank_account_id) q.set("bank_account_id", String(params.bank_account_id));
    const qs = q.toString();
    return apiFetch(`/api/v1/payments/batches${qs ? `?${qs}` : ""}`);
    }

    export function getPaymentBatch(id) {
    return apiFetch(`/api/v1/payments/batches/${id}`);
    }

    export function createPaymentBatch(payload) {
    return apiFetch(`/api/v1/payments/batches`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function approvePaymentBatch(id, payload = {}) {
    return apiFetch(`/api/v1/payments/batches/${id}/approve`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function exportPaymentBatch(id, payload = { format: "CSV" }) {
    return apiFetch(`/api/v1/payments/batches/${id}/export`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function postPaymentBatch(id, payload = {}) {
    return apiFetch(`/api/v1/payments/batches/${id}/post`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function cancelPaymentBatch(id, payload = {}) {
    return apiFetch(`/api/v1/payments/batches/${id}/cancel`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }
    ```

    ---

    ## 12) List page — `frontend/src/pages/payments/PaymentBatchListPage.jsx`

    ```jsx
    // frontend/src/pages/payments/PaymentBatchListPage.jsx

    import { useEffect, useState } from "react";
    import { Link } from "react-router-dom";
    import { listPaymentBatches } from "../../api/payments.js";

    export default function PaymentBatchListPage() {
    const [items, setItems] = useState([]);
    const [err, setErr] = useState("");
    const [loading, setLoading] = useState(false);

    async function load() {
        setLoading(true);
        setErr("");
        try {
        const res = await listPaymentBatches({});
        setItems(res.items || []);
        } catch (e) {
        setErr(e.message || "Failed to load payment batches");
        } finally {
        setLoading(false);
        }
    }

    useEffect(() => { load(); }, []);

    return (
        <div className="p-4">
        <div className="rounded border bg-white p-4">
            <div className="flex items-center mb-3">
            <h1 className="text-lg font-semibold">Payment Batches</h1>
            <Link className="ml-auto underline" to="/payments/batches/new">New Batch</Link>
            </div>

            {err ? <div className="text-sm text-red-600 mb-2">{err}</div> : null}

            {loading ? (
            <div>Loading...</div>
            ) : (
            <div className="overflow-auto">
                <table className="min-w-full text-sm border-collapse">
                <thead>
                    <tr className="border-b">
                    <th className="text-left p-2">Batch No</th>
                    <th className="text-left p-2">Source</th>
                    <th className="text-left p-2">Bank</th>
                    <th className="text-left p-2">Currency</th>
                    <th className="text-left p-2">Total</th>
                    <th className="text-left p-2">Status</th>
                    <th className="text-left p-2">Lines</th>
                    </tr>
                </thead>
                <tbody>
                    {items.map((b) => (
                    <tr key={b.id} className="border-b">
                        <td className="p-2">
                        <Link className="underline" to={`/payments/batches/${b.id}`}>{b.batch_no}</Link>
                        </td>
                        <td className="p-2">{b.source_type}</td>
                        <td className="p-2">{b.bank_account_code}</td>
                        <td className="p-2">{b.currency_code}</td>
                        <td className="p-2">{b.total_amount}</td>
                        <td className="p-2">{b.status}</td>
                        <td className="p-2">{b.line_count}</td>
                    </tr>
                    ))}
                    {items.length === 0 && (
                    <tr><td className="p-2" colSpan={7}>No batches yet.</td></tr>
                    )}
                </tbody>
                </table>
            </div>
            )}
        </div>
        </div>
    );
    }
    ```

    ---

    ## 13) Detail page — `frontend/src/pages/payments/PaymentBatchDetailPage.jsx`

    ```jsx
    // frontend/src/pages/payments/PaymentBatchDetailPage.jsx

    import { useEffect, useState } from "react";
    import { useParams } from "react-router-dom";
    import {
    getPaymentBatch,
    approvePaymentBatch,
    exportPaymentBatch,
    postPaymentBatch,
    cancelPaymentBatch,
    } from "../../api/payments.js";

    export default function PaymentBatchDetailPage() {
    const { id } = useParams();
    const [batch, setBatch] = useState(null);
    const [err, setErr] = useState("");
    const [exportCsv, setExportCsv] = useState("");

    async function load() {
        setErr("");
        try {
        const res = await getPaymentBatch(id);
        setBatch(res);
        } catch (e) {
        setErr(e.message || "Failed to load batch");
        }
    }

    useEffect(() => { load(); }, [id]);

    async function onApprove() {
        try { await approvePaymentBatch(id, {}); await load(); } catch (e) { setErr(e.message || "Approve failed"); }
    }
    async function onExport() {
        try {
        const res = await exportPaymentBatch(id, { format: "CSV" });
        setExportCsv(res.export?.csv || "");
        await load();
        } catch (e) { setErr(e.message || "Export failed"); }
    }
    async function onPost() {
        try { await postPaymentBatch(id, {}); await load(); } catch (e) { setErr(e.message || "Post failed"); }
    }
    async function onCancel() {
        try { await cancelPaymentBatch(id, {}); await load(); } catch (e) { setErr(e.message || "Cancel failed"); }
    }

    if (!batch) return <div className="p-4">Loading...</div>;

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <div className="flex items-center gap-2">
            <h1 className="text-lg font-semibold">{batch.batch_no}</h1>
            <span className="text-sm border rounded px-2 py-0.5">{batch.status}</span>
            </div>
            {err ? <div className="text-sm text-red-600 mt-2">{err}</div> : null}

            <div className="grid grid-cols-2 md:grid-cols-4 gap-2 mt-3 text-sm">
            <div><b>Source:</b> {batch.source_type}</div>
            <div><b>Bank:</b> {batch.bank_account_code}</div>
            <div><b>Currency:</b> {batch.currency_code}</div>
            <div><b>Total:</b> {batch.total_amount}</div>
            </div>

            <div className="mt-3 flex gap-2">
            {batch.status === "DRAFT" && (
                <button className="border rounded px-2 py-1" onClick={onApprove} type="button">Approve</button>
            )}
            {(batch.status === "APPROVED" || batch.status === "EXPORTED") && (
                <>
                <button className="border rounded px-2 py-1" onClick={onExport} type="button">Export CSV</button>
                <button className="border rounded px-2 py-1" onClick={onPost} type="button">Post</button>
                <button className="border rounded px-2 py-1" onClick={onCancel} type="button">Cancel</button>
                </>
            )}
            </div>
        </div>

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Lines</h2>
            <div className="overflow-auto">
            <table className="min-w-full text-sm border-collapse">
                <thead>
                <tr className="border-b">
                    <th className="text-left p-2">#</th>
                    <th className="text-left p-2">Beneficiary</th>
                    <th className="text-left p-2">Payable Ref</th>
                    <th className="text-left p-2">Payable GL</th>
                    <th className="text-left p-2">Amount</th>
                    <th className="text-left p-2">Status</th>
                </tr>
                </thead>
                <tbody>
                {(batch.lines || []).map((l) => (
                    <tr key={l.id} className="border-b">
                    <td className="p-2">{l.line_no}</td>
                    <td className="p-2">{l.beneficiary_name}</td>
                    <td className="p-2">{l.payable_ref || "-"}</td>
                    <td className="p-2">{l.payable_gl_account_id}</td>
                    <td className="p-2">{l.amount}</td>
                    <td className="p-2">{l.status}</td>
                    </tr>
                ))}
                </tbody>
            </table>
            </div>
        </div>

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Audit</h2>
            <div className="space-y-1 text-sm">
            {(batch.audit || []).map((a) => (
                <div key={a.id} className="border rounded p-2">
                <b>{a.action}</b> — {a.acted_at}
                </div>
            ))}
            </div>
        </div>

        {exportCsv ? (
            <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">CSV Preview</h2>
            <pre className="text-xs whitespace-pre-wrap">{exportCsv}</pre>
            </div>
        ) : null}
        </div>
    );
    }
    ```

    ---

    ## 14) App routes — `frontend/src/App.jsx`

    ```jsx
    // frontend/src/App.jsx
    import PaymentBatchListPage from "./pages/payments/PaymentBatchListPage.js";
    import PaymentBatchDetailPage from "./pages/payments/PaymentBatchDetailPage.js";

    // ...
    <Route
    path="/payments/batches"
    element={
        <RequirePermission anyOf={["payments.batch.read"]}>
        <PaymentBatchListPage />
        </RequirePermission>
    }
    />

    <Route
    path="/payments/batches/:id"
    element={
        <RequirePermission anyOf={["payments.batch.read"]}>
        <PaymentBatchDetailPage />
        </RequirePermission>
    }
    />
    ```

    > You can skip `/payments/batches/new` for now and create batches via API/manual test first, or add a simple create page later.

    ---

    ## 15) Sidebar — `frontend/src/layouts/sidebarConfig.js`

    ```js
    // frontend/src/layouts/sidebarConfig.js
    {
    key: "payments",
    label: "Payments",
    children: [
        {
        key: "payment-batches",
        label: "Payment Batches",
        to: "/payments/batches",
        requiredPermissions: ["payments.batch.read"],
        },
    ],
    }
    ```

    ---

    ## 16) i18n — `frontend/src/i18n/messages.js`

    ```js
    // frontend/src/i18n/messages.js
    export default {
    // ...
    "sidebar.payments": "Payments",
    "sidebar.paymentBatches": "Payment Batches",
    };
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ Can create generic payment batch with header + lines
    * ✅ Batch total is derived from line sums
    * ✅ Idempotent create via `idempotency_key`
    * ✅ Maker-checker approval enforced (optional strict creator≠approver in v1)
    * ✅ CSV export works and stores export metadata/checksum
    * ✅ Posting is idempotent and creates settlement journal (`Dr Payable / Cr Bank`)
    * ✅ Lines move `PENDING -> PAID` on post
    * ✅ Duplicate payable target protection prevents double-paying
    * ✅ Audit rows exist for all major actions
    * ✅ Permissions enforced (`payments.batch.*`)
    * ✅ OpenAPI updated
    * ✅ Smoke test script exists and runs

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:payments:prb04`

    Should verify at least:

    1. **Create success**

    * POST batch (MANUAL source, 2 lines) → `201`
    * `status=DRAFT`, `total_amount=sum(lines)`

    2. **Idempotent create**

    * same payload + same `idempotency_key` → returns same batch (not duplicate)

    3. **Approve**

    * POST `/approve` → `status=APPROVED`
    * repeat approve blocked (`400`)

    4. **Export CSV**

    * POST `/export` → `status=EXPORTED`
    * response contains `csv`, `checksum`, `file_name`

    5. **Post**

    * POST `/post` → `status=POSTED`
    * `posted_journal_entry_id` present
    * batch lines now `PAID`

    6. **Idempotent post**

    * POST `/post` again → same `posted_journal_entry_id`, no duplicate journal

    7. **Duplicate payable protection**

    * new batch using same `payable_entity_type + payable_entity_id` while active/posted should fail (`409`)

    8. **Audit**

    * GET `/batches/:id` returns audit including `CREATED/APPROVED/EXPORTED/POSTED`

    9. **Permissions**

    * missing `read/create/approve/export/post` permissions returns `403`

    ---

    # Example manual payloads

    ## Create payment batch (MANUAL)

    ```json
    {
    "source_type": "MANUAL",
    "source_id": null,
    "bank_account_id": 1,
    "currency_code": "USD",
    "idempotency_key": "manual-2026-02-25-batch-001",
    "notes": "Manual salary advance settlements",
    "lines": [
        {
        "beneficiary_type": "EMPLOYEE",
        "beneficiary_id": 101,
        "beneficiary_name": "Alice Doe",
        "beneficiary_bank_ref": "ALICE-IBAN-001",
        "payable_entity_type": "MANUAL",
        "payable_entity_id": 5001,
        "payable_gl_account_id": 210501,
        "payable_ref": "ADV-EMP-101",
        "amount": 500.00
        },
        {
        "beneficiary_type": "EMPLOYEE",
        "beneficiary_id": 102,
        "beneficiary_name": "Bob Doe",
        "beneficiary_bank_ref": "BOB-IBAN-002",
        "payable_entity_type": "MANUAL",
        "payable_entity_id": 5002,
        "payable_gl_account_id": 210501,
        "payable_ref": "ADV-EMP-102",
        "amount": 450.00
        }
    ]
    }
    ```

    ## Approve

    ```json
    {
    "note": "Approved for release"
    }
    ```

    ## Export

    ```json
    {
    "format": "CSV"
    }
    ```

    ## Post

    ```json
    {
    "note": "Posted after bank file release",
    "external_payment_ref_prefix": "AZIZI"
    }
    ```

    ---

    # Tiny implementation notes (important)

    * **Keep this generic** — payroll/AP will only *feed* batch lines later.
    * Posting in B04 is **GL settlement posting only**; actual bank statement reconciliation still happens in **B03**.
    * In **PR-P04**, payroll should call `createBatch()` with `source_type="PAYROLL"` and `payable_entity_type="PAYROLL_LIABILITY"`.
    * In **PR-P05**, reconciliation-to-payroll feedback will update payroll liability statuses when bank lines match posted payment batches.

    ---

    If you want, next I can do **PR-P01 (Payroll Import Foundation)** in the same format so it plugs into this payment engine cleanly.

---

## Payroll PR Steps

# PR-P01: Payroll Import Foundation (Provider CSV → Payroll Subledger Runs)

    ## Goal

    Add a **Payroll subledger import foundation** (no payroll calculation engine yet).

    This PR gives you:

    * ✅ Payroll run header + employee-level payroll lines
    * ✅ CSV import (provider/export file)
    * ✅ Idempotency by file checksum
    * ✅ Basic validation (gross/net consistency)
    * ✅ Payroll run list + detail UI
    * ❌ No GL accrual posting yet (that’s **PR-P02**)
    * ❌ No payment batch generation yet (that’s later payroll-payment PR using **B04**)

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m039_payroll_import_foundation.js`
    * `backend/src/routes/payroll.runs.js`
    * `backend/src/routes/payroll.runs.validators.js`
    * `backend/src/services/payroll.runs.service.js`
    * `backend/src/services/payroll.parsers.csv.js`
    * `backend/scripts/test-payroll-prp01-import.js`

    ### Frontend

    * `frontend/src/api/payrollRuns.js`
    * `frontend/src/pages/payroll/PayrollRunImportPage.jsx`
    * `frontend/src/pages/payroll/PayrollRunsPage.jsx`
    * `frontend/src/pages/payroll/PayrollRunDetailPage.jsx`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js` (permissions)
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/App.jsx`
    * `frontend/src/layouts/sidebarConfig.js`
    * `frontend/src/i18n/messages.js`

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m039_payroll_import_foundation.js`

    ```js
    // backend/src/migrations/m039_payroll_import_foundation.js

    export default {
    key: "m039_payroll_import_foundation",
    description: "m039_payroll_import_foundation",
    async up(connection) {
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_runs (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            run_no VARCHAR(50) NOT NULL,
            provider_code VARCHAR(50) NOT NULL,            -- e.g. OUTSOURCED_PAYROLL_X
            entity_code VARCHAR(50) NOT NULL,              -- legal entity code (string for v1)
            payroll_period DATE NOT NULL,                  -- use period start date (YYYY-MM-01)
            pay_date DATE NOT NULL,
            currency_code CHAR(3) NOT NULL,
            source_batch_ref VARCHAR(100) NULL,
            original_filename VARCHAR(255) NOT NULL,
            file_checksum CHAR(64) NOT NULL,
            status VARCHAR(20) NOT NULL DEFAULT 'IMPORTED', -- IMPORTED, REVIEWED, FINALIZED (later PRs)
            line_count_total INT UNSIGNED NOT NULL DEFAULT 0,
            line_count_inserted INT UNSIGNED NOT NULL DEFAULT 0,
            line_count_duplicates INT UNSIGNED NOT NULL DEFAULT 0,
            employee_count INT UNSIGNED NOT NULL DEFAULT 0,

            total_base_salary DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_overtime_pay DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_bonus_pay DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_allowances DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_gross_pay DECIMAL(18,2) NOT NULL DEFAULT 0,

            total_employee_tax DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_employee_social_security DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_other_deductions DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_net_pay DECIMAL(18,2) NOT NULL DEFAULT 0,

            total_employer_tax DECIMAL(18,2) NOT NULL DEFAULT 0,
            total_employer_social_security DECIMAL(18,2) NOT NULL DEFAULT 0,

            raw_meta_json JSON NULL,
            imported_by BIGINT UNSIGNED NULL,
            imported_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

            PRIMARY KEY (id),
            UNIQUE KEY uq_payroll_runs_run_no (run_no),
            UNIQUE KEY uq_payroll_runs_checksum (entity_code, payroll_period, provider_code, file_checksum),
            KEY idx_payroll_runs_period (payroll_period),
            KEY idx_payroll_runs_entity (entity_code),
            KEY idx_payroll_runs_status (status),
            KEY idx_payroll_runs_imported_at (imported_at)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_run_lines (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            run_id BIGINT UNSIGNED NOT NULL,
            line_no INT UNSIGNED NOT NULL,

            employee_code VARCHAR(100) NOT NULL,
            employee_name VARCHAR(255) NOT NULL,
            cost_center_code VARCHAR(100) NULL,

            base_salary DECIMAL(18,2) NOT NULL DEFAULT 0,
            overtime_pay DECIMAL(18,2) NOT NULL DEFAULT 0,
            bonus_pay DECIMAL(18,2) NOT NULL DEFAULT 0,
            allowances_total DECIMAL(18,2) NOT NULL DEFAULT 0,
            gross_pay DECIMAL(18,2) NOT NULL DEFAULT 0,

            employee_tax DECIMAL(18,2) NOT NULL DEFAULT 0,
            employee_social_security DECIMAL(18,2) NOT NULL DEFAULT 0,
            other_deductions DECIMAL(18,2) NOT NULL DEFAULT 0,
            net_pay DECIMAL(18,2) NOT NULL DEFAULT 0,

            employer_tax DECIMAL(18,2) NOT NULL DEFAULT 0,
            employer_social_security DECIMAL(18,2) NOT NULL DEFAULT 0,

            line_hash CHAR(64) NOT NULL,
            raw_row_json JSON NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

            PRIMARY KEY (id),
            UNIQUE KEY uq_payroll_run_lines_run_lineno (run_id, line_no),
            UNIQUE KEY uq_payroll_run_lines_run_hash (run_id, line_hash),
            KEY idx_payroll_run_lines_run (run_id),
            KEY idx_payroll_run_lines_employee (employee_code),
            KEY idx_payroll_run_lines_cost_center (cost_center_code),

            CONSTRAINT fk_payroll_run_lines_run
            FOREIGN KEY (run_id) REFERENCES payroll_runs(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_run_audit (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            run_id BIGINT UNSIGNED NOT NULL,
            action VARCHAR(30) NOT NULL,  -- IMPORTED, STATUS, VALIDATION
            payload_json JSON NULL,
            acted_by BIGINT UNSIGNED NULL,
            acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

            PRIMARY KEY (id),
            KEY idx_payroll_run_audit_run (run_id),
            KEY idx_payroll_run_audit_action (action),

            CONSTRAINT fk_payroll_run_audit_run
            FOREIGN KEY (run_id) REFERENCES payroll_runs(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);
    },

    async down(connection) {
        await connection.execute(`DROP TABLE IF EXISTS payroll_run_audit;`);
        await connection.execute(`DROP TABLE IF EXISTS payroll_run_lines;`);
        await connection.execute(`DROP TABLE IF EXISTS payroll_runs;`);
    },
    };
    ```

    ---

    ## 2) CSV parser — `backend/src/services/payroll.parsers.csv.js`

    > v1 CSV format is fixed (provider export normalized to this schema):

    **Header (required):**
    `employee_code,employee_name,cost_center_code,base_salary,overtime_pay,bonus_pay,allowances_total,gross_pay,employee_tax,employee_social_security,other_deductions,employer_tax,employer_social_security,net_pay`

    ```js
    // backend/src/services/payroll.parsers.csv.js

    function parseCsvLine(line) {
    const out = [];
    let cur = "";
    let inQuotes = false;

    for (let i = 0; i < line.length; i += 1) {
        const ch = line[i];

        if (ch === '"') {
        if (inQuotes && line[i + 1] === '"') {
            cur += '"';
            i += 1;
        } else {
            inQuotes = !inQuotes;
        }
        continue;
        }

        if (ch === "," && !inQuotes) {
        out.push(cur);
        cur = "";
        continue;
        }

        cur += ch;
    }

    out.push(cur);
    return out.map((s) => s.trim());
    }

    function parseMoney(value, fieldName) {
    const n = Number(String(value ?? "").replace(/,/g, ""));
    if (!Number.isFinite(n)) throw new Error(`${fieldName} is invalid number`);
    return Number(n.toFixed(2));
    }

    function parsePayrollCsv(csvText) {
    const text = String(csvText || "").replace(/\r\n/g, "\n").trim();
    if (!text) throw new Error("CSV is empty");

    const lines = text.split("\n").filter(Boolean);
    if (lines.length < 2) throw new Error("CSV must include header and at least one row");

    const header = parseCsvLine(lines[0]).map((x) => x.toLowerCase());
    const required = [
        "employee_code",
        "employee_name",
        "cost_center_code",
        "base_salary",
        "overtime_pay",
        "bonus_pay",
        "allowances_total",
        "gross_pay",
        "employee_tax",
        "employee_social_security",
        "other_deductions",
        "employer_tax",
        "employer_social_security",
        "net_pay",
    ];

    for (const c of required) {
        if (!header.includes(c)) throw new Error(`Missing CSV column: ${c}`);
    }

    const idx = Object.fromEntries(required.map((c) => [c, header.indexOf(c)]));
    const rows = [];

    for (let i = 1; i < lines.length; i += 1) {
        const cols = parseCsvLine(lines[i]);
        if (cols.every((c) => c === "")) continue;

        const raw = {};
        for (const c of required) raw[c] = cols[idx[c]] ?? "";

        const employee_code = String(raw.employee_code || "").trim();
        const employee_name = String(raw.employee_name || "").trim();
        const cost_center_code = String(raw.cost_center_code || "").trim() || null;

        if (!employee_code) throw new Error(`Row ${i + 1}: employee_code is required`);
        if (!employee_name) throw new Error(`Row ${i + 1}: employee_name is required`);

        const row = {
        line_no: i,
        employee_code,
        employee_name,
        cost_center_code,

        base_salary: parseMoney(raw.base_salary, `Row ${i + 1} base_salary`),
        overtime_pay: parseMoney(raw.overtime_pay, `Row ${i + 1} overtime_pay`),
        bonus_pay: parseMoney(raw.bonus_pay, `Row ${i + 1} bonus_pay`),
        allowances_total: parseMoney(raw.allowances_total, `Row ${i + 1} allowances_total`),
        gross_pay: parseMoney(raw.gross_pay, `Row ${i + 1} gross_pay`),

        employee_tax: parseMoney(raw.employee_tax, `Row ${i + 1} employee_tax`),
        employee_social_security: parseMoney(raw.employee_social_security, `Row ${i + 1} employee_social_security`),
        other_deductions: parseMoney(raw.other_deductions, `Row ${i + 1} other_deductions`),
        net_pay: parseMoney(raw.net_pay, `Row ${i + 1} net_pay`),

        employer_tax: parseMoney(raw.employer_tax, `Row ${i + 1} employer_tax`),
        employer_social_security: parseMoney(raw.employer_social_security, `Row ${i + 1} employer_social_security`),

        raw_row_json: raw,
        };

        // Basic consistency checks (tolerant for rounding)
        const grossExpected = Number(
        (row.base_salary + row.overtime_pay + row.bonus_pay + row.allowances_total).toFixed(2)
        );
        const netExpected = Number(
        (row.gross_pay - row.employee_tax - row.employee_social_security - row.other_deductions).toFixed(2)
        );

        if (Math.abs(grossExpected - row.gross_pay) > 0.05) {
        throw new Error(`Row ${i + 1}: gross_pay mismatch (expected ${grossExpected}, got ${row.gross_pay})`);
        }
        if (Math.abs(netExpected - row.net_pay) > 0.05) {
        throw new Error(`Row ${i + 1}: net_pay mismatch (expected ${netExpected}, got ${row.net_pay})`);
        }

        rows.push(row);
    }

    if (!rows.length) throw new Error("CSV has no valid rows");
    return rows;
    }

    export default {
    parsePayrollCsv,
    };
    ```

    ---

    ## 3) Validators — `backend/src/routes/payroll.runs.validators.js`

    ```js
    // backend/src/routes/payroll.runs.validators.js

    function requirePositiveInt(value, fieldName) {
    const n = Number(value);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${fieldName} must be positive integer`);
    return n;
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function requireDate(value, fieldName) {
    const s = String(value || "").trim();
    if (!/^\d{4}-\d{2}-\d{2}$/.test(s)) throw new Error(`${fieldName} must be YYYY-MM-DD`);
    return s;
    }

    function requireCurrency(value) {
    const s = String(value || "").trim().toUpperCase();
    if (!/^[A-Z]{3}$/.test(s)) throw new Error("currency_code must be 3 letters");
    return s;
    }

    function validateImportRequest(req) {
    const entity_code = String(req.body?.entity_code || "").trim();
    const provider_code = String(req.body?.provider_code || "").trim().toUpperCase();
    const payroll_period = requireDate(req.body?.payroll_period, "payroll_period");
    const pay_date = requireDate(req.body?.pay_date, "pay_date");
    const currency_code = requireCurrency(req.body?.currency_code);

    if (!entity_code) throw new Error("entity_code is required");
    if (!provider_code) throw new Error("provider_code is required");

    const original_filename =
        req.file?.originalname || normalizeString(req.body?.original_filename) || "payroll.csv";

    const csvText =
        req.file?.buffer?.toString("utf8") ||
        (typeof req.body?.csv_text === "string" ? req.body.csv_text : null);

    if (!csvText) throw new Error("CSV file or csv_text is required");

    return {
        entity_code,
        provider_code,
        payroll_period,
        pay_date,
        currency_code,
        source_batch_ref: normalizeString(req.body?.source_batch_ref),
        original_filename,
        csv_text: csvText,
    };
    }

    function validateIdParam(params = {}) {
    return { id: requirePositiveInt(params.id, "id") };
    }

    function validateListRunsQuery(query = {}) {
    return {
        entity_code: normalizeString(query.entity_code),
        provider_code: normalizeString(query.provider_code)?.toUpperCase() || null,
        payroll_period: query.payroll_period ? requireDate(query.payroll_period, "payroll_period") : null,
        status: normalizeString(query.status)?.toUpperCase() || null,
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 200) : 50,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    function validateListRunLinesQuery(query = {}) {
    return {
        q: normalizeString(query.q),
        cost_center_code: normalizeString(query.cost_center_code),
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 500) : 200,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    export default {
    validateImportRequest,
    validateIdParam,
    validateListRunsQuery,
    validateListRunLinesQuery,
    };
    ```

    ---

    ## 4) Service — `backend/src/services/payroll.runs.service.js`

    ```js
    // backend/src/services/payroll.runs.service.js

    import crypto from "crypto";
    import { parsePayrollCsv } from "./payroll.parsers.csv.js";
    function sha256(v) {
    return crypto.createHash("sha256").update(String(v)).digest("hex");
    }

    function normalizeHashPart(v) {
    if (v === null || v === undefined) return "";
    return String(v).trim().toUpperCase();
    }

    function buildLineHash(runHeader, row) {
    const key = [
        runHeader.entity_code,
        runHeader.provider_code,
        runHeader.payroll_period,
        row.employee_code,
        row.employee_name,
        row.cost_center_code || "",
        row.gross_pay.toFixed(2),
        row.net_pay.toFixed(2),
        row.employee_tax.toFixed(2),
        row.employee_social_security.toFixed(2),
        row.employer_tax.toFixed(2),
        row.employer_social_security.toFixed(2),
    ].join("|");

    return sha256(key);
    }

    async function writeAudit(db, runId, action, payload, userId = null) {
    await db.query(
        `INSERT INTO payroll_run_audit (run_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
        [runId, action, payload ? JSON.stringify(payload) : null, userId]
    );
    }

    async function nextRunNo(db, payrollPeriod) {
    const yyyymm = String(payrollPeriod).slice(0, 7).replace("-", "");
    const [rows] = await db.query(`SELECT COALESCE(MAX(id),0)+1 AS next_id FROM payroll_runs`);
    const n = Number(rows[0]?.next_id || 1);
    return `PR-${yyyymm}-${String(n).padStart(6, "0")}`;
    }

    function zeroTotals() {
    return {
        total_base_salary: 0,
        total_overtime_pay: 0,
        total_bonus_pay: 0,
        total_allowances: 0,
        total_gross_pay: 0,
        total_employee_tax: 0,
        total_employee_social_security: 0,
        total_other_deductions: 0,
        total_net_pay: 0,
        total_employer_tax: 0,
        total_employer_social_security: 0,
    };
    }

    function accumulateTotals(t, row) {
    t.total_base_salary += Number(row.base_salary);
    t.total_overtime_pay += Number(row.overtime_pay);
    t.total_bonus_pay += Number(row.bonus_pay);
    t.total_allowances += Number(row.allowances_total);
    t.total_gross_pay += Number(row.gross_pay);

    t.total_employee_tax += Number(row.employee_tax);
    t.total_employee_social_security += Number(row.employee_social_security);
    t.total_other_deductions += Number(row.other_deductions);
    t.total_net_pay += Number(row.net_pay);

    t.total_employer_tax += Number(row.employer_tax);
    t.total_employer_social_security += Number(row.employer_social_security);
    }

    function roundTotals(t) {
    const out = {};
    for (const [k, v] of Object.entries(t)) out[k] = Number(v.toFixed(2));
    return out;
    }

    async function getRunById(db, id) {
    const [rows] = await db.query(
        `
        SELECT *
        FROM payroll_runs
        WHERE id = ?
        LIMIT 1
        `,
        [id]
    );
    return rows[0] || null;
    }

    async function listRuns(db, query) {
    const where = [];
    const params = [];

    if (query.entity_code) {
        where.push(`entity_code = ?`);
        params.push(query.entity_code);
    }
    if (query.provider_code) {
        where.push(`provider_code = ?`);
        params.push(query.provider_code);
    }
    if (query.payroll_period) {
        where.push(`payroll_period = ?`);
        params.push(query.payroll_period);
    }
    if (query.status) {
        where.push(`status = ?`);
        params.push(query.status);
    }

    let sql = `
        SELECT
        id, run_no, provider_code, entity_code, payroll_period, pay_date, currency_code,
        status, line_count_total, line_count_inserted, line_count_duplicates, employee_count,
        total_gross_pay, total_net_pay, total_employee_tax, total_employee_social_security,
        total_employer_tax, total_employer_social_security,
        imported_at
        FROM payroll_runs
    `;

    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY payroll_period DESC, id DESC LIMIT ? OFFSET ?`;
    params.push(query.limit, query.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function listRunLines(db, runId, query) {
    const where = [`run_id = ?`];
    const params = [runId];

    if (query.q) {
        where.push(`(employee_code LIKE ? OR employee_name LIKE ?)`);
        params.push(`%${query.q}%`, `%${query.q}%`);
    }
    if (query.cost_center_code) {
        where.push(`cost_center_code = ?`);
        params.push(query.cost_center_code);
    }

    let sql = `
        SELECT
        id, run_id, line_no, employee_code, employee_name, cost_center_code,
        base_salary, overtime_pay, bonus_pay, allowances_total, gross_pay,
        employee_tax, employee_social_security, other_deductions, net_pay,
        employer_tax, employer_social_security
        FROM payroll_run_lines
        WHERE ${where.join(" AND ")}
        ORDER BY line_no ASC
        LIMIT ? OFFSET ?
    `;
    params.push(query.limit, query.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function listRunAudit(db, runId) {
    const [rows] = await db.query(
        `
        SELECT id, action, payload_json, acted_by, acted_at
        FROM payroll_run_audit
        WHERE run_id = ?
        ORDER BY id DESC
        `,
        [runId]
    );
    return rows;
    }

    async function importPayrollRunCsv(db, payload, userId = null) {
    const fileChecksum = sha256(payload.csv_text);

    const [dupRows] = await db.query(
        `
        SELECT id
        FROM payroll_runs
        WHERE entity_code = ?
        AND payroll_period = ?
        AND provider_code = ?
        AND file_checksum = ?
        LIMIT 1
        `,
        [payload.entity_code, payload.payroll_period, payload.provider_code, fileChecksum]
    );

    if (dupRows[0]) {
        const err = new Error("This payroll file was already imported for the same entity/period/provider");
        err.statusCode = 409;
        throw err;
    }

    const parsedRows = parsePayrollCsv(payload.csv_text);
    const runNo = await nextRunNo(db, payload.payroll_period);

    const conn = db.getConnection ? await db.getConnection() : null;
    const q = conn || db;

    try {
        if (conn) await conn.beginTransaction();

        const [insRun] = await q.query(
        `
        INSERT INTO payroll_runs
        (run_no, provider_code, entity_code, payroll_period, pay_date, currency_code,
        source_batch_ref, original_filename, file_checksum, status, raw_meta_json, imported_by)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, 'IMPORTED', ?, ?)
        `,
        [
            runNo,
            payload.provider_code,
            payload.entity_code,
            payload.payroll_period,
            payload.pay_date,
            payload.currency_code,
            payload.source_batch_ref || null,
            payload.original_filename,
            fileChecksum,
            JSON.stringify({ parser: "payroll-csv-v1" }),
            userId,
        ]
        );

        const runId = insRun.insertId;

        let inserted = 0;
        let duplicates = 0;
        const totals = zeroTotals();
        const employeeCodes = new Set();

        for (const row of parsedRows) {
        const lineHash = buildLineHash(payload, row);

        try {
            await q.query(
            `
            INSERT INTO payroll_run_lines
            (run_id, line_no, employee_code, employee_name, cost_center_code,
            base_salary, overtime_pay, bonus_pay, allowances_total, gross_pay,
            employee_tax, employee_social_security, other_deductions, net_pay,
            employer_tax, employer_social_security, line_hash, raw_row_json)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            `,
            [
                runId,
                row.line_no,
                row.employee_code,
                row.employee_name,
                row.cost_center_code,
                row.base_salary,
                row.overtime_pay,
                row.bonus_pay,
                row.allowances_total,
                row.gross_pay,
                row.employee_tax,
                row.employee_social_security,
                row.other_deductions,
                row.net_pay,
                row.employer_tax,
                row.employer_social_security,
                lineHash,
                JSON.stringify(row.raw_row_json || null),
            ]
            );

            inserted += 1;
            employeeCodes.add(row.employee_code);
            accumulateTotals(totals, row);
        } catch (e) {
            if (e && e.code === "ER_DUP_ENTRY") {
            duplicates += 1;
            continue;
            }
            throw e;
        }
        }

        const rt = roundTotals(totals);

        await q.query(
        `
        UPDATE payroll_runs
        SET line_count_total = ?,
            line_count_inserted = ?,
            line_count_duplicates = ?,
            employee_count = ?,
            total_base_salary = ?,
            total_overtime_pay = ?,
            total_bonus_pay = ?,
            total_allowances = ?,
            total_gross_pay = ?,
            total_employee_tax = ?,
            total_employee_social_security = ?,
            total_other_deductions = ?,
            total_net_pay = ?,
            total_employer_tax = ?,
            total_employer_social_security = ?,
            raw_meta_json = JSON_SET(
                COALESCE(raw_meta_json, JSON_OBJECT()),
                '$.inserted', ?,
                '$.duplicates', ?,
                '$.employee_count', ?
            )
        WHERE id = ?
        `,
        [
            parsedRows.length,
            inserted,
            duplicates,
            employeeCodes.size,
            rt.total_base_salary,
            rt.total_overtime_pay,
            rt.total_bonus_pay,
            rt.total_allowances,
            rt.total_gross_pay,
            rt.total_employee_tax,
            rt.total_employee_social_security,
            rt.total_other_deductions,
            rt.total_net_pay,
            rt.total_employer_tax,
            rt.total_employer_social_security,
            inserted,
            duplicates,
            employeeCodes.size,
            runId,
        ]
        );

        await writeAudit(q, runId, "IMPORTED", {
        line_count_total: parsedRows.length,
        line_count_inserted: inserted,
        line_count_duplicates: duplicates,
        employee_count: employeeCodes.size,
        }, userId);

        if (conn) await conn.commit();

        return getRunById(db, runId);
    } catch (err) {
        if (conn) {
        try { await conn.rollback(); } catch (_) {}
        }
        throw err;
    } finally {
        if (conn) conn.release();
    }
    }

    export default {
    importPayrollRunCsv,
    listRuns,
    getRunById,
    listRunLines,
    listRunAudit,
    };
    ```

    ---

    ## 5) Routes — `backend/src/routes/payroll.runs.js`

    ```js
    // backend/src/routes/payroll.runs.js

    import express from "express";
    import multer from "multer";
    import { validateImportRequest,
    validateIdParam,
    validateListRunsQuery,
    validateListRunLinesQuery, } from "./payroll.runs.validators.js";
    import service from "../services/payroll.runs.service.js";
    // Replace with your project helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();
    const upload = multer({ storage: multer.memoryStorage() });

    // POST /api/v1/payroll/runs/import
    router.post(
    "/runs/import",
    requireAuth,
    requirePermission("payroll.runs.import"),
    upload.single("file"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const payload = validateImportRequest(req);
        const userId = req.user?.id ?? null;
        const row = await service.importPayrollRunCsv(db, payload, userId);
        res.status(201).json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/payroll/runs
    router.get(
    "/runs",
    requireAuth,
    requirePermission("payroll.runs.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateListRunsQuery(req.query);
        const items = await service.listRuns(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/payroll/runs/:id
    router.get(
    "/runs/:id",
    requireAuth,
    requirePermission("payroll.runs.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);

        const run = await service.getRunById(db, id);
        if (!run) return res.status(404).json({ error: "Not found" });

        const [lines, audit] = await Promise.all([
            service.listRunLines(db, id, { q: null, cost_center_code: null, limit: 500, offset: 0 }),
            service.listRunAudit(db, id),
        ]);

        res.json({ ...run, lines, audit });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/payroll/runs/:id/lines
    router.get(
    "/runs/:id/lines",
    requireAuth,
    requirePermission("payroll.runs.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateIdParam(req.params);
        const q = validateListRunLinesQuery(req.query);

        const run = await service.getRunById(db, id);
        if (!run) return res.status(404).json({ error: "Not found" });

        const items = await service.listRunLines(db, id, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 6) Mount route — `backend/src/index.js`

    ```js
    // backend/src/index.js
    import payrollRunsRoutes from "./routes/payroll.runs.js";
    // ...
    app.use("/api/v1/payroll", payrollRunsRoutes);
    ```

    ---

    ## 7) Migration registry — `backend/src/migrations/index.js`

    ```js
    // backend/src/migrations/index.js
    import m039_payroll_import_foundation from "./m039_payroll_import_foundation.js";
    export default [
    // ...
    m039_payroll_import_foundation,
    ];
    ```

    ---

    ## 8) Seed permissions — `backend/src/seedCore.js`

    ```js
    // backend/src/seedCore.js
    const PAYROLL_PERMISSIONS = [
    "payroll.runs.read",
    "payroll.runs.import",
    ];

    // merge into your permissions seed list
    ```

    ---

    ## 9) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Register these paths:

    * `POST /api/v1/payroll/runs/import`
    * `GET /api/v1/payroll/runs`
    * `GET /api/v1/payroll/runs/{id}`
    * `GET /api/v1/payroll/runs/{id}/lines`

    ---

    ## 10) Backend smoke test — `backend/scripts/test-payroll-prp01-import.js`

    > Make this a real `supertest` script in your project style.
    > Here’s the exact behavior to test.

    ```js
    // backend/scripts/test-payroll-prp01-import.js

    async function main() {
    // Flow:
    // 1) Build a valid payroll CSV (2-3 rows)
    // 2) POST /api/v1/payroll/runs/import with:
    //    entity_code, provider_code, payroll_period, pay_date, currency_code, csv_text
    //    -> expect 201, status=IMPORTED
    // 3) GET /api/v1/payroll/runs -> imported run appears
    // 4) GET /api/v1/payroll/runs/:id -> returns header + lines + audit
    // 5) Re-import same file same entity/period/provider -> 409 checksum idempotency
    // 6) Import invalid CSV (gross/net mismatch) -> 400 validation error
    // 7) Permission checks -> payroll.runs.read / payroll.runs.import enforced (403)
    console.log("PR-P01 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    ---

    ## 11) `backend/package.json` updates

    ```json
    {
    "scripts": {
        "test:payroll:prp01": "node backend/scripts/test-payroll-prp01-import.js"
    }
    }
    ```

    ---

    # Frontend skeletons

    ## 12) API client — `frontend/src/api/payrollRuns.js`

    ```js
    // frontend/src/api/payrollRuns.js

    import { apiFetch } from "./client.js"; // adapt to your helper

    export function importPayrollRun({ file, csv_text, ...meta }) {
    if (file) {
        const form = new FormData();
        Object.entries(meta).forEach(([k, v]) => {
        if (v !== undefined && v !== null) form.append(k, String(v));
        });
        form.append("file", file);

        return apiFetch(`/api/v1/payroll/runs/import`, {
        method: "POST",
        body: form,
        });
    }

    return apiFetch(`/api/v1/payroll/runs/import`, {
        method: "POST",
        body: JSON.stringify({ ...meta, csv_text }),
    });
    }

    export function listPayrollRuns(params = {}) {
    const q = new URLSearchParams();
    if (params.entity_code) q.set("entity_code", params.entity_code);
    if (params.provider_code) q.set("provider_code", params.provider_code);
    if (params.payroll_period) q.set("payroll_period", params.payroll_period);
    if (params.status) q.set("status", params.status);
    const qs = q.toString();
    return apiFetch(`/api/v1/payroll/runs${qs ? `?${qs}` : ""}`);
    }

    export function getPayrollRun(id) {
    return apiFetch(`/api/v1/payroll/runs/${id}`);
    }

    export function listPayrollRunLines(id, params = {}) {
    const q = new URLSearchParams();
    if (params.q) q.set("q", params.q);
    if (params.cost_center_code) q.set("cost_center_code", params.cost_center_code);
    const qs = q.toString();
    return apiFetch(`/api/v1/payroll/runs/${id}/lines${qs ? `?${qs}` : ""}`);
    }
    ```

    ---

    ## 13) Import page — `frontend/src/pages/payroll/PayrollRunImportPage.jsx`

    ```jsx
    // frontend/src/pages/payroll/PayrollRunImportPage.jsx

    import { useState } from "react";
    import { importPayrollRun } from "../../api/payrollRuns.js";

    export default function PayrollRunImportPage() {
    const [form, setForm] = useState({
        entity_code: "",
        provider_code: "PROVIDER_X",
        payroll_period: "",
        pay_date: "",
        currency_code: "USD",
        source_batch_ref: "",
    });
    const [file, setFile] = useState(null);
    const [result, setResult] = useState(null);
    const [err, setErr] = useState("");
    const [submitting, setSubmitting] = useState(false);

    async function onSubmit(e) {
        e.preventDefault();
        setErr("");
        setResult(null);

        try {
        if (!form.entity_code) throw new Error("Entity code is required");
        if (!form.payroll_period) throw new Error("Payroll period is required");
        if (!form.pay_date) throw new Error("Pay date is required");
        if (!file) throw new Error("CSV file is required");

        setSubmitting(true);
        const res = await importPayrollRun({ ...form, file });
        setResult(res);
        } catch (e) {
        setErr(e.message || "Import failed");
        } finally {
        setSubmitting(false);
        }
    }

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <h1 className="text-lg font-semibold mb-3">Payroll Import</h1>

            {err ? <div className="text-sm text-red-600 mb-2">{err}</div> : null}

            <form className="grid grid-cols-1 md:grid-cols-3 gap-2" onSubmit={onSubmit}>
            <input
                className="border rounded px-2 py-1"
                placeholder="Entity Code"
                value={form.entity_code}
                onChange={(e) => setForm((s) => ({ ...s, entity_code: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="Provider Code"
                value={form.provider_code}
                onChange={(e) => setForm((s) => ({ ...s, provider_code: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="Currency"
                value={form.currency_code}
                onChange={(e) => setForm((s) => ({ ...s, currency_code: e.target.value }))}
            />

            <input
                className="border rounded px-2 py-1"
                type="date"
                value={form.payroll_period}
                onChange={(e) => setForm((s) => ({ ...s, payroll_period: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                type="date"
                value={form.pay_date}
                onChange={(e) => setForm((s) => ({ ...s, pay_date: e.target.value }))}
            />
            <input
                className="border rounded px-2 py-1"
                placeholder="Source Batch Ref (optional)"
                value={form.source_batch_ref}
                onChange={(e) => setForm((s) => ({ ...s, source_batch_ref: e.target.value }))}
            />

            <div className="md:col-span-3">
                <input
                className="block"
                type="file"
                accept=".csv,text/csv"
                onChange={(e) => setFile(e.target.files?.[0] || null)}
                />
            </div>

            <div className="md:col-span-3">
                <button
                type="submit"
                className="px-3 py-1 rounded bg-black text-white disabled:opacity-50"
                disabled={submitting}
                >
                {submitting ? "Importing..." : "Import Payroll CSV"}
                </button>
            </div>
            </form>
        </div>

        {result ? (
            <div className="rounded border bg-white p-4 text-sm">
            <div className="font-medium mb-2">Import Result</div>
            <div>Run No: {result.run_no}</div>
            <div>Status: {result.status}</div>
            <div>Employees: {result.employee_count}</div>
            <div>Gross: {result.total_gross_pay}</div>
            <div>Net: {result.total_net_pay}</div>
            </div>
        ) : null}
        </div>
    );
    }
    ```

    ---

    ## 14) Runs list page — `frontend/src/pages/payroll/PayrollRunsPage.jsx`

    ```jsx
    // frontend/src/pages/payroll/PayrollRunsPage.jsx

    import { useEffect, useState } from "react";
    import { Link } from "react-router-dom";
    import { listPayrollRuns } from "../../api/payrollRuns.js";

    export default function PayrollRunsPage() {
    const [items, setItems] = useState([]);
    const [err, setErr] = useState("");
    const [loading, setLoading] = useState(false);

    async function load() {
        setLoading(true);
        setErr("");
        try {
        const res = await listPayrollRuns({});
        setItems(res.items || []);
        } catch (e) {
        setErr(e.message || "Failed to load payroll runs");
        } finally {
        setLoading(false);
        }
    }

    useEffect(() => {
        load();
    }, []);

    return (
        <div className="p-4">
        <div className="rounded border bg-white p-4">
            <div className="flex items-center mb-3">
            <h1 className="text-lg font-semibold">Payroll Runs</h1>
            <Link className="ml-auto underline" to="/payroll/runs/import">
                Import Run
            </Link>
            </div>

            {err ? <div className="text-sm text-red-600 mb-2">{err}</div> : null}

            {loading ? (
            <div>Loading...</div>
            ) : (
            <div className="overflow-auto">
                <table className="min-w-full text-sm border-collapse">
                <thead>
                    <tr className="border-b">
                    <th className="text-left p-2">Run No</th>
                    <th className="text-left p-2">Entity</th>
                    <th className="text-left p-2">Period</th>
                    <th className="text-left p-2">Pay Date</th>
                    <th className="text-left p-2">Employees</th>
                    <th className="text-left p-2">Gross</th>
                    <th className="text-left p-2">Net</th>
                    <th className="text-left p-2">Status</th>
                    </tr>
                </thead>
                <tbody>
                    {items.map((r) => (
                    <tr key={r.id} className="border-b">
                        <td className="p-2">
                        <Link className="underline" to={`/payroll/runs/${r.id}`}>
                            {r.run_no}
                        </Link>
                        </td>
                        <td className="p-2">{r.entity_code}</td>
                        <td className="p-2">{r.payroll_period}</td>
                        <td className="p-2">{r.pay_date}</td>
                        <td className="p-2">{r.employee_count}</td>
                        <td className="p-2">{r.total_gross_pay}</td>
                        <td className="p-2">{r.total_net_pay}</td>
                        <td className="p-2">{r.status}</td>
                    </tr>
                    ))}
                    {items.length === 0 && (
                    <tr>
                        <td className="p-2" colSpan={8}>
                        No payroll runs yet.
                        </td>
                    </tr>
                    )}
                </tbody>
                </table>
            </div>
            )}
        </div>
        </div>
    );
    }
    ```

    ---

    ## 15) Run detail page — `frontend/src/pages/payroll/PayrollRunDetailPage.jsx`

    ```jsx
    // frontend/src/pages/payroll/PayrollRunDetailPage.jsx

    import { useEffect, useState } from "react";
    import { useParams } from "react-router-dom";
    import { getPayrollRun } from "../../api/payrollRuns.js";

    export default function PayrollRunDetailPage() {
    const { id } = useParams();
    const [run, setRun] = useState(null);
    const [err, setErr] = useState("");

    async function load() {
        setErr("");
        try {
        const res = await getPayrollRun(id);
        setRun(res);
        } catch (e) {
        setErr(e.message || "Failed to load payroll run");
        }
    }

    useEffect(() => {
        load();
    }, [id]);

    if (err) return <div className="p-4 text-red-600">{err}</div>;
    if (!run) return <div className="p-4">Loading...</div>;

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <div className="flex items-center gap-2">
            <h1 className="text-lg font-semibold">{run.run_no}</h1>
            <span className="text-sm border rounded px-2 py-0.5">{run.status}</span>
            </div>

            <div className="grid grid-cols-2 md:grid-cols-4 gap-2 mt-3 text-sm">
            <div><b>Entity:</b> {run.entity_code}</div>
            <div><b>Provider:</b> {run.provider_code}</div>
            <div><b>Period:</b> {run.payroll_period}</div>
            <div><b>Pay Date:</b> {run.pay_date}</div>
            <div><b>Currency:</b> {run.currency_code}</div>
            <div><b>Employees:</b> {run.employee_count}</div>
            <div><b>Gross:</b> {run.total_gross_pay}</div>
            <div><b>Net:</b> {run.total_net_pay}</div>
            </div>
        </div>

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Employees</h2>
            <div className="overflow-auto">
            <table className="min-w-full text-sm border-collapse">
                <thead>
                <tr className="border-b">
                    <th className="text-left p-2">#</th>
                    <th className="text-left p-2">Employee</th>
                    <th className="text-left p-2">Cost Center</th>
                    <th className="text-left p-2">Gross</th>
                    <th className="text-left p-2">Net</th>
                    <th className="text-left p-2">Emp Tax</th>
                    <th className="text-left p-2">Emp SS</th>
                    <th className="text-left p-2">Employer Tax</th>
                    <th className="text-left p-2">Employer SS</th>
                </tr>
                </thead>
                <tbody>
                {(run.lines || []).map((l) => (
                    <tr key={l.id} className="border-b">
                    <td className="p-2">{l.line_no}</td>
                    <td className="p-2">{l.employee_code} - {l.employee_name}</td>
                    <td className="p-2">{l.cost_center_code || "-"}</td>
                    <td className="p-2">{l.gross_pay}</td>
                    <td className="p-2">{l.net_pay}</td>
                    <td className="p-2">{l.employee_tax}</td>
                    <td className="p-2">{l.employee_social_security}</td>
                    <td className="p-2">{l.employer_tax}</td>
                    <td className="p-2">{l.employer_social_security}</td>
                    </tr>
                ))}
                {(run.lines || []).length === 0 && (
                    <tr><td className="p-2" colSpan={9}>No lines.</td></tr>
                )}
                </tbody>
            </table>
            </div>
        </div>

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Audit</h2>
            <div className="space-y-1 text-sm">
            {(run.audit || []).map((a) => (
                <div key={a.id} className="border rounded p-2">
                <b>{a.action}</b> — {a.acted_at}
                </div>
            ))}
            {(run.audit || []).length === 0 && <div>No audit rows yet.</div>}
            </div>
        </div>
        </div>
    );
    }
    ```

    ---

    ## 16) App routes — `frontend/src/App.jsx`

    ```jsx
    // frontend/src/App.jsx
    import PayrollRunImportPage from "./pages/payroll/PayrollRunImportPage.js";
    import PayrollRunsPage from "./pages/payroll/PayrollRunsPage.js";
    import PayrollRunDetailPage from "./pages/payroll/PayrollRunDetailPage.js";

    // ...
    <Route
    path="/payroll/runs"
    element={
        <RequirePermission anyOf={["payroll.runs.read"]}>
        <PayrollRunsPage />
        </RequirePermission>
    }
    />

    <Route
    path="/payroll/runs/import"
    element={
        <RequirePermission anyOf={["payroll.runs.import"]}>
        <PayrollRunImportPage />
        </RequirePermission>
    }
    />

    <Route
    path="/payroll/runs/:id"
    element={
        <RequirePermission anyOf={["payroll.runs.read"]}>
        <PayrollRunDetailPage />
        </RequirePermission>
    }
    />
    ```

    ---

    ## 17) Sidebar — `frontend/src/layouts/sidebarConfig.js`

    ```js
    // frontend/src/layouts/sidebarConfig.js
    {
    key: "payroll",
    label: "Payroll",
    children: [
        {
        key: "payroll-runs",
        label: "Payroll Runs",
        to: "/payroll/runs",
        requiredPermissions: ["payroll.runs.read"],
        },
        {
        key: "payroll-import",
        label: "Payroll Import",
        to: "/payroll/runs/import",
        requiredPermissions: ["payroll.runs.import"],
        },
    ],
    }
    ```

    ---

    ## 18) i18n — `frontend/src/i18n/messages.js`

    ```js
    // frontend/src/i18n/messages.js
    export default {
    // ...
    "sidebar.payroll": "Payroll",
    "sidebar.payrollRuns": "Payroll Runs",
    "sidebar.payrollImport": "Payroll Import",
    };
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ Payroll CSV import creates `payroll_runs` header + `payroll_run_lines`
    * ✅ Duplicate import is blocked by checksum (same entity/period/provider/file)
    * ✅ Employee-level payroll details are stored in payroll subledger
    * ✅ Gross/net consistency validation runs on import
    * ✅ Payroll run totals are aggregated on header
    * ✅ Runs list + detail endpoints work
    * ✅ Route + UI permission checks use `payroll.runs.read/import`
    * ✅ OpenAPI updated
    * ✅ Smoke test script exists and runs

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:payroll:prp01`

    Should verify at least:

    1. **Import success**

    * POST valid payroll CSV → `201`
    * response includes `run_no`, `status=IMPORTED`
    * totals and employee counts are populated

    2. **List runs**

    * GET `/api/v1/payroll/runs` includes imported run

    3. **Run detail**

    * GET `/api/v1/payroll/runs/:id` returns header + lines + audit
    * line count matches CSV rows

    4. **Checksum idempotency**

    * Re-import same file with same entity/period/provider → `409`

    5. **Validation**

    * Import CSV with wrong `net_pay` or `gross_pay` math → `400`

    6. **Permissions**

    * Missing `payroll.runs.import` or `payroll.runs.read` → `403`

    ---

    # CSV format for manual testing (v1)

    Use this exact header:

    ```csv
    employee_code,employee_name,cost_center_code,base_salary,overtime_pay,bonus_pay,allowances_total,gross_pay,employee_tax,employee_social_security,other_deductions,employer_tax,employer_social_security,net_pay
    E001,Alice Doe,ADM,1000.00,100.00,50.00,25.00,1175.00,100.00,50.00,25.00,80.00,40.00,1000.00
    E002,Bob Doe,SCH,1200.00,0.00,0.00,0.00,1200.00,120.00,60.00,20.00,90.00,45.00,1000.00
    E003,Carol Doe,SCH,900.00,50.00,0.00,0.00,950.00,90.00,40.00,20.00,70.00,35.00,800.00
    ```

    ---

    # Tiny implementation notes (important)

    * **P01 is subledger import only** (no payroll engine yet).
    * This already supports your real-world flow: provider calculates payroll → your system imports and stores auditable payroll detail.
    * In **PR-P02**, you’ll add:

    * payroll accrual posting (`Dr Salary Expense`, `Dr Employer Tax/SS Expense`, `Cr Payroll Payable`, `Cr Tax/SS Payable`)
    * component-to-GL mapping (effective-dated)
    * In later payroll payment PR, payroll run liabilities will feed **PR-B04 Payment Batches** (`source_type="PAYROLL"`).

Perfect — here’s **PR-P02** in the same concrete format.

# PR-P02: Payroll Accrual Posting + Effective-Dated Component Mapping

    ## Goal

    Turn imported payroll runs (**PR-P01**) into **auditable GL accruals** using effective-dated payroll component mappings.

    This PR gives you:

    * ✅ Effective-dated payroll component → GL account mappings
    * ✅ Payroll accrual preview (mapping validation + balanced posting preview)
    * ✅ Payroll run review step
    * ✅ Finalize payroll run = post accrual journal (idempotent) + lock run
    * ✅ Audit trail for mapping changes and payroll accrual posting
    * ❌ No payment batch generation yet (that comes later via **PR-B04** integration)

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m040_payroll_accrual_posting.js`
    * `backend/src/routes/payroll.mappings.js`
    * `backend/src/routes/payroll.mappings.validators.js`
    * `backend/src/routes/payroll.accruals.js`
    * `backend/src/routes/payroll.accruals.validators.js`
    * `backend/src/services/payroll.mappings.service.js`
    * `backend/src/services/payroll.accruals.service.js`
    * `backend/scripts/test-payroll-prp02-accrual-posting.js`

    ### Frontend

    * `frontend/src/api/payrollMappings.js`
    * `frontend/src/pages/payroll/PayrollComponentMappingsPage.jsx`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js`
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/api/payrollRuns.js`
    * `frontend/src/pages/payroll/PayrollRunDetailPage.jsx`
    * `frontend/src/App.jsx`
    * `frontend/src/layouts/sidebarConfig.js`
    * `frontend/src/i18n/messages.js`

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m040_payroll_accrual_posting.js`

    ```js
    // backend/src/migrations/m040_payroll_accrual_posting.js

    export default {
    key: "m040_payroll_accrual_posting",
    description: "m040_payroll_accrual_posting",
    async up(connection) {
        // Effective-dated mapping table
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_component_gl_mappings (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            entity_code VARCHAR(50) NOT NULL,
            provider_code VARCHAR(50) NULL,              -- NULL = fallback for any provider
            currency_code CHAR(3) NOT NULL,
            component_code VARCHAR(50) NOT NULL,         -- see service constants
            entry_side VARCHAR(6) NOT NULL,              -- DEBIT / CREDIT
            gl_account_id BIGINT UNSIGNED NOT NULL,
            effective_from DATE NOT NULL,
            effective_to DATE NULL,
            is_active TINYINT(1) NOT NULL DEFAULT 1,
            notes VARCHAR(500) NULL,
            created_by BIGINT UNSIGNED NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            KEY idx_pcm_lookup (entity_code, currency_code, component_code, effective_from, effective_to),
            KEY idx_pcm_provider (provider_code),
            KEY idx_pcm_gl (gl_account_id),
            KEY idx_pcm_active (is_active),
            CONSTRAINT fk_pcm_gl_account
            FOREIGN KEY (gl_account_id) REFERENCES accounts(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_component_gl_mapping_audit (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            mapping_id BIGINT UNSIGNED NULL,
            action VARCHAR(30) NOT NULL, -- CREATED, CLOSED_PREVIOUS, DEACTIVATED
            payload_json JSON NULL,
            acted_by BIGINT UNSIGNED NULL,
            acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (id),
            KEY idx_pcm_audit_mapping (mapping_id),
            KEY idx_pcm_audit_action (action)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        // Extend payroll_runs with accrual posting metadata
        await connection.execute(`
        ALTER TABLE payroll_runs
            ADD COLUMN reviewed_by BIGINT UNSIGNED NULL AFTER imported_by,
            ADD COLUMN reviewed_at DATETIME NULL AFTER imported_at,
            ADD COLUMN finalized_by BIGINT UNSIGNED NULL AFTER reviewed_at,
            ADD COLUMN finalized_at DATETIME NULL AFTER finalized_by,
            ADD COLUMN accrual_journal_entry_id BIGINT UNSIGNED NULL AFTER finalized_at,
            ADD COLUMN accrual_posted_by BIGINT UNSIGNED NULL AFTER accrual_journal_entry_id,
            ADD COLUMN accrual_posted_at DATETIME NULL AFTER accrual_posted_by;
        `).catch(() => {}); // safe re-run during dev

        await connection.execute(`
        ALTER TABLE payroll_runs
            ADD KEY idx_payroll_runs_accrual_je (accrual_journal_entry_id)
        `).catch(() => {});
    },

    async down(connection) {
        // Keep ALTER TABLE down simple/safe for dev environments
        await connection.execute(`DROP TABLE IF EXISTS payroll_component_gl_mapping_audit;`);
        await connection.execute(`DROP TABLE IF EXISTS payroll_component_gl_mappings;`);
        // (Optional) drop added payroll_runs columns if you maintain strict down migrations
    },
    };
    ```

    ---

    ## 2) Mapping validators — `backend/src/routes/payroll.mappings.validators.js`

    ```js
    // backend/src/routes/payroll.mappings.validators.js

    const ALLOWED_COMPONENTS = [
    "BASE_SALARY_EXPENSE",
    "OVERTIME_EXPENSE",
    "BONUS_EXPENSE",
    "ALLOWANCES_EXPENSE",
    "EMPLOYER_TAX_EXPENSE",
    "EMPLOYER_SOCIAL_SECURITY_EXPENSE",
    "PAYROLL_NET_PAYABLE",
    "EMPLOYEE_TAX_PAYABLE",
    "EMPLOYEE_SOCIAL_SECURITY_PAYABLE",
    "EMPLOYER_TAX_PAYABLE",
    "EMPLOYER_SOCIAL_SECURITY_PAYABLE",
    "OTHER_DEDUCTIONS_PAYABLE",
    ];

    function requirePositiveInt(v, field) {
    const n = Number(v);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${field} must be positive integer`);
    return n;
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function requireDate(v, field) {
    const s = String(v || "").trim();
    if (!/^\d{4}-\d{2}-\d{2}$/.test(s)) throw new Error(`${field} must be YYYY-MM-DD`);
    return s;
    }

    function requireCurrency(v) {
    const s = String(v || "").trim().toUpperCase();
    if (!/^[A-Z]{3}$/.test(s)) throw new Error("currency_code must be 3 letters");
    return s;
    }

    function validateListMappingsQuery(query = {}) {
    return {
        entity_code: normalizeString(query.entity_code),
        provider_code: normalizeString(query.provider_code)?.toUpperCase() || null,
        currency_code: normalizeString(query.currency_code)?.toUpperCase() || null,
        component_code: normalizeString(query.component_code)?.toUpperCase() || null,
        as_of_date: query.as_of_date ? requireDate(query.as_of_date, "as_of_date") : null,
        active_only: String(query.active_only || "true").toLowerCase() !== "false",
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 500) : 200,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    function validateUpsertMapping(body = {}) {
    const component_code = String(body.component_code || "").trim().toUpperCase();
    if (!ALLOWED_COMPONENTS.includes(component_code)) {
        throw new Error(`component_code must be one of ${ALLOWED_COMPONENTS.join(", ")}`);
    }

    const entry_side = String(body.entry_side || "").trim().toUpperCase();
    if (!["DEBIT", "CREDIT"].includes(entry_side)) {
        throw new Error("entry_side must be DEBIT or CREDIT");
    }

    return {
        entity_code: String(body.entity_code || "").trim() || (() => { throw new Error("entity_code is required"); })(),
        provider_code: normalizeString(body.provider_code)?.toUpperCase() || null,
        currency_code: requireCurrency(body.currency_code),
        component_code,
        entry_side,
        gl_account_id: requirePositiveInt(body.gl_account_id, "gl_account_id"),
        effective_from: requireDate(body.effective_from, "effective_from"),
        effective_to: body.effective_to ? requireDate(body.effective_to, "effective_to") : null,
        close_previous_open_mapping: String(body.close_previous_open_mapping || "true").toLowerCase() !== "false",
        notes: normalizeString(body.notes),
    };
    }

    export default {
    ALLOWED_COMPONENTS,
    validateListMappingsQuery,
    validateUpsertMapping,
    };
    ```

    ---

    ## 3) Accrual validators — `backend/src/routes/payroll.accruals.validators.js`

    ```js
    // backend/src/routes/payroll.accruals.validators.js

    function requirePositiveInt(v, field) {
    const n = Number(v);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${field} must be positive integer`);
    return n;
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function validateRunIdParam(params = {}) {
    return { id: requirePositiveInt(params.id, "id") };
    }

    function validateReviewBody(body = {}) {
    return { note: normalizeString(body.note) };
    }

    function validateFinalizeBody(body = {}) {
    return {
        note: normalizeString(body.note),
        force_from_imported: String(body.force_from_imported || "false").toLowerCase() === "true",
    };
    }

    export default {
    validateRunIdParam,
    validateReviewBody,
    validateFinalizeBody,
    };
    ```

    ---

    ## 4) Mapping service — `backend/src/services/payroll.mappings.service.js`

    ```js
    // backend/src/services/payroll.mappings.service.js

    const EXPECTED_SIDE_BY_COMPONENT = {
    BASE_SALARY_EXPENSE: "DEBIT",
    OVERTIME_EXPENSE: "DEBIT",
    BONUS_EXPENSE: "DEBIT",
    ALLOWANCES_EXPENSE: "DEBIT",
    EMPLOYER_TAX_EXPENSE: "DEBIT",
    EMPLOYER_SOCIAL_SECURITY_EXPENSE: "DEBIT",

    PAYROLL_NET_PAYABLE: "CREDIT",
    EMPLOYEE_TAX_PAYABLE: "CREDIT",
    EMPLOYEE_SOCIAL_SECURITY_PAYABLE: "CREDIT",
    EMPLOYER_TAX_PAYABLE: "CREDIT",
    EMPLOYER_SOCIAL_SECURITY_PAYABLE: "CREDIT",
    OTHER_DEDUCTIONS_PAYABLE: "CREDIT",
    };

    async function writeMappingAudit(db, { mappingId = null, action, payload = null, userId = null }) {
    await db.query(
        `INSERT INTO payroll_component_gl_mapping_audit (mapping_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
        [mappingId, action, payload ? JSON.stringify(payload) : null, userId]
    );
    }

    async function listMappings(db, q) {
    const where = [];
    const params = [];

    if (q.entity_code) {
        where.push(`m.entity_code = ?`);
        params.push(q.entity_code);
    }
    if (q.provider_code) {
        where.push(`(m.provider_code = ? OR m.provider_code IS NULL)`);
        params.push(q.provider_code);
    }
    if (q.currency_code) {
        where.push(`m.currency_code = ?`);
        params.push(q.currency_code);
    }
    if (q.component_code) {
        where.push(`m.component_code = ?`);
        params.push(q.component_code);
    }
    if (q.active_only) {
        where.push(`m.is_active = 1`);
    }
    if (q.as_of_date) {
        where.push(`m.effective_from <= ? AND (m.effective_to IS NULL OR m.effective_to >= ?)`);
        params.push(q.as_of_date, q.as_of_date);
    }

    let sql = `
        SELECT
        m.id, m.entity_code, m.provider_code, m.currency_code, m.component_code, m.entry_side,
        m.gl_account_id, a.code AS gl_account_code, a.name AS gl_account_name,
        m.effective_from, m.effective_to, m.is_active, m.notes, m.created_at, m.updated_at
        FROM payroll_component_gl_mappings m
        JOIN accounts a ON a.id = m.gl_account_id
    `;
    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY m.component_code ASC, m.provider_code DESC, m.effective_from DESC, m.id DESC LIMIT ? OFFSET ?`;
    params.push(q.limit, q.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    async function upsertMapping(db, payload, userId = null) {
    const expectedSide = EXPECTED_SIDE_BY_COMPONENT[payload.component_code];
    if (expectedSide && expectedSide !== payload.entry_side) {
        const err = new Error(`entry_side must be ${expectedSide} for ${payload.component_code}`);
        err.statusCode = 400;
        throw err;
    }

    if (payload.effective_to && payload.effective_to < payload.effective_from) {
        const err = new Error("effective_to cannot be before effective_from");
        err.statusCode = 400;
        throw err;
    }

    // Optional: close previous open mapping for same key
    if (payload.close_previous_open_mapping) {
        const [prev] = await db.query(
        `
        SELECT id, effective_from
        FROM payroll_component_gl_mappings
        WHERE entity_code = ?
            AND ((provider_code IS NULL AND ? IS NULL) OR provider_code = ?)
            AND currency_code = ?
            AND component_code = ?
            AND is_active = 1
            AND effective_to IS NULL
            AND effective_from < ?
        ORDER BY effective_from DESC, id DESC
        LIMIT 1
        `,
        [
            payload.entity_code,
            payload.provider_code,
            payload.provider_code,
            payload.currency_code,
            payload.component_code,
            payload.effective_from,
        ]
        );

        if (prev[0]) {
        await db.query(
            `
            UPDATE payroll_component_gl_mappings
            SET effective_to = DATE_SUB(?, INTERVAL 1 DAY), updated_at = NOW()
            WHERE id = ?
            `,
            [payload.effective_from, prev[0].id]
        );

        await writeMappingAudit(db, {
            mappingId: prev[0].id,
            action: "CLOSED_PREVIOUS",
            payload: { closed_due_to_new_mapping_effective_from: payload.effective_from },
            userId,
        });
        }
    }

    // Reject overlap (active rows) for same key
    const [overlaps] = await db.query(
        `
        SELECT id
        FROM payroll_component_gl_mappings
        WHERE entity_code = ?
        AND ((provider_code IS NULL AND ? IS NULL) OR provider_code = ?)
        AND currency_code = ?
        AND component_code = ?
        AND is_active = 1
        AND (
            (effective_from <= ? AND (effective_to IS NULL OR effective_to >= ?))
            OR
            (? <= effective_from AND (? IS NULL OR ? >= effective_from))
        )
        LIMIT 1
        `,
        [
        payload.entity_code,
        payload.provider_code,
        payload.provider_code,
        payload.currency_code,
        payload.component_code,
        payload.effective_from,
        payload.effective_from,
        payload.effective_from,
        payload.effective_to,
        payload.effective_to,
        ]
    );

    if (overlaps[0]) {
        const err = new Error("Overlapping effective-dated mapping exists for this component");
        err.statusCode = 409;
        throw err;
    }

    const [ins] = await db.query(
        `
        INSERT INTO payroll_component_gl_mappings
        (entity_code, provider_code, currency_code, component_code, entry_side, gl_account_id, effective_from, effective_to, is_active, notes, created_by)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, 1, ?, ?)
        `,
        [
        payload.entity_code,
        payload.provider_code,
        payload.currency_code,
        payload.component_code,
        payload.entry_side,
        payload.gl_account_id,
        payload.effective_from,
        payload.effective_to,
        payload.notes || null,
        userId,
        ]
    );

    await writeMappingAudit(db, {
        mappingId: ins.insertId,
        action: "CREATED",
        payload: payload,
        userId,
    });

    const [rows] = await db.query(
        `
        SELECT m.*, a.code AS gl_account_code, a.name AS gl_account_name
        FROM payroll_component_gl_mappings m
        JOIN accounts a ON a.id = m.gl_account_id
        WHERE m.id = ?
        LIMIT 1
        `,
        [ins.insertId]
    );

    return rows[0];
    }

    export default {
    EXPECTED_SIDE_BY_COMPONENT,
    listMappings,
    upsertMapping,
    };
    ```

    ---

    ## 5) Accrual service — `backend/src/services/payroll.accruals.service.js`

    > **Important:** this assumes your GL tables are named `journal_entries` / `journal_entry_lines` and support posted inserts like your earlier payment PR skeleton. Adapt if needed.

    ```js
    // backend/src/services/payroll.accruals.service.js

    import { EXPECTED_SIDE_BY_COMPONENT } from "./payroll.mappings.service.js";
    const COMPONENT_BUILDERS = [
    { code: "BASE_SALARY_EXPENSE", field: "base_salary", side: "DEBIT", label: "Base Salary Expense" },
    { code: "OVERTIME_EXPENSE", field: "overtime_pay", side: "DEBIT", label: "Overtime Expense" },
    { code: "BONUS_EXPENSE", field: "bonus_pay", side: "DEBIT", label: "Bonus Expense" },
    { code: "ALLOWANCES_EXPENSE", field: "allowances_total", side: "DEBIT", label: "Allowances Expense" },
    { code: "EMPLOYER_TAX_EXPENSE", field: "employer_tax", side: "DEBIT", label: "Employer Tax Expense" },
    { code: "EMPLOYER_SOCIAL_SECURITY_EXPENSE", field: "employer_social_security", side: "DEBIT", label: "Employer SS Expense" },

    { code: "PAYROLL_NET_PAYABLE", field: "net_pay", side: "CREDIT", label: "Payroll Net Payable" },
    { code: "EMPLOYEE_TAX_PAYABLE", field: "employee_tax", side: "CREDIT", label: "Employee Tax Payable" },
    { code: "EMPLOYEE_SOCIAL_SECURITY_PAYABLE", field: "employee_social_security", side: "CREDIT", label: "Employee SS Payable" },
    { code: "EMPLOYER_TAX_PAYABLE", field: "employer_tax", side: "CREDIT", label: "Employer Tax Payable" },
    { code: "EMPLOYER_SOCIAL_SECURITY_PAYABLE", field: "employer_social_security", side: "CREDIT", label: "Employer SS Payable" },
    { code: "OTHER_DEDUCTIONS_PAYABLE", field: "other_deductions", side: "CREDIT", label: "Other Deductions Payable" },
    ];

    async function writeRunAudit(db, runId, action, payload, userId = null) {
    await db.query(
        `INSERT INTO payroll_run_audit (run_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
        [runId, action, payload ? JSON.stringify(payload) : null, userId]
    );
    }

    async function getRunHeader(db, runId) {
    const [rows] = await db.query(`SELECT * FROM payroll_runs WHERE id = ? LIMIT 1`, [runId]);
    return rows[0] || null;
    }

    async function getRunTotals(db, runId) {
    const [rows] = await db.query(
        `
        SELECT
        COALESCE(SUM(base_salary),0) AS base_salary,
        COALESCE(SUM(overtime_pay),0) AS overtime_pay,
        COALESCE(SUM(bonus_pay),0) AS bonus_pay,
        COALESCE(SUM(allowances_total),0) AS allowances_total,
        COALESCE(SUM(gross_pay),0) AS gross_pay,
        COALESCE(SUM(employee_tax),0) AS employee_tax,
        COALESCE(SUM(employee_social_security),0) AS employee_social_security,
        COALESCE(SUM(other_deductions),0) AS other_deductions,
        COALESCE(SUM(net_pay),0) AS net_pay,
        COALESCE(SUM(employer_tax),0) AS employer_tax,
        COALESCE(SUM(employer_social_security),0) AS employer_social_security
        FROM payroll_run_lines
        WHERE run_id = ?
        `,
        [runId]
    );
    const r = rows[0] || {};
    const out = {};
    Object.keys(r).forEach((k) => (out[k] = Number(Number(r[k] || 0).toFixed(2))));
    return out;
    }

    async function resolveMappingForComponent(db, { entity_code, provider_code, currency_code, pay_date, component_code }) {
    const [rows] = await db.query(
        `
        SELECT
        m.id, m.entity_code, m.provider_code, m.currency_code, m.component_code, m.entry_side,
        m.gl_account_id, m.effective_from, m.effective_to,
        a.code AS gl_account_code, a.name AS gl_account_name
        FROM payroll_component_gl_mappings m
        JOIN accounts a ON a.id = m.gl_account_id
        WHERE m.entity_code = ?
        AND m.currency_code = ?
        AND m.component_code = ?
        AND m.is_active = 1
        AND (m.provider_code = ? OR m.provider_code IS NULL)
        AND m.effective_from <= ?
        AND (m.effective_to IS NULL OR m.effective_to >= ?)
        ORDER BY
        CASE WHEN m.provider_code = ? THEN 0 ELSE 1 END,
        m.effective_from DESC,
        m.id DESC
        LIMIT 1
        `,
        [entity_code, currency_code, component_code, provider_code, pay_date, pay_date, provider_code]
    );

    return rows[0] || null;
    }

    function buildComponentAmounts(totals) {
    return COMPONENT_BUILDERS
        .map((c) => ({
        component_code: c.code,
        label: c.label,
        entry_side: c.side,
        amount: Number(Number(totals[c.field] || 0).toFixed(2)),
        }))
        .filter((x) => x.amount > 0.004);
    }

    async function buildAccrualPreview(db, runId) {
    const run = await getRunHeader(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }

    const totals = await getRunTotals(db, runId);
    const components = buildComponentAmounts(totals);

    const posting_lines = [];
    const missing_mappings = [];

    for (const c of components) {
        const mapping = await resolveMappingForComponent(db, {
        entity_code: run.entity_code,
        provider_code: run.provider_code,
        currency_code: run.currency_code,
        pay_date: run.pay_date,
        component_code: c.component_code,
        });

        if (!mapping) {
        missing_mappings.push({
            component_code: c.component_code,
            entry_side: c.entry_side,
            amount: c.amount,
        });
        continue;
        }

        if (mapping.entry_side !== c.entry_side) {
        missing_mappings.push({
            component_code: c.component_code,
            entry_side: c.entry_side,
            amount: c.amount,
            issue: `Mapping side mismatch (${mapping.entry_side})`,
        });
        continue;
        }

        posting_lines.push({
        component_code: c.component_code,
        entry_side: c.entry_side,
        amount: c.amount,
        gl_account_id: Number(mapping.gl_account_id),
        gl_account_code: mapping.gl_account_code,
        gl_account_name: mapping.gl_account_name,
        mapping_id: Number(mapping.id),
        memo: `${run.run_no} ${c.label}`,
        });
    }

    const debit_total = Number(
        posting_lines.filter((x) => x.entry_side === "DEBIT").reduce((s, x) => s + x.amount, 0).toFixed(2)
    );
    const credit_total = Number(
        posting_lines.filter((x) => x.entry_side === "CREDIT").reduce((s, x) => s + x.amount, 0).toFixed(2)
    );

    return {
        run: {
        id: run.id,
        run_no: run.run_no,
        status: run.status,
        entity_code: run.entity_code,
        provider_code: run.provider_code,
        payroll_period: run.payroll_period,
        pay_date: run.pay_date,
        currency_code: run.currency_code,
        accrual_journal_entry_id: run.accrual_journal_entry_id || null,
        },
        totals,
        components,
        posting_lines,
        missing_mappings,
        debit_total,
        credit_total,
        is_balanced: Math.abs(debit_total - credit_total) < 0.01,
        can_finalize:
        !run.accrual_journal_entry_id &&
        missing_mappings.length === 0 &&
        Math.abs(debit_total - credit_total) < 0.01 &&
        ["IMPORTED", "REVIEWED", "FINALIZED"].includes(run.status),
    };
    }

    async function markRunReviewed(db, runId, body, userId = null) {
    const run = await getRunHeader(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }
    if (run.status === "FINALIZED" && run.accrual_journal_entry_id) {
        return run; // harmless idempotent review after finalize
    }

    const preview = await buildAccrualPreview(db, runId);

    await db.query(
        `
        UPDATE payroll_runs
        SET status = 'REVIEWED',
            reviewed_by = COALESCE(reviewed_by, ?),
            reviewed_at = COALESCE(reviewed_at, NOW())
        WHERE id = ?
        `,
        [userId, runId]
    );

    await writeRunAudit(db, runId, "VALIDATION", {
        missing_mapping_count: preview.missing_mappings.length,
        debit_total: preview.debit_total,
        credit_total: preview.credit_total,
        is_balanced: preview.is_balanced,
        note: body.note || null,
    }, userId);

    await writeRunAudit(db, runId, "STATUS", { to: "REVIEWED" }, userId);

    return getRunHeader(db, runId);
    }

    async function createAccrualJournal(db, preview, userId = null) {
    const run = preview.run;

    const [jeIns] = await db.query(
        `
        INSERT INTO journal_entries
        (journal_no, status, memo, posted_at, created_by)
        VALUES (?, 'POSTED', ?, NOW(), ?)
        `,
        [`PAYACC-${run.run_no}`, `Payroll accrual ${run.run_no}`, userId]
    );

    const journalId = jeIns.insertId;
    let lineNo = 1;

    for (const l of preview.posting_lines) {
        const dr = l.entry_side === "DEBIT" ? l.amount : 0;
        const cr = l.entry_side === "CREDIT" ? l.amount : 0;
        const signedAmount = l.entry_side === "DEBIT" ? l.amount : -l.amount;

        await db.query(
        `
        INSERT INTO journal_entry_lines
        (journal_entry_id, line_no, account_id, dr_amount, cr_amount, amount, memo)
        VALUES (?, ?, ?, ?, ?, ?, ?)
        `,
        [journalId, lineNo++, l.gl_account_id, dr, cr, signedAmount, l.memo]
        );
    }

    return journalId;
    }

    async function finalizeRunAccrual(db, runId, body, userId = null) {
    const run = await getRunHeader(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }

    if (run.accrual_journal_entry_id) {
        // idempotent finalize/post
        return getRunHeader(db, runId);
    }

    if (!["IMPORTED", "REVIEWED"].includes(run.status) && !body.force_from_imported) {
        const err = new Error(`Cannot finalize payroll run in status ${run.status}`);
        err.statusCode = 400;
        throw err;
    }

    // Optional maker-checker rule (recommended)
    if (run.imported_by && userId && Number(run.imported_by) === Number(userId)) {
        const err = new Error("Importer cannot finalize the same payroll run");
        err.statusCode = 403;
        throw err;
    }

    const preview = await buildAccrualPreview(db, runId);

    if (preview.missing_mappings.length) {
        const err = new Error("Cannot finalize: missing component GL mappings");
        err.statusCode = 400;
        err.details = preview.missing_mappings;
        throw err;
    }
    if (!preview.is_balanced) {
        const err = new Error("Cannot finalize: accrual journal preview is not balanced");
        err.statusCode = 400;
        throw err;
    }

    const conn = db.getConnection ? await db.getConnection() : null;
    const q = conn || db;

    try {
        if (conn) await conn.beginTransaction();

        const currentPreview = await buildAccrualPreview(q, runId);
        if (currentPreview.run.accrual_journal_entry_id) {
        if (conn) await conn.commit();
        return getRunHeader(db, runId);
        }

        const journalId = await createAccrualJournal(q, currentPreview, userId);

        await q.query(
        `
        UPDATE payroll_runs
        SET status = 'FINALIZED',
            finalized_by = ?,
            finalized_at = NOW(),
            accrual_journal_entry_id = ?,
            accrual_posted_by = ?,
            accrual_posted_at = NOW()
        WHERE id = ?
        `,
        [userId, journalId, userId, runId]
        );

        await writeRunAudit(q, runId, "ACCRUAL_POSTED", {
        journal_entry_id: journalId,
        debit_total: currentPreview.debit_total,
        credit_total: currentPreview.credit_total,
        line_count: currentPreview.posting_lines.length,
        note: body.note || null,
        }, userId);

        await writeRunAudit(q, runId, "STATUS", { to: "FINALIZED" }, userId);

        if (conn) await conn.commit();
        return getRunHeader(db, runId);
    } catch (err) {
        if (conn) {
        try { await conn.rollback(); } catch (_) {}
        }
        throw err;
    } finally {
        if (conn) conn.release();
    }
    }

    export default {
    buildAccrualPreview,
    markRunReviewed,
    finalizeRunAccrual,
    };
    ```

    ---

    ## 6) Mapping routes — `backend/src/routes/payroll.mappings.js`

    ```js
    // backend/src/routes/payroll.mappings.js

    import express from "express";
    import { validateListMappingsQuery, validateUpsertMapping } from "./payroll.mappings.validators.js";
    import service from "../services/payroll.mappings.service.js";
    // replace with your actual helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();

    // GET /api/v1/payroll/mappings
    router.get(
    "/mappings",
    requireAuth,
    requirePermission("payroll.mappings.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateListMappingsQuery(req.query);
        const items = await service.listMappings(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payroll/mappings/upsert
    router.post(
    "/mappings/upsert",
    requireAuth,
    requirePermission("payroll.mappings.write"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const body = validateUpsertMapping(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.upsertMapping(db, body, userId);
        res.status(201).json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 7) Accrual routes — `backend/src/routes/payroll.accruals.js`

    ```js
    // backend/src/routes/payroll.accruals.js

    import express from "express";
    import { validateRunIdParam,
    validateReviewBody,
    validateFinalizeBody, } from "./payroll.accruals.validators.js";
    import service from "../services/payroll.accruals.service.js";
    // replace with your actual helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();

    // GET /api/v1/payroll/runs/:id/accrual-preview
    router.get(
    "/runs/:id/accrual-preview",
    requireAuth,
    requirePermission("payroll.runs.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const result = await service.buildAccrualPreview(db, id);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payroll/runs/:id/review
    router.post(
    "/runs/:id/review",
    requireAuth,
    requirePermission("payroll.runs.review"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const body = validateReviewBody(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.markRunReviewed(db, id, body, userId);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payroll/runs/:id/finalize
    router.post(
    "/runs/:id/finalize",
    requireAuth,
    requirePermission("payroll.runs.finalize"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const body = validateFinalizeBody(req.body);
        const userId = req.user?.id ?? null;
        const row = await service.finalizeRunAccrual(db, id, body, userId);
        res.json(row);
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 8) Mount routes — `backend/src/index.js`

    ```js
    // backend/src/index.js
    import payrollMappingsRoutes from "./routes/payroll.mappings.js";
    import payrollAccrualsRoutes from "./routes/payroll.accruals.js";
    // ...
    app.use("/api/v1/payroll", payrollMappingsRoutes);
    app.use("/api/v1/payroll", payrollAccrualsRoutes);
    ```

    ---

    ## 9) Migration registry — `backend/src/migrations/index.js`

    ```js
    // backend/src/migrations/index.js
    import m040_payroll_accrual_posting from "./m040_payroll_accrual_posting.js";
    export default [
    // ...
    m040_payroll_accrual_posting,
    ];
    ```

    ---

    ## 10) Seed permissions — `backend/src/seedCore.js`

    ```js
    // backend/src/seedCore.js
    const PAYROLL_P02_PERMISSIONS = [
    "payroll.mappings.read",
    "payroll.mappings.write",
    "payroll.runs.review",
    "payroll.runs.finalize",
    ];

    // merge into permission seed list
    ```

    ---

    ## 11) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Register these paths:

    * `GET /api/v1/payroll/mappings`
    * `POST /api/v1/payroll/mappings/upsert`
    * `GET /api/v1/payroll/runs/{id}/accrual-preview`
    * `POST /api/v1/payroll/runs/{id}/review`
    * `POST /api/v1/payroll/runs/{id}/finalize`

    ---

    ## 12) Backend smoke test — `backend/scripts/test-payroll-prp02-accrual-posting.js`

    ```js
    // backend/scripts/test-payroll-prp02-accrual-posting.js

    async function main() {
    // Preconditions:
    // - PR-P01 is implemented (import endpoint + payroll_runs exists)
    // - GL accounts exist for expense/payable mapping targets
    //
    // Flow:
    // 1) Import a payroll CSV run (or reuse existing fresh run)
    // 2) Create effective-dated mappings for all non-zero payroll components
    // 3) GET /api/v1/payroll/runs/:id/accrual-preview
    //    -> missing_mappings = []
    //    -> is_balanced = true
    //    -> posting_lines returned
    // 4) POST /api/v1/payroll/runs/:id/review
    //    -> status becomes REVIEWED
    // 5) POST /api/v1/payroll/runs/:id/finalize
    //    -> status FINALIZED
    //    -> accrual_journal_entry_id present
    // 6) POST /finalize again
    //    -> idempotent (same accrual_journal_entry_id)
    // 7) Create another run without one required mapping
    //    -> finalize fails 400 (missing mappings)
    // 8) Effective-date check:
    //    - Create new mapping version effective later date
    //    - Preview picks old mapping for old pay_date, new mapping for later pay_date
    // 9) Permissions:
    //    - payroll.mappings.read/write, payroll.runs.review/finalize enforced (403)
    console.log("PR-P02 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    ---

    ## 13) `backend/package.json` updates

    ```json
    {
    "scripts": {
        "test:payroll:prp02": "node backend/scripts/test-payroll-prp02-accrual-posting.js"
    }
    }
    ```

    ---

    # Frontend skeletons

    ## 14) Mapping API client — `frontend/src/api/payrollMappings.js`

    ```js
    // frontend/src/api/payrollMappings.js

    import { apiFetch } from "./client.js"; // adapt to your helper

    export function listPayrollMappings(params = {}) {
    const q = new URLSearchParams();
    if (params.entity_code) q.set("entity_code", params.entity_code);
    if (params.provider_code) q.set("provider_code", params.provider_code);
    if (params.currency_code) q.set("currency_code", params.currency_code);
    if (params.component_code) q.set("component_code", params.component_code);
    if (params.as_of_date) q.set("as_of_date", params.as_of_date);
    const qs = q.toString();
    return apiFetch(`/api/v1/payroll/mappings${qs ? `?${qs}` : ""}`);
    }

    export function upsertPayrollMapping(payload) {
    return apiFetch(`/api/v1/payroll/mappings/upsert`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }
    ```

    ---

    ## 15) Payroll mappings page — `frontend/src/pages/payroll/PayrollComponentMappingsPage.jsx`

    ```jsx
    // frontend/src/pages/payroll/PayrollComponentMappingsPage.jsx

    import { useEffect, useState } from "react";
    import { listPayrollMappings, upsertPayrollMapping } from "../../api/payrollMappings.js";

    const COMPONENTS = [
    "BASE_SALARY_EXPENSE",
    "OVERTIME_EXPENSE",
    "BONUS_EXPENSE",
    "ALLOWANCES_EXPENSE",
    "EMPLOYER_TAX_EXPENSE",
    "EMPLOYER_SOCIAL_SECURITY_EXPENSE",
    "PAYROLL_NET_PAYABLE",
    "EMPLOYEE_TAX_PAYABLE",
    "EMPLOYEE_SOCIAL_SECURITY_PAYABLE",
    "EMPLOYER_TAX_PAYABLE",
    "EMPLOYER_SOCIAL_SECURITY_PAYABLE",
    "OTHER_DEDUCTIONS_PAYABLE",
    ];

    export default function PayrollComponentMappingsPage() {
    const [items, setItems] = useState([]);
    const [err, setErr] = useState("");
    const [form, setForm] = useState({
        entity_code: "",
        provider_code: "",
        currency_code: "USD",
        component_code: COMPONENTS[0],
        entry_side: "DEBIT",
        gl_account_id: "",
        effective_from: "",
        notes: "",
    });

    async function load() {
        setErr("");
        try {
        const res = await listPayrollMappings({
            entity_code: form.entity_code || undefined,
            provider_code: form.provider_code || undefined,
            currency_code: form.currency_code || undefined,
        });
        setItems(res.items || []);
        } catch (e) {
        setErr(e.message || "Failed to load mappings");
        }
    }

    useEffect(() => {
        // optional initial load without filters
        load();
    }, []);

    async function onSubmit(e) {
        e.preventDefault();
        setErr("");
        try {
        await upsertPayrollMapping({
            ...form,
            gl_account_id: Number(form.gl_account_id),
        });
        await load();
        } catch (e) {
        setErr(e.message || "Failed to save mapping");
        }
    }

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <h1 className="text-lg font-semibold mb-3">Payroll Component Mappings</h1>
            {err ? <div className="text-sm text-red-600 mb-2">{err}</div> : null}

            <form className="grid grid-cols-1 md:grid-cols-3 gap-2" onSubmit={onSubmit}>
            <input className="border rounded px-2 py-1" placeholder="Entity Code"
                value={form.entity_code}
                onChange={(e) => setForm((s) => ({ ...s, entity_code: e.target.value }))} />

            <input className="border rounded px-2 py-1" placeholder="Provider Code (optional)"
                value={form.provider_code}
                onChange={(e) => setForm((s) => ({ ...s, provider_code: e.target.value }))} />

            <input className="border rounded px-2 py-1" placeholder="Currency"
                value={form.currency_code}
                onChange={(e) => setForm((s) => ({ ...s, currency_code: e.target.value }))} />

            <select className="border rounded px-2 py-1"
                value={form.component_code}
                onChange={(e) => setForm((s) => ({ ...s, component_code: e.target.value }))}>
                {COMPONENTS.map((c) => <option key={c} value={c}>{c}</option>)}
            </select>

            <select className="border rounded px-2 py-1"
                value={form.entry_side}
                onChange={(e) => setForm((s) => ({ ...s, entry_side: e.target.value }))}>
                <option value="DEBIT">DEBIT</option>
                <option value="CREDIT">CREDIT</option>
            </select>

            <input className="border rounded px-2 py-1" placeholder="GL Account ID"
                value={form.gl_account_id}
                onChange={(e) => setForm((s) => ({ ...s, gl_account_id: e.target.value }))} />

            <input className="border rounded px-2 py-1" type="date"
                value={form.effective_from}
                onChange={(e) => setForm((s) => ({ ...s, effective_from: e.target.value }))} />

            <input className="border rounded px-2 py-1 md:col-span-2" placeholder="Notes"
                value={form.notes}
                onChange={(e) => setForm((s) => ({ ...s, notes: e.target.value }))} />

            <div className="md:col-span-3 flex gap-2">
                <button className="px-3 py-1 rounded border" type="submit">Save Mapping</button>
                <button className="px-3 py-1 rounded border" type="button" onClick={load}>Refresh</button>
            </div>
            </form>
        </div>

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Mappings</h2>
            <div className="overflow-auto">
            <table className="min-w-full text-sm border-collapse">
                <thead>
                <tr className="border-b">
                    <th className="text-left p-2">Component</th>
                    <th className="text-left p-2">Side</th>
                    <th className="text-left p-2">GL</th>
                    <th className="text-left p-2">Entity</th>
                    <th className="text-left p-2">Provider</th>
                    <th className="text-left p-2">Effective</th>
                </tr>
                </thead>
                <tbody>
                {items.map((m) => (
                    <tr key={m.id} className="border-b">
                    <td className="p-2">{m.component_code}</td>
                    <td className="p-2">{m.entry_side}</td>
                    <td className="p-2">{m.gl_account_code || m.gl_account_id}</td>
                    <td className="p-2">{m.entity_code}</td>
                    <td className="p-2">{m.provider_code || "*"}</td>
                    <td className="p-2">{m.effective_from} → {m.effective_to || "open"}</td>
                    </tr>
                ))}
                {items.length === 0 && <tr><td className="p-2" colSpan={6}>No mappings found.</td></tr>}
                </tbody>
            </table>
            </div>
        </div>
        </div>
    );
    }
    ```

    ---

    ## 16) Update payroll run API — `frontend/src/api/payrollRuns.js`

    Add these functions:

    ```js
    // frontend/src/api/payrollRuns.js

    export function getPayrollRunAccrualPreview(id) {
    return apiFetch(`/api/v1/payroll/runs/${id}/accrual-preview`);
    }

    export function reviewPayrollRun(id, payload = {}) {
    return apiFetch(`/api/v1/payroll/runs/${id}/review`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function finalizePayrollRun(id, payload = {}) {
    return apiFetch(`/api/v1/payroll/runs/${id}/finalize`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }
    ```

    ---

    ## 17) Update payroll run detail page — `frontend/src/pages/payroll/PayrollRunDetailPage.jsx`

    > Add a preview/finalize panel (keep your existing header + lines + audit).

    ```jsx
    // add imports
    import {
    getPayrollRun,
    getPayrollRunAccrualPreview,
    reviewPayrollRun,
    finalizePayrollRun,
    } from "../../api/payrollRuns.js";

    // inside component state
    const [preview, setPreview] = useState(null);

    // load preview alongside run
    async function load() {
    setErr("");
    try {
        const [runRes, previewRes] = await Promise.all([
        getPayrollRun(id),
        getPayrollRunAccrualPreview(id).catch(() => null),
        ]);
        setRun(runRes);
        setPreview(previewRes);
    } catch (e) {
        setErr(e.message || "Failed to load payroll run");
    }
    }

    async function onReview() {
    try {
        await reviewPayrollRun(id, {});
        await load();
    } catch (e) {
        setErr(e.message || "Review failed");
    }
    }

    async function onFinalize() {
    try {
        await finalizePayrollRun(id, {});
        await load();
    } catch (e) {
        setErr(e.message || "Finalize failed");
    }
    }
    ```

    Add a new panel in the JSX (below the header block is a good spot):

    ```jsx
    <div className="rounded border bg-white p-4">
    <div className="flex items-center gap-2 mb-2">
        <h2 className="font-medium">Accrual Preview</h2>
        {preview?.is_balanced ? (
        <span className="text-xs border rounded px-2 py-0.5">Balanced</span>
        ) : (
        <span className="text-xs border rounded px-2 py-0.5">Not Balanced</span>
        )}
    </div>

    {!preview ? (
        <div className="text-sm text-gray-600">Preview unavailable.</div>
    ) : (
        <div className="space-y-3 text-sm">
        <div className="grid grid-cols-2 md:grid-cols-4 gap-2">
            <div><b>Debit Total:</b> {preview.debit_total}</div>
            <div><b>Credit Total:</b> {preview.credit_total}</div>
            <div><b>Missing Mappings:</b> {preview.missing_mappings?.length || 0}</div>
            <div><b>JE:</b> {preview.run?.accrual_journal_entry_id || "-"}</div>
        </div>

        {preview.missing_mappings?.length > 0 && (
            <div className="border rounded p-2">
            <div className="font-medium mb-1">Missing Mappings</div>
            <ul className="list-disc pl-5">
                {preview.missing_mappings.map((m, idx) => (
                <li key={idx}>
                    {m.component_code} ({m.entry_side}) amount={m.amount}
                    {m.issue ? ` - ${m.issue}` : ""}
                </li>
                ))}
            </ul>
            </div>
        )}

        <div className="overflow-auto">
            <table className="min-w-full text-sm border-collapse">
            <thead>
                <tr className="border-b">
                <th className="text-left p-2">Component</th>
                <th className="text-left p-2">Side</th>
                <th className="text-left p-2">GL</th>
                <th className="text-left p-2">Amount</th>
                </tr>
            </thead>
            <tbody>
                {(preview.posting_lines || []).map((l, idx) => (
                <tr key={`${l.component_code}-${idx}`} className="border-b">
                    <td className="p-2">{l.component_code}</td>
                    <td className="p-2">{l.entry_side}</td>
                    <td className="p-2">{l.gl_account_code || l.gl_account_id}</td>
                    <td className="p-2">{l.amount}</td>
                </tr>
                ))}
            </tbody>
            </table>
        </div>

        <div className="flex gap-2">
            {run?.status !== "FINALIZED" && (
            <>
                <button className="border rounded px-2 py-1" type="button" onClick={onReview}>
                Mark Reviewed
                </button>
                <button
                className="border rounded px-2 py-1"
                type="button"
                onClick={onFinalize}
                disabled={!preview.can_finalize}
                >
                Finalize + Post Accrual
                </button>
            </>
            )}
        </div>
        </div>
    )}
    </div>
    ```

    ---

    ## 18) App routes — `frontend/src/App.jsx`

    ```jsx
    // frontend/src/App.jsx
    import PayrollComponentMappingsPage from "./pages/payroll/PayrollComponentMappingsPage.js";

    // ...
    <Route
    path="/payroll/mappings"
    element={
        <RequirePermission anyOf={["payroll.mappings.read"]}>
        <PayrollComponentMappingsPage />
        </RequirePermission>
    }
    />
    ```

    ---

    ## 19) Sidebar — `frontend/src/layouts/sidebarConfig.js`

    Add under Payroll:

    ```js
    {
    key: "payroll-mappings",
    label: "Payroll Mappings",
    to: "/payroll/mappings",
    requiredPermissions: ["payroll.mappings.read"],
    }
    ```

    ---

    ## 20) i18n — `frontend/src/i18n/messages.js`

    ```js
    // frontend/src/i18n/messages.js
    export default {
    // ...
    "sidebar.payrollMappings": "Payroll Mappings",
    };
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ Effective-dated payroll component → GL mappings can be created and listed
    * ✅ Mapping side is validated (debit components can’t be mapped as credit, etc.)
    * ✅ Payroll accrual preview returns posting lines, missing mappings, and balance check
    * ✅ Payroll run can be marked `REVIEWED`
    * ✅ Finalize posts accrual JE and marks payroll run `FINALIZED`
    * ✅ Finalize is idempotent (no duplicate accrual journal)
    * ✅ Mapping changes and payroll posting actions write audit rows
    * ✅ Permissions enforced for mappings/review/finalize
    * ✅ OpenAPI updated
    * ✅ Smoke test script exists and runs

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:payroll:prp02`

    Should verify at least:

    1. **Create mappings**

    * POST `/api/v1/payroll/mappings/upsert` for all non-zero components
    * rows created with correct effective dates

    2. **Accrual preview**

    * GET `/api/v1/payroll/runs/:id/accrual-preview`
    * `missing_mappings=[]`
    * `is_balanced=true`
    * posting lines returned

    3. **Review**

    * POST `/api/v1/payroll/runs/:id/review`
    * run status becomes `REVIEWED`

    4. **Finalize accrual**

    * POST `/api/v1/payroll/runs/:id/finalize`
    * run status becomes `FINALIZED`
    * `accrual_journal_entry_id` is set

    5. **Idempotent finalize**

    * POST `/finalize` again
    * same `accrual_journal_entry_id`, no duplicate JE

    6. **Missing mapping failure**

    * Another payroll run with one mapping intentionally missing
    * finalize returns `400` with missing component info

    7. **Effective-dated selection**

    * Two versions of a mapping with different `effective_from`
    * preview picks correct one based on `pay_date`

    8. **Permissions**

    * `payroll.mappings.read/write`, `payroll.runs.review`, `payroll.runs.finalize` all enforced (`403`)

    ---

    # Example mapping payloads (manual test)

    ## Base salary expense mapping

    ```json
    {
    "entity_code": "AFG-ENTITY-01",
    "provider_code": "PROVIDER_X",
    "currency_code": "USD",
    "component_code": "BASE_SALARY_EXPENSE",
    "entry_side": "DEBIT",
    "gl_account_id": 610100,
    "effective_from": "2026-01-01",
    "notes": "Payroll base salaries"
    }
    ```

    ## Payroll net payable mapping

    ```json
    {
    "entity_code": "AFG-ENTITY-01",
    "provider_code": "PROVIDER_X",
    "currency_code": "USD",
    "component_code": "PAYROLL_NET_PAYABLE",
    "entry_side": "CREDIT",
    "gl_account_id": 320100,
    "effective_from": "2026-01-01",
    "notes": "Net salaries payable"
    }
    ```

    ---

    # Payroll components to map in P02

    Map these (at minimum when amounts are non-zero):

    ### Debit (Expense)

    * `BASE_SALARY_EXPENSE`
    * `OVERTIME_EXPENSE`
    * `BONUS_EXPENSE`
    * `ALLOWANCES_EXPENSE`
    * `EMPLOYER_TAX_EXPENSE`
    * `EMPLOYER_SOCIAL_SECURITY_EXPENSE`

    ### Credit (Payables)

    * `PAYROLL_NET_PAYABLE`
    * `EMPLOYEE_TAX_PAYABLE`
    * `EMPLOYEE_SOCIAL_SECURITY_PAYABLE`
    * `EMPLOYER_TAX_PAYABLE`
    * `EMPLOYER_SOCIAL_SECURITY_PAYABLE`
    * `OTHER_DEDUCTIONS_PAYABLE`

    ---

    # Tiny implementation notes (important)

    * **P02 posts accrual only** — no bank/cash movement yet.
    * This matches the real-world contract:

    * Payroll run imported and validated
    * Accrual posted to GL
    * Liabilities later settled through **Payment Batches (PR-B04)**
    * In the next payroll payment PR, you’ll generate `source_type="PAYROLL"` payment batches from finalized payroll runs and settle `PAYROLL_NET_PAYABLE` through the bank module.

    ---

    If you want, next I can do **PR-P03 (Payroll Liability Breakdown + Payment Batch Preparation)** so payroll runs can feed **PR-B04** cleanly without losing employee-level traceability.

Perfect — here’s **PR-P03** in the same concrete format.

# PR-P03: Payroll Liability Breakdown + Payment Batch Preparation (Feeds PR-B04)

    ## Goal

    Convert a **FINALIZED payroll run (PR-P02)** into a payroll liability subledger, then prepare **generic Payment Batches (PR-B04)** from those liabilities.

    This PR gives you:

    * ✅ Payroll liability records (employee net + statutory liabilities)
    * ✅ Employee-level traceability preserved after accrual posting
    * ✅ Idempotent liability build from finalized payroll run
    * ✅ Payment batch preview (B04-compatible payload)
    * ✅ Create payroll payment batch (`source_type="PAYROLL"`) from liabilities
    * ✅ Liability ↔ payment batch link table
    * ✅ Audit trail
    * ❌ No auto-mark-paid from bank reconciliation yet (next payroll payment sync PR)

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m041_payroll_liabilities_payment_prep.js`
    * `backend/src/routes/payroll.liabilities.js`
    * `backend/src/routes/payroll.liabilities.validators.js`
    * `backend/src/services/payroll.liabilities.service.js`
    * `backend/scripts/test-payroll-prp03-liabilities-payment-prep.js`

    ### Frontend

    * `frontend/src/api/payrollLiabilities.js`
    * `frontend/src/pages/payroll/PayrollLiabilitiesPage.jsx`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js`
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/pages/payroll/PayrollRunDetailPage.jsx`
    * `frontend/src/App.jsx`
    * `frontend/src/layouts/sidebarConfig.js`
    * `frontend/src/i18n/messages.js`

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m041_payroll_liabilities_payment_prep.js`

    ```js
    // backend/src/migrations/m041_payroll_liabilities_payment_prep.js

    export default {
    key: "m041_payroll_liabilities_payment_prep",
    description: "m041_payroll_liabilities_payment_prep",
    async up(connection) {
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_run_liabilities (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            run_id BIGINT UNSIGNED NOT NULL,
            liability_key VARCHAR(120) NOT NULL, -- deterministic idempotency key per liability row
            liability_type VARCHAR(50) NOT NULL, -- NET_PAY, EMPLOYEE_TAX, EMPLOYEE_SOCIAL_SECURITY, EMPLOYER_TAX, EMPLOYER_SOCIAL_SECURITY, OTHER_DEDUCTIONS
            liability_group VARCHAR(30) NOT NULL, -- EMPLOYEE_NET, STATUTORY
            source_run_line_id BIGINT UNSIGNED NULL,

            employee_code VARCHAR(100) NULL,
            employee_name VARCHAR(255) NULL,
            cost_center_code VARCHAR(100) NULL,

            beneficiary_type VARCHAR(30) NOT NULL, -- EMPLOYEE, TAX_AUTHORITY, SOCIAL_SECURITY_AUTHORITY, OTHER
            beneficiary_id BIGINT UNSIGNED NULL,
            beneficiary_name VARCHAR(255) NOT NULL,
            beneficiary_bank_ref VARCHAR(255) NULL,

            payable_component_code VARCHAR(50) NOT NULL, -- maps to payroll component payable code in P02
            payable_gl_account_id BIGINT UNSIGNED NOT NULL,
            payable_ref VARCHAR(100) NULL,

            amount DECIMAL(18,2) NOT NULL,
            currency_code CHAR(3) NOT NULL,

            status VARCHAR(20) NOT NULL DEFAULT 'OPEN', -- OPEN, IN_BATCH, PAID, CANCELLED
            reserved_payment_batch_id BIGINT UNSIGNED NULL,
            paid_at DATETIME NULL,

            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

            PRIMARY KEY (id),
            UNIQUE KEY uq_payroll_liability_key (liability_key),
            KEY idx_payroll_liabilities_run (run_id),
            KEY idx_payroll_liabilities_status (status),
            KEY idx_payroll_liabilities_type (liability_type),
            KEY idx_payroll_liabilities_batch (reserved_payment_batch_id),

            CONSTRAINT fk_payroll_liabilities_run
            FOREIGN KEY (run_id) REFERENCES payroll_runs(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_payroll_liabilities_run_line
            FOREIGN KEY (source_run_line_id) REFERENCES payroll_run_lines(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_payroll_liabilities_gl
            FOREIGN KEY (payable_gl_account_id) REFERENCES accounts(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_payroll_liabilities_reserved_batch
            FOREIGN KEY (reserved_payment_batch_id) REFERENCES payment_batches(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_liability_payment_links (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            payroll_liability_id BIGINT UNSIGNED NOT NULL,
            payment_batch_id BIGINT UNSIGNED NOT NULL,
            payment_batch_line_id BIGINT UNSIGNED NULL,
            allocated_amount DECIMAL(18,2) NOT NULL,
            status VARCHAR(20) NOT NULL DEFAULT 'LINKED', -- LINKED, PAID, RELEASED
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

            PRIMARY KEY (id),
            UNIQUE KEY uq_payroll_liability_batch (payroll_liability_id, payment_batch_id),
            KEY idx_plinks_liability (payroll_liability_id),
            KEY idx_plinks_batch (payment_batch_id),
            KEY idx_plinks_batch_line (payment_batch_line_id),

            CONSTRAINT fk_plinks_liability
            FOREIGN KEY (payroll_liability_id) REFERENCES payroll_run_liabilities(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_plinks_batch
            FOREIGN KEY (payment_batch_id) REFERENCES payment_batches(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_plinks_batch_line
            FOREIGN KEY (payment_batch_line_id) REFERENCES payment_batch_lines(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_liability_audit (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            run_id BIGINT UNSIGNED NOT NULL,
            payroll_liability_id BIGINT UNSIGNED NULL,
            action VARCHAR(30) NOT NULL, -- BUILT, STATUS, LINKED_BATCH, RELEASED
            payload_json JSON NULL,
            acted_by BIGINT UNSIGNED NULL,
            acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

            PRIMARY KEY (id),
            KEY idx_pla_run (run_id),
            KEY idx_pla_liability (payroll_liability_id),
            KEY idx_pla_action (action),

            CONSTRAINT fk_pla_run
            FOREIGN KEY (run_id) REFERENCES payroll_runs(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_pla_liability
            FOREIGN KEY (payroll_liability_id) REFERENCES payroll_run_liabilities(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        await connection.execute(`
        ALTER TABLE payroll_runs
            ADD COLUMN liabilities_built_by BIGINT UNSIGNED NULL AFTER accrual_posted_at,
            ADD COLUMN liabilities_built_at DATETIME NULL AFTER liabilities_built_by
        `).catch(() => {});

        await connection.execute(`
        ALTER TABLE payroll_runs
            ADD KEY idx_payroll_runs_liabilities_built_at (liabilities_built_at)
        `).catch(() => {});
    },

    async down(connection) {
        await connection.execute(`DROP TABLE IF EXISTS payroll_liability_audit;`);
        await connection.execute(`DROP TABLE IF EXISTS payroll_liability_payment_links;`);
        await connection.execute(`DROP TABLE IF EXISTS payroll_run_liabilities;`);
    },
    };
    ```

    ---

    ## 2) Validators — `backend/src/routes/payroll.liabilities.validators.js`

    ```js
    // backend/src/routes/payroll.liabilities.validators.js

    function requirePositiveInt(v, field) {
    const n = Number(v);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${field} must be positive integer`);
    return n;
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function validateRunIdParam(params = {}) {
    return { id: requirePositiveInt(params.id, "id") };
    }

    function validateBuildLiabilitiesBody(body = {}) {
    return {
        note: normalizeString(body.note),
    };
    }

    function validateListPayrollLiabilitiesQuery(query = {}) {
    const scope = normalizeString(query.scope)?.toUpperCase() || null;
    if (scope && !["NET_PAY", "STATUTORY", "ALL"].includes(scope)) {
        throw new Error("scope must be NET_PAY, STATUTORY, or ALL");
    }

    return {
        run_id: query.run_id ? requirePositiveInt(query.run_id, "run_id") : null,
        status: normalizeString(query.status)?.toUpperCase() || null,
        liability_type: normalizeString(query.liability_type)?.toUpperCase() || null,
        scope,
        limit: query.limit ? Math.min(requirePositiveInt(query.limit, "limit"), 500) : 200,
        offset: query.offset ? Math.max(Number(query.offset) || 0, 0) : 0,
    };
    }

    function validatePaymentBatchPreviewQuery(query = {}) {
    const scope = normalizeString(query.scope)?.toUpperCase() || "NET_PAY";
    if (!["NET_PAY", "STATUTORY", "ALL"].includes(scope)) {
        throw new Error("scope must be NET_PAY, STATUTORY, or ALL");
    }
    return { scope };
    }

    function validateCreatePaymentBatchBody(body = {}) {
    const scope = normalizeString(body.scope)?.toUpperCase() || "NET_PAY";
    if (!["NET_PAY", "STATUTORY", "ALL"].includes(scope)) {
        throw new Error("scope must be NET_PAY, STATUTORY, or ALL");
    }

    return {
        scope,
        bank_account_id: requirePositiveInt(body.bank_account_id, "bank_account_id"),
        idempotency_key: normalizeString(body.idempotency_key),
        notes: normalizeString(body.notes),
    };
    }

    export default {
    validateRunIdParam,
    validateBuildLiabilitiesBody,
    validateListPayrollLiabilitiesQuery,
    validatePaymentBatchPreviewQuery,
    validateCreatePaymentBatchBody,
    };
    ```

    ---

    ## 3) Service — `backend/src/services/payroll.liabilities.service.js`

    > Depends on **PR-B04** (`payments.service.js`) and **PR-P02** mappings/finalized runs.

    ```js
    // backend/src/services/payroll.liabilities.service.js

    import paymentsService from "./payments.service.js";
    const LIABILITY_COMPONENT_MAP = {
    NET_PAY: { payable_component_code: "PAYROLL_NET_PAYABLE", beneficiary_type: "EMPLOYEE" },
    EMPLOYEE_TAX: { payable_component_code: "EMPLOYEE_TAX_PAYABLE", beneficiary_type: "TAX_AUTHORITY" },
    EMPLOYEE_SOCIAL_SECURITY: { payable_component_code: "EMPLOYEE_SOCIAL_SECURITY_PAYABLE", beneficiary_type: "SOCIAL_SECURITY_AUTHORITY" },
    EMPLOYER_TAX: { payable_component_code: "EMPLOYER_TAX_PAYABLE", beneficiary_type: "TAX_AUTHORITY" },
    EMPLOYER_SOCIAL_SECURITY: { payable_component_code: "EMPLOYER_SOCIAL_SECURITY_PAYABLE", beneficiary_type: "SOCIAL_SECURITY_AUTHORITY" },
    OTHER_DEDUCTIONS: { payable_component_code: "OTHER_DEDUCTIONS_PAYABLE", beneficiary_type: "OTHER" },
    };

    async function writeLiabilityAudit(db, { runId, liabilityId = null, action, payload = null, userId = null }) {
    await db.query(
        `INSERT INTO payroll_liability_audit (run_id, payroll_liability_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?, ?)`,
        [runId, liabilityId, action, payload ? JSON.stringify(payload) : null, userId]
    );
    }

    async function getRun(db, runId) {
    const [rows] = await db.query(`SELECT * FROM payroll_runs WHERE id=? LIMIT 1`, [runId]);
    return rows[0] || null;
    }

    async function resolvePayableMapping(db, { entity_code, provider_code, currency_code, pay_date, payable_component_code }) {
    const [rows] = await db.query(
        `
        SELECT m.id, m.gl_account_id, m.entry_side, a.code AS gl_account_code, a.name AS gl_account_name
        FROM payroll_component_gl_mappings m
        JOIN accounts a ON a.id = m.gl_account_id
        WHERE m.entity_code = ?
        AND m.currency_code = ?
        AND m.component_code = ?
        AND m.is_active = 1
        AND (m.provider_code = ? OR m.provider_code IS NULL)
        AND m.effective_from <= ?
        AND (m.effective_to IS NULL OR m.effective_to >= ?)
        ORDER BY
        CASE WHEN m.provider_code = ? THEN 0 ELSE 1 END,
        m.effective_from DESC,
        m.id DESC
        LIMIT 1
        `,
        [entity_code, currency_code, payable_component_code, provider_code, pay_date, pay_date, provider_code]
    );
    return rows[0] || null;
    }

    async function getRunLines(db, runId) {
    const [rows] = await db.query(
        `
        SELECT id, line_no, employee_code, employee_name, cost_center_code, net_pay,
            employee_tax, employee_social_security, employer_tax, employer_social_security, other_deductions
        FROM payroll_run_lines
        WHERE run_id = ?
        ORDER BY line_no ASC
        `,
        [runId]
    );
    return rows;
    }

    async function listRunLiabilities(db, runId) {
    const [rows] = await db.query(
        `
        SELECT
        l.*,
        a.code AS payable_gl_account_code,
        a.name AS payable_gl_account_name
        FROM payroll_run_liabilities l
        JOIN accounts a ON a.id = l.payable_gl_account_id
        WHERE l.run_id = ?
        ORDER BY
        CASE WHEN l.liability_group='EMPLOYEE_NET' THEN 0 ELSE 1 END,
        l.id ASC
        `,
        [runId]
    );
    return rows;
    }

    async function listPayrollLiabilities(db, q) {
    const where = [];
    const params = [];

    if (q.run_id) {
        where.push(`l.run_id = ?`);
        params.push(q.run_id);
    }
    if (q.status) {
        where.push(`l.status = ?`);
        params.push(q.status);
    }
    if (q.liability_type) {
        where.push(`l.liability_type = ?`);
        params.push(q.liability_type);
    }
    if (q.scope === "NET_PAY") where.push(`l.liability_group = 'EMPLOYEE_NET'`);
    if (q.scope === "STATUTORY") where.push(`l.liability_group = 'STATUTORY'`);

    let sql = `
        SELECT
        l.id, l.run_id, l.liability_type, l.liability_group, l.employee_code, l.employee_name,
        l.beneficiary_name, l.amount, l.currency_code, l.status, l.reserved_payment_batch_id,
        l.payable_component_code, l.payable_gl_account_id, a.code AS payable_gl_account_code
        FROM payroll_run_liabilities l
        JOIN accounts a ON a.id = l.payable_gl_account_id
    `;
    if (where.length) sql += ` WHERE ${where.join(" AND ")}`;
    sql += ` ORDER BY l.id DESC LIMIT ? OFFSET ?`;
    params.push(q.limit, q.offset);

    const [rows] = await db.query(sql, params);
    return rows;
    }

    function amount2(n) {
    return Number(Number(n || 0).toFixed(2));
    }

    async function buildRunLiabilities(db, runId, body = {}, userId = null) {
    const run = await getRun(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }

    if (run.status !== "FINALIZED" || !run.accrual_journal_entry_id) {
        const err = new Error("Payroll run must be FINALIZED with accrual journal before building liabilities");
        err.statusCode = 400;
        throw err;
    }

    const [existingRows] = await db.query(
        `SELECT COUNT(*) AS c FROM payroll_run_liabilities WHERE run_id = ?`,
        [runId]
    );
    if (Number(existingRows[0]?.c || 0) > 0) {
        // idempotent
        return {
        run,
        items: await listRunLiabilities(db, runId),
        summary: await summarizeRunLiabilities(db, runId),
        already_built: true,
        };
    }

    const runLines = await getRunLines(db, runId);

    const payableMappings = {};
    const requiredComponents = [
        "PAYROLL_NET_PAYABLE",
        "EMPLOYEE_TAX_PAYABLE",
        "EMPLOYEE_SOCIAL_SECURITY_PAYABLE",
        "EMPLOYER_TAX_PAYABLE",
        "EMPLOYER_SOCIAL_SECURITY_PAYABLE",
        "OTHER_DEDUCTIONS_PAYABLE",
    ];

    for (const c of requiredComponents) {
        const m = await resolvePayableMapping(db, {
        entity_code: run.entity_code,
        provider_code: run.provider_code,
        currency_code: run.currency_code,
        pay_date: run.pay_date,
        payable_component_code: c,
        });

        // allow missing only if total amount for that component will be zero
        payableMappings[c] = m || null;
    }

    const conn = db.getConnection ? await db.getConnection() : null;
    const q = conn || db;

    try {
        if (conn) await conn.beginTransaction();

        const insertedLiabilityIds = [];

        // 1) Employee net liabilities (one row per employee)
        for (const line of runLines) {
        const amount = amount2(line.net_pay);
        if (amount <= 0) continue;

        const comp = LIABILITY_COMPONENT_MAP.NET_PAY.payable_component_code;
        const mapping = payableMappings[comp];
        if (!mapping) {
            const err = new Error(`Missing payable mapping for ${comp}`);
            err.statusCode = 400;
            throw err;
        }

        const liabilityKey = `PRL|RUN:${runId}|NET|RL:${line.id}`;

        const [ins] = await q.query(
            `
            INSERT INTO payroll_run_liabilities
            (run_id, liability_key, liability_type, liability_group, source_run_line_id,
            employee_code, employee_name, cost_center_code,
            beneficiary_type, beneficiary_name, beneficiary_bank_ref,
            payable_component_code, payable_gl_account_id, payable_ref,
            amount, currency_code, status)
            VALUES (?, ?, 'NET_PAY', 'EMPLOYEE_NET', ?, ?, ?, ?, 'EMPLOYEE', ?, NULL, ?, ?, ?, ?, ?, 'OPEN')
            `,
            [
            runId,
            liabilityKey,
            line.id,
            line.employee_code,
            line.employee_name,
            line.cost_center_code || null,
            line.employee_name,
            comp,
            Number(mapping.gl_account_id),
            `${run.run_no}-EMP-${line.employee_code}`,
            amount,
            run.currency_code,
            ]
        );

        insertedLiabilityIds.push(ins.insertId);
        await writeLiabilityAudit(q, {
            runId,
            liabilityId: ins.insertId,
            action: "BUILT",
            payload: { liability_type: "NET_PAY", amount, source_run_line_id: line.id },
            userId,
        });
        }

        // 2) Statutory / deductions liabilities (aggregated by run)
        const statutoryDefs = [
        { liability_type: "EMPLOYEE_TAX", field: "employee_tax", label: "Payroll Tax Authority" },
        { liability_type: "EMPLOYEE_SOCIAL_SECURITY", field: "employee_social_security", label: "Payroll Social Security" },
        { liability_type: "EMPLOYER_TAX", field: "employer_tax", label: "Payroll Employer Tax Authority" },
        { liability_type: "EMPLOYER_SOCIAL_SECURITY", field: "employer_social_security", label: "Payroll Employer Social Security" },
        { liability_type: "OTHER_DEDUCTIONS", field: "other_deductions", label: "Payroll Deductions Clearing" },
        ];

        for (const def of statutoryDefs) {
        const total = amount2(run[`total_${def.field}`]);
        if (total <= 0) continue;

        const comp = LIABILITY_COMPONENT_MAP[def.liability_type].payable_component_code;
        const mapping = payableMappings[comp];
        if (!mapping) {
            const err = new Error(`Missing payable mapping for ${comp}`);
            err.statusCode = 400;
            throw err;
        }

        const liabilityKey = `PRL|RUN:${runId}|STAT|${def.liability_type}`;

        const [ins] = await q.query(
            `
            INSERT INTO payroll_run_liabilities
            (run_id, liability_key, liability_type, liability_group, source_run_line_id,
            beneficiary_type, beneficiary_name,
            payable_component_code, payable_gl_account_id, payable_ref,
            amount, currency_code, status)
            VALUES (?, ?, ?, 'STATUTORY', NULL, ?, ?, ?, ?, ?, ?, ?, 'OPEN')
            `,
            [
            runId,
            liabilityKey,
            def.liability_type,
            LIABILITY_COMPONENT_MAP[def.liability_type].beneficiary_type,
            def.label,
            comp,
            Number(mapping.gl_account_id),
            `${run.run_no}-${def.liability_type}`,
            total,
            run.currency_code,
            ]
        );

        insertedLiabilityIds.push(ins.insertId);
        await writeLiabilityAudit(q, {
            runId,
            liabilityId: ins.insertId,
            action: "BUILT",
            payload: { liability_type: def.liability_type, amount: total },
            userId,
        });
        }

        await q.query(
        `
        UPDATE payroll_runs
        SET liabilities_built_by = COALESCE(liabilities_built_by, ?),
            liabilities_built_at = COALESCE(liabilities_built_at, NOW())
        WHERE id = ?
        `,
        [userId, runId]
        );

        await q.query(
        `INSERT INTO payroll_run_audit (run_id, action, payload_json, acted_by) VALUES (?, 'LIABILITIES_BUILT', ?, ?)`,
        [runId, JSON.stringify({ count: insertedLiabilityIds.length, note: body.note || null }), userId]
        );

        if (conn) await conn.commit();

        return {
        run: await getRun(db, runId),
        items: await listRunLiabilities(db, runId),
        summary: await summarizeRunLiabilities(db, runId),
        already_built: false,
        };
    } catch (err) {
        if (conn) {
        try { await conn.rollback(); } catch (_) {}
        }
        throw err;
    } finally {
        if (conn) conn.release();
    }
    }

    async function summarizeRunLiabilities(db, runId) {
    const [rows] = await db.query(
        `
        SELECT
        COUNT(*) AS liability_count,
        COALESCE(SUM(amount),0) AS total_amount,
        COALESCE(SUM(CASE WHEN liability_group='EMPLOYEE_NET' THEN amount ELSE 0 END),0) AS total_employee_net,
        COALESCE(SUM(CASE WHEN liability_group='STATUTORY' THEN amount ELSE 0 END),0) AS total_statutory,
        COALESCE(SUM(CASE WHEN status='OPEN' THEN amount ELSE 0 END),0) AS total_open,
        COALESCE(SUM(CASE WHEN status='IN_BATCH' THEN amount ELSE 0 END),0) AS total_in_batch,
        COALESCE(SUM(CASE WHEN status='PAID' THEN amount ELSE 0 END),0) AS total_paid
        FROM payroll_run_liabilities
        WHERE run_id = ?
        `,
        [runId]
    );
    const r = rows[0] || {};
    Object.keys(r).forEach((k) => {
        if (k.endsWith("_amount") || k.startsWith("total_")) r[k] = amount2(r[k]);
    });
    return r;
    }

    function scopePredicate(scope) {
    if (scope === "NET_PAY") return `liability_group='EMPLOYEE_NET'`;
    if (scope === "STATUTORY") return `liability_group='STATUTORY'`;
    return `1=1`;
    }

    async function buildPaymentBatchPreview(db, runId, scope = "NET_PAY") {
    const run = await getRun(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }

    const [rows] = await db.query(
        `
        SELECT *
        FROM payroll_run_liabilities
        WHERE run_id = ?
        AND status = 'OPEN'
        AND ${scopePredicate(scope)}
        ORDER BY id ASC
        `,
        [runId]
    );

    const lines = rows.map((l) => ({
        payroll_liability_id: l.id,
        beneficiary_type: l.beneficiary_type,
        beneficiary_id: l.beneficiary_id,
        beneficiary_name: l.beneficiary_name,
        beneficiary_bank_ref: l.beneficiary_bank_ref,
        payable_entity_type: "PAYROLL_LIABILITY",
        payable_entity_id: l.id,
        payable_gl_account_id: l.payable_gl_account_id,
        payable_ref: l.payable_ref || l.liability_key,
        amount: amount2(l.amount),
    }));

    const total_amount = amount2(lines.reduce((s, l) => s + Number(l.amount), 0));

    return {
        run: {
        id: run.id,
        run_no: run.run_no,
        status: run.status,
        currency_code: run.currency_code,
        entity_code: run.entity_code,
        pay_date: run.pay_date,
        },
        scope,
        eligible_liability_count: rows.length,
        total_amount,
        can_prepare_payment_batch: rows.length > 0,
        batch_payload_template: {
        source_type: "PAYROLL",
        source_id: run.id,
        currency_code: run.currency_code,
        lines,
        },
    };
    }

    async function createPayrollPaymentBatch(db, runId, body, userId = null) {
    const run = await getRun(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }
    if (run.status !== "FINALIZED") {
        const err = new Error("Payroll run must be FINALIZED");
        err.statusCode = 400;
        throw err;
    }

    // Idempotent retry shortcut
    if (body.idempotency_key) {
        const [existing] = await db.query(
        `
        SELECT id
        FROM payment_batches
        WHERE source_type='PAYROLL' AND source_id=? AND idempotency_key=?
        LIMIT 1
        `,
        [runId, body.idempotency_key]
        );
        if (existing[0]) {
        const batch = await paymentsService.getBatchById(db, existing[0].id);
        return { batch, idempotent: true };
        }
    }

    const preview = await buildPaymentBatchPreview(db, runId, body.scope);
    if (!preview.can_prepare_payment_batch) {
        const err = new Error("No OPEN payroll liabilities eligible for payment batch");
        err.statusCode = 400;
        throw err;
    }

    const conn = db.getConnection ? await db.getConnection() : null;
    const q = conn || db;

    try {
        if (conn) await conn.beginTransaction();

        const batch = await paymentsService.createBatch(
        q,
        {
            source_type: "PAYROLL",
            source_id: runId,
            bank_account_id: body.bank_account_id,
            currency_code: run.currency_code,
            idempotency_key: body.idempotency_key || null,
            notes: body.notes || `Payroll ${body.scope} payment batch for ${run.run_no}`,
            lines: preview.batch_payload_template.lines,
        },
        userId
        );

        const batchLines = Array.isArray(batch.lines) ? batch.lines : [];

        for (const l of preview.batch_payload_template.lines) {
        const liabilityId = Number(l.payable_entity_id);
        const batchLine = batchLines.find((b) => Number(b.payable_entity_id) === liabilityId);

        if (!batchLine) {
            const err = new Error(`Batch line not found for payroll liability ${liabilityId}`);
            err.statusCode = 500;
            throw err;
        }

        await q.query(
            `
            INSERT INTO payroll_liability_payment_links
            (payroll_liability_id, payment_batch_id, payment_batch_line_id, allocated_amount, status)
            VALUES (?, ?, ?, ?, 'LINKED')
            ON DUPLICATE KEY UPDATE
            payment_batch_line_id = VALUES(payment_batch_line_id),
            allocated_amount = VALUES(allocated_amount),
            status = 'LINKED'
            `,
            [liabilityId, batch.id, batchLine.id, amount2(l.amount)]
        );

        await q.query(
            `
            UPDATE payroll_run_liabilities
            SET status='IN_BATCH', reserved_payment_batch_id=?, updated_at=NOW()
            WHERE id=? AND status='OPEN'
            `,
            [batch.id, liabilityId]
        );

        await writeLiabilityAudit(q, {
            runId,
            liabilityId,
            action: "LINKED_BATCH",
            payload: { payment_batch_id: batch.id, payment_batch_line_id: batchLine.id, amount: l.amount },
            userId,
        });
        }

        await q.query(
        `INSERT INTO payroll_run_audit (run_id, action, payload_json, acted_by) VALUES (?, 'PAYMENT_BATCH_PREPARED', ?, ?)`,
        [runId, JSON.stringify({ payment_batch_id: batch.id, scope: body.scope, count: preview.eligible_liability_count }), userId]
        );

        if (conn) await conn.commit();

        return {
        batch: await paymentsService.getBatchById(db, batch.id),
        preview,
        idempotent: false,
        };
    } catch (err) {
        if (conn) {
        try { await conn.rollback(); } catch (_) {}
        }
        throw err;
    } finally {
        if (conn) conn.release();
    }
    }

    async function listLiabilityAuditForRun(db, runId) {
    const [rows] = await db.query(
        `
        SELECT id, payroll_liability_id, action, payload_json, acted_by, acted_at
        FROM payroll_liability_audit
        WHERE run_id = ?
        ORDER BY id DESC
        `,
        [runId]
    );
    return rows;
    }

    export default {
    buildRunLiabilities,
    listRunLiabilities,
    listPayrollLiabilities,
    summarizeRunLiabilities,
    buildPaymentBatchPreview,
    createPayrollPaymentBatch,
    listLiabilityAuditForRun,
    };
    ```

    ---

    ## 4) Routes — `backend/src/routes/payroll.liabilities.js`

    ```js
    // backend/src/routes/payroll.liabilities.js

    import express from "express";
    import { validateRunIdParam,
    validateBuildLiabilitiesBody,
    validateListPayrollLiabilitiesQuery,
    validatePaymentBatchPreviewQuery,
    validateCreatePaymentBatchBody, } from "./payroll.liabilities.validators.js";
    import service from "../services/payroll.liabilities.service.js";
    // replace with your actual helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();

    // GET /api/v1/payroll/liabilities
    router.get(
    "/liabilities",
    requireAuth,
    requirePermission("payroll.liabilities.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const q = validateListPayrollLiabilitiesQuery(req.query);
        const items = await service.listPayrollLiabilities(db, q);
        res.json({ items });
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payroll/runs/:id/liabilities/build
    router.post(
    "/runs/:id/liabilities/build",
    requireAuth,
    requirePermission("payroll.liabilities.build"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const body = validateBuildLiabilitiesBody(req.body);
        const userId = req.user?.id ?? null;
        const result = await service.buildRunLiabilities(db, id, body, userId);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/payroll/runs/:id/liabilities
    router.get(
    "/runs/:id/liabilities",
    requireAuth,
    requirePermission("payroll.liabilities.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const [items, summary, audit] = await Promise.all([
            service.listRunLiabilities(db, id),
            service.summarizeRunLiabilities(db, id),
            service.listLiabilityAuditForRun(db, id),
        ]);
        res.json({ items, summary, audit });
        } catch (err) {
        next(err);
        }
    }
    );

    // GET /api/v1/payroll/runs/:id/payment-batch-preview?scope=NET_PAY
    router.get(
    "/runs/:id/payment-batch-preview",
    requireAuth,
    requirePermission("payroll.liabilities.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const q = validatePaymentBatchPreviewQuery(req.query);
        const result = await service.buildPaymentBatchPreview(db, id, q.scope);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payroll/runs/:id/payment-batches
    router.post(
    "/runs/:id/payment-batches",
    requireAuth,
    requirePermission("payroll.payment.prepare"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const body = validateCreatePaymentBatchBody(req.body);
        const userId = req.user?.id ?? null;
        const result = await service.createPayrollPaymentBatch(db, id, body, userId);
        res.status(201).json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 5) Mount route — `backend/src/index.js`

    ```js
    // backend/src/index.js
    import payrollLiabilitiesRoutes from "./routes/payroll.liabilities.js";
    // ...
    app.use("/api/v1/payroll", payrollLiabilitiesRoutes);
    ```

    ---

    ## 6) Migration registry — `backend/src/migrations/index.js`

    ```js
    // backend/src/migrations/index.js
    import m041_payroll_liabilities_payment_prep from "./m041_payroll_liabilities_payment_prep.js";
    export default [
    // ...
    m041_payroll_liabilities_payment_prep,
    ];
    ```

    ---

    ## 7) Seed permissions — `backend/src/seedCore.js`

    ```js
    // backend/src/seedCore.js
    const PAYROLL_P03_PERMISSIONS = [
    "payroll.liabilities.read",
    "payroll.liabilities.build",
    "payroll.payment.prepare",
    ];

    // merge into permission seed list
    ```

    ---

    ## 8) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Register these paths:

    * `GET /api/v1/payroll/liabilities`
    * `POST /api/v1/payroll/runs/{id}/liabilities/build`
    * `GET /api/v1/payroll/runs/{id}/liabilities`
    * `GET /api/v1/payroll/runs/{id}/payment-batch-preview`
    * `POST /api/v1/payroll/runs/{id}/payment-batches`

    ---

    ## 9) Backend smoke test — `backend/scripts/test-payroll-prp03-liabilities-payment-prep.js`

    ```js
    // backend/scripts/test-payroll-prp03-liabilities-payment-prep.js

    async function main() {
    // Preconditions:
    // - PR-B04 implemented (generic payment batch engine)
    // - PR-P01/P02 implemented (import + accrual finalize)
    // - A bank account exists for payment batch creation
    //
    // Flow:
    // 1) Import + finalize a payroll run (or use a fresh FINALIZED run)
    // 2) POST /api/v1/payroll/runs/:id/liabilities/build
    //    -> creates employee net liabilities + statutory liabilities
    // 3) POST build again
    //    -> idempotent (already_built=true, no duplicate liabilities)
    // 4) GET /api/v1/payroll/runs/:id/liabilities
    //    -> summary totals present, audit present
    // 5) GET /api/v1/payroll/runs/:id/payment-batch-preview?scope=NET_PAY
    //    -> returns B04-compatible lines for employee net liabilities
    // 6) POST /api/v1/payroll/runs/:id/payment-batches (scope=NET_PAY)
    //    -> creates payment_batches row (source_type=PAYROLL, source_id=runId)
    //    -> liability links created
    //    -> liabilities move OPEN -> IN_BATCH
    // 7) POST same with same idempotency_key
    //    -> idempotent, same batch id
    // 8) GET /api/v1/payroll/liabilities?run_id=:id&status=IN_BATCH
    //    -> linked liabilities visible
    // 9) Permissions:
    //    - payroll.liabilities.read/build, payroll.payment.prepare enforced (403)
    console.log("PR-P03 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    ---

    ## 10) `backend/package.json` updates

    ```json
    {
    "scripts": {
        "test:payroll:prp03": "node backend/scripts/test-payroll-prp03-liabilities-payment-prep.js"
    }
    }
    ```

    ---

    # Frontend skeletons

    ## 11) API client — `frontend/src/api/payrollLiabilities.js`

    ```js
    // frontend/src/api/payrollLiabilities.js

    import { apiFetch } from "./client.js"; // adapt

    export function listPayrollLiabilities(params = {}) {
    const q = new URLSearchParams();
    if (params.run_id) q.set("run_id", String(params.run_id));
    if (params.status) q.set("status", params.status);
    if (params.liability_type) q.set("liability_type", params.liability_type);
    if (params.scope) q.set("scope", params.scope);
    const qs = q.toString();
    return apiFetch(`/api/v1/payroll/liabilities${qs ? `?${qs}` : ""}`);
    }

    export function buildPayrollRunLiabilities(runId, payload = {}) {
    return apiFetch(`/api/v1/payroll/runs/${runId}/liabilities/build`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }

    export function getPayrollRunLiabilities(runId) {
    return apiFetch(`/api/v1/payroll/runs/${runId}/liabilities`);
    }

    export function getPayrollRunPaymentBatchPreview(runId, scope = "NET_PAY") {
    return apiFetch(`/api/v1/payroll/runs/${runId}/payment-batch-preview?scope=${encodeURIComponent(scope)}`);
    }

    export function createPayrollRunPaymentBatch(runId, payload) {
    return apiFetch(`/api/v1/payroll/runs/${runId}/payment-batches`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }
    ```

    ---

    ## 12) Page — `frontend/src/pages/payroll/PayrollLiabilitiesPage.jsx`

    > Same page can serve both:
    >
    > * `/payroll/liabilities` (global list)
    > * `/payroll/runs/:id/liabilities` (run-specific actions)

    ```jsx
    // frontend/src/pages/payroll/PayrollLiabilitiesPage.jsx

    import { useEffect, useMemo, useState } from "react";
    import { Link, useParams } from "react-router-dom";
    import {
    listPayrollLiabilities,
    buildPayrollRunLiabilities,
    getPayrollRunLiabilities,
    getPayrollRunPaymentBatchPreview,
    createPayrollRunPaymentBatch,
    } from "../../api/payrollLiabilities.js";

    export default function PayrollLiabilitiesPage() {
    const { id: runIdParam } = useParams();
    const runId = runIdParam ? Number(runIdParam) : null;

    const [items, setItems] = useState([]);
    const [summary, setSummary] = useState(null);
    const [audit, setAudit] = useState([]);
    const [preview, setPreview] = useState(null);
    const [err, setErr] = useState("");
    const [scope, setScope] = useState("NET_PAY");

    const [batchForm, setBatchForm] = useState({
        bank_account_id: "",
        idempotency_key: "",
        notes: "",
    });

    async function loadGlobal() {
        const res = await listPayrollLiabilities({});
        setItems(res.items || []);
        setSummary(null);
        setAudit([]);
        setPreview(null);
    }

    async function loadRun() {
        const [liab, prev] = await Promise.all([
        getPayrollRunLiabilities(runId),
        getPayrollRunPaymentBatchPreview(runId, scope).catch(() => null),
        ]);
        setItems(liab.items || []);
        setSummary(liab.summary || null);
        setAudit(liab.audit || []);
        setPreview(prev);
    }

    async function load() {
        setErr("");
        try {
        if (runId) await loadRun();
        else await loadGlobal();
        } catch (e) {
        setErr(e.message || "Failed to load payroll liabilities");
        }
    }

    useEffect(() => {
        load();
    }, [runId, scope]);

    const totalAmount = useMemo(
        () => (items || []).reduce((s, i) => s + Number(i.amount || 0), 0).toFixed(2),
        [items]
    );

    async function onBuild() {
        try {
        setErr("");
        await buildPayrollRunLiabilities(runId, {});
        await load();
        } catch (e) {
        setErr(e.message || "Build failed");
        }
    }

    async function onPrepareBatch() {
        try {
        setErr("");
        const payload = {
            scope,
            bank_account_id: Number(batchForm.bank_account_id),
            idempotency_key: batchForm.idempotency_key || undefined,
            notes: batchForm.notes || undefined,
        };
        const res = await createPayrollRunPaymentBatch(runId, payload);
        const batchId = res?.batch?.id;
        if (batchId) {
            setBatchForm((s) => ({
            ...s,
            idempotency_key: s.idempotency_key || `payroll-${runId}-${scope.toLowerCase()}`,
            }));
        }
        await load();
        } catch (e) {
        setErr(e.message || "Prepare payment batch failed");
        }
    }

    return (
        <div className="p-4 space-y-4">
        <div className="rounded border bg-white p-4">
            <div className="flex items-center gap-2">
            <h1 className="text-lg font-semibold">
                {runId ? `Payroll Liabilities (Run #${runId})` : "Payroll Liabilities"}
            </h1>
            {runId ? (
                <Link className="ml-auto underline" to={`/payroll/runs/${runId}`}>
                Back to Payroll Run
                </Link>
            ) : null}
            </div>

            {err ? <div className="text-sm text-red-600 mt-2">{err}</div> : null}

            <div className="mt-3 text-sm">
            <b>Total:</b> {totalAmount}
            {summary ? (
                <>
                {" · "} <b>Open:</b> {summary.total_open}
                {" · "} <b>In Batch:</b> {summary.total_in_batch}
                {" · "} <b>Paid:</b> {summary.total_paid}
                </>
            ) : null}
            </div>

            {runId ? (
            <div className="mt-3 grid grid-cols-1 md:grid-cols-3 gap-2">
                <button className="border rounded px-2 py-1" type="button" onClick={onBuild}>
                Build Liabilities
                </button>

                <select
                className="border rounded px-2 py-1"
                value={scope}
                onChange={(e) => setScope(e.target.value)}
                >
                <option value="NET_PAY">NET_PAY</option>
                <option value="STATUTORY">STATUTORY</option>
                <option value="ALL">ALL</option>
                </select>

                <input
                className="border rounded px-2 py-1"
                placeholder="Bank Account ID"
                value={batchForm.bank_account_id}
                onChange={(e) => setBatchForm((s) => ({ ...s, bank_account_id: e.target.value }))}
                />

                <input
                className="border rounded px-2 py-1 md:col-span-2"
                placeholder="Idempotency Key (optional)"
                value={batchForm.idempotency_key}
                onChange={(e) => setBatchForm((s) => ({ ...s, idempotency_key: e.target.value }))}
                />

                <input
                className="border rounded px-2 py-1"
                placeholder="Notes (optional)"
                value={batchForm.notes}
                onChange={(e) => setBatchForm((s) => ({ ...s, notes: e.target.value }))}
                />

                <button
                className="border rounded px-2 py-1"
                type="button"
                onClick={onPrepareBatch}
                disabled={!preview?.can_prepare_payment_batch}
                >
                Prepare Payment Batch
                </button>
            </div>
            ) : null}
        </div>

        {runId && preview ? (
            <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Payment Batch Preview ({scope})</h2>
            <div className="text-sm mb-2">
                Eligible liabilities: {preview.eligible_liability_count} · Total: {preview.total_amount}
            </div>
            <div className="overflow-auto">
                <table className="min-w-full text-sm border-collapse">
                <thead>
                    <tr className="border-b">
                    <th className="text-left p-2">Liability ID</th>
                    <th className="text-left p-2">Beneficiary</th>
                    <th className="text-left p-2">GL</th>
                    <th className="text-left p-2">Amount</th>
                    </tr>
                </thead>
                <tbody>
                    {(preview.batch_payload_template?.lines || []).map((l) => (
                    <tr key={l.payable_entity_id} className="border-b">
                        <td className="p-2">{l.payable_entity_id}</td>
                        <td className="p-2">{l.beneficiary_name}</td>
                        <td className="p-2">{l.payable_gl_account_id}</td>
                        <td className="p-2">{l.amount}</td>
                    </tr>
                    ))}
                    {(preview.batch_payload_template?.lines || []).length === 0 ? (
                    <tr><td className="p-2" colSpan={4}>No eligible liabilities.</td></tr>
                    ) : null}
                </tbody>
                </table>
            </div>
            </div>
        ) : null}

        <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Liabilities</h2>
            <div className="overflow-auto">
            <table className="min-w-full text-sm border-collapse">
                <thead>
                <tr className="border-b">
                    <th className="text-left p-2">ID</th>
                    <th className="text-left p-2">Run</th>
                    <th className="text-left p-2">Type</th>
                    <th className="text-left p-2">Employee</th>
                    <th className="text-left p-2">Beneficiary</th>
                    <th className="text-left p-2">Amount</th>
                    <th className="text-left p-2">Status</th>
                    <th className="text-left p-2">Batch</th>
                </tr>
                </thead>
                <tbody>
                {items.map((l) => (
                    <tr key={l.id} className="border-b">
                    <td className="p-2">{l.id}</td>
                    <td className="p-2">{l.run_id}</td>
                    <td className="p-2">{l.liability_type}</td>
                    <td className="p-2">{l.employee_code ? `${l.employee_code} - ${l.employee_name}` : "-"}</td>
                    <td className="p-2">{l.beneficiary_name}</td>
                    <td className="p-2">{l.amount}</td>
                    <td className="p-2">{l.status}</td>
                    <td className="p-2">
                        {l.reserved_payment_batch_id ? (
                        <Link className="underline" to={`/payments/batches/${l.reserved_payment_batch_id}`}>
                            {l.reserved_payment_batch_id}
                        </Link>
                        ) : "-"}
                    </td>
                    </tr>
                ))}
                {items.length === 0 && (
                    <tr><td className="p-2" colSpan={8}>No payroll liabilities found.</td></tr>
                )}
                </tbody>
            </table>
            </div>
        </div>

        {runId ? (
            <div className="rounded border bg-white p-4">
            <h2 className="font-medium mb-2">Liability Audit</h2>
            <div className="space-y-1 text-sm">
                {audit.map((a) => (
                <div key={a.id} className="border rounded p-2">
                    <b>{a.action}</b> — {a.acted_at}
                </div>
                ))}
                {audit.length === 0 ? <div>No audit rows.</div> : null}
            </div>
            </div>
        ) : null}
        </div>
    );
    }
    ```

    ---

    ## 13) Update payroll run detail page — `frontend/src/pages/payroll/PayrollRunDetailPage.jsx`

    Add a link button in the header/actions area:

    ```jsx
    // frontend/src/pages/payroll/PayrollRunDetailPage.jsx
    import { Link } from "react-router-dom";

    // inside JSX (header card is fine)
    <Link className="border rounded px-2 py-1 inline-block" to={`/payroll/runs/${run.id}/liabilities`}>
    Liabilities & Payment Prep
    </Link>
    ```

    ---

    ## 14) App routes — `frontend/src/App.jsx`

    ```jsx
    // frontend/src/App.jsx
    import PayrollLiabilitiesPage from "./pages/payroll/PayrollLiabilitiesPage.js";

    // ...
    <Route
    path="/payroll/liabilities"
    element={
        <RequirePermission anyOf={["payroll.liabilities.read"]}>
        <PayrollLiabilitiesPage />
        </RequirePermission>
    }
    />

    <Route
    path="/payroll/runs/:id/liabilities"
    element={
        <RequirePermission anyOf={["payroll.liabilities.read"]}>
        <PayrollLiabilitiesPage />
        </RequirePermission>
    }
    />
    ```

    ---

    ## 15) Sidebar — `frontend/src/layouts/sidebarConfig.js`

    Add under Payroll:

    ```js
    {
    key: "payroll-liabilities",
    label: "Payroll Liabilities",
    to: "/payroll/liabilities",
    requiredPermissions: ["payroll.liabilities.read"],
    }
    ```

    ---

    ## 16) i18n — `frontend/src/i18n/messages.js`

    ```js
    // frontend/src/i18n/messages.js
    export default {
    // ...
    "sidebar.payrollLiabilities": "Payroll Liabilities",
    };
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ FINALIZED payroll run can generate payroll liabilities (employee net + statutory)
    * ✅ Liability build is idempotent (no duplicate rows on re-run)
    * ✅ Payroll liabilities store employee-level traceability for net pay
    * ✅ Liability rows carry payable GL account (resolved from effective-dated mappings)
    * ✅ Payment batch preview returns B04-compatible payload
    * ✅ Can create generic payment batch from payroll liabilities (`source_type="PAYROLL"`)
    * ✅ Liability ↔ payment batch links are stored
    * ✅ Liabilities move `OPEN -> IN_BATCH` when batch is prepared
    * ✅ Audit rows exist for liability build and batch linking
    * ✅ Permissions enforced (`payroll.liabilities.*`, `payroll.payment.prepare`)
    * ✅ OpenAPI updated
    * ✅ Smoke test script exists and runs

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:payroll:prp03`

    Should verify at least:

    1. **Build liabilities**

    * POST `/api/v1/payroll/runs/:id/liabilities/build`
    * creates:

        * employee net liabilities (one per payroll employee with net pay > 0)
        * statutory liabilities (aggregated by component)
    * totals reconcile to payroll run payable totals

    2. **Idempotent build**

    * Re-run build → no duplicates, returns `already_built=true`

    3. **Run liabilities read**

    * GET `/api/v1/payroll/runs/:id/liabilities`
    * returns `items + summary + audit`

    4. **Payment batch preview**

    * GET `/api/v1/payroll/runs/:id/payment-batch-preview?scope=NET_PAY`
    * returns B04-compatible `batch_payload_template`
    * includes employee beneficiaries and payable GL accounts

    5. **Create payroll payment batch**

    * POST `/api/v1/payroll/runs/:id/payment-batches`
    * creates `payment_batches` row with:

        * `source_type="PAYROLL"`
        * `source_id=<runId>`
    * creates `payroll_liability_payment_links`
    * liabilities move to `IN_BATCH`

    6. **Idempotent prepare**

    * Same request with same `idempotency_key` returns same batch (no duplicates)

    7. **Global list**

    * GET `/api/v1/payroll/liabilities?run_id=:id&status=IN_BATCH`
    * returns linked liabilities

    8. **Permissions**

    * `payroll.liabilities.read`, `payroll.liabilities.build`, `payroll.payment.prepare` enforced (`403`)

    ---

    # Example manual payloads

    ## Build liabilities

    ```json
    {
    "note": "Build payroll liabilities after accrual finalization"
    }
    ```

    ## Payment batch preview

    `GET /api/v1/payroll/runs/12/payment-batch-preview?scope=NET_PAY`

    ## Create payroll payment batch (employee net pay)

    ```json
    {
    "scope": "NET_PAY",
    "bank_account_id": 1,
    "idempotency_key": "payroll-run-12-netpay-v1",
    "notes": "Payroll net salary payment batch"
    }
    ```

    ## Create payroll payment batch (statutory)

    ```json
    {
    "scope": "STATUTORY",
    "bank_account_id": 1,
    "idempotency_key": "payroll-run-12-statutory-v1",
    "notes": "Payroll statutory remittance batch"
    }
    ```

    ---

    # Tiny implementation notes (important)

    * **P03 prepares payment batches** but does **not** mark payroll liabilities as paid yet.
    * Actual payment completion should be driven by:

    * **B04 batch posting**
    * then **bank reconciliation (B03)**
    * then payroll settlement sync (next payroll PR)
    * This keeps the contract clean:

    * Payroll owns liability subledger
    * Payments/Bank own execution + reconciliation
    * Sync layer updates payroll liability status when payment is truly settled

Perfect — here’s **PR-P04** in the same format, and I’ll keep the **frontend part shorter** (only key integration snippets + comments, no full page tables).

# PR-P04: Payroll Payment Settlement Sync (Payment Batches + Bank Reconciliation Feedback)

    ## Goal

    Close the loop after **PR-P03** by syncing payroll liabilities from:

    * **PR-B04 Payment Batch execution status**
    * **PR-B03 Bank reconciliation evidence**

    This PR gives you:

    * ✅ Sync preview: what will move `IN_BATCH -> PAID` (or be released back to `OPEN`)
    * ✅ Sync apply (idempotent): updates payroll liabilities safely
    * ✅ Payroll settlement records (audit-grade evidence trail)
    * ✅ Link-level settlement/release state
    * ✅ Payroll run audit entries for sync activity
    * ❌ No payroll reversals/off-cycle correction engine yet (later PR)

    ---

    ## Integration contract assumptions (important)

    This PR assumes your B04/B03 stack exposes **some** evidence that a payment batch line is truly settled/reconciled.

    ### Expected (adapt names to your actual schema)

    On `payment_batch_lines` (or equivalent), payroll sync should be able to read **at least one** of these patterns:

    * `status` (e.g. `PAID`, `SETTLED`, `CANCELLED`, `FAILED`)
    * `reconciliation_status` (e.g. `RECONCILED`)
    * `bank_statement_line_id` (nullable FK when matched by bank reconciliation)
    * `executed_at`, `reconciled_at`

    If your actual B03/B04 schema uses different names, **only the evidence query needs adaptation**; payroll sync behavior stays the same.

    ---

    ## Files to create

    ### Backend

    * `backend/src/migrations/m042_payroll_payment_settlement_sync.js`
    * `backend/src/routes/payroll.paymentSync.js`
    * `backend/src/routes/payroll.paymentSync.validators.js`
    * `backend/src/services/payroll.paymentSync.service.js`
    * `backend/scripts/test-payroll-prp04-payment-settlement-sync.js`

    ### Frontend (shorter snippets only)

    * `frontend/src/api/payrollPaymentSync.js`

    ---

    ## Files to update

    ### Backend

    * `backend/src/migrations/index.js`
    * `backend/src/index.js`
    * `backend/src/seedCore.js`
    * `backend/scripts/generate-openapi.js`
    * `backend/package.json`

    ### Frontend

    * `frontend/src/pages/payroll/PayrollLiabilitiesPage.jsx` (add preview/apply sync actions)
    * `frontend/src/pages/payroll/PayrollRunDetailPage.jsx` (optional quick sync link/button)
    * `frontend/src/App.jsx` (if you want a dedicated sync route later; not required now)
    * `frontend/src/i18n/messages.js` (optional labels)

    ---

    # Concrete skeletons

    ## 1) Migration — `backend/src/migrations/m042_payroll_payment_settlement_sync.js`

    ```js
    // backend/src/migrations/m042_payroll_payment_settlement_sync.js

    export default {
    key: "m042_payroll_payment_settlement_sync",
    description: "m042_payroll_payment_settlement_sync",
    async up(connection) {
        // Settlement evidence table (audit-grade, idempotent)
        await connection.execute(`
        CREATE TABLE IF NOT EXISTS payroll_liability_settlements (
            id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
            settlement_key VARCHAR(190) NOT NULL, -- deterministic for idempotent sync apply

            run_id BIGINT UNSIGNED NOT NULL,
            payroll_liability_id BIGINT UNSIGNED NOT NULL,
            payroll_liability_payment_link_id BIGINT UNSIGNED NOT NULL,

            payment_batch_id BIGINT UNSIGNED NOT NULL,
            payment_batch_line_id BIGINT UNSIGNED NULL,

            bank_statement_line_id BIGINT UNSIGNED NULL, -- nullable if your B03 stores evidence elsewhere
            settlement_source VARCHAR(30) NOT NULL,      -- B04_ONLY, B03_RECON, MANUAL_OVERRIDE (future)
            settled_amount DECIMAL(18,2) NOT NULL,
            currency_code CHAR(3) NOT NULL,
            settled_at DATETIME NOT NULL,

            payload_json JSON NULL,
            created_by BIGINT UNSIGNED NULL,
            created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

            PRIMARY KEY (id),
            UNIQUE KEY uq_payroll_liability_settlements_key (settlement_key),
            KEY idx_pls_run (run_id),
            KEY idx_pls_liability (payroll_liability_id),
            KEY idx_pls_batch (payment_batch_id),
            KEY idx_pls_batch_line (payment_batch_line_id),

            CONSTRAINT fk_pls_run
            FOREIGN KEY (run_id) REFERENCES payroll_runs(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_pls_liability
            FOREIGN KEY (payroll_liability_id) REFERENCES payroll_run_liabilities(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_pls_link
            FOREIGN KEY (payroll_liability_payment_link_id) REFERENCES payroll_liability_payment_links(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT,

            CONSTRAINT fk_pls_batch
            FOREIGN KEY (payment_batch_id) REFERENCES payment_batches(id)
            ON UPDATE RESTRICT ON DELETE RESTRICT
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        `);

        // Extend links with sync status
        await connection.execute(`
        ALTER TABLE payroll_liability_payment_links
            ADD COLUMN settled_amount DECIMAL(18,2) NOT NULL DEFAULT 0 AFTER allocated_amount,
            ADD COLUMN settled_at DATETIME NULL AFTER settled_amount,
            ADD COLUMN released_at DATETIME NULL AFTER settled_at,
            ADD COLUMN last_sync_at DATETIME NULL AFTER released_at,
            ADD COLUMN sync_note VARCHAR(255) NULL AFTER last_sync_at
        `).catch(() => {});

        await connection.execute(`
        ALTER TABLE payroll_liability_payment_links
            ADD KEY idx_plinks_settled_at (settled_at),
            ADD KEY idx_plinks_last_sync_at (last_sync_at)
        `).catch(() => {});

        // Optional convenience columns on liabilities
        await connection.execute(`
        ALTER TABLE payroll_run_liabilities
            ADD COLUMN paid_payment_batch_id BIGINT UNSIGNED NULL AFTER paid_at,
            ADD COLUMN paid_payment_batch_line_id BIGINT UNSIGNED NULL AFTER paid_payment_batch_id,
            ADD COLUMN paid_bank_statement_line_id BIGINT UNSIGNED NULL AFTER paid_payment_batch_line_id
        `).catch(() => {});

        // Payroll run sync timestamps
        await connection.execute(`
        ALTER TABLE payroll_runs
            ADD COLUMN payment_sync_last_preview_at DATETIME NULL AFTER liabilities_built_at,
            ADD COLUMN payment_sync_last_applied_at DATETIME NULL AFTER payment_sync_last_preview_at
        `).catch(() => {});
    },

    async down(connection) {
        await connection.execute(`DROP TABLE IF EXISTS payroll_liability_settlements;`);
        // (Optional strict down for ALTER columns omitted for dev simplicity)
    },
    };
    ```

    ---

    ## 2) Validators — `backend/src/routes/payroll.paymentSync.validators.js`

    ```js
    // backend/src/routes/payroll.paymentSync.validators.js

    function requirePositiveInt(v, field) {
    const n = Number(v);
    if (!Number.isInteger(n) || n <= 0) throw new Error(`${field} must be positive integer`);
    return n;
    }

    function normalizeString(v) {
    if (v === undefined || v === null) return null;
    const s = String(v).trim();
    return s === "" ? null : s;
    }

    function validateRunIdParam(params = {}) {
    return { id: requirePositiveInt(params.id, "id") };
    }

    function validateSyncPreviewQuery(query = {}) {
    const scope = String(query.scope || "ALL").trim().toUpperCase();
    if (!["ALL", "NET_PAY", "STATUTORY"].includes(scope)) {
        throw new Error("scope must be ALL, NET_PAY, or STATUTORY");
    }
    return { scope };
    }

    function validateSyncApplyBody(body = {}) {
    const scope = String(body.scope || "ALL").trim().toUpperCase();
    if (!["ALL", "NET_PAY", "STATUTORY"].includes(scope)) {
        throw new Error("scope must be ALL, NET_PAY, or STATUTORY");
    }

    return {
        scope,
        note: normalizeString(body.note),
        allow_b04_only_settlement: String(body.allow_b04_only_settlement || "false").toLowerCase() === "true",
    };
    }

    export default {
    validateRunIdParam,
    validateSyncPreviewQuery,
    validateSyncApplyBody,
    };
    ```

    ---

    ## 3) Service — `backend/src/services/payroll.paymentSync.service.js`

    ```js
    // backend/src/services/payroll.paymentSync.service.js

    function amount2(n) {
    return Number(Number(n || 0).toFixed(2));
    }

    async function getRun(db, runId) {
    const [rows] = await db.query(`SELECT * FROM payroll_runs WHERE id=? LIMIT 1`, [runId]);
    return rows[0] || null;
    }

    function scopeSql(scope) {
    if (scope === "NET_PAY") return `AND l.liability_group = 'EMPLOYEE_NET'`;
    if (scope === "STATUTORY") return `AND l.liability_group = 'STATUTORY'`;
    return ``;
    }

    /**
     * IMPORTANT:
     * Adapt this query's payment/reconciliation evidence columns to your actual PR-B03/B04 schema.
     * Current skeleton assumes payment_batch_lines has:
     *   - status
     *   - reconciliation_status
     *   - bank_statement_line_id
     *   - executed_at / reconciled_at
     */
    async function listSyncCandidates(db, runId, scope = "ALL") {
    const [rows] = await db.query(
        `
        SELECT
        l.id AS payroll_liability_id,
        l.run_id,
        l.liability_type,
        l.liability_group,
        l.beneficiary_name,
        l.amount,
        l.currency_code,
        l.status AS liability_status,
        l.reserved_payment_batch_id,

        pl.id AS link_id,
        pl.payment_batch_id,
        pl.payment_batch_line_id,
        pl.allocated_amount,
        pl.settled_amount AS link_settled_amount,
        pl.status AS link_status,

        pb.status AS payment_batch_status,

        pbl.status AS payment_batch_line_status,
        pbl.reconciliation_status AS payment_batch_line_reconciliation_status,
        pbl.bank_statement_line_id,
        pbl.executed_at,
        pbl.reconciled_at

        FROM payroll_run_liabilities l
        JOIN payroll_liability_payment_links pl
        ON pl.payroll_liability_id = l.id
        JOIN payment_batches pb
        ON pb.id = pl.payment_batch_id
        LEFT JOIN payment_batch_lines pbl
        ON pbl.id = pl.payment_batch_line_id
        WHERE l.run_id = ?
        AND l.status IN ('IN_BATCH', 'PAID')
        ${scopeSql(scope)}
        ORDER BY l.id ASC
        `,
        [runId]
    );

    return rows;
    }

    function classifyCandidate(row, { allow_b04_only_settlement = false } = {}) {
    const amount = amount2(row.allocated_amount || row.amount);

    const batchCancelled = ["CANCELLED", "FAILED", "REJECTED"].includes(String(row.payment_batch_status || "").toUpperCase());
    const lineCancelled = ["CANCELLED", "FAILED", "REJECTED"].includes(String(row.payment_batch_line_status || "").toUpperCase());

    const linePaid = ["PAID", "SETTLED", "EXECUTED"].includes(String(row.payment_batch_line_status || "").toUpperCase());
    const reconciled = String(row.payment_batch_line_reconciliation_status || "").toUpperCase() === "RECONCILED";
    const hasBankEvidence = !!row.bank_statement_line_id;

    const hasSettlementEvidence = hasBankEvidence || reconciled || (allow_b04_only_settlement && linePaid);

    if (row.liability_status === "IN_BATCH" && hasSettlementEvidence) {
        return {
        action: "MARK_PAID",
        amount,
        settled_at: row.reconciled_at || row.executed_at || new Date().toISOString().slice(0, 19).replace("T", " "),
        settlement_source: hasBankEvidence || reconciled ? "B03_RECON" : "B04_ONLY",
        bank_statement_line_id: row.bank_statement_line_id || null,
        reason: hasBankEvidence ? "bank_matched" : (reconciled ? "reconciled_flag" : "b04_paid_status"),
        };
    }

    if (row.liability_status === "IN_BATCH" && (batchCancelled || lineCancelled)) {
        return {
        action: "RELEASE_TO_OPEN",
        amount,
        reason: batchCancelled ? "payment_batch_cancelled" : "payment_batch_line_cancelled",
        };
    }

    return {
        action: "NOOP",
        amount,
        reason: "no_new_evidence",
    };
    }

    function buildSettlementKey(row, verdict) {
    return [
        "PRPAYSETTLE",
        `RUN:${row.run_id}`,
        `L:${row.payroll_liability_id}`,
        `LINK:${row.link_id}`,
        `B:${row.payment_batch_id}`,
        `BL:${row.payment_batch_line_id || 0}`,
        `SRC:${verdict.settlement_source || "NA"}`,
    ].join("|");
    }

    async function buildRunPaymentSyncPreview(db, runId, opts = {}) {
    const run = await getRun(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }

    const rows = await listSyncCandidates(db, runId, opts.scope || "ALL");
    const items = rows.map((r) => {
        const verdict = classifyCandidate(r, opts);
        return { ...r, verdict };
    });

    const summary = {
        total_candidates: items.length,
        mark_paid_count: 0,
        mark_paid_amount: 0,
        release_count: 0,
        release_amount: 0,
        noop_count: 0,
        noop_amount: 0,
    };

    for (const i of items) {
        if (i.verdict.action === "MARK_PAID") {
        summary.mark_paid_count += 1;
        summary.mark_paid_amount += Number(i.verdict.amount);
        } else if (i.verdict.action === "RELEASE_TO_OPEN") {
        summary.release_count += 1;
        summary.release_amount += Number(i.verdict.amount);
        } else {
        summary.noop_count += 1;
        summary.noop_amount += Number(i.verdict.amount);
        }
    }

    Object.keys(summary).forEach((k) => {
        if (k.endsWith("_amount")) summary[k] = amount2(summary[k]);
    });

    // optional preview timestamp
    await db.query(
        `UPDATE payroll_runs SET payment_sync_last_preview_at = NOW() WHERE id = ?`,
        [runId]
    ).catch(() => {});

    return {
        run: {
        id: run.id,
        run_no: run.run_no,
        status: run.status,
        pay_date: run.pay_date,
        currency_code: run.currency_code,
        },
        scope: opts.scope || "ALL",
        allow_b04_only_settlement: !!opts.allow_b04_only_settlement,
        summary,
        items,
    };
    }

    async function writeLiabilityAudit(db, { runId, liabilityId = null, action, payload = null, userId = null }) {
    await db.query(
        `INSERT INTO payroll_liability_audit (run_id, payroll_liability_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?, ?)`,
        [runId, liabilityId, action, payload ? JSON.stringify(payload) : null, userId]
    );
    }

    async function applyRunPaymentSync(db, runId, opts = {}, userId = null) {
    const run = await getRun(db, runId);
    if (!run) {
        const err = new Error("Payroll run not found");
        err.statusCode = 404;
        throw err;
    }

    const conn = db.getConnection ? await db.getConnection() : null;
    const q = conn || db;

    try {
        if (conn) await conn.beginTransaction();

        const preview = await buildRunPaymentSyncPreview(q, runId, opts);

        let markPaidApplied = 0;
        let releasedApplied = 0;

        for (const item of preview.items) {
        const v = item.verdict;
        if (v.action === "NOOP") continue;

        if (v.action === "MARK_PAID") {
            const settlementKey = buildSettlementKey(item, v);

            // settlement evidence row (idempotent by unique settlement_key)
            await q.query(
            `
            INSERT INTO payroll_liability_settlements
            (settlement_key, run_id, payroll_liability_id, payroll_liability_payment_link_id,
            payment_batch_id, payment_batch_line_id, bank_statement_line_id,
            settlement_source, settled_amount, currency_code, settled_at, payload_json, created_by)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ON DUPLICATE KEY UPDATE
                settled_at = VALUES(settled_at)
            `,
            [
                settlementKey,
                item.run_id,
                item.payroll_liability_id,
                item.link_id,
                item.payment_batch_id,
                item.payment_batch_line_id || null,
                v.bank_statement_line_id || null,
                v.settlement_source,
                amount2(v.amount),
                item.currency_code,
                v.settled_at,
                JSON.stringify({ reason: v.reason }),
                userId,
            ]
            );

            await q.query(
            `
            UPDATE payroll_liability_payment_links
            SET status = 'PAID',
                settled_amount = ?,
                settled_at = ?,
                last_sync_at = NOW(),
                sync_note = ?
            WHERE id = ?
            `,
            [amount2(v.amount), v.settled_at, `synced:${v.reason}`, item.link_id]
            );

            await q.query(
            `
            UPDATE payroll_run_liabilities
            SET status = 'PAID',
                paid_at = ?,
                paid_payment_batch_id = ?,
                paid_payment_batch_line_id = ?,
                paid_bank_statement_line_id = ?,
                updated_at = NOW()
            WHERE id = ?
                AND status IN ('IN_BATCH', 'PAID')
            `,
            [
                v.settled_at,
                item.payment_batch_id,
                item.payment_batch_line_id || null,
                v.bank_statement_line_id || null,
                item.payroll_liability_id,
            ]
            );

            await writeLiabilityAudit(q, {
            runId,
            liabilityId: item.payroll_liability_id,
            action: "SETTLED",
            payload: {
                payment_batch_id: item.payment_batch_id,
                payment_batch_line_id: item.payment_batch_line_id,
                bank_statement_line_id: v.bank_statement_line_id || null,
                amount: amount2(v.amount),
                settlement_source: v.settlement_source,
                reason: v.reason,
            },
            userId,
            });

            markPaidApplied += 1;
            continue;
        }

        if (v.action === "RELEASE_TO_OPEN") {
            await q.query(
            `
            UPDATE payroll_liability_payment_links
            SET status = 'RELEASED',
                released_at = NOW(),
                last_sync_at = NOW(),
                sync_note = ?
            WHERE id = ?
            `,
            [`released:${v.reason}`, item.link_id]
            );

            await q.query(
            `
            UPDATE payroll_run_liabilities
            SET status = 'OPEN',
                reserved_payment_batch_id = NULL,
                updated_at = NOW()
            WHERE id = ?
                AND status = 'IN_BATCH'
            `,
            [item.payroll_liability_id]
            );

            await writeLiabilityAudit(q, {
            runId,
            liabilityId: item.payroll_liability_id,
            action: "RELEASED",
            payload: {
                payment_batch_id: item.payment_batch_id,
                payment_batch_line_id: item.payment_batch_line_id,
                amount: amount2(v.amount),
                reason: v.reason,
            },
            userId,
            });

            releasedApplied += 1;
        }
        }

        await q.query(
        `UPDATE payroll_runs SET payment_sync_last_applied_at = NOW() WHERE id = ?`,
        [runId]
        );

        await q.query(
        `INSERT INTO payroll_run_audit (run_id, action, payload_json, acted_by) VALUES (?, 'PAYMENT_SYNC_APPLIED', ?, ?)`,
        [
            runId,
            JSON.stringify({
            scope: opts.scope || "ALL",
            mark_paid_count: markPaidApplied,
            released_count: releasedApplied,
            note: opts.note || null,
            allow_b04_only_settlement: !!opts.allow_b04_only_settlement,
            }),
            userId,
        ]
        );

        if (conn) await conn.commit();

        return {
        ok: true,
        run_id: runId,
        applied: {
            mark_paid_count: markPaidApplied,
            released_count: releasedApplied,
        },
        preview_summary: preview.summary,
        };
    } catch (err) {
        if (conn) {
        try { await conn.rollback(); } catch (_) {}
        }
        throw err;
    } finally {
        if (conn) conn.release();
    }
    }

    export default {
    buildRunPaymentSyncPreview,
    applyRunPaymentSync,
    };
    ```

    ---

    ## 4) Routes — `backend/src/routes/payroll.paymentSync.js`

    ```js
    // backend/src/routes/payroll.paymentSync.js

    import express from "express";
    import { validateRunIdParam,
    validateSyncPreviewQuery,
    validateSyncApplyBody, } from "./payroll.paymentSync.validators.js";
    import service from "../services/payroll.paymentSync.service.js";
    // replace with your actual helpers
    import { requireAuth } from "../middleware/auth.js";
    import { requirePermission } from "../middleware/rbac.js";
    import { query } from "../db.js";
    const router = express.Router();

    // GET /api/v1/payroll/runs/:id/payment-sync-preview
    router.get(
    "/runs/:id/payment-sync-preview",
    requireAuth,
    requirePermission("payroll.payment.sync.read"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const q = validateSyncPreviewQuery(req.query);
        const result = await service.buildRunPaymentSyncPreview(db, id, q);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    // POST /api/v1/payroll/runs/:id/payment-sync-apply
    router.post(
    "/runs/:id/payment-sync-apply",
    requireAuth,
    requirePermission("payroll.payment.sync.apply"),
    async (req, res, next) => {
        try {
        const db = { query }; // adapt to your service signature
        const { id } = validateRunIdParam(req.params);
        const body = validateSyncApplyBody(req.body);
        const userId = req.user?.id ?? null;
        const result = await service.applyRunPaymentSync(db, id, body, userId);
        res.json(result);
        } catch (err) {
        next(err);
        }
    }
    );

    export default router;
    ```

    ---

    ## 5) Mount route — `backend/src/index.js`

    ```js
    // backend/src/index.js
    import payrollPaymentSyncRoutes from "./routes/payroll.paymentSync.js";
    // ...
    app.use("/api/v1/payroll", payrollPaymentSyncRoutes);
    ```

    ---

    ## 6) Migration registry — `backend/src/migrations/index.js`

    ```js
    // backend/src/migrations/index.js
    import m042_payroll_payment_settlement_sync from "./m042_payroll_payment_settlement_sync.js";
    export default [
    // ...
    m042_payroll_payment_settlement_sync,
    ];
    ```

    ---

    ## 7) Seed permissions — `backend/src/seedCore.js`

    ```js
    // backend/src/seedCore.js
    const PAYROLL_P04_PERMISSIONS = [
    "payroll.payment.sync.read",
    "payroll.payment.sync.apply",
    ];

    // merge into permission seed list
    ```

    ---

    ## 8) OpenAPI generation — `backend/scripts/generate-openapi.js`

    Register these paths:

    * `GET /api/v1/payroll/runs/{id}/payment-sync-preview`
    * `POST /api/v1/payroll/runs/{id}/payment-sync-apply`

    ---

    ## 9) Backend smoke test — `backend/scripts/test-payroll-prp04-payment-settlement-sync.js`

    ```js
    // backend/scripts/test-payroll-prp04-payment-settlement-sync.js

    async function main() {
    // Preconditions:
    // - PR-P03 implemented (liabilities + payment batch prep)
    // - PR-B04 implemented (payment batches/lines)
    // - PR-B03 implemented or B04 line statuses available
    //
    // Flow:
    // 1) Create payroll payment batch from a finalized payroll run (P03)
    // 2) Simulate/perform payment execution on payment_batch_lines
    // 3) Simulate/perform bank reconciliation match (B03) for those lines
    // 4) GET /api/v1/payroll/runs/:id/payment-sync-preview
    //    -> shows MARK_PAID candidates with amounts
    // 5) POST /api/v1/payroll/runs/:id/payment-sync-apply
    //    -> liabilities IN_BATCH -> PAID
    //    -> payroll_liability_settlements rows created
    //    -> links status LINKED -> PAID
    // 6) POST sync apply again
    //    -> idempotent (no duplicate settlements)
    // 7) Simulate batch cancellation for another run/line
    //    -> preview shows RELEASE_TO_OPEN
    //    -> apply returns liability IN_BATCH -> OPEN and link -> RELEASED
    // 8) Permissions:
    //    - payroll.payment.sync.read/apply enforced (403)
    console.log("PR-P04 smoke test placeholder");
    }

    main().catch((err) => {
    console.error(err);
    process.exit(1);
    });
    ```

    ---

    ## 10) `backend/package.json` updates

    ```json
    {
    "scripts": {
        "test:payroll:prp04": "node backend/scripts/test-payroll-prp04-payment-settlement-sync.js"
    }
    }
    ```

    ---

    # Frontend (short version — key matching parts only)

    ## 11) API client — `frontend/src/api/payrollPaymentSync.js`

    ```js
    // frontend/src/api/payrollPaymentSync.js

    import { apiFetch } from "./client.js"; // adapt

    export function getPayrollPaymentSyncPreview(runId, params = {}) {
    const q = new URLSearchParams();
    if (params.scope) q.set("scope", params.scope);
    const qs = q.toString();
    return apiFetch(`/api/v1/payroll/runs/${runId}/payment-sync-preview${qs ? `?${qs}` : ""}`);
    }

    export function applyPayrollPaymentSync(runId, payload = {}) {
    return apiFetch(`/api/v1/payroll/runs/${runId}/payment-sync-apply`, {
        method: "POST",
        body: JSON.stringify(payload),
    });
    }
    ```

    ---

    ## 12) `PayrollLiabilitiesPage.jsx` — important parts only

    ### Add imports

    ```jsx
    import { getPayrollPaymentSyncPreview, applyPayrollPaymentSync } from "../../api/payrollPaymentSync.js";
    ```

    ### Add state

    ```jsx
    const [syncPreview, setSyncPreview] = useState(null);
    const [syncScope, setSyncScope] = useState("ALL");
    ```

    ### Load preview (when run page is open)

    ```jsx
    async function loadSyncPreview() {
    if (!runId) return;
    const res = await getPayrollPaymentSyncPreview(runId, { scope: syncScope });
    setSyncPreview(res);
    }

    // call inside your existing load() for run-specific page
    // await Promise.all([ ..., loadSyncPreview() ])
    ```

    ### Add apply action

    ```jsx
    async function onApplyPaymentSync() {
    try {
        setErr("");
        await applyPayrollPaymentSync(runId, {
        scope: syncScope,
        // keep false by default; only enable if you intentionally accept B04-only settlement
        allow_b04_only_settlement: false,
        });
        await load(); // reload liabilities + previews
    } catch (e) {
        setErr(e.message || "Payment sync failed");
    }
    }
    ```

    ### Add a compact sync panel (no tables needed)

    ```jsx
    {/* Payroll Payment Sync Panel (compact) */}
    <div className="rounded border bg-white p-4">
    <h2 className="font-medium mb-2">Payment Settlement Sync</h2>

    {/* Scope selector + actions */}
    {/* select value={syncScope} onChange=... options: ALL / NET_PAY / STATUTORY */}
    {/* button: Refresh Sync Preview -> calls loadSyncPreview */}
    {/* button: Apply Sync -> calls onApplyPaymentSync */}

    {syncPreview ? (
        <div className="text-sm space-y-1">
        <div>Mark PAID: {syncPreview.summary?.mark_paid_count} / {syncPreview.summary?.mark_paid_amount}</div>
        <div>Release to OPEN: {syncPreview.summary?.release_count} / {syncPreview.summary?.release_amount}</div>
        <div>No-op: {syncPreview.summary?.noop_count}</div>

        {/* Optional: show a short list of first 10 candidate rows with verdicts */}
        {/* Example fields to display: liability id, beneficiary, amount, verdict.action, verdict.reason */}
        </div>
    ) : (
        <div className="text-sm text-gray-600">No sync preview yet.</div>
    )}
    </div>
    ```

    ---

    ## 13) Optional quick link/button in `PayrollRunDetailPage.jsx`

    ```jsx
    // add near other payroll run actions
    <Link className="border rounded px-2 py-1 inline-block" to={`/payroll/runs/${run.id}/liabilities`}>
    Liabilities / Payment Sync
    </Link>
    ```

    ---

    # Acceptance criteria (repeat in PR)

    * ✅ Payroll payment sync preview classifies liabilities as:

    * `MARK_PAID` (has payment/reconciliation evidence)
    * `RELEASE_TO_OPEN` (batch/line cancelled/failed)
    * `NOOP`
    * ✅ Sync apply is idempotent (no duplicate settlement rows)
    * ✅ `MARK_PAID` updates:

    * `payroll_run_liabilities` → `PAID`
    * `payroll_liability_payment_links` → `PAID`
    * inserts `payroll_liability_settlements`
    * ✅ `RELEASE_TO_OPEN` updates:

    * `payroll_run_liabilities` → `OPEN`
    * `payroll_liability_payment_links` → `RELEASED`
    * ✅ Payroll audit rows written for sync actions
    * ✅ Permissions enforced (`payroll.payment.sync.read/apply`)
    * ✅ OpenAPI updated
    * ✅ Smoke test script exists and runs

    ---

    # Smoke test expectations (explicit)

    ## `npm run test:payroll:prp04`

    Should verify at least:

    1. **Sync preview after reconciliation**

    * Create payroll payment batch (P03)
    * Mark payment line executed/paid (B04)
    * Reconcile to bank statement (B03)
    * GET preview returns `MARK_PAID` candidates

    2. **Sync apply**

    * POST apply
    * liabilities `IN_BATCH -> PAID`
    * links `LINKED -> PAID`
    * settlement rows inserted

    3. **Idempotent apply**

    * Re-run apply
    * no duplicate `payroll_liability_settlements` rows
    * statuses remain stable

    4. **Release flow**

    * For another run, cancel/fail payment batch or line
    * GET preview returns `RELEASE_TO_OPEN`
    * POST apply releases liabilities back to `OPEN`

    5. **Scope filtering**

    * `scope=NET_PAY` only syncs employee net liabilities
    * `scope=STATUTORY` only syncs statutory liabilities

    6. **Permissions**

    * `payroll.payment.sync.read` and `payroll.payment.sync.apply` both enforced (`403`)

    ---

    # Tiny implementation notes (important)

    * **P04 makes payroll liability status truthy and auditable** without mixing payroll logic into bank/payment modules.
    * Payroll remains the **subledger owner**; B04/B03 remain the **execution/reconciliation owners**.
    * Later (optional), you can add:

    * scheduled auto-sync job
    * partial settlement support
    * manual override workflow (maker-checker + reason code)

    ---

---

## Bank + Payroll Follow-Ups

Recommended execution order for the follow-up PRs

If you want the most practical order:

PR-P05 (payroll correction safety first)

PR-P06 (partial settlement + manual override)

PR-B06 (payment file export/ack if not already present)

PR-B07 (reconciliation rules / exception automation)

PR-B05 (live bank connectivity)

PR-B08 (returns/fees/FX)

PR-B09 (controls hardening)

PR-P07 (beneficiary master snapshots)

PR-P08 (payroll close controls)

PR-P09 (provider adapters)

If your immediate pain is manual bank work, move B05/B06 earlier.

Perfect — here’s **PR-P05** in the same concrete format, with **frontend kept short** (only key integration snippets, no full tables/pages).

# PR-P05: Payroll Corrections (Full Reversal, Off-Cycle, Retro Adjustment Shells)

## Goal

Add safe payroll correction workflows after **P01→P04**:

- ✅ **Full reversal** of a finalized payroll run (with accrual JE reversal)
- ✅ Cancel unpaid payroll liabilities during reversal (if still `OPEN`)
- ✅ Block unsafe reversal when liabilities are already `IN_BATCH` or `PAID`
- ✅ Create **OFF_CYCLE** and **RETRO** correction run shells (linked to original run)
- ✅ Extend payroll import (P01) to import into correction shells
- ✅ Keep correction links and audit trail fully visible

---

## Important behavior rules (real-world safe defaults)

### Full reversal is allowed only if original run liabilities are not paid/in-batch

For **FULL REVERSAL**:

- ✅ Allowed if liabilities are only `OPEN` (they will be canceled)
- ❌ Blocked if any liability is `IN_BATCH` or `PAID`

Why: once payment has started/settled, you should use **RETRO** or **OFF_CYCLE** (delta correction), not hard reversal.

### Off-cycle / Retro runs are normal payroll runs with a type + link

They still go through the normal flow:

- P01 import
- P02 accrual finalize
- P03 liabilities/payment prep
- P04 settlement sync

P05 only adds the correction **framework + controls**.

---

## Files to create

### Backend

- `backend/src/migrations/m043_payroll_corrections_reversals.js`
- `backend/src/routes/payroll.corrections.js`
- `backend/src/routes/payroll.corrections.validators.js`
- `backend/src/services/payroll.corrections.service.js`
- `backend/scripts/test-payroll-prp05-corrections.js`

### Frontend (short snippets only)

- `frontend/src/api/payrollCorrections.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (P01 import integration)

- `backend/src/routes/payroll.imports.validators.js` _(or your actual P01 validator file)_
- `backend/src/services/payroll.imports.service.js` _(or your actual P01 import service file)_

### Frontend (short integration only)

- `frontend/src/pages/payroll/PayrollRunDetailPage.jsx`
- `frontend/src/pages/payroll/PayrollRunsPage.jsx` _(optional badges/filters)_
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m043_payroll_corrections_reversals.js`

```js
// backend/src/migrations/m043_payroll_corrections_reversals.js

export default {
  key: "m043_payroll_corrections_reversals",
  description: "m043_payroll_corrections_reversals",
  async up(connection) {
    // Extend payroll_runs with correction metadata
    await db
      .query(
        `
      ALTER TABLE payroll_runs
        ADD COLUMN run_type VARCHAR(20) NOT NULL DEFAULT 'REGULAR' AFTER status,
        ADD COLUMN correction_of_run_id BIGINT UNSIGNED NULL AFTER run_type,
        ADD COLUMN correction_reason VARCHAR(500) NULL AFTER correction_of_run_id,
        ADD COLUMN is_reversed TINYINT(1) NOT NULL DEFAULT 0 AFTER correction_reason,
        ADD COLUMN reversed_by_run_id BIGINT UNSIGNED NULL AFTER is_reversed,
        ADD COLUMN reversed_at DATETIME NULL AFTER reversed_by_run_id
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE payroll_runs
        ADD KEY idx_payroll_runs_run_type (run_type),
        ADD KEY idx_payroll_runs_correction_of (correction_of_run_id),
        ADD KEY idx_payroll_runs_reversed_by (reversed_by_run_id)
    `,
      )
      .catch(() => {});

    // Correction relationship / workflow table
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_run_corrections (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        original_run_id BIGINT UNSIGNED NULL,         -- null for standalone off-cycle if desired
        correction_run_id BIGINT UNSIGNED NOT NULL,
        correction_type VARCHAR(20) NOT NULL,         -- REVERSAL, OFF_CYCLE, RETRO
        status VARCHAR(20) NOT NULL DEFAULT 'CREATED',-- CREATED, APPLIED, CANCELLED
        idempotency_key VARCHAR(190) NULL,
        notes VARCHAR(500) NULL,
        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_payroll_corrections_run (correction_run_id),
        UNIQUE KEY uq_payroll_corrections_idem (idempotency_key),
        KEY idx_payroll_corrections_orig (original_run_id),
        KEY idx_payroll_corrections_type (correction_type),
        KEY idx_payroll_corrections_status (status),

        CONSTRAINT fk_prc_original_run
          FOREIGN KEY (original_run_id) REFERENCES payroll_runs(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_prc_correction_run
          FOREIGN KEY (correction_run_id) REFERENCES payroll_runs(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Helpful ledger-side audit for reversal liability cancellation (P03 table already exists)
    await db
      .query(
        `
      ALTER TABLE payroll_run_liabilities
        ADD COLUMN cancelled_at DATETIME NULL AFTER paid_at,
        ADD COLUMN cancelled_reason VARCHAR(255) NULL AFTER cancelled_at
    `,
      )
      .catch(() => {});
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS payroll_run_corrections;`);
    // (Optional strict down for ALTER columns omitted for dev simplicity)
  },
};
```

---

## 2) Validators — `backend/src/routes/payroll.corrections.validators.js`

```js
// backend/src/routes/payroll.corrections.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function requireDate(v, field) {
  const s = String(v || "").trim();
  if (!/^\d{4}-\d{2}-\d{2}$/.test(s))
    throw new Error(`${field} must be YYYY-MM-DD`);
  return s;
}

function requireCurrency(v) {
  const s = String(v || "")
    .trim()
    .toUpperCase();
  if (!/^[A-Z]{3}$/.test(s)) throw new Error("currency_code must be 3 letters");
  return s;
}

function validateRunIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateReverseRunBody(body = {}) {
  return {
    reason: normalizeString(body.reason) || "Payroll run reversal",
    note: normalizeString(body.note),
    idempotency_key: normalizeString(body.idempotency_key),
  };
}

function validateCreateCorrectionShellBody(body = {}) {
  const correction_type = String(body.correction_type || "")
    .trim()
    .toUpperCase();
  if (!["OFF_CYCLE", "RETRO"].includes(correction_type)) {
    throw new Error("correction_type must be OFF_CYCLE or RETRO");
  }

  return {
    correction_type,
    original_run_id: body.original_run_id
      ? requirePositiveInt(body.original_run_id, "original_run_id")
      : null,
    entity_code:
      String(body.entity_code || "").trim() ||
      (() => {
        throw new Error("entity_code is required");
      })(),
    provider_code: normalizeString(body.provider_code)?.toUpperCase() || null,
    payroll_period:
      String(body.payroll_period || "").trim() ||
      (() => {
        throw new Error("payroll_period is required");
      })(),
    pay_date: requireDate(body.pay_date, "pay_date"),
    currency_code: requireCurrency(body.currency_code),
    reason: normalizeString(body.reason),
    idempotency_key: normalizeString(body.idempotency_key),
  };
}

export default {
  validateRunIdParam,
  validateReverseRunBody,
  validateCreateCorrectionShellBody,
};
```

---

## 3) Service — `backend/src/services/payroll.corrections.service.js`

```js
// backend/src/services/payroll.corrections.service.js

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

async function getRun(db, runId) {
  const [rows] = await db.query(
    `SELECT * FROM payroll_runs WHERE id = ? LIMIT 1`,
    [runId],
  );
  return rows[0] || null;
}

async function writeRunAudit(db, runId, action, payload, userId = null) {
  await db.query(
    `INSERT INTO payroll_run_audit (run_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
    [runId, action, payload ? JSON.stringify(payload) : null, userId],
  );
}

async function writeLiabilityAudit(
  db,
  { runId, liabilityId = null, action, payload = null, userId = null },
) {
  await db.query(
    `INSERT INTO payroll_liability_audit (run_id, payroll_liability_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?, ?)`,
    [
      runId,
      liabilityId,
      action,
      payload ? JSON.stringify(payload) : null,
      userId,
    ],
  );
}

async function getRunLiabilitySummary(db, runId) {
  const [rows] = await db.query(
    `
    SELECT
      SUM(CASE WHEN status='OPEN' THEN 1 ELSE 0 END) AS open_count,
      SUM(CASE WHEN status='IN_BATCH' THEN 1 ELSE 0 END) AS in_batch_count,
      SUM(CASE WHEN status='PAID' THEN 1 ELSE 0 END) AS paid_count,
      SUM(CASE WHEN status='CANCELLED' THEN 1 ELSE 0 END) AS cancelled_count
    FROM payroll_run_liabilities
    WHERE run_id = ?
    `,
    [runId],
  );
  return (
    rows[0] || {
      open_count: 0,
      in_batch_count: 0,
      paid_count: 0,
      cancelled_count: 0,
    }
  );
}

async function reverseAccrualJournal(db, originalRun, userId = null) {
  if (!originalRun.accrual_journal_entry_id) {
    const err = new Error("Original payroll run has no accrual journal");
    err.statusCode = 400;
    throw err;
  }

  // Read original JE lines
  const [origLines] = await db.query(
    `
    SELECT line_no, account_id, dr_amount, cr_amount, amount, memo
    FROM journal_entry_lines
    WHERE journal_entry_id = ?
    ORDER BY line_no ASC
    `,
    [originalRun.accrual_journal_entry_id],
  );

  if (!origLines.length) {
    const err = new Error("Original accrual journal has no lines");
    err.statusCode = 400;
    throw err;
  }

  // Create reversal JE
  const [jeIns] = await db.query(
    `
    INSERT INTO journal_entries
    (journal_no, status, memo, posted_at, created_by)
    VALUES (?, 'POSTED', ?, NOW(), ?)
    `,
    [
      `PAYREV-${originalRun.run_no}`,
      `Payroll accrual reversal for ${originalRun.run_no}`,
      userId,
    ],
  );

  const reversalJeId = jeIns.insertId;

  let lineNo = 1;
  for (const l of origLines) {
    // Reverse dr/cr
    const dr = amount2(l.cr_amount);
    const cr = amount2(l.dr_amount);
    const signedAmount = amount2(Number(l.amount || 0) * -1);

    await db.query(
      `
      INSERT INTO journal_entry_lines
      (journal_entry_id, line_no, account_id, dr_amount, cr_amount, amount, memo)
      VALUES (?, ?, ?, ?, ?, ?, ?)
      `,
      [
        reversalJeId,
        lineNo++,
        l.account_id,
        dr,
        cr,
        signedAmount,
        `REV ${l.memo || ""}`.trim(),
      ],
    );
  }

  return reversalJeId;
}

async function cloneReversalRun(
  db,
  originalRun,
  reversalJeId,
  reason,
  userId = null,
) {
  // Clone header
  const [ins] = await db.query(
    `
    INSERT INTO payroll_runs
    (run_no, status, run_type, correction_of_run_id, correction_reason,
     entity_code, provider_code, payroll_period, pay_date, currency_code,
     source_file_name, source_file_hash,
     imported_by, imported_at,
     reviewed_by, reviewed_at,
     finalized_by, finalized_at,
     accrual_journal_entry_id, accrual_posted_by, accrual_posted_at)
    VALUES (?, 'FINALIZED', 'REVERSAL', ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, NOW(), ?, NOW(), ?, NOW(), ?, ?, NOW())
    `,
    [
      `REV-${originalRun.run_no}`,
      originalRun.id,
      reason,
      originalRun.entity_code,
      originalRun.provider_code,
      originalRun.payroll_period,
      originalRun.pay_date,
      originalRun.currency_code,
      originalRun.source_file_name || null,
      originalRun.source_file_hash || null,
      userId,
      userId,
      userId,
      reversalJeId,
      userId,
    ],
  );

  const reversalRunId = ins.insertId;

  // Clone lines as negative amounts (keeps employee-level traceability)
  const [origLines] = await db.query(
    `
    SELECT
      line_no, employee_code, employee_name, cost_center_code,
      base_salary, overtime_pay, bonus_pay, allowances_total, gross_pay,
      employee_tax, employee_social_security, other_deductions, net_pay,
      employer_tax, employer_social_security
    FROM payroll_run_lines
    WHERE run_id = ?
    ORDER BY line_no ASC
    `,
    [originalRun.id],
  );

  for (const l of origLines) {
    await db.query(
      `
      INSERT INTO payroll_run_lines
      (run_id, line_no, employee_code, employee_name, cost_center_code,
       base_salary, overtime_pay, bonus_pay, allowances_total, gross_pay,
       employee_tax, employee_social_security, other_deductions, net_pay,
       employer_tax, employer_social_security)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      `,
      [
        reversalRunId,
        l.line_no,
        l.employee_code,
        l.employee_name,
        l.cost_center_code || null,
        amount2(l.base_salary * -1),
        amount2(l.overtime_pay * -1),
        amount2(l.bonus_pay * -1),
        amount2(l.allowances_total * -1),
        amount2(l.gross_pay * -1),
        amount2(l.employee_tax * -1),
        amount2(l.employee_social_security * -1),
        amount2(l.other_deductions * -1),
        amount2(l.net_pay * -1),
        amount2(l.employer_tax * -1),
        amount2(l.employer_social_security * -1),
      ],
    );
  }

  // Mirror totals on header if your payroll_runs stores totals columns
  // (adapt if your schema differs)
  await db
    .query(
      `
    UPDATE payroll_runs
    SET
      total_base_salary = COALESCE(total_base_salary,0) * -1,
      total_overtime_pay = COALESCE(total_overtime_pay,0) * -1,
      total_bonus_pay = COALESCE(total_bonus_pay,0) * -1,
      total_allowances_total = COALESCE(total_allowances_total,0) * -1,
      total_gross_pay = COALESCE(total_gross_pay,0) * -1,
      total_employee_tax = COALESCE(total_employee_tax,0) * -1,
      total_employee_social_security = COALESCE(total_employee_social_security,0) * -1,
      total_other_deductions = COALESCE(total_other_deductions,0) * -1,
      total_net_pay = COALESCE(total_net_pay,0) * -1,
      total_employer_tax = COALESCE(total_employer_tax,0) * -1,
      total_employer_social_security = COALESCE(total_employer_social_security,0) * -1
    WHERE id = ?
    `,
      [reversalRunId],
    )
    .catch(() => {
      /* if your header totals are stored differently, adapt */
    });

  return reversalRunId;
}

async function cancelOpenLiabilitiesForReversal(
  db,
  originalRunId,
  userId = null,
) {
  const [openRows] = await db.query(
    `
    SELECT id, amount
    FROM payroll_run_liabilities
    WHERE run_id = ? AND status = 'OPEN'
    ORDER BY id ASC
    `,
    [originalRunId],
  );

  for (const l of openRows) {
    await db.query(
      `
      UPDATE payroll_run_liabilities
      SET status='CANCELLED',
          cancelled_at = NOW(),
          cancelled_reason = 'reversed_run',
          updated_at = NOW()
      WHERE id = ?
      `,
      [l.id],
    );

    await writeLiabilityAudit(db, {
      runId: originalRunId,
      liabilityId: l.id,
      action: "CANCELLED_BY_REVERSAL",
      payload: { amount: amount2(l.amount) },
      userId,
    });
  }

  return openRows.length;
}

async function reversePayrollRun(db, runId, body, userId = null) {
  const run = await getRun(db, runId);
  if (!run) {
    const err = new Error("Payroll run not found");
    err.statusCode = 404;
    throw err;
  }

  if (run.run_type === "REVERSAL") {
    const err = new Error("Cannot reverse a reversal run");
    err.statusCode = 400;
    throw err;
  }

  if (
    String(run.status).toUpperCase() !== "FINALIZED" ||
    !run.accrual_journal_entry_id
  ) {
    const err = new Error(
      "Only FINALIZED payroll runs with accrual journal can be reversed",
    );
    err.statusCode = 400;
    throw err;
  }

  // Idempotent re-call
  if (Number(run.is_reversed) === 1 && run.reversed_by_run_id) {
    const existing = await getRun(db, run.reversed_by_run_id);
    return { original_run: run, reversal_run: existing, idempotent: true };
  }

  const liabilitySummary = await getRunLiabilitySummary(db, runId);

  if (Number(liabilitySummary.in_batch_count || 0) > 0) {
    const err = new Error(
      "Cannot reverse: some payroll liabilities are IN_BATCH. Release/cancel payment batch first.",
    );
    err.statusCode = 409;
    throw err;
  }

  if (Number(liabilitySummary.paid_count || 0) > 0) {
    const err = new Error(
      "Cannot reverse: some payroll liabilities are already PAID. Use RETRO/OFF_CYCLE correction.",
    );
    err.statusCode = 409;
    throw err;
  }

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    // Re-check inside tx
    const currentRun = await getRun(q, runId);
    if (Number(currentRun.is_reversed) === 1 && currentRun.reversed_by_run_id) {
      if (conn) await conn.commit();
      const existing = await getRun(db, currentRun.reversed_by_run_id);
      return {
        original_run: currentRun,
        reversal_run: existing,
        idempotent: true,
      };
    }

    const reversedJeId = await reverseAccrualJournal(q, currentRun, userId);
    const reversalRunId = await cloneReversalRun(
      q,
      currentRun,
      reversedJeId,
      body.reason,
      userId,
    );

    const cancelledLiabilities = await cancelOpenLiabilitiesForReversal(
      q,
      runId,
      userId,
    );

    // Mark original run reversed
    await q.query(
      `
      UPDATE payroll_runs
      SET is_reversed = 1,
          reversed_by_run_id = ?,
          reversed_at = NOW(),
          correction_reason = COALESCE(correction_reason, ?)
      WHERE id = ?
      `,
      [reversalRunId, body.reason, runId],
    );

    // Correction relationship row
    await q
      .query(
        `
      INSERT INTO payroll_run_corrections
      (original_run_id, correction_run_id, correction_type, status, idempotency_key, notes, created_by)
      VALUES (?, ?, 'REVERSAL', 'APPLIED', ?, ?, ?)
      `,
        [
          runId,
          reversalRunId,
          body.idempotency_key || null,
          body.note || body.reason || null,
          userId,
        ],
      )
      .catch(async (e) => {
        // optional idempotency via unique key
        if (
          !String(e.message || "")
            .toLowerCase()
            .includes("duplicate")
        )
          throw e;
      });

    await writeRunAudit(
      q,
      runId,
      "REVERSED",
      {
        reversal_run_id: reversalRunId,
        reversal_journal_entry_id: reversedJeId,
        cancelled_open_liabilities: cancelledLiabilities,
        reason: body.reason,
      },
      userId,
    );

    await writeRunAudit(
      q,
      reversalRunId,
      "CREATED_AS_REVERSAL",
      {
        original_run_id: runId,
        reversal_journal_entry_id: reversedJeId,
        reason: body.reason,
      },
      userId,
    );

    if (conn) await conn.commit();

    return {
      original_run: await getRun(db, runId),
      reversal_run: await getRun(db, reversalRunId),
      idempotent: false,
    };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function createCorrectionShell(db, payload, userId = null) {
  // RETRO should reference an original run
  if (payload.correction_type === "RETRO" && !payload.original_run_id) {
    const err = new Error("RETRO correction requires original_run_id");
    err.statusCode = 400;
    throw err;
  }

  if (payload.original_run_id) {
    const original = await getRun(db, payload.original_run_id);
    if (!original) {
      const err = new Error("Original payroll run not found");
      err.statusCode = 404;
      throw err;
    }

    if (payload.correction_type === "RETRO") {
      // usually retro against finalized payroll
      if (String(original.status).toUpperCase() !== "FINALIZED") {
        const err = new Error(
          "RETRO correction can only target a FINALIZED payroll run",
        );
        err.statusCode = 400;
        throw err;
      }
    }

    if (
      original.entity_code !== payload.entity_code ||
      original.currency_code !== payload.currency_code
    ) {
      const err = new Error(
        "Correction shell entity/currency must match original payroll run",
      );
      err.statusCode = 400;
      throw err;
    }
  }

  if (payload.idempotency_key) {
    const [existing] = await db.query(
      `
      SELECT pr.id
      FROM payroll_run_corrections c
      JOIN payroll_runs pr ON pr.id = c.correction_run_id
      WHERE c.idempotency_key = ?
      LIMIT 1
      `,
      [payload.idempotency_key],
    );
    if (existing[0]) {
      const run = await getRun(db, existing[0].id);
      return { correction_run: run, idempotent: true };
    }
  }

  const prefix = payload.correction_type === "RETRO" ? "RET" : "OFC";
  const runNo = `${prefix}-${payload.payroll_period.replace(/[^0-9A-Za-z]/g, "")}-${Date.now()}`;

  const [ins] = await db.query(
    `
    INSERT INTO payroll_runs
    (run_no, status, run_type, correction_of_run_id, correction_reason,
     entity_code, provider_code, payroll_period, pay_date, currency_code,
     imported_by, imported_at)
    VALUES (?, 'DRAFT', ?, ?, ?, ?, ?, ?, ?, ?, ?, NOW())
    `,
    [
      runNo,
      payload.correction_type,
      payload.original_run_id || null,
      payload.reason || null,
      payload.entity_code,
      payload.provider_code,
      payload.payroll_period,
      payload.pay_date,
      payload.currency_code,
      userId,
    ],
  );

  const correctionRunId = ins.insertId;

  await db.query(
    `
    INSERT INTO payroll_run_corrections
    (original_run_id, correction_run_id, correction_type, status, idempotency_key, notes, created_by)
    VALUES (?, ?, ?, 'CREATED', ?, ?, ?)
    `,
    [
      payload.original_run_id || null,
      correctionRunId,
      payload.correction_type,
      payload.idempotency_key || null,
      payload.reason || null,
      userId,
    ],
  );

  await writeRunAudit(
    db,
    correctionRunId,
    "CORRECTION_SHELL_CREATED",
    {
      correction_type: payload.correction_type,
      original_run_id: payload.original_run_id || null,
      reason: payload.reason || null,
    },
    userId,
  );

  return {
    correction_run: await getRun(db, correctionRunId),
    idempotent: false,
  };
}

async function listCorrectionsForRun(db, runId) {
  const [rows] = await db.query(
    `
    SELECT
      c.id, c.original_run_id, c.correction_run_id, c.correction_type, c.status, c.notes, c.created_at,
      cr.run_no AS correction_run_no, cr.status AS correction_run_status, cr.run_type AS correction_run_type
    FROM payroll_run_corrections c
    JOIN payroll_runs cr ON cr.id = c.correction_run_id
    WHERE c.original_run_id = ? OR c.correction_run_id = ?
    ORDER BY c.id DESC
    `,
    [runId, runId],
  );
  return rows;
}

export default {
  reversePayrollRun,
  createCorrectionShell,
  listCorrectionsForRun,
};
```

---

## 4) Routes — `backend/src/routes/payroll.corrections.js`

```js
// backend/src/routes/payroll.corrections.js

import express from "express";
import { validateRunIdParam,
  validateReverseRunBody,
  validateCreateCorrectionShellBody, } from "./payroll.corrections.validators.js";
import service from "../services/payroll.corrections.service.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/payroll/runs/:id/corrections
router.get(
  "/runs/:id/corrections",
  requireAuth,
  requirePermission("payroll.corrections.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateRunIdParam(req.params);
      const items = await service.listCorrectionsForRun(db, id);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/runs/:id/reverse
router.post(
  "/runs/:id/reverse",
  requireAuth,
  requirePermission("payroll.corrections.reverse"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateRunIdParam(req.params);
      const body = validateReverseRunBody(req.body);
      const userId = req.user?.id ?? null;
      const result = await service.reversePayrollRun(db, id, body, userId);
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/corrections/shell
router.post(
  "/corrections/shell",
  requireAuth,
  requirePermission("payroll.corrections.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateCorrectionShellBody(req.body);
      const userId = req.user?.id ?? null;
      const result = await service.createCorrectionShell(db, body, userId);
      res.status(201).json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 5) Mount route — `backend/src/index.js`

```js
// backend/src/index.js
import payrollCorrectionsRoutes from "./routes/payroll.corrections.js";
// ...
app.use("/api/v1/payroll", payrollCorrectionsRoutes);
```

---

## 6) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m043_payroll_corrections_reversals from "./m043_payroll_corrections_reversals.js";
export default [
  // ...
  m043_payroll_corrections_reversals,
];
```

---

## 7) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const PAYROLL_P05_PERMISSIONS = [
  "payroll.corrections.read",
  "payroll.corrections.create",
  "payroll.corrections.reverse",
];

// merge into permission seed list
```

---

## 8) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/payroll/runs/{id}/corrections`
- `POST /api/v1/payroll/runs/{id}/reverse`
- `POST /api/v1/payroll/corrections/shell`

---

## 9) P01 import integration patch (important)

P05 correction shells are only useful if your P01 import can import **into an existing DRAFT run**.

### Update your P01 validator (`payroll.imports.validators.js`)

Add optional fields:

- `target_run_id` (import into existing DRAFT correction shell)
- `run_type` (optional on direct import; for future use)
- `correction_of_run_id` (optional on direct import)

```js
// backend/src/routes/payroll.imports.validators.js (patch snippet)

function validatePayrollImportBody(body = {}) {
  // ...existing P01 validations...

  return {
    // existing fields...
    target_run_id: body.target_run_id
      ? requirePositiveInt(body.target_run_id, "target_run_id")
      : null,
    run_type: body.run_type ? String(body.run_type).trim().toUpperCase() : null, // REGULAR/OFF_CYCLE/RETRO
    correction_of_run_id: body.correction_of_run_id
      ? requirePositiveInt(body.correction_of_run_id, "correction_of_run_id")
      : null,
  };
}
```

### Update your P01 import service (`payroll.imports.service.js`)

Behavior patch:

- If `target_run_id` is provided:

  - Load run
  - Ensure `status='DRAFT'`
  - Ensure run metadata matches (entity/currency/provider)
  - Import lines into that run
  - Set run status → `IMPORTED`
  - Keep `run_type` and `correction_of_run_id` from shell

```js
// backend/src/services/payroll.imports.service.js (patch snippet)

if (payload.target_run_id) {
  const draftRun = await getPayrollRunById(db, payload.target_run_id);
  if (!draftRun) throw notFound("Target payroll run not found");
  if (draftRun.status !== "DRAFT")
    throw badRequest("Target payroll run must be DRAFT");

  // validate entity/provider/currency consistency...
  // insert lines into target run...
  // update totals...
  await db.query(
    `UPDATE payroll_runs SET status='IMPORTED', imported_at=NOW(), imported_by=? WHERE id=?`,
    [userId, draftRun.id],
  );

  // write payroll_run_audit action like IMPORTED_TO_CORRECTION_SHELL
}
```

---

## 10) Backend smoke test — `backend/scripts/test-payroll-prp05-corrections.js`

```js
// backend/scripts/test-payroll-prp05-corrections.js

async function main() {
  // Preconditions:
  // - P01..P04 implemented
  // - At least one FINALIZED payroll run exists for tests
  //
  // Flow A: full reversal (safe/unpaid)
  // 1) Create a FINALIZED payroll run with liabilities still OPEN (no payment batch)
  // 2) POST /api/v1/payroll/runs/:id/reverse
  //    -> creates reversal JE
  //    -> creates reversal payroll run (run_type=REVERSAL)
  //    -> marks original is_reversed=1
  //    -> cancels OPEN liabilities
  // 3) POST reverse again
  //    -> idempotent (same reversal run returned)
  //
  // Flow B: reversal blocked
  // 4) For another run, prepare payment batch (P03) so liabilities are IN_BATCH
  // 5) POST reverse
  //    -> 409 blocked
  // 6) For another run, settle liabilities (P04) so some are PAID
  // 7) POST reverse
  //    -> 409 blocked (use RETRO/OFF_CYCLE)
  //
  // Flow C: correction shells
  // 8) POST /api/v1/payroll/corrections/shell (OFF_CYCLE)
  //    -> DRAFT run created, linked in payroll_run_corrections
  // 9) POST /api/v1/payroll/corrections/shell (RETRO, with original_run_id)
  //    -> DRAFT run created and linked
  // 10) Import payroll file into target_run_id (P01 patch)
  //     -> DRAFT -> IMPORTED
  //
  // Flow D: read corrections
  // 11) GET /api/v1/payroll/runs/:id/corrections
  //     -> returns reversal/retro/off-cycle links
  //
  // Permissions:
  // - payroll.corrections.read/create/reverse enforced (403)
  console.log("PR-P05 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 11) `backend/package.json` updates

```json
{
  "scripts": {
    "test:payroll:prp05": "node backend/scripts/test-payroll-prp05-corrections.js"
  }
}
```

---

## Frontend (short version — important parts only)

## 12) API client — `frontend/src/api/payrollCorrections.js`

```js
// frontend/src/api/payrollCorrections.js

import { apiFetch } from "./client.js"; // adapt

export function listPayrollRunCorrections(runId) {
  return apiFetch(`/api/v1/payroll/runs/${runId}/corrections`);
}

export function reversePayrollRun(runId, payload = {}) {
  return apiFetch(`/api/v1/payroll/runs/${runId}/reverse`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function createPayrollCorrectionShell(payload) {
  return apiFetch(`/api/v1/payroll/corrections/shell`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}
```

---

## 13) `PayrollRunDetailPage.jsx` — key integration snippets only

### Add imports

```jsx
import {
  listPayrollRunCorrections,
  reversePayrollRun,
  createPayrollCorrectionShell,
} from "../../api/payrollCorrections.js";
```

### Add state

```jsx
const [corrections, setCorrections] = useState([]);
const [correctionErr, setCorrectionErr] = useState("");
```

### Load corrections with run detail

```jsx
async function load() {
  // existing run + preview loads...
  const [runRes, correctionRes] = await Promise.all([
    getPayrollRun(id),
    listPayrollRunCorrections(id).catch(() => ({ items: [] })),
  ]);
  setRun(runRes);
  setCorrections(correctionRes.items || []);
}
```

### Reverse action (button)

```jsx
async function onReverseRun() {
  try {
    setCorrectionErr("");
    await reversePayrollRun(id, {
      reason: "Correction - reverse unsafe payroll close",
      idempotency_key: `reverse-run-${id}`,
    });
    await load();
  } catch (e) {
    setCorrectionErr(e.message || "Reverse failed");
  }
}
```

### Create RETRO shell action

```jsx
async function onCreateRetroShell() {
  try {
    setCorrectionErr("");
    const res = await createPayrollCorrectionShell({
      correction_type: "RETRO",
      original_run_id: Number(id),
      entity_code: run.entity_code,
      provider_code: run.provider_code,
      payroll_period: run.payroll_period,
      pay_date: run.pay_date,
      currency_code: run.currency_code,
      reason: "Retro adjustment shell",
      idempotency_key: `retro-shell-${id}`,
    });

    // navigate user to import page / run detail
    // e.g. navigate(`/payroll/runs/${res.correction_run.id}`)
    await load();
  } catch (e) {
    setCorrectionErr(e.message || "Retro shell create failed");
  }
}
```

### Create OFF_CYCLE shell action

```jsx
async function onCreateOffCycleShell() {
  try {
    setCorrectionErr("");
    const res = await createPayrollCorrectionShell({
      correction_type: "OFF_CYCLE",
      // original_run_id optional for off-cycle
      entity_code: run.entity_code,
      provider_code: run.provider_code,
      payroll_period: run.payroll_period,
      pay_date: run.pay_date,
      currency_code: run.currency_code,
      reason: "Off-cycle payroll shell",
      idempotency_key: `offcycle-shell-${id}`,
    });

    // navigate(`/payroll/runs/${res.correction_run.id}`)
    await load();
  } catch (e) {
    setCorrectionErr(e.message || "Off-cycle shell create failed");
  }
}
```

### Compact UI block (no table)

```jsx
{
  /* Payroll Corrections Panel (compact) */
}
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Corrections</h2>

  {/* Buttons */}
  {/* - Reverse Run (only if run.status === FINALIZED && !run.is_reversed) */}
  {/* - Create Retro Shell */}
  {/* - Create Off-Cycle Shell */}

  {correctionErr ? (
    <div className="text-sm text-red-600">{correctionErr}</div>
  ) : null}

  <div className="text-sm space-y-1 mt-2">
    {/* Show latest correction links/status only (no full table needed) */}
    {/* Example fields: correction_type, correction_run_no, correction_run_status, created_at */}
  </div>

  {/* Optional helper text:
      "After shell creation, import payroll file into target_run_id through existing payroll import flow." */}
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Can reverse a **FINALIZED** payroll run with accrual JE (creates reversal JE)
- ✅ Reversal creates a linked payroll run (`run_type='REVERSAL'`) with negative payroll lines for traceability
- ✅ Reversal cancels original run liabilities if they are still `OPEN`
- ✅ Reversal is blocked if original liabilities are `IN_BATCH` or `PAID`
- ✅ Reversal is idempotent (repeat call returns same reversal run)
- ✅ Can create **OFF_CYCLE** correction shell (`DRAFT`)
- ✅ Can create **RETRO** correction shell linked to original run (`DRAFT`)
- ✅ P01 import can import into `target_run_id` correction shell (`DRAFT -> IMPORTED`)
- ✅ Correction links are queryable on payroll run detail
- ✅ Audit rows exist for reversal and shell creation
- ✅ Permissions enforced (`payroll.corrections.*`)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:payroll:prp05`

Should verify at least:

1. **Safe reversal**

   - Reverse a finalized run with only `OPEN` liabilities
   - Reversal JE posted
   - Reversal run created
   - Original liabilities canceled

2. **Idempotent reversal**

   - Re-run reverse endpoint
   - Same reversal run returned, no duplicate JE

3. **Blocked reversal**

   - Run with `IN_BATCH` liabilities → reverse returns `409`
   - Run with `PAID` liabilities → reverse returns `409`

4. **Correction shells**

   - Create OFF_CYCLE shell → `DRAFT` run created + linked
   - Create RETRO shell (with `original_run_id`) → `DRAFT` run created + linked

5. **Import into correction shell**

   - P01 import using `target_run_id`
   - Target run transitions `DRAFT -> IMPORTED`
   - Audit row written

6. **Read corrections**

   - GET corrections returns reversal/off-cycle/retro links

7. **Permissions**

   - `payroll.corrections.read`, `payroll.corrections.create`, `payroll.corrections.reverse` enforced (`403`)

---

## Tiny implementation notes (important)

- **P05 does not replace P02/P03/P04** — correction runs still flow through the same pipeline.
- **Reversal** is intentionally strict (only before payment execution/settlement).
- **RETRO/OFF_CYCLE** are the safe path once liabilities are already in payment flow or paid.
- In **P06**, you can extend this with:

  - partial settlement-aware corrections
  - manual settlement overrides
  - correction approval workflow (maker-checker)

---

# PR-P06: Partial Settlement + Manual Payroll Settlement Override (Maker-Checker)

## Goal

Extend **P04 settlement sync** to support real-world partial payments and controlled manual settlement overrides.

This PR gives you:

- ✅ Partial settlement support (`IN_BATCH -> PARTIALLY_PAID -> PAID`)
- ✅ Cumulative settlement tracking on liabilities and payment links
- ✅ Over-settlement protection
- ✅ Manual settlement override request (maker)
- ✅ Manual settlement override approve+apply (checker, different user)
- ✅ Manual override audit trail + settlement evidence rows
- ✅ P04 sync upgraded to handle partial evidence (not only full settlement)

---

## Important behavior rules

### 1) Settlement is cumulative

A payroll liability can be settled in multiple parts over time.
We track:

- `allocated_amount` (from P03 link)
- `settled_amount` (cumulative)
- `remaining = allocated_amount - settled_amount`

### 2) Manual override is maker-checker

- **Requester** creates the manual settlement request
- **Approver** (different user) approves and applies it
- Same user cannot request and approve the same override

### 3) Manual override is only for liabilities in payment flow

For this PR, manual override is applied to liabilities already linked to a payment batch:

- ✅ `IN_BATCH`
- ✅ `PARTIALLY_PAID`

This keeps it consistent with the existing `payroll_liability_settlements` table (which references payment batch/link).

---

## Files to create

### Backend

- `backend/src/migrations/m044_payroll_partial_settlement_and_manual_override.js`
- `backend/src/routes/payroll.settlementOverrides.js`
- `backend/src/routes/payroll.settlementOverrides.validators.js`
- `backend/src/services/payroll.settlementOverrides.service.js`
- `backend/scripts/test-payroll-prp06-partial-settlement-and-manual-override.js`

### Frontend (short snippets only)

- `frontend/src/api/payrollSettlementOverrides.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (patch existing payroll services)

- `backend/src/services/payroll.paymentSync.service.js` _(P04 patch: partial sync support)_
- `backend/src/services/payroll.liabilities.service.js` _(P03 patch: settled/outstanding columns + summary)_

### Frontend (short integration only)

- `frontend/src/pages/payroll/PayrollLiabilitiesPage.jsx`
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m044_payroll_partial_settlement_and_manual_override.js`

```js
// backend/src/migrations/m044_payroll_partial_settlement_and_manual_override.js

export default {
  key: "m044_payroll_partial_settlement_and_manual_override",
  description: "m044_payroll_partial_settlement_and_manual_override",
  async up(connection) {
    // Add cumulative settlement tracking on liabilities
    await db
      .query(
        `
      ALTER TABLE payroll_run_liabilities
        ADD COLUMN settled_amount DECIMAL(18,2) NOT NULL DEFAULT 0 AFTER amount,
        ADD COLUMN outstanding_amount DECIMAL(18,2) NOT NULL DEFAULT 0 AFTER settled_amount
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE payroll_run_liabilities
        ADD KEY idx_payroll_liabilities_outstanding (outstanding_amount)
    `,
      )
      .catch(() => {});

    // Backfill for existing rows
    await db
      .query(
        `
      UPDATE payroll_run_liabilities
      SET
        settled_amount = COALESCE(settled_amount, 0),
        outstanding_amount = ROUND(COALESCE(amount,0) - COALESCE(settled_amount,0), 2)
    `,
      )
      .catch(() => {});

    // Manual settlement override request workflow table
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_liability_override_requests (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        payroll_liability_id BIGINT UNSIGNED NOT NULL,
        payroll_liability_payment_link_id BIGINT UNSIGNED NULL,

        request_type VARCHAR(30) NOT NULL DEFAULT 'MANUAL_SETTLEMENT',
        requested_amount DECIMAL(18,2) NOT NULL,
        currency_code CHAR(3) NOT NULL,
        settled_at DATETIME NOT NULL,
        reason VARCHAR(500) NOT NULL,
        external_ref VARCHAR(190) NULL,

        status VARCHAR(20) NOT NULL DEFAULT 'REQUESTED', -- REQUESTED, APPLIED, REJECTED
        idempotency_key VARCHAR(190) NULL,

        requested_by BIGINT UNSIGNED NULL,
        requested_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        approved_by BIGINT UNSIGNED NULL,
        approved_at DATETIME NULL,

        rejected_by BIGINT UNSIGNED NULL,
        rejected_at DATETIME NULL,

        decision_note VARCHAR(500) NULL,
        applied_settlement_id BIGINT UNSIGNED NULL,

        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_plior_idem (idempotency_key),
        KEY idx_plior_liability (payroll_liability_id),
        KEY idx_plior_link (payroll_liability_payment_link_id),
        KEY idx_plior_status (status),

        CONSTRAINT fk_plior_liability
          FOREIGN KEY (payroll_liability_id) REFERENCES payroll_run_liabilities(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_plior_link
          FOREIGN KEY (payroll_liability_payment_link_id) REFERENCES payroll_liability_payment_links(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_plior_settlement
          FOREIGN KEY (applied_settlement_id) REFERENCES payroll_liability_settlements(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS payroll_liability_override_requests;`);
    // Optional strict down for ALTER columns omitted for dev simplicity
  },
};
```

---

## 2) Validators — `backend/src/routes/payroll.settlementOverrides.validators.js`

```js
// backend/src/routes/payroll.settlementOverrides.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function requirePositiveAmount(v, field) {
  const n = Number(v);
  if (!Number.isFinite(n) || n <= 0) throw new Error(`${field} must be > 0`);
  return Number(n.toFixed(2));
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function requireDateTimeish(v, field) {
  const s = String(v || "").trim();
  // Accept ISO-ish; DB will store DATETIME
  if (!s) throw new Error(`${field} is required`);
  return s;
}

function validateLiabilityIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateOverrideRequestIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreateOverrideRequestBody(body = {}) {
  return {
    amount: requirePositiveAmount(body.amount, "amount"),
    settled_at: requireDateTimeish(body.settled_at, "settled_at"),
    reason:
      normalizeString(body.reason) ||
      (() => {
        throw new Error("reason is required");
      })(),
    external_ref: normalizeString(body.external_ref),
    idempotency_key: normalizeString(body.idempotency_key),
  };
}

function validateApproveApplyOverrideBody(body = {}) {
  return {
    decision_note: normalizeString(body.decision_note),
  };
}

function validateRejectOverrideBody(body = {}) {
  return {
    decision_note: normalizeString(body.decision_note) || "Rejected",
  };
}

export default {
  validateLiabilityIdParam,
  validateOverrideRequestIdParam,
  validateCreateOverrideRequestBody,
  validateApproveApplyOverrideBody,
  validateRejectOverrideBody,
};
```

---

## 3) Service — `backend/src/services/payroll.settlementOverrides.service.js`

```js
// backend/src/services/payroll.settlementOverrides.service.js

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

async function writeLiabilityAudit(
  db,
  { runId, liabilityId = null, action, payload = null, userId = null },
) {
  await db.query(
    `INSERT INTO payroll_liability_audit (run_id, payroll_liability_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?, ?)`,
    [
      runId,
      liabilityId,
      action,
      payload ? JSON.stringify(payload) : null,
      userId,
    ],
  );
}

async function getLiabilityWithActiveLink(db, liabilityId) {
  // Prefer latest non-released link for liability
  const [rows] = await db.query(
    `
    SELECT
      l.*,
      pl.id AS link_id,
      pl.payment_batch_id,
      pl.payment_batch_line_id,
      pl.allocated_amount,
      pl.settled_amount AS link_settled_amount,
      pl.status AS link_status
    FROM payroll_run_liabilities l
    LEFT JOIN payroll_liability_payment_links pl
      ON pl.payroll_liability_id = l.id
     AND pl.status IN ('LINKED', 'PARTIALLY_PAID', 'PAID')
    WHERE l.id = ?
    ORDER BY pl.id DESC
    LIMIT 1
    `,
    [liabilityId],
  );
  return rows[0] || null;
}

function deriveSettlementState({ liabilityAmount, currentSettled, delta }) {
  const totalSettled = amount2(currentSettled + delta);
  const outstanding = amount2(liabilityAmount - totalSettled);

  if (totalSettled < 0 || outstanding < -0.009) {
    const err = new Error("Over-settlement detected");
    err.statusCode = 409;
    throw err;
  }

  const normalizedOutstanding = outstanding < 0 ? 0 : outstanding;

  let liabilityStatus = "PARTIALLY_PAID";
  let linkStatus = "PARTIALLY_PAID";

  if (totalSettled <= 0) {
    liabilityStatus = "IN_BATCH";
    linkStatus = "LINKED";
  } else if (normalizedOutstanding === 0) {
    liabilityStatus = "PAID";
    linkStatus = "PAID";
  }

  return {
    totalSettled,
    outstanding: normalizedOutstanding,
    liabilityStatus,
    linkStatus,
  };
}

async function listManualSettlementRequestsForLiability(db, liabilityId) {
  const [rows] = await db.query(
    `
    SELECT
      r.id, r.payroll_liability_id, r.payroll_liability_payment_link_id,
      r.requested_amount, r.currency_code, r.settled_at, r.reason, r.external_ref,
      r.status, r.requested_by, r.requested_at, r.approved_by, r.approved_at,
      r.rejected_by, r.rejected_at, r.decision_note, r.applied_settlement_id
    FROM payroll_liability_override_requests r
    WHERE r.payroll_liability_id = ?
    ORDER BY r.id DESC
    `,
    [liabilityId],
  );
  return rows;
}

async function createManualSettlementRequest(
  db,
  liabilityId,
  body,
  userId = null,
) {
  const liab = await getLiabilityWithActiveLink(db, liabilityId);
  if (!liab) {
    const err = new Error("Payroll liability not found");
    err.statusCode = 404;
    throw err;
  }

  if (!liab.link_id) {
    const err = new Error(
      "Manual settlement override requires a payroll payment link (liability must be in payment flow)",
    );
    err.statusCode = 400;
    throw err;
  }

  if (
    !["IN_BATCH", "PARTIALLY_PAID"].includes(
      String(liab.status || "").toUpperCase(),
    )
  ) {
    const err = new Error(
      "Manual settlement override allowed only for IN_BATCH or PARTIALLY_PAID liabilities",
    );
    err.statusCode = 400;
    throw err;
  }

  if (body.idempotency_key) {
    const [existing] = await db.query(
      `SELECT * FROM payroll_liability_override_requests WHERE idempotency_key = ? LIMIT 1`,
      [body.idempotency_key],
    );
    if (existing[0]) {
      return { request: existing[0], idempotent: true };
    }
  }

  const remaining = amount2(
    liab.outstanding_amount ?? liab.amount - liab.settled_amount,
  );
  if (body.amount > remaining) {
    const err = new Error(
      `Requested amount exceeds remaining liability amount (${remaining})`,
    );
    err.statusCode = 409;
    throw err;
  }

  const [ins] = await db.query(
    `
    INSERT INTO payroll_liability_override_requests
    (payroll_liability_id, payroll_liability_payment_link_id, requested_amount, currency_code, settled_at, reason, external_ref, status, idempotency_key, requested_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, 'REQUESTED', ?, ?)
    `,
    [
      liabilityId,
      liab.link_id,
      amount2(body.amount),
      liab.currency_code,
      body.settled_at,
      body.reason,
      body.external_ref || null,
      body.idempotency_key || null,
      userId,
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM payroll_liability_override_requests WHERE id = ? LIMIT 1`,
    [ins.insertId],
  );

  await writeLiabilityAudit(db, {
    runId: liab.run_id,
    liabilityId,
    action: "MANUAL_SETTLEMENT_REQUESTED",
    payload: {
      request_id: ins.insertId,
      amount: amount2(body.amount),
      reason: body.reason,
    },
    userId,
  });

  return { request: rows[0], idempotent: false };
}

async function approveApplyManualSettlementRequest(
  db,
  requestId,
  body,
  approverUserId = null,
) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [reqRows] = await q.query(
      `
      SELECT r.*
      FROM payroll_liability_override_requests r
      WHERE r.id = ?
      LIMIT 1
      FOR UPDATE
      `,
      [requestId],
    );
    const req = reqRows[0];
    if (!req) {
      const err = new Error("Manual settlement request not found");
      err.statusCode = 404;
      throw err;
    }

    if (req.status === "APPLIED") {
      const [sett] = await q.query(
        `SELECT * FROM payroll_liability_settlements WHERE id = ? LIMIT 1`,
        [req.applied_settlement_id],
      );
      if (conn) await conn.commit();
      return { request: req, settlement: sett[0] || null, idempotent: true };
    }

    if (req.status !== "REQUESTED") {
      const err = new Error(
        `Request status ${req.status} cannot be approved/applied`,
      );
      err.statusCode = 400;
      throw err;
    }

    if (
      req.requested_by &&
      approverUserId &&
      Number(req.requested_by) === Number(approverUserId)
    ) {
      const err = new Error(
        "Maker-checker violation: requester cannot approve/apply the same manual settlement request",
      );
      err.statusCode = 403;
      throw err;
    }

    const liab = await getLiabilityWithActiveLink(q, req.payroll_liability_id);
    if (!liab || !liab.link_id) {
      const err = new Error(
        "Associated payroll liability/payment link not found",
      );
      err.statusCode = 404;
      throw err;
    }

    if (
      Number(liab.link_id) !== Number(req.payroll_liability_payment_link_id)
    ) {
      const err = new Error(
        "Payment link mismatch on manual settlement request",
      );
      err.statusCode = 409;
      throw err;
    }

    const currentSettled = amount2(liab.link_settled_amount || 0);
    const allocated = amount2(liab.allocated_amount || liab.amount);
    const requestAmount = amount2(req.requested_amount);
    const remaining = amount2(allocated - currentSettled);

    if (requestAmount > remaining) {
      const err = new Error(
        `Manual settlement would over-settle link (remaining ${remaining})`,
      );
      err.statusCode = 409;
      throw err;
    }

    const state = deriveSettlementState({
      liabilityAmount: amount2(liab.amount),
      currentSettled: amount2(liab.settled_amount || 0),
      delta: requestAmount,
    });

    const settlementKey = `PRMANSET|REQ:${req.id}`;

    const [settlementIns] = await q.query(
      `
      INSERT INTO payroll_liability_settlements
      (settlement_key, run_id, payroll_liability_id, payroll_liability_payment_link_id,
       payment_batch_id, payment_batch_line_id, bank_statement_line_id,
       settlement_source, settled_amount, currency_code, settled_at, payload_json, created_by)
      VALUES (?, ?, ?, ?, ?, ?, NULL, 'MANUAL_OVERRIDE', ?, ?, ?, ?, ?)
      ON DUPLICATE KEY UPDATE
        settled_at = VALUES(settled_at)
      `,
      [
        settlementKey,
        liab.run_id,
        liab.id,
        liab.link_id,
        liab.payment_batch_id,
        liab.payment_batch_line_id || null,
        requestAmount,
        liab.currency_code,
        req.settled_at,
        JSON.stringify({
          reason: req.reason,
          external_ref: req.external_ref || null,
        }),
        approverUserId,
      ],
    );

    const settlementId =
      settlementIns.insertId || req.applied_settlement_id || null;

    await q.query(
      `
      UPDATE payroll_liability_payment_links
      SET
        settled_amount = ROUND(COALESCE(settled_amount,0) + ?, 2),
        settled_at = ?,
        last_sync_at = NOW(),
        sync_note = 'manual_override',
        status = ?
      WHERE id = ?
      `,
      [requestAmount, req.settled_at, state.linkStatus, liab.link_id],
    );

    await q.query(
      `
      UPDATE payroll_run_liabilities
      SET
        settled_amount = ?,
        outstanding_amount = ?,
        status = ?,
        paid_at = CASE WHEN ? = 'PAID' THEN ? ELSE paid_at END,
        paid_payment_batch_id = CASE WHEN ? = 'PAID' THEN ? ELSE paid_payment_batch_id END,
        paid_payment_batch_line_id = CASE WHEN ? = 'PAID' THEN ? ELSE paid_payment_batch_line_id END,
        updated_at = NOW()
      WHERE id = ?
      `,
      [
        state.totalSettled,
        state.outstanding,
        state.liabilityStatus,
        state.liabilityStatus,
        req.settled_at,
        state.liabilityStatus,
        liab.payment_batch_id || null,
        state.liabilityStatus,
        liab.payment_batch_line_id || null,
        liab.id,
      ],
    );

    await q.query(
      `
      UPDATE payroll_liability_override_requests
      SET
        status = 'APPLIED',
        approved_by = ?,
        approved_at = NOW(),
        decision_note = ?,
        applied_settlement_id = COALESCE(applied_settlement_id, ?)
      WHERE id = ?
      `,
      [approverUserId, body.decision_note || null, settlementId, req.id],
    );

    await writeLiabilityAudit(q, {
      runId: liab.run_id,
      liabilityId: liab.id,
      action: "MANUAL_SETTLEMENT_APPLIED",
      payload: {
        request_id: req.id,
        amount: requestAmount,
        settlement_source: "MANUAL_OVERRIDE",
        link_status: state.linkStatus,
        liability_status: state.liabilityStatus,
      },
      userId: approverUserId,
    });

    const [updatedReqRows] = await q.query(
      `SELECT * FROM payroll_liability_override_requests WHERE id = ? LIMIT 1`,
      [req.id],
    );
    const [settRows] = await q.query(
      `SELECT * FROM payroll_liability_settlements WHERE settlement_key = ? LIMIT 1`,
      [settlementKey],
    );

    if (conn) await conn.commit();

    return {
      request: updatedReqRows[0],
      settlement: settRows[0] || null,
      idempotent: false,
    };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function rejectManualSettlementRequest(
  db,
  requestId,
  body,
  userId = null,
) {
  const [rows] = await db.query(
    `SELECT * FROM payroll_liability_override_requests WHERE id = ? LIMIT 1`,
    [requestId],
  );
  const req = rows[0];
  if (!req) {
    const err = new Error("Manual settlement request not found");
    err.statusCode = 404;
    throw err;
  }

  if (req.status === "REJECTED") return { request: req, idempotent: true };
  if (req.status !== "REQUESTED") {
    const err = new Error(`Request status ${req.status} cannot be rejected`);
    err.statusCode = 400;
    throw err;
  }

  if (
    req.requested_by &&
    userId &&
    Number(req.requested_by) === Number(userId)
  ) {
    const err = new Error(
      "Maker-checker violation: requester cannot reject own request",
    );
    err.statusCode = 403;
    throw err;
  }

  await db.query(
    `
    UPDATE payroll_liability_override_requests
    SET status='REJECTED', rejected_by=?, rejected_at=NOW(), decision_note=?
    WHERE id=?
    `,
    [userId, body.decision_note || "Rejected", requestId],
  );

  const [liabRows] = await db.query(
    `SELECT id, run_id FROM payroll_run_liabilities WHERE id = ? LIMIT 1`,
    [req.payroll_liability_id],
  );
  const liab = liabRows[0];

  if (liab) {
    await writeLiabilityAudit(db, {
      runId: liab.run_id,
      liabilityId: liab.id,
      action: "MANUAL_SETTLEMENT_REJECTED",
      payload: {
        request_id: requestId,
        decision_note: body.decision_note || "Rejected",
      },
      userId,
    });
  }

  const [updated] = await db.query(
    `SELECT * FROM payroll_liability_override_requests WHERE id = ? LIMIT 1`,
    [requestId],
  );

  return { request: updated[0], idempotent: false };
}

export default {
  listManualSettlementRequestsForLiability,
  createManualSettlementRequest,
  approveApplyManualSettlementRequest,
  rejectManualSettlementRequest,
};
```

---

## 4) Routes — `backend/src/routes/payroll.settlementOverrides.js`

```js
// backend/src/routes/payroll.settlementOverrides.js

import express from "express";
import { validateLiabilityIdParam,
  validateOverrideRequestIdParam,
  validateCreateOverrideRequestBody,
  validateApproveApplyOverrideBody,
  validateRejectOverrideBody, } from "./payroll.settlementOverrides.validators.js";
import service from "../services/payroll.settlementOverrides.service.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/payroll/liabilities/:id/manual-settlement-requests
router.get(
  "/liabilities/:id/manual-settlement-requests",
  requireAuth,
  requirePermission("payroll.settlement.override.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateLiabilityIdParam(req.params);
      const items = await service.listManualSettlementRequestsForLiability(
        db,
        id,
      );
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/liabilities/:id/manual-settlement-requests
router.post(
  "/liabilities/:id/manual-settlement-requests",
  requireAuth,
  requirePermission("payroll.settlement.override.request"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateLiabilityIdParam(req.params);
      const body = validateCreateOverrideRequestBody(req.body);
      const userId = req.user?.id ?? null;
      const result = await service.createManualSettlementRequest(
        db,
        id,
        body,
        userId,
      );
      res.status(201).json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/manual-settlement-requests/:id/approve-apply
router.post(
  "/manual-settlement-requests/:id/approve-apply",
  requireAuth,
  requirePermission("payroll.settlement.override.approve"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateOverrideRequestIdParam(req.params);
      const body = validateApproveApplyOverrideBody(req.body);
      const userId = req.user?.id ?? null;
      const result = await service.approveApplyManualSettlementRequest(
        db,
        id,
        body,
        userId,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/manual-settlement-requests/:id/reject
router.post(
  "/manual-settlement-requests/:id/reject",
  requireAuth,
  requirePermission("payroll.settlement.override.approve"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateOverrideRequestIdParam(req.params);
      const body = validateRejectOverrideBody(req.body);
      const userId = req.user?.id ?? null;
      const result = await service.rejectManualSettlementRequest(
        db,
        id,
        body,
        userId,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 5) Patch P04 service — `backend/src/services/payroll.paymentSync.service.js` (important partial-settlement upgrade)

> Keep your P04 file; apply these **behavior changes**.
> The exact evidence column names on `payment_batch_lines` may differ in your B04 schema — adapt the evidence extraction query only.

### A) Query: include evidence settled amount (adapt names)

```js
// In listSyncCandidates(...) SELECT add one or more of these (adapt to your schema)
pbl.settled_amount AS payment_batch_line_settled_amount,
pbl.executed_amount AS payment_batch_line_executed_amount,
pbl.paid_amount AS payment_batch_line_paid_amount
```

### B) Classifier: return partial vs full settlement

```js
// patch classifyCandidate(row, opts)

function classifyCandidate(row, { allow_b04_only_settlement = false } = {}) {
  const allocated = amount2(row.allocated_amount || row.amount);
  const currentSettled = amount2(row.link_settled_amount || 0);

  const batchCancelled = ["CANCELLED", "FAILED", "REJECTED"].includes(
    String(row.payment_batch_status || "").toUpperCase(),
  );
  const lineCancelled = ["CANCELLED", "FAILED", "REJECTED"].includes(
    String(row.payment_batch_line_status || "").toUpperCase(),
  );

  const linePaidLike = ["PAID", "SETTLED", "EXECUTED"].includes(
    String(row.payment_batch_line_status || "").toUpperCase(),
  );
  const reconciled =
    String(row.payment_batch_line_reconciliation_status || "").toUpperCase() ===
    "RECONCILED";
  const hasBankEvidence = !!row.bank_statement_line_id;

  // Evidence amount (prefer explicit amount from B04/B03 line)
  const explicitEvidenceAmount =
    row.payment_batch_line_settled_amount ??
    row.payment_batch_line_paid_amount ??
    row.payment_batch_line_executed_amount ??
    null;

  const evidenceExists =
    hasBankEvidence ||
    reconciled ||
    (allow_b04_only_settlement && linePaidLike);

  if (
    row.liability_status === "IN_BATCH" ||
    row.liability_status === "PARTIALLY_PAID"
  ) {
    if (evidenceExists) {
      // If explicit evidence amount is missing, fallback to full allocated amount (legacy/full-only behavior)
      const targetSettled = amount2(
        Math.min(
          allocated,
          explicitEvidenceAmount == null
            ? allocated
            : Number(explicitEvidenceAmount),
        ),
      );

      if (targetSettled > currentSettled) {
        const delta = amount2(targetSettled - currentSettled);
        const action =
          targetSettled >= allocated ? "MARK_PAID" : "MARK_PARTIAL";
        return {
          action,
          delta_amount: delta,
          target_settled_amount: targetSettled,
          settlement_source:
            hasBankEvidence || reconciled ? "B03_RECON" : "B04_ONLY",
          bank_statement_line_id: row.bank_statement_line_id || null,
          settled_at:
            row.reconciled_at ||
            row.executed_at ||
            new Date().toISOString().slice(0, 19).replace("T", " "),
          reason: hasBankEvidence
            ? "bank_matched"
            : reconciled
              ? "reconciled_flag"
              : "b04_paid_status",
        };
      }
    }

    if ((batchCancelled || lineCancelled) && currentSettled === 0) {
      return {
        action: "RELEASE_TO_OPEN",
        reason: batchCancelled
          ? "payment_batch_cancelled"
          : "payment_batch_line_cancelled",
      };
    }

    if ((batchCancelled || lineCancelled) && currentSettled > 0) {
      return {
        action: "EXCEPTION",
        reason: "cancelled_after_partial_settlement",
      };
    }
  }

  return { action: "NOOP", reason: "no_new_evidence" };
}
```

### C) Apply sync: update cumulative settlement + partial statuses

```js
// In applyRunPaymentSync(...) inside loop, handle MARK_PARTIAL and MARK_PAID together

if (v.action === "MARK_PARTIAL" || v.action === "MARK_PAID") {
  const settlementKey = buildSettlementKey(item, {
    settlement_source: v.settlement_source,
  });

  // Upsert settlement evidence row as cumulative for that source/link
  // (If the same batch line gets more settled later, this row can be updated)
  await q.query(
    `
    INSERT INTO payroll_liability_settlements
    (settlement_key, run_id, payroll_liability_id, payroll_liability_payment_link_id,
     payment_batch_id, payment_batch_line_id, bank_statement_line_id,
     settlement_source, settled_amount, currency_code, settled_at, payload_json, created_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ON DUPLICATE KEY UPDATE
      settled_amount = GREATEST(settled_amount, VALUES(settled_amount)),
      settled_at = VALUES(settled_at),
      bank_statement_line_id = COALESCE(VALUES(bank_statement_line_id), bank_statement_line_id)
    `,
    [
      settlementKey,
      item.run_id,
      item.payroll_liability_id,
      item.link_id,
      item.payment_batch_id,
      item.payment_batch_line_id || null,
      v.bank_statement_line_id || null,
      v.settlement_source,
      amount2(v.target_settled_amount), // cumulative per source/link row
      item.currency_code,
      v.settled_at,
      JSON.stringify({ reason: v.reason }),
      userId,
    ],
  );

  const allocated = amount2(item.allocated_amount || item.amount);
  const newLinkSettled = amount2(v.target_settled_amount);
  const linkStatus = newLinkSettled >= allocated ? "PAID" : "PARTIALLY_PAID";

  // Liability-level settled is often same as one active link, but keep explicit
  const liabilityAmount = amount2(item.amount);
  const liabilityOutstanding = amount2(
    Math.max(0, liabilityAmount - newLinkSettled),
  );
  const liabilityStatus =
    liabilityOutstanding === 0 ? "PAID" : "PARTIALLY_PAID";

  await q.query(
    `
    UPDATE payroll_liability_payment_links
    SET status = ?,
        settled_amount = ?,
        settled_at = ?,
        last_sync_at = NOW(),
        sync_note = ?
    WHERE id = ?
    `,
    [
      linkStatus,
      newLinkSettled,
      v.settled_at,
      `synced:${v.reason}`,
      item.link_id,
    ],
  );

  await q.query(
    `
    UPDATE payroll_run_liabilities
    SET status = ?,
        settled_amount = ?,
        outstanding_amount = ?,
        paid_at = CASE WHEN ?='PAID' THEN ? ELSE paid_at END,
        paid_payment_batch_id = CASE WHEN ?='PAID' THEN ? ELSE paid_payment_batch_id END,
        paid_payment_batch_line_id = CASE WHEN ?='PAID' THEN ? ELSE paid_payment_batch_line_id END,
        paid_bank_statement_line_id = CASE WHEN ?='PAID' THEN ? ELSE paid_bank_statement_line_id END,
        updated_at = NOW()
    WHERE id = ?
    `,
    [
      liabilityStatus,
      newLinkSettled,
      liabilityOutstanding,
      liabilityStatus,
      v.settled_at,
      liabilityStatus,
      item.payment_batch_id,
      liabilityStatus,
      item.payment_batch_line_id || null,
      liabilityStatus,
      v.bank_statement_line_id || null,
      item.payroll_liability_id,
    ],
  );

  await writeLiabilityAudit(q, {
    runId,
    liabilityId: item.payroll_liability_id,
    action: liabilityStatus === "PAID" ? "SETTLED" : "PARTIALLY_SETTLED",
    payload: {
      payment_batch_id: item.payment_batch_id,
      payment_batch_line_id: item.payment_batch_line_id,
      amount_delta: amount2(v.delta_amount),
      total_settled: newLinkSettled,
      settlement_source: v.settlement_source,
      reason: v.reason,
    },
    userId,
  });

  // bump counters
}
```

### D) Preview summary: include partial + exception counts

Add in P04 preview summary:

- `mark_partial_count`
- `mark_partial_amount`
- `exception_count`

---

## 6) Patch P03 liabilities service — `backend/src/services/payroll.liabilities.service.js`

### A) Insert liabilities with `outstanding_amount = amount`

In both liability insert blocks (employee + statutory), include the new columns:

```js
// add columns in INSERT:
// amount, settled_amount, outstanding_amount, currency_code, ...

// values:
amount, 0, amount, run.currency_code;
```

### B) Include settled/outstanding in list

```js
// include in SELECTs:
l.settled_amount, l.outstanding_amount;
```

### C) Summary should include partials

```js
// in summarizeRunLiabilities(...) add:
COALESCE(SUM(CASE WHEN status='PARTIALLY_PAID' THEN amount ELSE 0 END),0) AS total_partially_paid_amount,
COALESCE(SUM(CASE WHEN status='PARTIALLY_PAID' THEN outstanding_amount ELSE 0 END),0) AS total_partially_paid_outstanding,
COALESCE(SUM(outstanding_amount),0) AS total_outstanding
```

---

## 7) Mount route — `backend/src/index.js`

```js
// backend/src/index.js
import payrollSettlementOverridesRoutes from "./routes/payroll.settlementOverrides.js";
// ...
app.use("/api/v1/payroll", payrollSettlementOverridesRoutes);
```

---

## 8) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m044_payroll_partial_settlement_and_manual_override from "./m044_payroll_partial_settlement_and_manual_override.js";
export default [
  // ...
  m044_payroll_partial_settlement_and_manual_override,
];
```

---

## 9) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const PAYROLL_P06_PERMISSIONS = [
  "payroll.settlement.override.read",
  "payroll.settlement.override.request",
  "payroll.settlement.override.approve",
];

// merge into permission seed list
```

---

## 10) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/payroll/liabilities/{id}/manual-settlement-requests`
- `POST /api/v1/payroll/liabilities/{id}/manual-settlement-requests`
- `POST /api/v1/payroll/manual-settlement-requests/{id}/approve-apply`
- `POST /api/v1/payroll/manual-settlement-requests/{id}/reject`

Also update existing P04 endpoint docs to reflect new preview actions:

- `MARK_PARTIAL`
- `MARK_PAID`
- `RELEASE_TO_OPEN`
- `EXCEPTION`
- `NOOP`

---

## 11) Backend smoke test — `backend/scripts/test-payroll-prp06-partial-settlement-and-manual-override.js`

```js
// backend/scripts/test-payroll-prp06-partial-settlement-and-manual-override.js

async function main() {
  // Preconditions:
  // - P03/P04 implemented
  // - B04 payment batch lines support either explicit settled amount OR full-status fallback
  //
  // Flow A: Partial settlement via P04 sync
  // 1) Create payroll payment batch for a run (P03)
  // 2) Simulate B04/B03 evidence for partial amount (e.g. payment_batch_line.settled_amount < allocated_amount)
  // 3) GET /payment-sync-preview
  //    -> candidate action MARK_PARTIAL
  // 4) POST /payment-sync-apply
  //    -> liability status becomes PARTIALLY_PAID
  //    -> link status becomes PARTIALLY_PAID
  //    -> settled_amount/outstanding_amount updated
  // 5) Simulate remaining settlement evidence
  // 6) Preview/apply again
  //    -> liability/link become PAID
  //
  // Flow B: Manual settlement override request + approve (maker-checker)
  // 7) For another liability in IN_BATCH (or PARTIALLY_PAID), POST manual-settlement-request as User A
  // 8) Same User A tries approve-apply -> 403 maker-checker block
  // 9) User B approves/applies
  //    -> settlement row (MANUAL_OVERRIDE) inserted
  //    -> settled amounts incremented
  //    -> liability/link move PARTIALLY_PAID or PAID
  // 10) Re-approve same request -> idempotent
  //
  // Flow C: Over-settlement protection
  // 11) Create manual request amount > remaining
  //     -> 409
  //
  // Flow D: Reject request
  // 12) Create request
  // 13) Reject as checker
  //     -> status REJECTED, no settlement row created
  //
  // Permissions:
  // - payroll.settlement.override.read/request/approve enforced (403)
  console.log("PR-P06 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 12) `backend/package.json` updates

```json
{
  "scripts": {
    "test:payroll:prp06": "node backend/scripts/test-payroll-prp06-partial-settlement-and-manual-override.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 13) API client — `frontend/src/api/payrollSettlementOverrides.js`

```js
// frontend/src/api/payrollSettlementOverrides.js

import { apiFetch } from "./client.js"; // adapt

export function listPayrollManualSettlementRequests(liabilityId) {
  return apiFetch(
    `/api/v1/payroll/liabilities/${liabilityId}/manual-settlement-requests`,
  );
}

export function createPayrollManualSettlementRequest(liabilityId, payload) {
  return apiFetch(
    `/api/v1/payroll/liabilities/${liabilityId}/manual-settlement-requests`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}

export function approveApplyPayrollManualSettlementRequest(
  requestId,
  payload = {},
) {
  return apiFetch(
    `/api/v1/payroll/manual-settlement-requests/${requestId}/approve-apply`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}

export function rejectPayrollManualSettlementRequest(requestId, payload = {}) {
  return apiFetch(
    `/api/v1/payroll/manual-settlement-requests/${requestId}/reject`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}
```

---

## 14) `PayrollLiabilitiesPage.jsx` — key integration snippets only

### Add imports

```jsx
import {
  listPayrollManualSettlementRequests,
  createPayrollManualSettlementRequest,
  approveApplyPayrollManualSettlementRequest,
  rejectPayrollManualSettlementRequest,
} from "../../api/payrollSettlementOverrides.js";
```

### Extend displayed liability fields (important)

```jsx
// Wherever you render liability rows/cards, make sure to show:
{
  /* status */
}
{
  /* amount */
}
{
  /* settled_amount */
}
{
  /* outstanding_amount */
}
```

### Add state for selected liability manual overrides

```jsx
const [selectedLiabilityId, setSelectedLiabilityId] = useState(null);
const [overrideRequests, setOverrideRequests] = useState([]);
const [overrideErr, setOverrideErr] = useState("");
```

### Load manual override requests (on liability select)

```jsx
async function loadOverrideRequests(liabilityId) {
  setSelectedLiabilityId(liabilityId);
  const res = await listPayrollManualSettlementRequests(liabilityId);
  setOverrideRequests(res.items || []);
}
```

### Create manual settlement request (maker)

```jsx
async function onCreateManualSettlementRequest(liability) {
  try {
    setOverrideErr("");
    await createPayrollManualSettlementRequest(liability.id, {
      amount: 100.0, // from form input
      settled_at: new Date().toISOString(),
      reason:
        "Bank evidence unavailable, approved statement confirmation received",
      external_ref: "MANUAL-REF-001",
      idempotency_key: `manual-settle-${liability.id}-100`,
    });
    await load(); // reload liabilities
    await loadOverrideRequests(liability.id);
  } catch (e) {
    setOverrideErr(e.message || "Manual settlement request failed");
  }
}
```

### Approve/apply request (checker)

```jsx
async function onApproveApplyOverride(reqRow) {
  try {
    setOverrideErr("");
    await approveApplyPayrollManualSettlementRequest(reqRow.id, {
      decision_note: "Approved after treasury confirmation",
    });
    await load();
    await loadOverrideRequests(reqRow.payroll_liability_id);
  } catch (e) {
    setOverrideErr(e.message || "Approve/apply failed");
  }
}
```

### Reject request

```jsx
async function onRejectOverride(reqRow) {
  try {
    setOverrideErr("");
    await rejectPayrollManualSettlementRequest(reqRow.id, {
      decision_note: "Insufficient evidence",
    });
    await loadOverrideRequests(reqRow.payroll_liability_id);
  } catch (e) {
    setOverrideErr(e.message || "Reject failed");
  }
}
```

### Compact UI panel (no tables)

```jsx
{
  /* Manual Settlement Override Panel (compact) */
}
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Manual Settlement Overrides</h2>

  {/* 
    - Trigger from a selected liability (button on each liability row/card)
    - Show selected liability summary: status / amount / settled / outstanding
    - Request form: amount, settled_at, reason, external_ref
    - Buttons:
      - Request Manual Settlement (maker)
      - Approve & Apply (checker) on pending items
      - Reject on pending items
  */}

  {overrideErr ? (
    <div className="text-sm text-red-600">{overrideErr}</div>
  ) : null}

  {/* Optional compact list:
      request id, amount, status, requested_by, requested_at, reason
  */}
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Payroll liabilities support cumulative settlement tracking:

  - `settled_amount`
  - `outstanding_amount`

- ✅ Liability/payment-link statuses support partial settlement:

  - `IN_BATCH -> PARTIALLY_PAID -> PAID`

- ✅ P04 payment sync can classify and apply **partial** settlement (`MARK_PARTIAL`)
- ✅ Settlement sync remains idempotent across re-runs
- ✅ Manual settlement override request can be created (maker)
- ✅ Manual settlement override approve+apply requires different user (checker)
- ✅ Manual override creates `payroll_liability_settlements` row with `settlement_source='MANUAL_OVERRIDE'`
- ✅ Over-settlement is blocked
- ✅ Rejected override requests do not create settlement rows
- ✅ Audit rows exist for request / apply / reject
- ✅ Permissions enforced (`payroll.settlement.override.*`)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:payroll:prp06`

Should verify at least:

1. **Partial settlement via sync**

   - Preview shows `MARK_PARTIAL`
   - Apply sets liability/link to `PARTIALLY_PAID`
   - Settled/outstanding amounts updated correctly

2. **Final settlement completion**

   - Second sync applies remaining settlement
   - Liability/link become `PAID`

3. **Manual override request + approve (maker-checker)**

   - User A requests override
   - User A cannot approve own request (`403`)
   - User B approves/applies successfully

4. **Manual override idempotency**

   - Re-approve same request returns idempotent result (no duplicate settlement)

5. **Over-settlement protection**

   - Request/apply beyond remaining amount returns `409`

6. **Reject flow**

   - Request can be rejected
   - No settlement row created for rejected request

7. **Permissions**

   - `payroll.settlement.override.read`
   - `payroll.settlement.override.request`
   - `payroll.settlement.override.approve`
     all enforced (`403`)

---

## Tiny implementation notes (important)

- This PR keeps **Payroll as subledger owner** and reuses the same settlement evidence table from P04.
- Manual override is intentionally limited to liabilities already in payment flow (linked to a payment batch).
  If you later want “off-system payment” support, add a new override path that can create a synthetic payment link or allow nullable link references.
- In a later PR (P08), you can add **approval policies/thresholds** for manual overrides (e.g., > X amount requires 2 approvers).

---

Let’s go in order — here’s **PR-B05** in the same concrete format.

# PR-B05: Bank Connectivity Adapter (Live Feed / Host-to-Host) via B02 Import Pipeline

## Goal

Add **live bank connectivity** (API/host-to-host/open-banking style) without changing your B02/B03 core.

This PR gives you:

- ✅ Bank connector master (provider + credentials + config + status)
- ✅ Connector ↔ internal bank account mapping
- ✅ Manual “pull statements now” sync
- ✅ Scheduled sync-ready fields + cron script
- ✅ Sync run logs/audit
- ✅ Reuse of **B02 normalized statement import pipeline** (no duplicate import logic)
- ❌ No payment file export/ack yet (that’s **B06**)

---

## Key design rule (important)

**B05 must not bypass B02/B03.**
All fetched bank transactions should be normalized and sent into the same flow as manual imports:

- `B05 connector adapter` → normalize lines
- `B02 import service` → store statement lines idempotently
- `B03 reconciliation` → works unchanged

That keeps your reconciliation and audit behavior consistent.

---

## Files to create

### Backend

- `backend/src/migrations/m045_bank_connectivity_adapters.js`
- `backend/src/routes/bank.connectors.js`
- `backend/src/routes/bank.connectors.validators.js`
- `backend/src/services/bank.connectors.service.js`
- `backend/src/services/bankConnectorAdapters/index.js`
- `backend/src/services/bankConnectorAdapters/mockOpenBanking.adapter.js`
- `backend/scripts/test-bank-prb05-connectivity.js`
- `backend/scripts/bank-sync-due-connectors.js`

### Frontend (short snippets only)

- `frontend/src/api/bankConnectors.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (important patch)

- `backend/src/services/bankStatementImports.service.js` _(or your actual B02 import service file)_
  Export a normalized import function B05 can call.

### Frontend (short integration only)

- `frontend/src/pages/bank/BankAccountsPage.jsx` _(or add a small connectors section)_
- `frontend/src/App.jsx` _(optional if adding dedicated route/page)_
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m045_bank_connectivity_adapters.js`

```js id="1qj5be"
// backend/src/migrations/m045_bank_connectivity_adapters.js

export default {
  key: "m045_bank_connectivity_adapters",
  description: "m045_bank_connectivity_adapters",
  async up(connection) {
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_connectors (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        connector_code VARCHAR(50) NOT NULL,           -- internal unique code (e.g. KBLBANK_MAIN)
        connector_name VARCHAR(190) NOT NULL,
        provider_code VARCHAR(50) NOT NULL,            -- e.g. MOCK_OB, XYZ_BANK_API
        connector_type VARCHAR(30) NOT NULL,           -- OPEN_BANKING, HOST_TO_HOST, SFTP

        entity_code VARCHAR(50) NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'DRAFT',   -- DRAFT, ACTIVE, PAUSED, ERROR, DISABLED

        // Keep secrets encrypted in app layer before insert
        credentials_ciphertext MEDIUMTEXT NULL,
        credentials_meta_json JSON NULL,               -- iv/tag/key version metadata or secret ref
        config_json JSON NULL,                         -- non-secret config (base_url, tenant_id, options)

        last_cursor VARCHAR(255) NULL,
        last_sync_at DATETIME NULL,
        last_success_at DATETIME NULL,
        last_error_at DATETIME NULL,
        last_error_message VARCHAR(500) NULL,

        sync_mode VARCHAR(20) NOT NULL DEFAULT 'MANUAL',   -- MANUAL, SCHEDULED
        sync_frequency_minutes INT NULL,
        next_sync_at DATETIME NULL,

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bank_connectors_code (connector_code),
        KEY idx_bank_connectors_status (status),
        KEY idx_bank_connectors_provider (provider_code),
        KEY idx_bank_connectors_next_sync (next_sync_at)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_connector_account_links (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_connector_id BIGINT UNSIGNED NOT NULL,
        external_account_id VARCHAR(190) NOT NULL,         -- provider account id / IBAN key
        external_account_name VARCHAR(190) NULL,
        external_currency_code CHAR(3) NOT NULL,

        bank_account_id BIGINT UNSIGNED NOT NULL,          -- your B01 internal bank account
        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE',

        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bcal_connector_external (bank_connector_id, external_account_id),
        KEY idx_bcal_bank_account (bank_account_id),

        CONSTRAINT fk_bcal_connector
          FOREIGN KEY (bank_connector_id) REFERENCES bank_connectors(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_connector_sync_runs (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_connector_id BIGINT UNSIGNED NOT NULL,
        run_type VARCHAR(30) NOT NULL DEFAULT 'STATEMENT_PULL',

        status VARCHAR(20) NOT NULL DEFAULT 'RUNNING', -- RUNNING, SUCCESS, PARTIAL, FAILED
        request_id VARCHAR(190) NULL,                  -- idempotency for manual/scheduled trigger
        started_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        finished_at DATETIME NULL,

        window_from DATE NULL,
        window_to DATE NULL,
        cursor_before VARCHAR(255) NULL,
        cursor_after VARCHAR(255) NULL,

        fetched_count INT NOT NULL DEFAULT 0,
        imported_count INT NOT NULL DEFAULT 0,
        duplicate_count INT NOT NULL DEFAULT 0,
        skipped_unmapped_count INT NOT NULL DEFAULT 0,
        error_count INT NOT NULL DEFAULT 0,

        payload_json JSON NULL,
        error_message VARCHAR(500) NULL,

        triggered_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bcsr_request_id (request_id),
        KEY idx_bcsr_connector (bank_connector_id),
        KEY idx_bcsr_status (status),
        KEY idx_bcsr_started (started_at),

        CONSTRAINT fk_bcsr_connector
          FOREIGN KEY (bank_connector_id) REFERENCES bank_connectors(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Optional helper table for import traceability into B02 batches (adapt if B02 already has connector fields)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_connector_sync_run_imports (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_connector_sync_run_id BIGINT UNSIGNED NOT NULL,
        bank_account_id BIGINT UNSIGNED NOT NULL,
        external_account_id VARCHAR(190) NOT NULL,
        import_ref VARCHAR(190) NOT NULL,   -- reference returned by B02 import (batch id/key)
        imported_count INT NOT NULL DEFAULT 0,
        duplicate_count INT NOT NULL DEFAULT 0,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_bcsri_sync_run (bank_connector_sync_run_id),

        CONSTRAINT fk_bcsri_sync_run
          FOREIGN KEY (bank_connector_sync_run_id) REFERENCES bank_connector_sync_runs(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS bank_connector_sync_run_imports;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_connector_sync_runs;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_connector_account_links;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_connectors;`);
  },
};
```

---

## 2) Validators — `backend/src/routes/bank.connectors.validators.js`

```js id="m5yvny"
// backend/src/routes/bank.connectors.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function requireDate(v, field) {
  const s = String(v || "").trim();
  if (!/^\d{4}-\d{2}-\d{2}$/.test(s))
    throw new Error(`${field} must be YYYY-MM-DD`);
  return s;
}

function validateConnectorIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreateConnectorBody(body = {}) {
  return {
    connector_code:
      normalizeString(body.connector_code) ||
      (() => {
        throw new Error("connector_code is required");
      })(),
    connector_name:
      normalizeString(body.connector_name) ||
      (() => {
        throw new Error("connector_name is required");
      })(),
    provider_code:
      String(body.provider_code || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("provider_code is required");
      })(),
    connector_type:
      String(body.connector_type || "")
        .trim()
        .toUpperCase() || "OPEN_BANKING",
    entity_code:
      normalizeString(body.entity_code) ||
      (() => {
        throw new Error("entity_code is required");
      })(),
    config: body.config || {},
    credentials: body.credentials || {}, // encrypted in service layer
    sync_mode: String(body.sync_mode || "MANUAL")
      .trim()
      .toUpperCase(),
    sync_frequency_minutes: body.sync_frequency_minutes
      ? Number(body.sync_frequency_minutes)
      : null,
  };
}

function validateUpdateConnectorBody(body = {}) {
  return {
    connector_name: normalizeString(body.connector_name),
    status: body.status ? String(body.status).trim().toUpperCase() : null,
    config: body.config,
    credentials: body.credentials, // optional rotation
    sync_mode: body.sync_mode
      ? String(body.sync_mode).trim().toUpperCase()
      : null,
    sync_frequency_minutes:
      body.sync_frequency_minutes !== undefined
        ? Number(body.sync_frequency_minutes)
        : undefined,
    next_sync_at: normalizeString(body.next_sync_at),
  };
}

function validateAccountLinkBody(body = {}) {
  return {
    external_account_id:
      normalizeString(body.external_account_id) ||
      (() => {
        throw new Error("external_account_id is required");
      })(),
    external_account_name: normalizeString(body.external_account_name),
    external_currency_code:
      String(body.external_currency_code || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("external_currency_code is required");
      })(),
    bank_account_id: requirePositiveInt(
      body.bank_account_id,
      "bank_account_id",
    ),
    status: body.status ? String(body.status).trim().toUpperCase() : "ACTIVE",
  };
}

function validateSyncTriggerBody(body = {}) {
  return {
    from_date: body.from_date ? requireDate(body.from_date, "from_date") : null,
    to_date: body.to_date ? requireDate(body.to_date, "to_date") : null,
    request_id: normalizeString(body.request_id),
    force_full: String(body.force_full || "false").toLowerCase() === "true",
  };
}

export default {
  validateConnectorIdParam,
  validateCreateConnectorBody,
  validateUpdateConnectorBody,
  validateAccountLinkBody,
  validateSyncTriggerBody,
};
```

---

## 3) Adapter registry — `backend/src/services/bankConnectorAdapters/index.js`

```js id="0gzdes"
// backend/src/services/bankConnectorAdapters/index.js

import mockOpenBankingAdapter from "./mockOpenBanking.adapter.js";
function getBankConnectorAdapter(providerCode) {
  switch (String(providerCode || "").toUpperCase()) {
    case "MOCK_OB":
      return mockOpenBankingAdapter;
    default: {
      const err = new Error(
        `Unsupported bank connector provider: ${providerCode}`,
      );
      err.statusCode = 400;
      throw err;
    }
  }
}

export default {
  getBankConnectorAdapter,
};
```

---

## 4) Mock adapter (reference interface) — `backend/src/services/bankConnectorAdapters/mockOpenBanking.adapter.js`

```js id="xvgh1h"
// backend/src/services/bankConnectorAdapters/mockOpenBanking.adapter.js

/**
 * Adapter contract (all providers should return this shape):
 * {
 *   accounts: [
 *     {
 *       external_account_id,
 *       account_name,
 *       currency_code,
 *       lines: [
 *         {
 *           external_txn_id,
 *           booking_date,      // YYYY-MM-DD
 *           value_date,        // YYYY-MM-DD (optional)
 *           amount,            // signed decimal (+in / -out)
 *           currency_code,
 *           description,
 *           reference,
 *           counterparty_name,
 *           balance_after      // optional
 *         }
 *       ]
 *     }
 *   ],
 *   next_cursor: string|null
 * }
 */

async function testConnection({ config, credentials }) {
  // Replace with real API call
  if (!credentials || !credentials.token) {
    const err = new Error("Missing API token");
    err.statusCode = 400;
    throw err;
  }

  return {
    ok: true,
    provider: "MOCK_OB",
    remote_bank_name: "Mock Open Banking Provider",
    checked_at: new Date().toISOString(),
  };
}

async function pullStatements({
  config,
  credentials,
  cursor,
  fromDate,
  toDate,
}) {
  // Replace with real API pagination. This is only a contract example.
  const today = new Date().toISOString().slice(0, 10);

  return {
    accounts: [
      {
        external_account_id: "EXT-ACC-001",
        account_name: "Main Operating Account",
        currency_code: "USD",
        lines: [
          {
            external_txn_id: `MOCK-TXN-${today}-001`,
            booking_date: today,
            value_date: today,
            amount: -1250.0,
            currency_code: "USD",
            description: "Payroll payment batch disbursement",
            reference: "PAYROLL-BATCH-2026-02",
            counterparty_name: "Salary Transfer",
            balance_after: 142000.5,
          },
        ],
      },
    ],
    next_cursor: cursor ? null : `CURSOR-${today}`,
  };
}

export default {
  provider_code: "MOCK_OB",
  testConnection,
  pullStatements,
};
```

---

## 5) Service — `backend/src/services/bank.connectors.service.js`

```js id="yo17x3"
// backend/src/services/bank.connectors.service.js

import { getBankConnectorAdapter } from "./bankConnectorAdapters.js";
// IMPORTANT: replace with your real encryption helper / KMS / vault integration
function encryptConnectorCredentials(credentialsObj = {}) {
  const json = JSON.stringify(credentialsObj || {});
  return {
    ciphertext: Buffer.from(json, "utf8").toString("base64"), // placeholder only
    meta: { scheme: "base64-placeholder", version: 1 },
  };
}
function decryptConnectorCredentials(ciphertext, meta) {
  if (!ciphertext) return {};
  try {
    return JSON.parse(Buffer.from(ciphertext, "base64").toString("utf8"));
  } catch {
    return {};
  }
}

function normalizeConnectorRow(row) {
  if (!row) return null;
  return {
    ...row,
    config_json: row.config_json || {},
    credentials_meta_json: row.credentials_meta_json || {},
    credentials_ciphertext: undefined, // never return secrets
  };
}

async function listBankConnectors(db) {
  const [rows] = await db.query(
    `SELECT * FROM bank_connectors ORDER BY id DESC`,
  );
  return rows.map(normalizeConnectorRow);
}

async function getBankConnector(db, id, { withSecrets = false } = {}) {
  const [rows] = await db.query(
    `SELECT * FROM bank_connectors WHERE id = ? LIMIT 1`,
    [id],
  );
  const row = rows[0] || null;
  if (!row) return null;
  if (withSecrets) return row;
  return normalizeConnectorRow(row);
}

async function createBankConnector(db, payload, userId = null) {
  const encrypted = encryptConnectorCredentials(payload.credentials || {});

  const [ins] = await db.query(
    `
    INSERT INTO bank_connectors
    (connector_code, connector_name, provider_code, connector_type, entity_code,
     status, credentials_ciphertext, credentials_meta_json, config_json,
     sync_mode, sync_frequency_minutes, created_by, updated_by)
    VALUES (?, ?, ?, ?, ?, 'DRAFT', ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      payload.connector_code,
      payload.connector_name,
      payload.provider_code,
      payload.connector_type,
      payload.entity_code,
      encrypted.ciphertext,
      JSON.stringify(encrypted.meta),
      JSON.stringify(payload.config || {}),
      payload.sync_mode || "MANUAL",
      payload.sync_frequency_minutes || null,
      userId,
      userId,
    ],
  );

  return getBankConnector(db, ins.insertId);
}

async function updateBankConnector(db, id, payload, userId = null) {
  const current = await getBankConnector(db, id, { withSecrets: true });
  if (!current) {
    const err = new Error("Bank connector not found");
    err.statusCode = 404;
    throw err;
  }

  let credentialsCipher = current.credentials_ciphertext;
  let credentialsMeta = current.credentials_meta_json;

  if (payload.credentials !== undefined) {
    const encrypted = encryptConnectorCredentials(payload.credentials || {});
    credentialsCipher = encrypted.ciphertext;
    credentialsMeta = encrypted.meta;
  }

  await db.query(
    `
    UPDATE bank_connectors
    SET
      connector_name = COALESCE(?, connector_name),
      status = COALESCE(?, status),
      config_json = COALESCE(?, config_json),
      credentials_ciphertext = ?,
      credentials_meta_json = ?,
      sync_mode = COALESCE(?, sync_mode),
      sync_frequency_minutes = ?,
      next_sync_at = COALESCE(?, next_sync_at),
      updated_by = ?,
      updated_at = NOW()
    WHERE id = ?
    `,
    [
      payload.connector_name || null,
      payload.status || null,
      payload.config !== undefined
        ? JSON.stringify(payload.config || {})
        : null,
      credentialsCipher,
      JSON.stringify(credentialsMeta || {}),
      payload.sync_mode || null,
      payload.sync_frequency_minutes !== undefined
        ? payload.sync_frequency_minutes
        : current.sync_frequency_minutes,
      payload.next_sync_at || null,
      userId,
      id,
    ],
  );

  return getBankConnector(db, id);
}

async function upsertBankConnectorAccountLink(
  db,
  connectorId,
  payload,
  userId = null,
) {
  const connector = await getBankConnector(db, connectorId);
  if (!connector) {
    const err = new Error("Bank connector not found");
    err.statusCode = 404;
    throw err;
  }

  // Optional: validate bank_account_id exists in your B01 bank_accounts table
  // await db.query(`SELECT id FROM bank_accounts WHERE id=?`, [payload.bank_account_id])

  await db.query(
    `
    INSERT INTO bank_connector_account_links
    (bank_connector_id, external_account_id, external_account_name, external_currency_code, bank_account_id, status, created_by)
    VALUES (?, ?, ?, ?, ?, ?, ?)
    ON DUPLICATE KEY UPDATE
      external_account_name = VALUES(external_account_name),
      external_currency_code = VALUES(external_currency_code),
      bank_account_id = VALUES(bank_account_id),
      status = VALUES(status),
      updated_at = NOW()
    `,
    [
      connectorId,
      payload.external_account_id,
      payload.external_account_name || null,
      payload.external_currency_code,
      payload.bank_account_id,
      payload.status || "ACTIVE",
      userId,
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM bank_connector_account_links WHERE bank_connector_id=? ORDER BY id DESC`,
    [connectorId],
  );
  return rows;
}

async function listConnectorSyncRuns(db, connectorId) {
  const [rows] = await db.query(
    `SELECT * FROM bank_connector_sync_runs WHERE bank_connector_id=? ORDER BY id DESC LIMIT 50`,
    [connectorId],
  );
  return rows;
}

async function testBankConnectorConnection(db, connectorId) {
  const connector = await getBankConnector(db, connectorId, {
    withSecrets: true,
  });
  if (!connector) {
    const err = new Error("Bank connector not found");
    err.statusCode = 404;
    throw err;
  }

  const adapter = getBankConnectorAdapter(connector.provider_code);
  const credentials = decryptConnectorCredentials(
    connector.credentials_ciphertext,
    connector.credentials_meta_json,
  );
  const config = connector.config_json || {};

  return adapter.testConnection({ config, credentials });
}

/**
 * IMPORTANT B02 PATCH CONTRACT:
 * This service expects your B02 import service to export a function like:
 *   importNormalizedBankStatementLines(db, {
 *     bank_account_id,
 *     currency_code,
 *     source_type,        // 'CONNECTOR'
 *     source_ref,         // stable batch key
 *     lines: [...]
 *     triggered_by
 *   })
 * returning:
 *   { import_ref, imported_count, duplicate_count }
 */
function getB02ImportFn() {
  // adapt file path/name to your actual B02 service
  import svc from "./bankStatementImports.service.js";
  if (typeof svc.importNormalizedBankStatementLines !== "function") {
    const err = new Error(
      "B02 importNormalizedBankStatementLines() export not found",
    );
    err.statusCode = 500;
    throw err;
  }
  return svc.importNormalizedBankStatementLines;
}

async function runConnectorStatementSync(
  db,
  connectorId,
  payload = {},
  userId = null,
) {
  const connector = await getBankConnector(db, connectorId, {
    withSecrets: true,
  });
  if (!connector) {
    const err = new Error("Bank connector not found");
    err.statusCode = 404;
    throw err;
  }

  if (
    !["ACTIVE", "DRAFT", "ERROR", "PAUSED"].includes(
      String(connector.status).toUpperCase(),
    )
  ) {
    const err = new Error(
      `Connector status ${connector.status} does not allow sync`,
    );
    err.statusCode = 400;
    throw err;
  }

  const requestId =
    payload.request_id || `BANKSYNC|CONN:${connectorId}|${Date.now()}`;

  // Idempotent trigger
  const [existingRuns] = await db.query(
    `SELECT * FROM bank_connector_sync_runs WHERE request_id = ? LIMIT 1`,
    [requestId],
  );
  if (existingRuns[0]) {
    return {
      sync_run: existingRuns[0],
      idempotent: true,
    };
  }

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    // lock connector row to avoid concurrent sync
    const [lockedRows] = await q.query(
      `SELECT * FROM bank_connectors WHERE id=? LIMIT 1 FOR UPDATE`,
      [connectorId],
    );
    const locked = lockedRows[0];
    if (!locked) {
      const err = new Error("Bank connector not found");
      err.statusCode = 404;
      throw err;
    }

    const [syncIns] = await q.query(
      `
      INSERT INTO bank_connector_sync_runs
      (bank_connector_id, run_type, status, request_id, window_from, window_to, cursor_before, triggered_by)
      VALUES (?, 'STATEMENT_PULL', 'RUNNING', ?, ?, ?, ?, ?)
      `,
      [
        connectorId,
        requestId,
        payload.from_date || null,
        payload.to_date || null,
        locked.last_cursor || null,
        userId,
      ],
    );

    const syncRunId = syncIns.insertId;

    const adapter = getBankConnectorAdapter(locked.provider_code);
    const credentials = decryptConnectorCredentials(
      locked.credentials_ciphertext,
      locked.credentials_meta_json,
    );
    const config = locked.config_json || {};

    const adapterRes = await adapter.pullStatements({
      config,
      credentials,
      cursor: payload.force_full ? null : locked.last_cursor || null,
      fromDate: payload.from_date || null,
      toDate: payload.to_date || null,
    });

    const importNormalizedBankStatementLines = getB02ImportFn();

    const [links] = await q.query(
      `SELECT * FROM bank_connector_account_links WHERE bank_connector_id=? AND status='ACTIVE'`,
      [connectorId],
    );

    const linkMap = new Map(
      links.map((l) => [String(l.external_account_id), l]),
    );

    let fetchedCount = 0;
    let importedCount = 0;
    let duplicateCount = 0;
    let skippedUnmappedCount = 0;
    let errorCount = 0;

    for (const acct of adapterRes.accounts || []) {
      const extAccountId = String(acct.external_account_id);
      const accountLink = linkMap.get(extAccountId);

      const acctLines = Array.isArray(acct.lines) ? acct.lines : [];
      fetchedCount += acctLines.length;

      if (!accountLink) {
        skippedUnmappedCount += acctLines.length;
        continue;
      }

      const normalizedLines = acctLines.map((line) => ({
        external_txn_id: String(line.external_txn_id),
        booking_date: line.booking_date,
        value_date: line.value_date || null,
        amount: Number(line.amount),
        currency_code: String(
          line.currency_code || acct.currency_code,
        ).toUpperCase(),
        description: line.description || null,
        reference: line.reference || null,
        counterparty_name: line.counterparty_name || null,
        balance_after: line.balance_after ?? null,
        raw_json: line,
      }));

      try {
        const importRes = await importNormalizedBankStatementLines(q, {
          bank_account_id: Number(accountLink.bank_account_id),
          currency_code: accountLink.external_currency_code,
          source_type: "CONNECTOR",
          source_ref: `CONN:${connectorId}|RUN:${syncRunId}|ACC:${extAccountId}`,
          lines: normalizedLines,
          triggered_by: userId,
        });

        importedCount += Number(importRes.imported_count || 0);
        duplicateCount += Number(importRes.duplicate_count || 0);

        await q.query(
          `
          INSERT INTO bank_connector_sync_run_imports
          (bank_connector_sync_run_id, bank_account_id, external_account_id, import_ref, imported_count, duplicate_count)
          VALUES (?, ?, ?, ?, ?, ?)
          `,
          [
            syncRunId,
            Number(accountLink.bank_account_id),
            extAccountId,
            String(
              importRes.import_ref || `B02IMP-${syncRunId}-${extAccountId}`,
            ),
            Number(importRes.imported_count || 0),
            Number(importRes.duplicate_count || 0),
          ],
        );
      } catch (e) {
        errorCount += acctLines.length;
        // continue other accounts; mark PARTIAL later
      }
    }

    const finalStatus =
      errorCount > 0 ? (importedCount > 0 ? "PARTIAL" : "FAILED") : "SUCCESS";

    const nextCursor = adapterRes.next_cursor || locked.last_cursor || null;

    await q.query(
      `
      UPDATE bank_connector_sync_runs
      SET
        status = ?,
        finished_at = NOW(),
        cursor_after = ?,
        fetched_count = ?,
        imported_count = ?,
        duplicate_count = ?,
        skipped_unmapped_count = ?,
        error_count = ?,
        payload_json = ?
      WHERE id = ?
      `,
      [
        finalStatus,
        nextCursor,
        fetchedCount,
        importedCount,
        duplicateCount,
        skippedUnmappedCount,
        errorCount,
        JSON.stringify({
          account_count: (adapterRes.accounts || []).length,
          next_cursor: nextCursor,
        }),
        syncRunId,
      ],
    );

    await q.query(
      `
      UPDATE bank_connectors
      SET
        last_sync_at = NOW(),
        last_success_at = CASE WHEN ? IN ('SUCCESS','PARTIAL') THEN NOW() ELSE last_success_at END,
        last_error_at = CASE WHEN ? = 'FAILED' THEN NOW() ELSE last_error_at END,
        last_error_message = CASE WHEN ? = 'FAILED' THEN 'Connector sync failed' ELSE NULL END,
        last_cursor = ?,
        status = CASE
          WHEN status='DRAFT' AND ? IN ('SUCCESS','PARTIAL') THEN 'ACTIVE'
          WHEN ?='FAILED' THEN 'ERROR'
          ELSE status
        END,
        next_sync_at = CASE
          WHEN sync_mode='SCHEDULED' AND sync_frequency_minutes IS NOT NULL
            THEN DATE_ADD(NOW(), INTERVAL sync_frequency_minutes MINUTE)
          ELSE next_sync_at
        END,
        updated_by = ?,
        updated_at = NOW()
      WHERE id = ?
      `,
      [
        finalStatus,
        finalStatus,
        finalStatus,
        nextCursor,
        finalStatus,
        finalStatus,
        userId,
        connectorId,
      ],
    );

    if (conn) await conn.commit();

    const [syncRows] = await db.query(
      `SELECT * FROM bank_connector_sync_runs WHERE id=? LIMIT 1`,
      [syncRunId],
    );

    return {
      sync_run: syncRows[0],
      idempotent: false,
    };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function syncDueBankConnectors(db, userId = null) {
  const [rows] = await db.query(
    `
    SELECT id
    FROM bank_connectors
    WHERE status IN ('ACTIVE','ERROR')
      AND sync_mode = 'SCHEDULED'
      AND next_sync_at IS NOT NULL
      AND next_sync_at <= NOW()
    ORDER BY next_sync_at ASC
    LIMIT 20
    `,
  );

  const results = [];
  for (const r of rows) {
    try {
      const res = await runConnectorStatementSync(
        db,
        r.id,
        {
          request_id: `AUTOSYNC|CONN:${r.id}|${new Date().toISOString().slice(0, 16)}`,
        },
        userId,
      );
      results.push({
        connector_id: r.id,
        ok: true,
        sync_run_id: res.sync_run?.id || null,
      });
    } catch (e) {
      results.push({
        connector_id: r.id,
        ok: false,
        error: e.message || "sync failed",
      });
    }
  }
  return results;
}

export default {
  listBankConnectors,
  getBankConnector,
  createBankConnector,
  updateBankConnector,
  upsertBankConnectorAccountLink,
  listConnectorSyncRuns,
  testBankConnectorConnection,
  runConnectorStatementSync,
  syncDueBankConnectors,
};
```

---

## 6) Routes — `backend/src/routes/bank.connectors.js`

```js id="e4aq8g"
// backend/src/routes/bank.connectors.js

import express from "express";
import { validateConnectorIdParam,
  validateCreateConnectorBody,
  validateUpdateConnectorBody,
  validateAccountLinkBody,
  validateSyncTriggerBody, } from "./bank.connectors.validators.js";
import service from "../services/bank.connectors.service.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/bank/connectors
router.get(
  "/connectors",
  requireAuth,
  requirePermission("bank.connectors.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const items = await service.listBankConnectors(db);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/connectors
router.post(
  "/connectors",
  requireAuth,
  requirePermission("bank.connectors.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateConnectorBody(req.body);
      const result = await service.createBankConnector(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json(result);
    } catch (err) {
      next(err);
    }
  },
);

// PATCH /api/v1/bank/connectors/:id
router.patch(
  "/connectors/:id",
  requireAuth,
  requirePermission("bank.connectors.update"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateConnectorIdParam(req.params);
      const body = validateUpdateConnectorBody(req.body);
      const result = await service.updateBankConnector(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/connectors/:id/test
router.post(
  "/connectors/:id/test",
  requireAuth,
  requirePermission("bank.connectors.test"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateConnectorIdParam(req.params);
      const result = await service.testBankConnectorConnection(db, id);
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// PUT /api/v1/bank/connectors/:id/account-links
router.put(
  "/connectors/:id/account-links",
  requireAuth,
  requirePermission("bank.connectors.accountlink.manage"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateConnectorIdParam(req.params);
      const body = validateAccountLinkBody(req.body);
      const items = await service.upsertBankConnectorAccountLink(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/bank/connectors/:id/sync-runs
router.get(
  "/connectors/:id/sync-runs",
  requireAuth,
  requirePermission("bank.connectors.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateConnectorIdParam(req.params);
      const items = await service.listConnectorSyncRuns(db, id);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/connectors/:id/sync-statements
router.post(
  "/connectors/:id/sync-statements",
  requireAuth,
  requirePermission("bank.connectors.sync"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateConnectorIdParam(req.params);
      const body = validateSyncTriggerBody(req.body);
      const result = await service.runConnectorStatementSync(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 7) Patch B02 import service — `backend/src/services/bankStatementImports.service.js` (important)

> **B05 depends on this.**
> Your B02 import service should expose a normalized import function that can be reused by connectors.

### Add/Export a normalized import entrypoint

```js id="yw3wyu"
// backend/src/services/bankStatementImports.service.js (patch snippet)

// Existing B02 likely parses CSV/etc. and then inserts lines.
// Add a reusable normalized insert function and export it.

async function importNormalizedBankStatementLines(db, payload) {
  // payload:
  // {
  //   bank_account_id,
  //   currency_code,
  //   source_type: 'CONNECTOR' | 'FILE',
  //   source_ref: 'CONN:..' or file hash key,
  //   lines: [{ external_txn_id, booking_date, amount, ... }],
  //   triggered_by
  // }

  // IMPORTANT:
  // Reuse your existing B02 dedupe/idempotency rules here.
  // Suggested dedupe key:
  //   (bank_account_id, external_txn_id)
  // or if no external_txn_id:
  //   hash(booking_date, amount, reference, description)

  let imported = 0;
  let duplicates = 0;

  // Optional: create B02 import batch row, return import_ref
  const importRef = payload.source_ref || `B02IMP-${Date.now()}`;

  for (const line of payload.lines || []) {
    try {
      // Insert into your B02 bank statement line table
      // ON DUPLICATE KEY UPDATE ... no-op / preserve existing
      // Track imported vs duplicate
      imported += 1; // replace with real count logic
    } catch (e) {
      // If duplicate key:
      // duplicates += 1;
      // else throw e;
      throw e;
    }
  }

  return {
    import_ref: importRef,
    imported_count: imported,
    duplicate_count: duplicates,
  };
}

export default {
  // existing exports...
  importNormalizedBankStatementLines,
};
```

---

## 8) Mount route — `backend/src/index.js`

```js id="0iunwx"
// backend/src/index.js
import bankConnectorRoutes from "./routes/bank.connectors.js";
// ...
app.use("/api/v1/bank", bankConnectorRoutes);
```

---

## 9) Migration registry — `backend/src/migrations/index.js`

```js id="jlwm2j"
// backend/src/migrations/index.js
import m045_bank_connectivity_adapters from "./m045_bank_connectivity_adapters.js";
export default [
  // ...
  m045_bank_connectivity_adapters,
];
```

---

## 10) Seed permissions — `backend/src/seedCore.js`

```js id="flvkrb"
// backend/src/seedCore.js
const BANK_B05_PERMISSIONS = [
  "bank.connectors.read",
  "bank.connectors.create",
  "bank.connectors.update",
  "bank.connectors.test",
  "bank.connectors.sync",
  "bank.connectors.accountlink.manage",
];

// merge into permission seed list
```

---

## 11) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/bank/connectors`
- `POST /api/v1/bank/connectors`
- `PATCH /api/v1/bank/connectors/{id}`
- `POST /api/v1/bank/connectors/{id}/test`
- `PUT /api/v1/bank/connectors/{id}/account-links`
- `GET /api/v1/bank/connectors/{id}/sync-runs`
- `POST /api/v1/bank/connectors/{id}/sync-statements`

Also document that B05 sync ultimately writes into the same B02 statement import pipeline.

---

## 12) Scheduled sync script — `backend/scripts/bank-sync-due-connectors.js`

```js id="s5wo27"
// backend/scripts/bank-sync-due-connectors.js

async function main() {
  // adapt to your app bootstrap/db getter
  import { getDbPool } from "../src/db.js";
  import { syncDueBankConnectors, } from "../src/services/bank.connectors.service.js";
  const db = getDbPool();
  const results = await syncDueBankConnectors(db, null);

  console.log("bank connector scheduled sync results:", results);
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 13) Backend smoke test — `backend/scripts/test-bank-prb05-connectivity.js`

```js id="s9h8vj"
// backend/scripts/test-bank-prb05-connectivity.js

async function main() {
  // Preconditions:
  // - B01 bank accounts exist
  // - B02 import pipeline implemented and exposes importNormalizedBankStatementLines(...)
  // - Mock adapter provider "MOCK_OB" available
  //
  // Flow:
  // 1) POST /api/v1/bank/connectors (DRAFT connector)
  // 2) POST /api/v1/bank/connectors/:id/test
  //    -> ok=true
  // 3) PUT /api/v1/bank/connectors/:id/account-links
  //    -> map EXT-ACC-001 to internal B01 bank_account_id
  // 4) PATCH connector status to ACTIVE
  // 5) POST /api/v1/bank/connectors/:id/sync-statements (manual trigger)
  //    -> creates bank_connector_sync_runs row
  //    -> imports lines via B02 normalized import
  // 6) Re-run same sync with same request_id
  //    -> idempotent sync_run (same run returned)
  // 7) Trigger another sync (new request_id)
  //    -> duplicates counted if same external_txn_id comes again
  // 8) Verify B03 can see imported statement lines (same queue as file-imported lines)
  // 9) Permissions enforced for create/test/sync/accountlink (403)
  //
  // Optional:
  // 10) Set connector sync_mode=SCHEDULED and next_sync_at<=NOW()
  // 11) Run backend/scripts/bank-sync-due-connectors.js
  //     -> due connector sync executes
  console.log("PR-B05 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 14) `backend/package.json` updates

```json id="d7l4qq"
{
  "scripts": {
    "test:bank:prb05": "node backend/scripts/test-bank-prb05-connectivity.js",
    "job:bank:sync-connectors": "node backend/scripts/bank-sync-due-connectors.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 15) API client — `frontend/src/api/bankConnectors.js`

```js id="ul7k2m"
// frontend/src/api/bankConnectors.js

import { apiFetch } from "./client.js"; // adapt

export function listBankConnectors() {
  return apiFetch("/api/v1/bank/connectors");
}

export function createBankConnector(payload) {
  return apiFetch("/api/v1/bank/connectors", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function updateBankConnector(connectorId, payload) {
  return apiFetch(`/api/v1/bank/connectors/${connectorId}`, {
    method: "PATCH",
    body: JSON.stringify(payload),
  });
}

export function testBankConnector(connectorId) {
  return apiFetch(`/api/v1/bank/connectors/${connectorId}/test`, {
    method: "POST",
  });
}

export function upsertBankConnectorAccountLink(connectorId, payload) {
  return apiFetch(`/api/v1/bank/connectors/${connectorId}/account-links`, {
    method: "PUT",
    body: JSON.stringify(payload),
  });
}

export function listBankConnectorSyncRuns(connectorId) {
  return apiFetch(`/api/v1/bank/connectors/${connectorId}/sync-runs`);
}

export function syncBankConnectorStatements(connectorId, payload = {}) {
  return apiFetch(`/api/v1/bank/connectors/${connectorId}/sync-statements`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}
```

---

## 16) `BankAccountsPage.jsx` (or a small “Connectors” panel) — key snippets only

### Add imports

```jsx id="qkdn1b"
import {
  listBankConnectors,
  createBankConnector,
  testBankConnector,
  syncBankConnectorStatements,
  listBankConnectorSyncRuns,
  upsertBankConnectorAccountLink,
  updateBankConnector,
} from "../../api/bankConnectors.js";
```

### Add state

```jsx id="31e1vu"
const [connectors, setConnectors] = useState([]);
const [selectedConnectorId, setSelectedConnectorId] = useState(null);
const [syncRuns, setSyncRuns] = useState([]);
const [connectorErr, setConnectorErr] = useState("");
```

### Load connectors / sync runs

```jsx id="xafuh7"
async function loadConnectors() {
  const res = await listBankConnectors();
  setConnectors(res.items || []);
}

async function loadSyncRuns(connectorId) {
  setSelectedConnectorId(connectorId);
  const res = await listBankConnectorSyncRuns(connectorId);
  setSyncRuns(res.items || []);
}
```

### Create connector

```jsx id="ot4l4w"
async function onCreateConnector() {
  try {
    setConnectorErr("");
    await createBankConnector({
      connector_code: "KBL_MAIN_OB",
      connector_name: "Kabul Bank Open Banking",
      provider_code: "MOCK_OB", // replace with real provider later
      connector_type: "OPEN_BANKING",
      entity_code: "MAIN",
      config: { base_url: "https://api.bank.example" },
      credentials: { token: "replace-me" },
      sync_mode: "MANUAL",
    });
    await loadConnectors();
  } catch (e) {
    setConnectorErr(e.message || "Create connector failed");
  }
}
```

### Test + activate + map account + sync

```jsx id="ckehk2"
async function onSetupAndSync(connector, bankAccountId) {
  try {
    setConnectorErr("");

    await testBankConnector(connector.id);

    await upsertBankConnectorAccountLink(connector.id, {
      external_account_id: "EXT-ACC-001",
      external_account_name: "Main Operating Account",
      external_currency_code: "USD",
      bank_account_id: bankAccountId,
    });

    await updateBankConnector(connector.id, { status: "ACTIVE" });

    await syncBankConnectorStatements(connector.id, {
      request_id: `manual-${connector.id}-${Date.now()}`,
    });

    await loadConnectors();
    await loadSyncRuns(connector.id);
  } catch (e) {
    setConnectorErr(e.message || "Connector sync failed");
  }
}
```

### Compact UI block (no big tables)

```jsx id="4vbxub"
{
  /* Bank Connectors Panel (compact) */
}
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Bank Connectors</h2>

  {/* Buttons:
      - Create Connector
      - Test
      - Activate/Pause
      - Sync Now
      - Map External Account -> Internal Bank Account
  */}

  {connectorErr ? (
    <div className="text-sm text-red-600">{connectorErr}</div>
  ) : null}

  <div className="text-sm space-y-1 mt-2">
    {/* For each connector show:
        name, provider, status, last_sync_at, last_success_at, last_error_message
    */}
  </div>

  <div className="text-sm space-y-1 mt-3">
    {/* For selected connector show recent sync runs:
        started_at, status, fetched/imported/duplicate/skipped_unmapped/error counts
    */}
  </div>
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Can create/update bank connectors (provider/config/credentials/status)
- ✅ Can test connector connection (provider adapter contract)
- ✅ Can map external bank account IDs to internal B01 bank accounts
- ✅ Manual sync creates `bank_connector_sync_runs` log
- ✅ Connector sync imports statement lines via **B02 normalized import service** (not duplicate code path)
- ✅ Sync trigger supports idempotency (`request_id`)
- ✅ Re-sync counts duplicates correctly (via B02 dedupe)
- ✅ Scheduled sync script exists and runs due connectors
- ✅ B03 reconciliation can consume synced statement lines unchanged
- ✅ Permissions enforced (`bank.connectors.*`)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:bank:prb05`

Should verify at least:

1. **Connector lifecycle**

   - Create connector (`DRAFT`)
   - Test connection succeeds
   - Update status to `ACTIVE`

2. **Account mapping**

   - Map external account to internal B01 `bank_account_id`
   - Sync without mapping should skip/unmapped
   - Sync with mapping should import

3. **Manual sync**

   - Trigger sync
   - `bank_connector_sync_runs` row created
   - Fetched/imported counts populated
   - B02 statement lines created

4. **Idempotent trigger**

   - Re-trigger with same `request_id`
   - Same sync run returned (no duplicate run)

5. **Duplicate transaction handling**

   - Trigger fresh sync with same mock transactions
   - B02 dedupe prevents duplicates
   - Duplicate count increments

6. **Scheduled sync**

   - Set connector `sync_mode=SCHEDULED` and `next_sync_at<=NOW()`
   - Run `npm run job:bank:sync-connectors`
   - Due connector sync executes and logs run

7. **Permissions**

   - `bank.connectors.read/create/update/test/sync/accountlink.manage` enforced (`403`)

---

## Tiny implementation notes (important)

- **B05 should stay thin**: provider adapter + orchestration only.
  The heavy lifting (dedupe + statement persistence) remains in **B02**.
- The adapter shown is a **mock provider** but defines the exact interface you’ll reuse for real banks.
- For production, replace the placeholder credential “encryption” with your real:

  - KMS / vault / secrets manager, or
  - AES-GCM app-layer encryption with rotation metadata.

---

Perfect — here’s **PR-B06** in the same concrete format, keeping frontend short.

# PR-B06: Payment File Export + Bank Acknowledgement Import (Generic, B04-Compatible)

## Goal

Close the outbound bank execution loop for **B04 payment batches**:

- ✅ Export approved payment batches into a bank file (provider/format-specific)
- ✅ Keep export runs idempotent and auditable
- ✅ Import bank acknowledgement files (accepted / rejected / partial / paid)
- ✅ Update `payment_batch_lines` statuses and executed amounts from ack
- ✅ Keep everything generic (works for Payroll/AP/etc. via B04)
- ❌ Final bank statement reconciliation still stays in **B03**

---

## Key design rule (important)

**B06 updates payment execution status only.**
It does **not** replace B03 reconciliation.

Flow remains:

- **B04** creates payment batch
- **B06** exports file + imports bank ack (execution outcome)
- **B03** reconciles actual bank statement movement
- **P04** (and later AP sync) can use B04/B03 evidence depending on policy

---

## Files to create

### Backend

- `backend/src/migrations/m046_bank_payment_exports_and_acks.js`
- `backend/src/routes/bank.paymentFiles.js`
- `backend/src/routes/bank.paymentFiles.validators.js`
- `backend/src/services/bank.paymentFiles.service.js`
- `backend/src/services/bankPaymentFileFormats/index.js`
- `backend/src/services/bankPaymentFileFormats/genericCsvV1.format.js`
- `backend/scripts/test-bank-prb06-payment-file-and-ack.js`

### Frontend (short snippets only)

- `frontend/src/api/bankPaymentFiles.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (important patch)

- `backend/src/services/bank.paymentBatches.service.js` _(or your actual B04 batch service file)_
  Add export-readiness checks + status compatibility.

### Frontend (short integration only)

- `frontend/src/pages/bank/PaymentBatchDetailPage.jsx` _(or your B04 batch detail page)_
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m046_bank_payment_exports_and_acks.js`

```js
// backend/src/migrations/m046_bank_payment_exports_and_acks.js

export default {
  key: "m046_bank_payment_exports_and_acks",
  description: "m046_bank_payment_exports_and_acks",
  async up(connection) {
    // Batch-level export/ack tracking
    await db
      .query(
        `
      ALTER TABLE payment_batches
        ADD COLUMN bank_file_format_code VARCHAR(50) NULL AFTER status,
        ADD COLUMN bank_export_status VARCHAR(20) NOT NULL DEFAULT 'NOT_EXPORTED' AFTER bank_file_format_code,
        ADD COLUMN last_exported_at DATETIME NULL AFTER bank_export_status,
        ADD COLUMN last_ack_imported_at DATETIME NULL AFTER last_exported_at
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE payment_batches
        ADD KEY idx_payment_batches_bank_export_status (bank_export_status)
    `,
      )
      .catch(() => {});

    // Line-level execution/ack fields (B04 line status remains source-of-truth status)
    await db
      .query(
        `
      ALTER TABLE payment_batch_lines
        ADD COLUMN exported_amount DECIMAL(18,2) NOT NULL DEFAULT 0 AFTER amount,
        ADD COLUMN executed_amount DECIMAL(18,2) NOT NULL DEFAULT 0 AFTER exported_amount,
        ADD COLUMN bank_reference VARCHAR(190) NULL AFTER executed_amount,
        ADD COLUMN ack_status VARCHAR(30) NULL AFTER bank_reference,
        ADD COLUMN ack_code VARCHAR(50) NULL AFTER ack_status,
        ADD COLUMN ack_message VARCHAR(255) NULL AFTER ack_code,
        ADD COLUMN exported_at DATETIME NULL AFTER ack_message,
        ADD COLUMN acknowledged_at DATETIME NULL AFTER exported_at
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE payment_batch_lines
        ADD KEY idx_payment_batch_lines_ack_status (ack_status)
    `,
      )
      .catch(() => {});

    // Export runs
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_payment_batch_exports (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        payment_batch_id BIGINT UNSIGNED NOT NULL,
        export_request_id VARCHAR(190) NULL,
        file_format_code VARCHAR(50) NOT NULL,
        export_status VARCHAR(20) NOT NULL DEFAULT 'GENERATED', -- GENERATED, SENT, CANCELLED
        file_name VARCHAR(255) NOT NULL,
        file_storage_path VARCHAR(500) NULL,                     -- local path/blob key
        file_mime_type VARCHAR(100) NOT NULL DEFAULT 'text/csv',
        file_sha256 VARCHAR(64) NULL,
        line_count INT NOT NULL DEFAULT 0,
        total_amount DECIMAL(18,2) NOT NULL DEFAULT 0,
        currency_code CHAR(3) NULL,
        payload_json JSON NULL,                                  -- metadata only, not full file content
        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bpbe_request_id (export_request_id),
        KEY idx_bpbe_batch (payment_batch_id),

        CONSTRAINT fk_bpbe_batch
          FOREIGN KEY (payment_batch_id) REFERENCES payment_batches(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Export line snapshots (freeze refs used by bank)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_payment_batch_export_lines (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_payment_batch_export_id BIGINT UNSIGNED NOT NULL,
        payment_batch_line_id BIGINT UNSIGNED NOT NULL,
        line_ref VARCHAR(190) NOT NULL,                      -- exported line reference used for ack matching
        beneficiary_name VARCHAR(255) NULL,
        beneficiary_account VARCHAR(190) NULL,
        amount DECIMAL(18,2) NOT NULL,
        currency_code CHAR(3) NOT NULL,
        reference_text VARCHAR(255) NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bpbel_export_lineref (bank_payment_batch_export_id, line_ref),
        UNIQUE KEY uq_bpbel_export_lineid (bank_payment_batch_export_id, payment_batch_line_id),
        KEY idx_bpbel_pbl (payment_batch_line_id),

        CONSTRAINT fk_bpbel_export
          FOREIGN KEY (bank_payment_batch_export_id) REFERENCES bank_payment_batch_exports(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Ack imports
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_payment_ack_imports (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        payment_batch_id BIGINT UNSIGNED NOT NULL,
        bank_payment_batch_export_id BIGINT UNSIGNED NULL,
        ack_request_id VARCHAR(190) NULL,
        file_format_code VARCHAR(50) NOT NULL,
        file_name VARCHAR(255) NULL,
        file_sha256 VARCHAR(64) NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'APPLIED', -- APPLIED, PARTIAL, FAILED
        total_rows INT NOT NULL DEFAULT 0,
        applied_rows INT NOT NULL DEFAULT 0,
        duplicate_rows INT NOT NULL DEFAULT 0,
        error_rows INT NOT NULL DEFAULT 0,
        payload_json JSON NULL,
        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bpai_request_id (ack_request_id),
        KEY idx_bpai_batch (payment_batch_id),

        CONSTRAINT fk_bpai_batch
          FOREIGN KEY (payment_batch_id) REFERENCES payment_batches(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_bpai_export
          FOREIGN KEY (bank_payment_batch_export_id) REFERENCES bank_payment_batch_exports(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Ack rows (traceability + idempotency)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_payment_ack_import_lines (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_payment_ack_import_id BIGINT UNSIGNED NOT NULL,
        payment_batch_line_id BIGINT UNSIGNED NULL,
        line_ref VARCHAR(190) NULL,
        bank_reference VARCHAR(190) NULL,
        ack_status VARCHAR(30) NOT NULL,               -- ACCEPTED, REJECTED, PARTIAL, PAID
        ack_code VARCHAR(50) NULL,
        ack_message VARCHAR(255) NULL,
        ack_amount DECIMAL(18,2) NULL,
        currency_code CHAR(3) NULL,
        executed_at DATETIME NULL,
        row_hash VARCHAR(64) NOT NULL,                 -- idempotency per ack row
        payload_json JSON NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bpail_row_hash (bank_payment_ack_import_id, row_hash),
        KEY idx_bpail_pbl (payment_batch_line_id),

        CONSTRAINT fk_bpail_ack_import
          FOREIGN KEY (bank_payment_ack_import_id) REFERENCES bank_payment_ack_imports(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS bank_payment_ack_import_lines;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_payment_ack_imports;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_payment_batch_export_lines;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_payment_batch_exports;`);
    // Optional strict down for ALTER columns omitted for dev simplicity
  },
};
```

---

## 2) Validators — `backend/src/routes/bank.paymentFiles.validators.js`

```js
// backend/src/routes/bank.paymentFiles.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function validateBatchIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateExportBatchBody(body = {}) {
  return {
    file_format_code:
      String(body.file_format_code || "")
        .trim()
        .toUpperCase() || "GENERIC_CSV_V1",
    export_request_id: normalizeString(body.export_request_id),
    mark_sent: String(body.mark_sent || "false").toLowerCase() === "true",
  };
}

function validateImportAckBody(body = {}) {
  return {
    file_format_code:
      String(body.file_format_code || "")
        .trim()
        .toUpperCase() || "GENERIC_CSV_V1",
    ack_request_id: normalizeString(body.ack_request_id),
    file_name: normalizeString(body.file_name) || "ack.csv",
    ack_text: String(body.ack_text || ""), // for API simplicity; later can be multipart upload
    export_id: body.export_id
      ? requirePositiveInt(body.export_id, "export_id")
      : null,
  };
}

export default {
  validateBatchIdParam,
  validateExportBatchBody,
  validateImportAckBody,
};
```

---

## 3) File format registry — `backend/src/services/bankPaymentFileFormats/index.js`

```js
// backend/src/services/bankPaymentFileFormats/index.js

import genericCsvV1 from "./genericCsvV1.format.js";
function getBankPaymentFileFormat(formatCode) {
  switch (String(formatCode || "").toUpperCase()) {
    case "GENERIC_CSV_V1":
      return genericCsvV1;
    default: {
      const err = new Error(
        `Unsupported bank payment file format: ${formatCode}`,
      );
      err.statusCode = 400;
      throw err;
    }
  }
}

export default {
  getBankPaymentFileFormat,
};
```

---

## 4) Generic CSV format adapter — `backend/src/services/bankPaymentFileFormats/genericCsvV1.format.js`

```js
// backend/src/services/bankPaymentFileFormats/genericCsvV1.format.js

function csvEscape(v) {
  const s = String(v ?? "");
  if (s.includes(",") || s.includes('"') || s.includes("\n")) {
    return `"${s.replace(/"/g, '""')}"`;
  }
  return s;
}

function toLineRef(batchId, lineId) {
  return `PB${batchId}-L${lineId}`;
}

function generatePaymentFile({ batch, lines }) {
  // lines should include beneficiary/payment fields from B04
  const headers = [
    "line_ref",
    "beneficiary_name",
    "beneficiary_account",
    "amount",
    "currency_code",
    "payment_reference",
  ];

  const rows = [headers.join(",")];
  const exportLines = [];

  for (const line of lines) {
    const lineRef = toLineRef(batch.id, line.id);
    const amount = Number(line.amount || 0).toFixed(2);

    rows.push(
      [
        csvEscape(lineRef),
        csvEscape(line.beneficiary_name || line.counterparty_name || ""),
        csvEscape(
          line.beneficiary_account || line.destination_account_no || "",
        ),
        csvEscape(amount),
        csvEscape(line.currency_code || batch.currency_code || ""),
        csvEscape(line.reference_text || line.reference || ""),
      ].join(","),
    );

    exportLines.push({
      payment_batch_line_id: line.id,
      line_ref: lineRef,
      beneficiary_name: line.beneficiary_name || line.counterparty_name || null,
      beneficiary_account:
        line.beneficiary_account || line.destination_account_no || null,
      amount: Number(line.amount || 0),
      currency_code: (
        line.currency_code ||
        batch.currency_code ||
        ""
      ).toUpperCase(),
      reference_text: line.reference_text || line.reference || null,
    });
  }

  return {
    file_name: `payment-batch-${batch.id}.csv`,
    mime_type: "text/csv",
    file_text: rows.join("\n"),
    export_lines: exportLines,
  };
}

/**
 * Ack CSV expected columns:
 * line_ref,ack_status,ack_amount,bank_reference,ack_code,ack_message,executed_at
 * ack_status values: ACCEPTED, REJECTED, PARTIAL, PAID
 */
function parseAcknowledgement({ ackText }) {
  const text = String(ackText || "").trim();
  if (!text) {
    const err = new Error("ack_text is required");
    err.statusCode = 400;
    throw err;
  }

  const lines = text.split(/\r?\n/).filter(Boolean);
  if (lines.length < 2) {
    const err = new Error("Ack file has no data rows");
    err.statusCode = 400;
    throw err;
  }

  const headers = lines[0].split(",").map((h) => h.trim());
  const idx = Object.fromEntries(headers.map((h, i) => [h, i]));

  const required = ["line_ref", "ack_status"];
  for (const r of required) {
    if (idx[r] === undefined) {
      const err = new Error(`Ack file missing column: ${r}`);
      err.statusCode = 400;
      throw err;
    }
  }

  const rows = [];
  for (let i = 1; i < lines.length; i++) {
    const cols = lines[i].split(","); // simple parser for skeleton
    rows.push({
      line_ref: (cols[idx.line_ref] || "").trim(),
      ack_status: (cols[idx.ack_status] || "").trim().toUpperCase(),
      ack_amount:
        idx.ack_amount !== undefined ? Number(cols[idx.ack_amount] || 0) : null,
      bank_reference:
        idx.bank_reference !== undefined
          ? (cols[idx.bank_reference] || "").trim()
          : null,
      ack_code:
        idx.ack_code !== undefined ? (cols[idx.ack_code] || "").trim() : null,
      ack_message:
        idx.ack_message !== undefined
          ? (cols[idx.ack_message] || "").trim()
          : null,
      executed_at:
        idx.executed_at !== undefined
          ? (cols[idx.executed_at] || "").trim()
          : null,
      raw_row: lines[i],
    });
  }

  return { rows };
}

export default {
  file_format_code: "GENERIC_CSV_V1",
  generatePaymentFile,
  parseAcknowledgement,
};
```

---

## 5) Service — `backend/src/services/bank.paymentFiles.service.js`

```js
// backend/src/services/bank.paymentFiles.service.js

import crypto from "crypto";
import fs from "fs";
import path from "path";
import { getBankPaymentFileFormat } from "./bankPaymentFileFormats.js";
function sha256(text) {
  return crypto
    .createHash("sha256")
    .update(String(text || ""))
    .digest("hex");
}

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

function nowSql() {
  return new Date().toISOString().slice(0, 19).replace("T", " ");
}

async function getPaymentBatchWithLines(db, batchId) {
  const [batches] = await db.query(
    `SELECT * FROM payment_batches WHERE id=? LIMIT 1`,
    [batchId],
  );
  if (!batches[0]) return null;

  const [lines] = await db.query(
    `SELECT * FROM payment_batch_lines WHERE payment_batch_id=? ORDER BY id ASC`,
    [batchId],
  );

  return { batch: batches[0], lines };
}

function ensureExportReady(batch, lines) {
  // Adapt to your B04 statuses. Safe default:
  const batchStatus = String(batch.status || "").toUpperCase();
  if (!["APPROVED", "READY", "PREPARED"].includes(batchStatus)) {
    const err = new Error(
      `Payment batch status ${batch.status} is not export-ready`,
    );
    err.statusCode = 400;
    throw err;
  }

  if (!lines.length) {
    const err = new Error("Payment batch has no lines");
    err.statusCode = 400;
    throw err;
  }

  for (const l of lines) {
    const s = String(l.status || "").toUpperCase();
    if (["CANCELLED", "PAID", "REJECTED"].includes(s)) {
      const err = new Error(
        `Payment batch line ${l.id} status ${l.status} cannot be exported`,
      );
      err.statusCode = 409;
      throw err;
    }
  }
}

async function listBatchExports(db, batchId) {
  const [rows] = await db.query(
    `SELECT * FROM bank_payment_batch_exports WHERE payment_batch_id=? ORDER BY id DESC`,
    [batchId],
  );
  return rows;
}

async function listBatchAckImports(db, batchId) {
  const [rows] = await db.query(
    `SELECT * FROM bank_payment_ack_imports WHERE payment_batch_id=? ORDER BY id DESC`,
    [batchId],
  );
  return rows;
}

async function exportPaymentBatchFile(db, batchId, body, userId = null) {
  if (body.export_request_id) {
    const [existing] = await db.query(
      `SELECT * FROM bank_payment_batch_exports WHERE export_request_id=? LIMIT 1`,
      [body.export_request_id],
    );
    if (existing[0]) return { export_run: existing[0], idempotent: true };
  }

  const format = getBankPaymentFileFormat(body.file_format_code);
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [batchRows] = await q.query(
      `SELECT * FROM payment_batches WHERE id=? LIMIT 1 FOR UPDATE`,
      [batchId],
    );
    const batch = batchRows[0];
    if (!batch) {
      const err = new Error("Payment batch not found");
      err.statusCode = 404;
      throw err;
    }

    const [lines] = await q.query(
      `SELECT * FROM payment_batch_lines WHERE payment_batch_id=? ORDER BY id ASC`,
      [batchId],
    );

    ensureExportReady(batch, lines);

    const generated = format.generatePaymentFile({ batch, lines });
    const fileText = generated.file_text;
    const fileHash = sha256(fileText);

    // Dev/local file storage (replace with object storage later)
    const dir = path.join(process.cwd(), "tmp", "bank-exports");
    fs.mkdirSync(dir, { recursive: true });
    const fileName = generated.file_name;
    const storagePath = path.join(dir, `${Date.now()}-${fileName}`);
    fs.writeFileSync(storagePath, fileText, "utf8");

    const totalAmount = amount2(
      lines.reduce((s, l) => s + Number(l.amount || 0), 0),
    );

    const [expIns] = await q.query(
      `
      INSERT INTO bank_payment_batch_exports
      (payment_batch_id, export_request_id, file_format_code, export_status, file_name, file_storage_path, file_mime_type, file_sha256,
       line_count, total_amount, currency_code, payload_json, created_by)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      `,
      [
        batchId,
        body.export_request_id || null,
        body.file_format_code,
        body.mark_sent ? "SENT" : "GENERATED",
        fileName,
        storagePath,
        generated.mime_type || "text/csv",
        fileHash,
        lines.length,
        totalAmount,
        batch.currency_code || null,
        JSON.stringify({ preview: `saved:${fileName}` }),
        userId,
      ],
    );

    const exportId = expIns.insertId;

    for (const x of generated.export_lines) {
      await q.query(
        `
        INSERT INTO bank_payment_batch_export_lines
        (bank_payment_batch_export_id, payment_batch_line_id, line_ref, beneficiary_name, beneficiary_account, amount, currency_code, reference_text)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        `,
        [
          exportId,
          x.payment_batch_line_id,
          x.line_ref,
          x.beneficiary_name,
          x.beneficiary_account,
          amount2(x.amount),
          x.currency_code,
          x.reference_text,
        ],
      );
    }

    // Mark batch + lines exported (without claiming paid/executed yet)
    await q.query(
      `
      UPDATE payment_batches
      SET bank_file_format_code=?, bank_export_status='EXPORTED', last_exported_at=NOW()
      WHERE id=?
      `,
      [body.file_format_code, batchId],
    );

    await q.query(
      `
      UPDATE payment_batch_lines
      SET exported_amount = amount,
          exported_at = NOW(),
          status = CASE
            WHEN status IN ('PREPARED','APPROVED','READY') THEN 'EXPORTED'
            ELSE status
          END
      WHERE payment_batch_id = ?
      `,
      [batchId],
    );

    // Optional: write B04 batch audit if table exists
    await q
      .query(
        `INSERT INTO payment_batch_audit (payment_batch_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
        [
          batchId,
          "BANK_FILE_EXPORTED",
          JSON.stringify({
            export_id: exportId,
            file_format_code: body.file_format_code,
          }),
          userId,
        ],
      )
      .catch(() => {});

    if (conn) await conn.commit();

    const [rows] = await db.query(
      `SELECT * FROM bank_payment_batch_exports WHERE id=? LIMIT 1`,
      [exportId],
    );
    return { export_run: rows[0], idempotent: false };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

function mapAckToLineStatus(ackStatus, executedAmount, lineAmount) {
  const s = String(ackStatus || "").toUpperCase();
  if (s === "REJECTED") return "REJECTED";
  if (s === "ACCEPTED") return "EXECUTED"; // accepted by bank, not yet paid
  if (s === "PAID")
    return amount2(executedAmount) >= amount2(lineAmount)
      ? "PAID"
      : "PARTIALLY_PAID";
  if (s === "PARTIAL") return "PARTIALLY_PAID";
  return "EXPORTED";
}

async function importPaymentBatchAck(db, batchId, body, userId = null) {
  if (body.ack_request_id) {
    const [existing] = await db.query(
      `SELECT * FROM bank_payment_ack_imports WHERE ack_request_id=? LIMIT 1`,
      [body.ack_request_id],
    );
    if (existing[0]) return { ack_import: existing[0], idempotent: true };
  }

  const format = getBankPaymentFileFormat(body.file_format_code);
  const parsed = format.parseAcknowledgement({ ackText: body.ack_text });
  const fileHash = sha256(body.ack_text || "");

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [batchRows] = await q.query(
      `SELECT * FROM payment_batches WHERE id=? LIMIT 1 FOR UPDATE`,
      [batchId],
    );
    const batch = batchRows[0];
    if (!batch) {
      const err = new Error("Payment batch not found");
      err.statusCode = 404;
      throw err;
    }

    let exportId = body.export_id || null;
    if (!exportId) {
      const [latest] = await q.query(
        `SELECT id FROM bank_payment_batch_exports WHERE payment_batch_id=? ORDER BY id DESC LIMIT 1`,
        [batchId],
      );
      exportId = latest[0]?.id || null;
    }

    const [ackIns] = await q.query(
      `
      INSERT INTO bank_payment_ack_imports
      (payment_batch_id, bank_payment_batch_export_id, ack_request_id, file_format_code, file_name, file_sha256, status, created_by)
      VALUES (?, ?, ?, ?, ?, ?, 'APPLIED', ?)
      `,
      [
        batchId,
        exportId,
        body.ack_request_id || null,
        body.file_format_code,
        body.file_name,
        fileHash,
        userId,
      ],
    );
    const ackImportId = ackIns.insertId;

    const [exportLines] = exportId
      ? await q.query(
          `SELECT * FROM bank_payment_batch_export_lines WHERE bank_payment_batch_export_id=?`,
          [exportId],
        )
      : [[]];

    const exportLineByRef = new Map(
      exportLines.map((r) => [String(r.line_ref), r]),
    );

    let totalRows = 0;
    let appliedRows = 0;
    let duplicateRows = 0;
    let errorRows = 0;

    for (const row of parsed.rows) {
      totalRows += 1;
      const rowHash = sha256(JSON.stringify(row));

      // Ack-row idempotency within same import
      const [dupCheck] = await q.query(
        `SELECT id FROM bank_payment_ack_import_lines WHERE bank_payment_ack_import_id=? AND row_hash=? LIMIT 1`,
        [ackImportId, rowHash],
      );
      if (dupCheck[0]) {
        duplicateRows += 1;
        continue;
      }

      let paymentBatchLineId = null;
      let lineAmount = null;

      if (row.line_ref && exportLineByRef.has(row.line_ref)) {
        const ex = exportLineByRef.get(row.line_ref);
        paymentBatchLineId = ex.payment_batch_line_id;
        lineAmount = amount2(ex.amount);
      }

      let rowApplied = false;
      let rowError = null;

      try {
        if (!paymentBatchLineId)
          throw new Error(`Unknown line_ref ${row.line_ref || "(blank)"}`);

        const [lineRows] = await q.query(
          `SELECT * FROM payment_batch_lines WHERE id=? AND payment_batch_id=? LIMIT 1`,
          [paymentBatchLineId, batchId],
        );
        const line = lineRows[0];
        if (!line)
          throw new Error(
            `Payment batch line not found for line_ref ${row.line_ref}`,
          );

        const currentExecuted = amount2(line.executed_amount || 0);
        let deltaExec = 0;

        // For PAID/PARTIAL, ack_amount is cumulative if provided; fallback full line on PAID
        const ackStatus = String(row.ack_status || "").toUpperCase();
        let targetExecuted = currentExecuted;

        if (["PAID", "PARTIAL"].includes(ackStatus)) {
          const implied =
            row.ack_amount == null || Number.isNaN(Number(row.ack_amount))
              ? ackStatus === "PAID"
                ? amount2(line.amount)
                : currentExecuted
              : amount2(row.ack_amount);

          if (implied < currentExecuted) {
            throw new Error(
              `Ack amount ${implied} less than current executed ${currentExecuted}`,
            );
          }
          if (implied > amount2(line.amount)) {
            throw new Error(
              `Ack amount ${implied} exceeds line amount ${line.amount}`,
            );
          }
          targetExecuted = implied;
          deltaExec = amount2(targetExecuted - currentExecuted);
        }

        const newStatus = mapAckToLineStatus(
          ackStatus,
          targetExecuted,
          line.amount,
        );

        await q.query(
          `
          UPDATE payment_batch_lines
          SET
            executed_amount = ?,
            bank_reference = COALESCE(?, bank_reference),
            ack_status = ?,
            ack_code = ?,
            ack_message = ?,
            acknowledged_at = NOW(),
            executed_at = CASE WHEN ? IN ('PAID','PARTIAL','ACCEPTED') THEN COALESCE(?, executed_at, NOW()) ELSE executed_at END,
            status = CASE
              WHEN ?='REJECTED' THEN 'REJECTED'
              WHEN ?='PARTIALLY_PAID' THEN 'PARTIALLY_PAID'
              WHEN ?='PAID' THEN 'PAID'
              WHEN ?='EXECUTED' THEN CASE WHEN status IN ('EXPORTED','APPROVED','READY','PREPARED') THEN 'EXECUTED' ELSE status END
              ELSE status
            END
          WHERE id = ?
          `,
          [
            targetExecuted,
            row.bank_reference || null,
            ackStatus,
            row.ack_code || null,
            row.ack_message || null,
            ackStatus,
            row.executed_at || nowSql(),
            newStatus,
            newStatus,
            newStatus,
            newStatus,
            line.id,
          ],
        );

        // Optional line audit
        await q
          .query(
            `INSERT INTO payment_batch_line_audit (payment_batch_line_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
            [
              line.id,
              "BANK_ACK_APPLIED",
              JSON.stringify({
                ack_status: ackStatus,
                ack_amount: row.ack_amount,
                delta_executed_amount: deltaExec,
                bank_reference: row.bank_reference || null,
                ack_code: row.ack_code || null,
              }),
              userId,
            ],
          )
          .catch(() => {});

        rowApplied = true;
      } catch (e) {
        rowError = e.message || "ack row apply failed";
        errorRows += 1;
      }

      await q.query(
        `
        INSERT INTO bank_payment_ack_import_lines
        (bank_payment_ack_import_id, payment_batch_line_id, line_ref, bank_reference, ack_status, ack_code, ack_message, ack_amount, currency_code, executed_at, row_hash, payload_json)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `,
        [
          ackImportId,
          paymentBatchLineId,
          row.line_ref || null,
          row.bank_reference || null,
          String(row.ack_status || "").toUpperCase(),
          row.ack_code || null,
          rowError || row.ack_message || null,
          row.ack_amount == null || Number.isNaN(Number(row.ack_amount))
            ? null
            : amount2(row.ack_amount),
          batch.currency_code || null,
          row.executed_at || null,
          rowHash,
          JSON.stringify({ raw_row: row.raw_row }),
        ],
      );

      if (rowApplied) appliedRows += 1;
    }

    const [lineAgg] = await q.query(
      `
      SELECT
        SUM(CASE WHEN status='PAID' THEN 1 ELSE 0 END) AS paid_count,
        SUM(CASE WHEN status='PARTIALLY_PAID' THEN 1 ELSE 0 END) AS partial_count,
        SUM(CASE WHEN status='REJECTED' THEN 1 ELSE 0 END) AS rejected_count,
        SUM(CASE WHEN status='EXECUTED' THEN 1 ELSE 0 END) AS executed_count,
        COUNT(*) AS total_count
      FROM payment_batch_lines
      WHERE payment_batch_id = ?
      `,
      [batchId],
    );

    const agg = lineAgg[0] || {};
    let batchExportStatus = "ACK_IMPORTED";
    if (
      Number(agg.rejected_count || 0) > 0 &&
      Number(agg.paid_count || 0) === 0 &&
      Number(agg.partial_count || 0) === 0
    ) {
      batchExportStatus = "ACK_REJECTED";
    } else if (Number(agg.partial_count || 0) > 0) {
      batchExportStatus = "ACK_PARTIAL";
    } else if (
      Number(agg.paid_count || 0) === Number(agg.total_count || 0) &&
      Number(agg.total_count || 0) > 0
    ) {
      batchExportStatus = "ACK_FULLY_PAID";
    }

    const ackImportStatus =
      errorRows > 0 ? (appliedRows > 0 ? "PARTIAL" : "FAILED") : "APPLIED";

    await q.query(
      `
      UPDATE bank_payment_ack_imports
      SET status=?, total_rows=?, applied_rows=?, duplicate_rows=?, error_rows=?, payload_json=?
      WHERE id=?
      `,
      [
        ackImportStatus,
        totalRows,
        appliedRows,
        duplicateRows,
        errorRows,
        JSON.stringify({ batch_export_status_after: batchExportStatus }),
        ackImportId,
      ],
    );

    await q.query(
      `
      UPDATE payment_batches
      SET bank_export_status = ?,
          last_ack_imported_at = NOW()
      WHERE id = ?
      `,
      [batchExportStatus, batchId],
    );

    await q
      .query(
        `INSERT INTO payment_batch_audit (payment_batch_id, action, payload_json, acted_by) VALUES (?, ?, ?, ?)`,
        [
          batchId,
          "BANK_ACK_IMPORTED",
          JSON.stringify({
            ack_import_id: ackImportId,
            applied_rows: appliedRows,
            error_rows: errorRows,
          }),
          userId,
        ],
      )
      .catch(() => {});

    if (conn) await conn.commit();

    const [rows] = await db.query(
      `SELECT * FROM bank_payment_ack_imports WHERE id=? LIMIT 1`,
      [ackImportId],
    );
    return { ack_import: rows[0], idempotent: false };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

export default {
  listBatchExports,
  listBatchAckImports,
  exportPaymentBatchFile,
  importPaymentBatchAck,
};
```

---

## 6) Routes — `backend/src/routes/bank.paymentFiles.js`

```js
// backend/src/routes/bank.paymentFiles.js

import express from "express";
import { validateBatchIdParam,
  validateExportBatchBody,
  validateImportAckBody, } from "./bank.paymentFiles.validators.js";
import service from "../services/bank.paymentFiles.service.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/bank/payment-batches/:id/exports
router.get(
  "/payment-batches/:id/exports",
  requireAuth,
  requirePermission("bank.payments.export.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateBatchIdParam(req.params);
      const items = await service.listBatchExports(db, id);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/payment-batches/:id/export-file
router.post(
  "/payment-batches/:id/export-file",
  requireAuth,
  requirePermission("bank.payments.export.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateBatchIdParam(req.params);
      const body = validateExportBatchBody(req.body);
      const result = await service.exportPaymentBatchFile(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/bank/payment-batches/:id/ack-imports
router.get(
  "/payment-batches/:id/ack-imports",
  requireAuth,
  requirePermission("bank.payments.ack.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateBatchIdParam(req.params);
      const items = await service.listBatchAckImports(db, id);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/payment-batches/:id/import-ack
router.post(
  "/payment-batches/:id/import-ack",
  requireAuth,
  requirePermission("bank.payments.ack.import"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateBatchIdParam(req.params);
      const body = validateImportAckBody(req.body);
      const result = await service.importPaymentBatchAck(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 7) Patch B04 batch service — `backend/src/services/bank.paymentBatches.service.js` (important)

> Keep your B04 service; apply these compatibility updates.

### A) Make line statuses export-compatible

Allow these statuses in your B04 state transitions and listings:

- `EXPORTED`
- `EXECUTED`
- `PARTIALLY_PAID`
- `PAID`
- `REJECTED`

### B) Export readiness helper (reuse in B06 if you prefer)

```js
// patch snippet inside B04 service (optional shared helper)
function isPaymentBatchExportReady(batch) {
  return ["APPROVED", "READY", "PREPARED"].includes(
    String(batch.status || "").toUpperCase(),
  );
}
```

### C) Batch summaries should include executed/partial/rejected counts

Add to B04 batch detail/list summary:

- `paid_line_count`
- `partial_paid_line_count`
- `executed_line_count`
- `rejected_line_count`
- `total_executed_amount`

This helps P04 and ops users see progress before B03 reconciliation.

---

## 8) Mount route — `backend/src/index.js`

```js
// backend/src/index.js
import bankPaymentFilesRoutes from "./routes/bank.paymentFiles.js";
// ...
app.use("/api/v1/bank", bankPaymentFilesRoutes);
```

---

## 9) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m046_bank_payment_exports_and_acks from "./m046_bank_payment_exports_and_acks.js";
export default [
  // ...
  m046_bank_payment_exports_and_acks,
];
```

---

## 10) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const BANK_B06_PERMISSIONS = [
  "bank.payments.export.read",
  "bank.payments.export.create",
  "bank.payments.ack.read",
  "bank.payments.ack.import",
];

// merge into permission seed list
```

---

## 11) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/bank/payment-batches/{id}/exports`
- `POST /api/v1/bank/payment-batches/{id}/export-file`
- `GET /api/v1/bank/payment-batches/{id}/ack-imports`
- `POST /api/v1/bank/payment-batches/{id}/import-ack`

Also document B06 line status effects:

- `EXPORTED`
- `EXECUTED`
- `PARTIALLY_PAID`
- `PAID`
- `REJECTED`

---

## 12) Backend smoke test — `backend/scripts/test-bank-prb06-payment-file-and-ack.js`

```js
// backend/scripts/test-bank-prb06-payment-file-and-ack.js

async function main() {
  // Preconditions:
  // - B04 payment batches implemented
  // - At least one export-ready payment batch exists (APPROVED/READY/PREPARED)
  //
  // Flow A: Export
  // 1) POST /api/v1/bank/payment-batches/:id/export-file (GENERIC_CSV_V1)
  //    -> creates bank_payment_batch_exports row
  //    -> creates export line snapshots with line_ref
  //    -> marks batch bank_export_status=EXPORTED
  //    -> marks lines status EXPORTED (if export-ready)
  // 2) Re-call with same export_request_id
  //    -> idempotent export run returned
  //
  // Flow B: Ack import (accepted/partial/paid/rejected)
  // 3) Build ack CSV text using exported line_ref values:
  //    line_ref,ack_status,ack_amount,bank_reference,ack_code,ack_message,executed_at
  // 4) POST /api/v1/bank/payment-batches/:id/import-ack
  //    -> creates ack import rows
  //    -> updates line statuses:
  //       ACCEPTED -> EXECUTED
  //       PARTIAL  -> PARTIALLY_PAID
  //       PAID     -> PAID or PARTIALLY_PAID depending ack_amount
  //       REJECTED -> REJECTED
  //    -> updates executed_amount / ack fields
  //
  // Flow C: Idempotent ack import
  // 5) Re-call with same ack_request_id
  //    -> idempotent ack import returned
  //
  // Flow D: Over-ack protection
  // 6) Ack row with ack_amount > line amount
  //    -> import records row error, line not over-updated
  //
  // Flow E: Integration handoff
  // 7) B03 reconciliation can still reconcile actual statement lines later
  // 8) P04 (if enabled for B04-only evidence) can read executed/paid statuses safely
  //
  // Permissions:
  // - bank.payments.export.* and bank.payments.ack.* enforced (403)
  console.log("PR-B06 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 13) `backend/package.json` updates

```json
{
  "scripts": {
    "test:bank:prb06": "node backend/scripts/test-bank-prb06-payment-file-and-ack.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 14) API client — `frontend/src/api/bankPaymentFiles.js`

```js
// frontend/src/api/bankPaymentFiles.js

import { apiFetch } from "./client.js"; // adapt

export function listPaymentBatchExports(batchId) {
  return apiFetch(`/api/v1/bank/payment-batches/${batchId}/exports`);
}

export function exportPaymentBatchFile(batchId, payload) {
  return apiFetch(`/api/v1/bank/payment-batches/${batchId}/export-file`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function listPaymentBatchAckImports(batchId) {
  return apiFetch(`/api/v1/bank/payment-batches/${batchId}/ack-imports`);
}

export function importPaymentBatchAck(batchId, payload) {
  return apiFetch(`/api/v1/bank/payment-batches/${batchId}/import-ack`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}
```

---

## 15) `PaymentBatchDetailPage.jsx` (or your B04 batch page) — key snippets only

### Add imports

```jsx
import {
  listPaymentBatchExports,
  exportPaymentBatchFile,
  listPaymentBatchAckImports,
  importPaymentBatchAck,
} from "../../api/bankPaymentFiles.js";
```

### Add state

```jsx
const [exportsList, setExportsList] = useState([]);
const [ackImports, setAckImports] = useState([]);
const [ackText, setAckText] = useState("");
const [bankFileErr, setBankFileErr] = useState("");
```

### Load export/ack history

```jsx
async function loadBankFileHistory(batchId) {
  const [expRes, ackRes] = await Promise.all([
    listPaymentBatchExports(batchId),
    listPaymentBatchAckImports(batchId),
  ]);
  setExportsList(expRes.items || []);
  setAckImports(ackRes.items || []);
}
```

### Export button

```jsx
async function onExportBankFile(batchId) {
  try {
    setBankFileErr("");
    await exportPaymentBatchFile(batchId, {
      file_format_code: "GENERIC_CSV_V1",
      export_request_id: `exp-${batchId}-${Date.now()}`,
    });
    await load(); // existing batch detail reload
    await loadBankFileHistory(batchId);
  } catch (e) {
    setBankFileErr(e.message || "Bank file export failed");
  }
}
```

### Ack import button

```jsx
async function onImportAck(batchId) {
  try {
    setBankFileErr("");
    await importPaymentBatchAck(batchId, {
      file_format_code: "GENERIC_CSV_V1",
      ack_request_id: `ack-${batchId}-${Date.now()}`,
      file_name: "ack.csv",
      ack_text: ackText, // textarea content
    });
    await load();
    await loadBankFileHistory(batchId);
  } catch (e) {
    setBankFileErr(e.message || "Ack import failed");
  }
}
```

### Compact UI block (no full tables)

```jsx
{
  /* Bank File Export / Ack Panel */
}
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Bank Execution</h2>

  {/* Buttons:
      - Export Bank File
      - Import Ack
  */}

  {/* Ack textarea input (temporary dev UX) */}
  {/* <textarea value={ackText} onChange={...} /> */}

  {bankFileErr ? (
    <div className="text-sm text-red-600">{bankFileErr}</div>
  ) : null}

  <div className="text-sm mt-2 space-y-1">
    {/* Show latest export summary:
        file_format_code, export_status, line_count, total_amount, created_at
    */}
  </div>

  <div className="text-sm mt-3 space-y-1">
    {/* Show latest ack import summary:
        status, total_rows, applied_rows, error_rows, created_at
    */}
  </div>
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Can export a B04 payment batch into a bank file (`bank_payment_batch_exports`)
- ✅ Export creates line snapshots with stable `line_ref` values for ack matching
- ✅ Export is idempotent (`export_request_id`)
- ✅ Export updates batch/line export status fields (without marking paid)
- ✅ Can import bank ack file and map rows back to payment batch lines by `line_ref`
- ✅ Ack import updates line status and `executed_amount` safely:

  - `ACCEPTED -> EXECUTED`
  - `PARTIAL -> PARTIALLY_PAID`
  - `PAID -> PAID/PARTIALLY_PAID`
  - `REJECTED -> REJECTED`

- ✅ Over-ack / invalid ack rows are blocked or recorded as row errors (no bad line updates)
- ✅ Ack import is idempotent (`ack_request_id`)
- ✅ B03 reconciliation remains unchanged and can reconcile actual statement later
- ✅ Permissions enforced (`bank.payments.export.*`, `bank.payments.ack.*`)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:bank:prb06`

Should verify at least:

1. **Export**

   - Export-ready batch can be exported
   - Export row + export line snapshots created
   - Batch/line export statuses updated

2. **Export idempotency**

   - Same `export_request_id` returns same export run

3. **Ack import**

   - `ACCEPTED` row -> line `EXECUTED`
   - `PARTIAL` row -> line `PARTIALLY_PAID`, executed amount updated
   - `PAID` row -> line `PAID` (or partial if ack_amount < full)
   - `REJECTED` row -> line `REJECTED`

4. **Ack import idempotency**

   - Same `ack_request_id` returns same ack import

5. **Over-ack protection**

   - `ack_amount > line amount` produces row error and no invalid update

6. **Permissions**

   - `bank.payments.export.read`
   - `bank.payments.export.create`
   - `bank.payments.ack.read`
   - `bank.payments.ack.import`
     all enforced (`403`)

---

## Tiny implementation notes (important)

- **B06 is generic**: works for payroll, AP, refunds, etc. because it only depends on B04 payment batches.
- The `GENERIC_CSV_V1` format is your starter. Add real bank formats later as new adapters:

  - local bank CSV
  - ISO 20022 pain.001 (export)
  - camt.054 / bank-specific ack formats (import)

- For production, replace local file path storage with object storage and signed download endpoints.

---

Perfect — here’s **PR-B07** in the same format.

# PR-B07: Reconciliation Rules Engine + Exception Queue (B03 Scalable Automation)

## Goal

Make **B03 reconciliation** scalable by adding:

- ✅ Deterministic rules engine (priority-based)
- ✅ Auto-reconciliation preview + apply
- ✅ Exception queue for unmatched / ambiguous / policy-blocked items
- ✅ Rule hit audit (which rule matched, confidence, method)
- ✅ Re-try flow after fixing data/rules
- ✅ Reuse B03 reconciliation core (manual and auto use same contract)

---

## Key design rule (important)

**B07 does not replace B03.**
It adds an automation layer **on top of** B03:

- **B02/B05** import statement lines
- **B06** updates payment execution/ack status
- **B07** tries auto-match using rules
- **B03** remains the source of truth for reconciliation records and final status

So manual reconciliation still works unchanged.

---

## Important behavior rules

### 1) Rule evaluation is deterministic

Rules are evaluated in this order:

1. `priority` ASC (lower number = higher priority)
2. `id` ASC (tie-breaker)

### 2) Preview is read-only

Auto preview never writes:

- no reconciliation
- no exceptions
- no status updates

### 3) Apply is safe

Auto apply will **only** auto-reconcile when exactly one valid target is found.

If:

- no target found
- more than one target found (ambiguous)
- policy blocks action

➡️ create/update exception queue item instead.

### 4) Manual and auto use the same B03 reconcile helper

This avoids split logic and keeps audit/reversal consistent.

### 5) Exception queue is lifecycle-managed

Exception statuses:

- `OPEN`
- `ASSIGNED`
- `RESOLVED`
- `IGNORED`

If a statement line is reconciled later, linked OPEN/ASSIGNED exception is auto-closed as `RESOLVED`.

---

## Files to create

### Backend

- `backend/src/migrations/m047_bank_reconciliation_rules_and_exceptions.js`
- `backend/src/routes/bank.reconciliationRules.js`
- `backend/src/routes/bank.reconciliationRules.validators.js`
- `backend/src/routes/bank.reconciliationExceptions.js`
- `backend/src/routes/bank.reconciliationExceptions.validators.js`
- `backend/src/services/bank.reconciliationRules.service.js`
- `backend/src/services/bank.reconciliationExceptions.service.js`
- `backend/src/services/bank.reconciliationEngine.service.js`
- `backend/scripts/test-bank-prb07-reconciliation-rules-and-exceptions.js`

### Frontend (short snippets only)

- `frontend/src/api/bankReconciliationAutomation.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (important patch)

- `backend/src/services/bank.reconciliation.service.js` _(your B03 core service file; adapt name)_

  - export reusable reconcile helper
  - support reconciliation metadata (`method`, `rule_id`, `confidence`)
  - auto-close exception if present

### Frontend (short integration only)

- `frontend/src/pages/bank/BankReconciliationPage.jsx`
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m047_bank_reconciliation_rules_and_exceptions.js`

```js id="j4c9pw"
// backend/src/migrations/m047_bank_reconciliation_rules_and_exceptions.js

export default {
  key: "m047_bank_reconciliation_rules_and_exceptions",
  description: "m047_bank_reconciliation_rules_and_exceptions",
  async up(connection) {
    // Add reconciliation metadata to statement lines (adapt table name if different in B02/B03)
    await db
      .query(
        `
      ALTER TABLE bank_statement_lines
        ADD COLUMN reconciliation_method VARCHAR(20) NULL AFTER reconciliation_status,
        ADD COLUMN reconciliation_rule_id BIGINT UNSIGNED NULL AFTER reconciliation_method,
        ADD COLUMN reconciliation_confidence DECIMAL(5,2) NULL AFTER reconciliation_rule_id
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE bank_statement_lines
        ADD KEY idx_bsl_recon_rule (reconciliation_rule_id)
    `,
      )
      .catch(() => {});

    // Reconciliation rules master
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_reconciliation_rules (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        rule_code VARCHAR(50) NOT NULL,
        rule_name VARCHAR(190) NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE', -- ACTIVE, PAUSED, DISABLED
        priority INT NOT NULL DEFAULT 100,

        scope_type VARCHAR(20) NOT NULL DEFAULT 'GLOBAL', -- GLOBAL, BANK_ACCOUNT
        bank_account_id BIGINT UNSIGNED NULL,

        match_type VARCHAR(30) NOT NULL, -- PAYMENT_BY_BANK_REFERENCE, PAYMENT_BY_TEXT_AND_AMOUNT, TEXT_PATTERN_ONLY
        conditions_json JSON NOT NULL,   -- text includes/regex, debit_credit, amount tolerance, date lag, etc.
        action_type VARCHAR(30) NOT NULL, -- AUTO_MATCH_PAYMENT_LINE, QUEUE_EXCEPTION, SUGGEST_ONLY
        action_payload_json JSON NULL,

        stop_on_match TINYINT(1) NOT NULL DEFAULT 1,
        effective_from DATE NULL,
        effective_to DATE NULL,

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_brr_rule_code (rule_code),
        KEY idx_brr_status_priority (status, priority),
        KEY idx_brr_scope (scope_type, bank_account_id),
        KEY idx_brr_effective (effective_from, effective_to)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Auto-run logs (preview/apply)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_reconciliation_auto_runs (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        run_request_id VARCHAR(190) NULL,
        run_mode VARCHAR(20) NOT NULL, -- PREVIEW, APPLY
        status VARCHAR(20) NOT NULL DEFAULT 'SUCCESS', -- SUCCESS, PARTIAL, FAILED
        bank_account_id BIGINT UNSIGNED NULL,
        date_from DATE NULL,
        date_to DATE NULL,

        scanned_count INT NOT NULL DEFAULT 0,
        matched_count INT NOT NULL DEFAULT 0,
        reconciled_count INT NOT NULL DEFAULT 0,
        exception_count INT NOT NULL DEFAULT 0,
        skipped_count INT NOT NULL DEFAULT 0,
        error_count INT NOT NULL DEFAULT 0,

        payload_json JSON NULL,
        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_brar_request_id (run_request_id),
        KEY idx_brar_mode (run_mode),
        KEY idx_brar_created (created_at)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Exception queue
    await db
      .query(
        `
      CREATE TABLE IF NOT EXISTS bank_reconciliation_exceptions (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_statement_line_id BIGINT UNSIGNED NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'OPEN', -- OPEN, ASSIGNED, RESOLVED, IGNORED
        severity VARCHAR(20) NOT NULL DEFAULT 'MEDIUM', -- LOW, MEDIUM, HIGH

        reason_code VARCHAR(50) NOT NULL, -- NO_RULE_MATCH, AMBIGUOUS_TARGET, POLICY_BLOCKED, APPLY_ERROR
        reason_message VARCHAR(255) NULL,

        matched_rule_id BIGINT UNSIGNED NULL,
        suggested_action_type VARCHAR(30) NULL,
        suggested_payload_json JSON NULL,

        assigned_to BIGINT UNSIGNED NULL,
        assigned_at DATETIME NULL,
        resolved_by BIGINT UNSIGNED NULL,
        resolved_at DATETIME NULL,
        resolution_code VARCHAR(50) NULL,
        resolution_note VARCHAR(500) NULL,

        first_seen_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        last_seen_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        occurrence_count INT NOT NULL DEFAULT 1,

        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bre_line_open (
          bank_statement_line_id, status
        ),
        KEY idx_bre_status (status),
        KEY idx_bre_reason (reason_code),
        KEY idx_bre_rule (matched_rule_id),

        CONSTRAINT fk_bre_statement_line
          FOREIGN KEY (bank_statement_line_id) REFERENCES bank_statement_lines(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `,
      )
      .catch(async () => {
        // Some MySQL versions dislike the unique design with status for reopened rows.
        // If needed, fall back to no unique and enforce in service.
      });

    // Exception event audit
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_reconciliation_exception_events (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_reconciliation_exception_id BIGINT UNSIGNED NOT NULL,
        event_type VARCHAR(30) NOT NULL, -- CREATED, UPDATED, ASSIGNED, RESOLVED, IGNORED, RETRIED
        payload_json JSON NULL,
        acted_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_bree_exception (bank_reconciliation_exception_id),

        CONSTRAINT fk_bree_exception
          FOREIGN KEY (bank_reconciliation_exception_id) REFERENCES bank_reconciliation_exceptions(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(
      `DROP TABLE IF EXISTS bank_reconciliation_exception_events;`,
    );
    await connection.execute(`DROP TABLE IF EXISTS bank_reconciliation_exceptions;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_reconciliation_auto_runs;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_reconciliation_rules;`);
    // Optional strict down for ALTER columns omitted for dev simplicity
  },
};
```

---

## 2) Validators — `backend/src/routes/bank.reconciliationRules.validators.js`

```js id="hxq6w2"
// backend/src/routes/bank.reconciliationRules.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function validateRuleIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreateRuleBody(body = {}) {
  return {
    rule_code:
      normalizeString(body.rule_code) ||
      (() => {
        throw new Error("rule_code is required");
      })(),
    rule_name:
      normalizeString(body.rule_name) ||
      (() => {
        throw new Error("rule_name is required");
      })(),
    priority: body.priority !== undefined ? Number(body.priority) : 100,
    scope_type: String(body.scope_type || "GLOBAL")
      .trim()
      .toUpperCase(),
    bank_account_id: body.bank_account_id
      ? requirePositiveInt(body.bank_account_id, "bank_account_id")
      : null,
    match_type:
      String(body.match_type || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("match_type is required");
      })(),
    conditions: body.conditions || {},
    action_type:
      String(body.action_type || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("action_type is required");
      })(),
    action_payload: body.action_payload || {},
    stop_on_match:
      body.stop_on_match === undefined ? true : !!body.stop_on_match,
    effective_from: normalizeString(body.effective_from),
    effective_to: normalizeString(body.effective_to),
    status: String(body.status || "ACTIVE")
      .trim()
      .toUpperCase(),
  };
}

function validateUpdateRuleBody(body = {}) {
  return {
    rule_name: normalizeString(body.rule_name),
    priority: body.priority !== undefined ? Number(body.priority) : undefined,
    status: body.status ? String(body.status).trim().toUpperCase() : null,
    conditions: body.conditions,
    action_type: body.action_type
      ? String(body.action_type).trim().toUpperCase()
      : null,
    action_payload: body.action_payload,
    stop_on_match:
      body.stop_on_match === undefined ? undefined : !!body.stop_on_match,
    effective_from:
      body.effective_from !== undefined
        ? normalizeString(body.effective_from)
        : undefined,
    effective_to:
      body.effective_to !== undefined
        ? normalizeString(body.effective_to)
        : undefined,
  };
}

function validateAutoPreviewBody(body = {}) {
  return {
    bank_account_id: body.bank_account_id
      ? requirePositiveInt(body.bank_account_id, "bank_account_id")
      : null,
    date_from: normalizeString(body.date_from),
    date_to: normalizeString(body.date_to),
    limit: body.limit ? Math.min(500, Math.max(1, Number(body.limit))) : 100,
  };
}

function validateAutoApplyBody(body = {}) {
  return {
    ...validateAutoPreviewBody(body),
    run_request_id: normalizeString(body.run_request_id),
  };
}

export default {
  validateRuleIdParam,
  validateCreateRuleBody,
  validateUpdateRuleBody,
  validateAutoPreviewBody,
  validateAutoApplyBody,
};
```

---

## 3) Validators — `backend/src/routes/bank.reconciliationExceptions.validators.js`

```js id="3ntv5r"
// backend/src/routes/bank.reconciliationExceptions.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}
function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function validateExceptionIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateListExceptionsQuery(query = {}) {
  return {
    status: normalizeString(query.status)?.toUpperCase() || null,
    bank_account_id: query.bank_account_id
      ? requirePositiveInt(query.bank_account_id, "bank_account_id")
      : null,
    reason_code: normalizeString(query.reason_code)?.toUpperCase() || null,
    limit: query.limit ? Math.min(500, Math.max(1, Number(query.limit))) : 100,
  };
}

function validateAssignBody(body = {}) {
  return {
    assigned_to: body.assigned_to
      ? requirePositiveInt(body.assigned_to, "assigned_to")
      : null,
  };
}

function validateResolveBody(body = {}) {
  return {
    resolution_code:
      normalizeString(body.resolution_code)?.toUpperCase() ||
      "RESOLVED_MANUALLY",
    resolution_note: normalizeString(body.resolution_note),
  };
}

function validateIgnoreBody(body = {}) {
  return {
    resolution_note: normalizeString(body.resolution_note) || "Ignored",
  };
}

export default {
  validateExceptionIdParam,
  validateListExceptionsQuery,
  validateAssignBody,
  validateResolveBody,
  validateIgnoreBody,
};
```

---

## 4) Rules service — `backend/src/services/bank.reconciliationRules.service.js`

```js id="pf76qn"
// backend/src/services/bank.reconciliationRules.service.js

async function listReconciliationRules(db) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_rules ORDER BY priority ASC, id ASC`,
  );
  return rows;
}

async function createReconciliationRule(db, body, userId = null) {
  const [ins] = await db.query(
    `
    INSERT INTO bank_reconciliation_rules
    (rule_code, rule_name, status, priority, scope_type, bank_account_id, match_type, conditions_json,
     action_type, action_payload_json, stop_on_match, effective_from, effective_to, created_by, updated_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      body.rule_code,
      body.rule_name,
      body.status || "ACTIVE",
      body.priority ?? 100,
      body.scope_type || "GLOBAL",
      body.bank_account_id || null,
      body.match_type,
      JSON.stringify(body.conditions || {}),
      body.action_type,
      JSON.stringify(body.action_payload || {}),
      body.stop_on_match ? 1 : 0,
      body.effective_from || null,
      body.effective_to || null,
      userId,
      userId,
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_rules WHERE id=?`,
    [ins.insertId],
  );
  return rows[0];
}

async function updateReconciliationRule(db, id, body, userId = null) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_rules WHERE id=?`,
    [id],
  );
  if (!rows[0]) {
    const err = new Error("Reconciliation rule not found");
    err.statusCode = 404;
    throw err;
  }
  const current = rows[0];

  await db.query(
    `
    UPDATE bank_reconciliation_rules
    SET
      rule_name = COALESCE(?, rule_name),
      priority = COALESCE(?, priority),
      status = COALESCE(?, status),
      conditions_json = COALESCE(?, conditions_json),
      action_type = COALESCE(?, action_type),
      action_payload_json = COALESCE(?, action_payload_json),
      stop_on_match = COALESCE(?, stop_on_match),
      effective_from = ?,
      effective_to = ?,
      updated_by = ?,
      updated_at = NOW()
    WHERE id = ?
    `,
    [
      body.rule_name || null,
      body.priority !== undefined ? body.priority : null,
      body.status || null,
      body.conditions !== undefined
        ? JSON.stringify(body.conditions || {})
        : null,
      body.action_type || null,
      body.action_payload !== undefined
        ? JSON.stringify(body.action_payload || {})
        : null,
      body.stop_on_match !== undefined ? (body.stop_on_match ? 1 : 0) : null,
      body.effective_from !== undefined
        ? body.effective_from
        : current.effective_from,
      body.effective_to !== undefined
        ? body.effective_to
        : current.effective_to,
      userId,
      id,
    ],
  );

  const [updated] = await db.query(
    `SELECT * FROM bank_reconciliation_rules WHERE id=?`,
    [id],
  );
  return updated[0];
}

export default {
  listReconciliationRules,
  createReconciliationRule,
  updateReconciliationRule,
};
```

---

## 5) Exceptions service — `backend/src/services/bank.reconciliationExceptions.service.js`

```js id="e7yk9a"
// backend/src/services/bank.reconciliationExceptions.service.js

async function writeExceptionEvent(
  db,
  exceptionId,
  eventType,
  payload = null,
  userId = null,
) {
  await db.query(
    `INSERT INTO bank_reconciliation_exception_events (bank_reconciliation_exception_id, event_type, payload_json, acted_by)
     VALUES (?, ?, ?, ?)`,
    [exceptionId, eventType, payload ? JSON.stringify(payload) : null, userId],
  );
}

async function listReconciliationExceptions(db, filters = {}) {
  const where = [];
  const args = [];

  if (filters.status) {
    where.push(`e.status = ?`);
    args.push(filters.status);
  }
  if (filters.reason_code) {
    where.push(`e.reason_code = ?`);
    args.push(filters.reason_code);
  }
  if (filters.bank_account_id) {
    where.push(`sl.bank_account_id = ?`);
    args.push(filters.bank_account_id);
  }

  const [rows] = await db.query(
    `
    SELECT
      e.*,
      sl.bank_account_id,
      sl.booking_date,
      sl.amount,
      sl.currency_code,
      sl.description,
      sl.reference,
      sl.reconciliation_status
    FROM bank_reconciliation_exceptions e
    JOIN bank_statement_lines sl ON sl.id = e.bank_statement_line_id
    ${where.length ? `WHERE ${where.join(" AND ")}` : ""}
    ORDER BY
      CASE e.status
        WHEN 'OPEN' THEN 1
        WHEN 'ASSIGNED' THEN 2
        WHEN 'RESOLVED' THEN 3
        WHEN 'IGNORED' THEN 4
        ELSE 5
      END,
      e.updated_at DESC
    LIMIT ?
    `,
    [...args, filters.limit || 100],
  );
  return rows;
}

async function assignReconciliationException(
  db,
  exceptionId,
  body,
  userId = null,
) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
    [exceptionId],
  );
  const ex = rows[0];
  if (!ex) {
    const err = new Error("Reconciliation exception not found");
    err.statusCode = 404;
    throw err;
  }
  if (!["OPEN", "ASSIGNED"].includes(String(ex.status))) {
    const err = new Error(`Exception status ${ex.status} cannot be assigned`);
    err.statusCode = 400;
    throw err;
  }

  await db.query(
    `UPDATE bank_reconciliation_exceptions
     SET status='ASSIGNED', assigned_to=?, assigned_at=NOW(), updated_at=NOW()
     WHERE id=?`,
    [body.assigned_to || userId || null, exceptionId],
  );

  await writeExceptionEvent(
    db,
    exceptionId,
    "ASSIGNED",
    { assigned_to: body.assigned_to || userId || null },
    userId,
  );

  const [updated] = await db.query(
    `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
    [exceptionId],
  );
  return updated[0];
}

async function resolveReconciliationException(
  db,
  exceptionId,
  body,
  userId = null,
) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
    [exceptionId],
  );
  const ex = rows[0];
  if (!ex) {
    const err = new Error("Reconciliation exception not found");
    err.statusCode = 404;
    throw err;
  }
  if (!["OPEN", "ASSIGNED"].includes(String(ex.status))) {
    return ex; // idempotent-ish
  }

  await db.query(
    `
    UPDATE bank_reconciliation_exceptions
    SET status='RESOLVED',
        resolved_by=?,
        resolved_at=NOW(),
        resolution_code=?,
        resolution_note=?,
        updated_at=NOW()
    WHERE id=?
    `,
    [
      userId,
      body.resolution_code || "RESOLVED_MANUALLY",
      body.resolution_note || null,
      exceptionId,
    ],
  );

  await writeExceptionEvent(
    db,
    exceptionId,
    "RESOLVED",
    {
      resolution_code: body.resolution_code || "RESOLVED_MANUALLY",
      resolution_note: body.resolution_note || null,
    },
    userId,
  );

  const [updated] = await db.query(
    `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
    [exceptionId],
  );
  return updated[0];
}

async function ignoreReconciliationException(
  db,
  exceptionId,
  body,
  userId = null,
) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
    [exceptionId],
  );
  const ex = rows[0];
  if (!ex) {
    const err = new Error("Reconciliation exception not found");
    err.statusCode = 404;
    throw err;
  }

  await db.query(
    `
    UPDATE bank_reconciliation_exceptions
    SET status='IGNORED',
        resolved_by=?,
        resolved_at=NOW(),
        resolution_code='IGNORED',
        resolution_note=?,
        updated_at=NOW()
    WHERE id=?
    `,
    [userId, body.resolution_note || "Ignored", exceptionId],
  );

  await writeExceptionEvent(
    db,
    exceptionId,
    "IGNORED",
    { resolution_note: body.resolution_note || "Ignored" },
    userId,
  );

  const [updated] = await db.query(
    `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
    [exceptionId],
  );
  return updated[0];
}

export default {
  listReconciliationExceptions,
  assignReconciliationException,
  resolveReconciliationException,
  ignoreReconciliationException,
  writeExceptionEvent,
};
```

---

## 6) Engine service — `backend/src/services/bank.reconciliationEngine.service.js`

```js id="6t81nm"
// backend/src/services/bank.reconciliationEngine.service.js

import { writeExceptionEvent, } from "./bank.reconciliationExceptions.service.js";
// IMPORTANT: patch B03 to export this helper (see patch section below)
async function getB03ReconcileHelper() {
  const svc = (await import("./bank.reconciliation.service.js")).default; // adapt to your B03 service path
  if (typeof svc.reconcileStatementLineToPaymentBatchLine !== "function") {
    const err = new Error(
      "B03 reconcile helper export missing: reconcileStatementLineToPaymentBatchLine",
    );
    err.statusCode = 500;
    throw err;
  }
  return svc.reconcileStatementLineToPaymentBatchLine;
}

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

function normalizeText(s) {
  return String(s || "").toLowerCase();
}

function parseJsonField(v, fallback) {
  if (!v) return fallback;
  if (typeof v === "object") return v;
  try {
    return JSON.parse(v);
  } catch {
    return fallback;
  }
}

function isRuleEffective(rule, bookingDate) {
  const d = String(bookingDate || "").slice(0, 10);
  if (rule.effective_from && d < String(rule.effective_from).slice(0, 10))
    return false;
  if (rule.effective_to && d > String(rule.effective_to).slice(0, 10))
    return false;
  return true;
}

function matchesConditions(line, conditions = {}) {
  const desc = normalizeText(line.description);
  const ref = normalizeText(line.reference);
  const text = `${desc} ${ref}`.trim();

  if (conditions.debit_credit) {
    const dc = String(conditions.debit_credit).toUpperCase();
    if (dc === "DEBIT" && Number(line.amount) >= 0) return false;
    if (dc === "CREDIT" && Number(line.amount) <= 0) return false;
  }

  if (
    conditions.currency_code &&
    String(conditions.currency_code).toUpperCase() !==
      String(line.currency_code).toUpperCase()
  ) {
    return false;
  }

  if (conditions.text_contains) {
    const need = normalizeText(conditions.text_contains);
    if (!text.includes(need)) return false;
  }

  if (Array.isArray(conditions.text_any_of) && conditions.text_any_of.length) {
    const ok = conditions.text_any_of.some((x) =>
      text.includes(normalizeText(x)),
    );
    if (!ok) return false;
  }

  if (conditions.reference_starts_with) {
    if (!ref.startsWith(normalizeText(conditions.reference_starts_with)))
      return false;
  }

  if (conditions.amount_abs_equals !== undefined) {
    if (
      amount2(Math.abs(line.amount)) !==
      amount2(Math.abs(conditions.amount_abs_equals))
    )
      return false;
  }

  if (conditions.amount_abs_min !== undefined) {
    if (amount2(Math.abs(line.amount)) < amount2(conditions.amount_abs_min))
      return false;
  }

  if (conditions.amount_abs_max !== undefined) {
    if (amount2(Math.abs(line.amount)) > amount2(conditions.amount_abs_max))
      return false;
  }

  return true;
}

async function loadActiveRules(db, line) {
  const [rows] = await db.query(
    `
    SELECT *
    FROM bank_reconciliation_rules
    WHERE status = 'ACTIVE'
      AND (scope_type = 'GLOBAL' OR (scope_type='BANK_ACCOUNT' AND bank_account_id = ?))
    ORDER BY priority ASC, id ASC
    `,
    [line.bank_account_id],
  );

  return rows.filter((r) => isRuleEffective(r, line.booking_date));
}

async function findPaymentBatchLineTargets(db, line, rule) {
  const cond = parseJsonField(rule.conditions_json, {});
  const tol = cond.amount_tolerance || 0;

  const baseAmount = amount2(Math.abs(line.amount));

  // Strategy A: bank_reference exact from B06 ack
  if (String(rule.match_type).toUpperCase() === "PAYMENT_BY_BANK_REFERENCE") {
    const [rows] = await db.query(
      `
      SELECT pbl.*
      FROM payment_batch_lines pbl
      WHERE pbl.bank_reference = ?
        AND pbl.currency_code = ?
        AND ABS(ABS(pbl.amount) - ?) <= ?
        AND pbl.status IN ('EXPORTED','EXECUTED','PARTIALLY_PAID','PAID')
      LIMIT 5
      `,
      [line.reference || null, line.currency_code, baseAmount, Number(tol)],
    );
    return rows;
  }

  // Strategy B: text + amount matching (common payroll references)
  if (String(rule.match_type).toUpperCase() === "PAYMENT_BY_TEXT_AND_AMOUNT") {
    const [rows] = await db.query(
      `
      SELECT pbl.*
      FROM payment_batch_lines pbl
      WHERE pbl.currency_code = ?
        AND ABS(ABS(pbl.amount) - ?) <= ?
        AND pbl.status IN ('EXPORTED','EXECUTED','PARTIALLY_PAID','PAID')
        AND (
          LOWER(COALESCE(pbl.reference_text, '')) LIKE ?
          OR LOWER(COALESCE(pbl.reference, '')) LIKE ?
        )
      LIMIT 10
      `,
      [
        line.currency_code,
        baseAmount,
        Number(tol),
        `%${String(cond.text_contains || "").toLowerCase()}%`,
        `%${String(cond.text_contains || "").toLowerCase()}%`,
      ],
    );
    return rows;
  }

  return [];
}

async function evaluateLineAgainstRules(db, line) {
  const rules = await loadActiveRules(db, line);

  for (const rule of rules) {
    const conditions = parseJsonField(rule.conditions_json, {});
    if (!matchesConditions(line, conditions)) continue;

    const actionType = String(rule.action_type || "").toUpperCase();

    if (actionType === "QUEUE_EXCEPTION") {
      return {
        matched: true,
        rule,
        outcome: {
          action: "QUEUE_EXCEPTION",
          reason_code: "POLICY_BLOCKED",
          reason_message: "Rule explicitly queues for manual review",
          confidence: 0.6,
        },
      };
    }

    if (actionType === "AUTO_MATCH_PAYMENT_LINE") {
      const targets = await findPaymentBatchLineTargets(db, line, rule);

      if (targets.length === 1) {
        return {
          matched: true,
          rule,
          outcome: {
            action: "AUTO_MATCH_PAYMENT_LINE",
            target: targets[0],
            confidence: 0.95,
          },
        };
      }

      if (targets.length > 1) {
        return {
          matched: true,
          rule,
          outcome: {
            action: "QUEUE_EXCEPTION",
            reason_code: "AMBIGUOUS_TARGET",
            reason_message: `Multiple payment line targets found (${targets.length})`,
            confidence: 0.5,
            candidates: targets.map((t) => ({
              id: t.id,
              amount: t.amount,
              status: t.status,
            })),
          },
        };
      }

      // no target, continue if not stop_on_match? rule matched condition but target unresolved
      if (Number(rule.stop_on_match || 1) === 1) {
        return {
          matched: true,
          rule,
          outcome: {
            action: "QUEUE_EXCEPTION",
            reason_code: "NO_TARGET_FOUND",
            reason_message:
              "Rule matched text/amount but no payment target found",
            confidence: 0.4,
          },
        };
      }
    }

    if (actionType === "SUGGEST_ONLY") {
      return {
        matched: true,
        rule,
        outcome: {
          action: "QUEUE_EXCEPTION",
          reason_code: "SUGGESTION_ONLY",
          reason_message: "Rule created suggestion only",
          confidence: 0.4,
          suggested_action_type: "SUGGEST_ONLY",
          suggested_payload: parseJsonField(rule.action_payload_json, {}),
        },
      };
    }
  }

  return {
    matched: false,
    rule: null,
    outcome: {
      action: "QUEUE_EXCEPTION",
      reason_code: "NO_RULE_MATCH",
      reason_message: "No active rule matched this statement line",
      confidence: 0.0,
    },
  };
}

async function listUnreconciledStatementLines(db, filters = {}) {
  const where = [`COALESCE(sl.reconciliation_status, 'OPEN') <> 'RECONCILED'`];
  const args = [];

  if (filters.bank_account_id) {
    where.push(`sl.bank_account_id = ?`);
    args.push(filters.bank_account_id);
  }
  if (filters.date_from) {
    where.push(`sl.booking_date >= ?`);
    args.push(filters.date_from);
  }
  if (filters.date_to) {
    where.push(`sl.booking_date <= ?`);
    args.push(filters.date_to);
  }

  const [rows] = await db.query(
    `
    SELECT sl.*
    FROM bank_statement_lines sl
    WHERE ${where.join(" AND ")}
    ORDER BY sl.booking_date ASC, sl.id ASC
    LIMIT ?
    `,
    [...args, filters.limit || 100],
  );
  return rows;
}

async function upsertExceptionForLine(db, lineId, payload, userId = null) {
  const [existing] = await db.query(
    `
    SELECT * FROM bank_reconciliation_exceptions
    WHERE bank_statement_line_id = ? AND status IN ('OPEN','ASSIGNED')
    ORDER BY id DESC LIMIT 1
    `,
    [lineId],
  );

  const row = existing[0];

  if (row) {
    await db.query(
      `
      UPDATE bank_reconciliation_exceptions
      SET
        reason_code = ?,
        reason_message = ?,
        matched_rule_id = ?,
        suggested_action_type = ?,
        suggested_payload_json = ?,
        severity = ?,
        last_seen_at = NOW(),
        occurrence_count = occurrence_count + 1,
        updated_at = NOW()
      WHERE id = ?
      `,
      [
        payload.reason_code,
        payload.reason_message || null,
        payload.matched_rule_id || null,
        payload.suggested_action_type || null,
        payload.suggested_payload
          ? JSON.stringify(payload.suggested_payload)
          : null,
        payload.severity || "MEDIUM",
        row.id,
      ],
    );

    await writeExceptionEvent(db, row.id, "UPDATED", payload, userId);

    const [updated] = await db.query(
      `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
      [row.id],
    );
    return updated[0];
  }

  const [ins] = await db.query(
    `
    INSERT INTO bank_reconciliation_exceptions
    (bank_statement_line_id, status, severity, reason_code, reason_message, matched_rule_id,
     suggested_action_type, suggested_payload_json)
    VALUES (?, 'OPEN', ?, ?, ?, ?, ?, ?)
    `,
    [
      lineId,
      payload.severity || "MEDIUM",
      payload.reason_code,
      payload.reason_message || null,
      payload.matched_rule_id || null,
      payload.suggested_action_type || null,
      payload.suggested_payload
        ? JSON.stringify(payload.suggested_payload)
        : null,
    ],
  );

  await writeExceptionEvent(db, ins.insertId, "CREATED", payload, userId);

  const [created] = await db.query(
    `SELECT * FROM bank_reconciliation_exceptions WHERE id=?`,
    [ins.insertId],
  );
  return created[0];
}

async function previewAutoReconciliation(db, filters = {}, userId = null) {
  const lines = await listUnreconciledStatementLines(db, filters);

  const preview = [];
  let matched = 0;
  let exceptions = 0;

  for (const line of lines) {
    const ev = await evaluateLineAgainstRules(db, line);

    if (ev.outcome.action === "AUTO_MATCH_PAYMENT_LINE") matched += 1;
    else exceptions += 1;

    preview.push({
      bank_statement_line_id: line.id,
      booking_date: line.booking_date,
      amount: line.amount,
      currency_code: line.currency_code,
      description: line.description,
      reference: line.reference,
      matched_rule_id: ev.rule?.id || null,
      matched_rule_code: ev.rule?.rule_code || null,
      action: ev.outcome.action,
      confidence: ev.outcome.confidence ?? null,
      reason_code: ev.outcome.reason_code || null,
      reason_message: ev.outcome.reason_message || null,
      target: ev.outcome.target
        ? {
            type: "PAYMENT_BATCH_LINE",
            id: ev.outcome.target.id,
            amount: ev.outcome.target.amount,
            status: ev.outcome.target.status,
          }
        : null,
      candidates: ev.outcome.candidates || null,
    });
  }

  return {
    summary: {
      scanned_count: lines.length,
      matched_count: matched,
      exception_count: exceptions,
    },
    items: preview,
  };
}

async function applyAutoReconciliation(db, filters = {}, userId = null) {
  const reconcileStatementLineToPaymentBatchLine = getB03ReconcileHelper();

  if (filters.run_request_id) {
    const [existing] = await db.query(
      `SELECT * FROM bank_reconciliation_auto_runs WHERE run_request_id=? LIMIT 1`,
      [filters.run_request_id],
    );
    if (existing[0]) return { auto_run: existing[0], idempotent: true };
  }

  const [runIns] = await db.query(
    `
    INSERT INTO bank_reconciliation_auto_runs
    (run_request_id, run_mode, status, bank_account_id, date_from, date_to, created_by)
    VALUES (?, 'APPLY', 'SUCCESS', ?, ?, ?, ?)
    `,
    [
      filters.run_request_id || null,
      filters.bank_account_id || null,
      filters.date_from || null,
      filters.date_to || null,
      userId,
    ],
  );
  const autoRunId = runIns.insertId;

  const lines = await listUnreconciledStatementLines(db, filters);

  let scanned = 0;
  let matched = 0;
  let reconciled = 0;
  let exceptionCount = 0;
  let skipped = 0;
  let errorCount = 0;

  for (const line of lines) {
    scanned += 1;

    try {
      const ev = await evaluateLineAgainstRules(db, line);

      if (ev.outcome.action === "AUTO_MATCH_PAYMENT_LINE") {
        matched += 1;

        await reconcileStatementLineToPaymentBatchLine(db, {
          bank_statement_line_id: line.id,
          payment_batch_line_id: ev.outcome.target.id,
          method: "RULE_AUTO",
          matched_rule_id: ev.rule?.id || null,
          confidence: ev.outcome.confidence ?? null,
          user_id: userId,
        });

        reconciled += 1;
        continue;
      }

      await upsertExceptionForLine(
        db,
        line.id,
        {
          reason_code: ev.outcome.reason_code || "NO_RULE_MATCH",
          reason_message: ev.outcome.reason_message || null,
          matched_rule_id: ev.rule?.id || null,
          suggested_action_type: ev.outcome.suggested_action_type || null,
          suggested_payload: ev.outcome.suggested_payload || {
            candidates: ev.outcome.candidates || null,
          },
          severity:
            ev.outcome.reason_code === "AMBIGUOUS_TARGET" ? "HIGH" : "MEDIUM",
        },
        userId,
      );

      exceptionCount += 1;
    } catch (e) {
      errorCount += 1;

      try {
        await upsertExceptionForLine(
          db,
          line.id,
          {
            reason_code: "APPLY_ERROR",
            reason_message: e.message || "Auto reconcile apply failed",
            matched_rule_id: null,
            severity: "HIGH",
          },
          userId,
        );
        exceptionCount += 1;
      } catch (_) {
        skipped += 1;
      }
    }
  }

  const status =
    errorCount > 0 ? (reconciled > 0 ? "PARTIAL" : "FAILED") : "SUCCESS";

  await db.query(
    `
    UPDATE bank_reconciliation_auto_runs
    SET status=?, scanned_count=?, matched_count=?, reconciled_count=?, exception_count=?, skipped_count=?, error_count=?,
        payload_json=?
    WHERE id=?
    `,
    [
      status,
      scanned,
      matched,
      reconciled,
      exceptionCount,
      skipped,
      errorCount,
      JSON.stringify({ applied_at: new Date().toISOString() }),
      autoRunId,
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_auto_runs WHERE id=?`,
    [autoRunId],
  );
  return { auto_run: rows[0], idempotent: false };
}

async function retryReconciliationException(db, exceptionId, userId = null) {
  const [rows] = await db.query(
    `
    SELECT e.*, sl.bank_account_id
    FROM bank_reconciliation_exceptions e
    JOIN bank_statement_lines sl ON sl.id = e.bank_statement_line_id
    WHERE e.id = ?
    LIMIT 1
    `,
    [exceptionId],
  );
  const ex = rows[0];
  if (!ex) {
    const err = new Error("Reconciliation exception not found");
    err.statusCode = 404;
    throw err;
  }

  await writeExceptionEvent(db, ex.id, "RETRIED", null, userId);

  return applyAutoReconciliation(
    db,
    {
      bank_account_id: ex.bank_account_id,
      limit: 50,
      run_request_id: `RETRY|EX:${exceptionId}|${Date.now()}`,
    },
    userId,
  );
}

export default {
  previewAutoReconciliation,
  applyAutoReconciliation,
  retryReconciliationException,
  upsertExceptionForLine,
};
```

---

## 7) Routes — `backend/src/routes/bank.reconciliationRules.js`

```js id="vp7f1e"
// backend/src/routes/bank.reconciliationRules.js

import express from "express";
import rulesService from "../services/bank.reconciliationRules.service.js";
import engineService from "../services/bank.reconciliationEngine.service.js";
import { validateRuleIdParam,
  validateCreateRuleBody,
  validateUpdateRuleBody,
  validateAutoPreviewBody,
  validateAutoApplyBody, } from "./bank.reconciliationRules.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/bank/reconciliation/rules
router.get(
  "/reconciliation/rules",
  requireAuth,
  requirePermission("bank.recon.rules.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const items = await rulesService.listReconciliationRules(db);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/rules
router.post(
  "/reconciliation/rules",
  requireAuth,
  requirePermission("bank.recon.rules.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateRuleBody(req.body);
      const item = await rulesService.createReconciliationRule(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json(item);
    } catch (err) {
      next(err);
    }
  },
);

// PATCH /api/v1/bank/reconciliation/rules/:id
router.patch(
  "/reconciliation/rules/:id",
  requireAuth,
  requirePermission("bank.recon.rules.update"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateRuleIdParam(req.params);
      const body = validateUpdateRuleBody(req.body);
      const item = await rulesService.updateReconciliationRule(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/auto-preview
router.post(
  "/reconciliation/auto-preview",
  requireAuth,
  requirePermission("bank.recon.auto.run"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateAutoPreviewBody(req.body);
      const result = await engineService.previewAutoReconciliation(
        db,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/auto-apply
router.post(
  "/reconciliation/auto-apply",
  requireAuth,
  requirePermission("bank.recon.auto.run"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateAutoApplyBody(req.body);
      const result = await engineService.applyAutoReconciliation(
        db,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 8) Routes — `backend/src/routes/bank.reconciliationExceptions.js`

```js id="w2r4hk"
// backend/src/routes/bank.reconciliationExceptions.js

import express from "express";
import exService from "../services/bank.reconciliationExceptions.service.js";
import engineService from "../services/bank.reconciliationEngine.service.js";
import { validateExceptionIdParam,
  validateListExceptionsQuery,
  validateAssignBody,
  validateResolveBody,
  validateIgnoreBody, } from "./bank.reconciliationExceptions.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/bank/reconciliation/exceptions
router.get(
  "/reconciliation/exceptions",
  requireAuth,
  requirePermission("bank.recon.exceptions.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const q = validateListExceptionsQuery(req.query);
      const items = await exService.listReconciliationExceptions(db, q);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/exceptions/:id/assign
router.post(
  "/reconciliation/exceptions/:id/assign",
  requireAuth,
  requirePermission("bank.recon.exceptions.assign"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateExceptionIdParam(req.params);
      const body = validateAssignBody(req.body);
      const item = await exService.assignReconciliationException(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/exceptions/:id/resolve
router.post(
  "/reconciliation/exceptions/:id/resolve",
  requireAuth,
  requirePermission("bank.recon.exceptions.resolve"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateExceptionIdParam(req.params);
      const body = validateResolveBody(req.body);
      const item = await exService.resolveReconciliationException(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/exceptions/:id/ignore
router.post(
  "/reconciliation/exceptions/:id/ignore",
  requireAuth,
  requirePermission("bank.recon.exceptions.resolve"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateExceptionIdParam(req.params);
      const body = validateIgnoreBody(req.body);
      const item = await exService.ignoreReconciliationException(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/exceptions/:id/retry
router.post(
  "/reconciliation/exceptions/:id/retry",
  requireAuth,
  requirePermission("bank.recon.exceptions.retry"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateExceptionIdParam(req.params);
      const result = await engineService.retryReconciliationException(
        db,
        id,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 9) Patch B03 core service — `backend/src/services/bank.reconciliation.service.js` (important)

> Keep your existing B03 manual reconciliation service. Add a reusable helper so B07 uses the same reconciliation contract.

### A) Export a reusable reconcile helper

```js id="j3tt8m"
// patch snippet inside B03 service (adapt table names/logic)

async function reconcileStatementLineToPaymentBatchLine(
  db,
  {
    bank_statement_line_id,
    payment_batch_line_id,
    method = "MANUAL", // MANUAL | RULE_AUTO
    matched_rule_id = null,
    confidence = null,
    user_id = null,
  },
) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    // 1) Validate statement line open
    const [slRows] = await q.query(
      `SELECT * FROM bank_statement_lines WHERE id=? LIMIT 1 FOR UPDATE`,
      [bank_statement_line_id],
    );
    const sl = slRows[0];
    if (!sl) {
      const err = new Error("Bank statement line not found");
      err.statusCode = 404;
      throw err;
    }
    if (
      String(sl.reconciliation_status || "OPEN").toUpperCase() === "RECONCILED"
    ) {
      if (conn) await conn.commit();
      return { idempotent: true, statement_line_id: sl.id };
    }

    // 2) Validate payment line exists / amount compatibility
    const [pblRows] = await q.query(
      `SELECT * FROM payment_batch_lines WHERE id=? LIMIT 1 FOR UPDATE`,
      [payment_batch_line_id],
    );
    const pbl = pblRows[0];
    if (!pbl) {
      const err = new Error("Payment batch line not found");
      err.statusCode = 404;
      throw err;
    }

    // 3) Create B03 reconciliation link row (adapt to your actual table)
    await q.query(
      `
      INSERT INTO bank_reconciliations
      (bank_statement_line_id, target_type, target_id, amount, currency_code, method, matched_rule_id, confidence, created_by)
      VALUES (?, 'PAYMENT_BATCH_LINE', ?, ?, ?, ?, ?, ?, ?)
      `,
      [
        sl.id,
        pbl.id,
        sl.amount,
        sl.currency_code,
        method,
        matched_rule_id,
        confidence,
        user_id,
      ],
    );

    // 4) Mark statement line reconciled + metadata
    await q.query(
      `
      UPDATE bank_statement_lines
      SET reconciliation_status='RECONCILED',
          reconciled_at=NOW(),
          reconciliation_method=?,
          reconciliation_rule_id=?,
          reconciliation_confidence=?,
          updated_at=NOW()
      WHERE id=?
      `,
      [method, matched_rule_id, confidence, sl.id],
    );

    // 5) Auto-close open exception (if any)
    await q
      .query(
        `
      UPDATE bank_reconciliation_exceptions
      SET status='RESOLVED',
          resolved_by=?,
          resolved_at=NOW(),
          resolution_code='RECONCILED',
          resolution_note='Auto-closed on reconciliation',
          updated_at=NOW()
      WHERE bank_statement_line_id=?
        AND status IN ('OPEN','ASSIGNED')
      `,
        [user_id, sl.id],
      )
      .catch(() => {});

    // 6) Optional B03 audit row
    await q
      .query(
        `
      INSERT INTO bank_reconciliation_audit (bank_statement_line_id, action, payload_json, acted_by)
      VALUES (?, 'RECONCILED', ?, ?)
      `,
        [
          sl.id,
          JSON.stringify({
            target_type: "PAYMENT_BATCH_LINE",
            target_id: pbl.id,
            method,
            matched_rule_id,
            confidence,
          }),
          user_id,
        ],
      )
      .catch(() => {});

    if (conn) await conn.commit();

    return {
      idempotent: false,
      statement_line_id: sl.id,
      payment_batch_line_id: pbl.id,
    };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

// export it
export default {
  // existing exports...
  reconcileStatementLineToPaymentBatchLine,
};
```

### B) Include reconciliation metadata in B03 line list/detail

Add to your statement-line list/detail SELECT:

- `reconciliation_method`
- `reconciliation_rule_id`
- `reconciliation_confidence`

This helps UI show whether a line was matched manually or by rule.

---

## 10) Mount routes — `backend/src/index.js`

```js id="uu8rkr"
// backend/src/index.js
import bankReconciliationRulesRoutes from "./routes/bank.reconciliationRules.js";
import bankReconciliationExceptionsRoutes from "./routes/bank.reconciliationExceptions.js";
// ...
app.use("/api/v1/bank", bankReconciliationRulesRoutes);
app.use("/api/v1/bank", bankReconciliationExceptionsRoutes);
```

---

## 11) Migration registry — `backend/src/migrations/index.js`

```js id="mqc1jn"
// backend/src/migrations/index.js
import m047_bank_reconciliation_rules_and_exceptions from "./m047_bank_reconciliation_rules_and_exceptions.js";
export default [
  // ...
  m047_bank_reconciliation_rules_and_exceptions,
];
```

---

## 12) Seed permissions — `backend/src/seedCore.js`

```js id="lg1v4h"
// backend/src/seedCore.js
const BANK_B07_PERMISSIONS = [
  "bank.recon.rules.read",
  "bank.recon.rules.create",
  "bank.recon.rules.update",
  "bank.recon.auto.run",
  "bank.recon.exceptions.read",
  "bank.recon.exceptions.assign",
  "bank.recon.exceptions.resolve",
  "bank.recon.exceptions.retry",
];

// merge into permission seed list
```

---

## 13) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

### Rules + automation

- `GET /api/v1/bank/reconciliation/rules`
- `POST /api/v1/bank/reconciliation/rules`
- `PATCH /api/v1/bank/reconciliation/rules/{id}`
- `POST /api/v1/bank/reconciliation/auto-preview`
- `POST /api/v1/bank/reconciliation/auto-apply`

### Exception queue

- `GET /api/v1/bank/reconciliation/exceptions`
- `POST /api/v1/bank/reconciliation/exceptions/{id}/assign`
- `POST /api/v1/bank/reconciliation/exceptions/{id}/resolve`
- `POST /api/v1/bank/reconciliation/exceptions/{id}/ignore`
- `POST /api/v1/bank/reconciliation/exceptions/{id}/retry`

Also document new statement-line metadata:

- `reconciliation_method`
- `reconciliation_rule_id`
- `reconciliation_confidence`

---

## 14) Backend smoke test — `backend/scripts/test-bank-prb07-reconciliation-rules-and-exceptions.js`

```js id="1yqk2m"
// backend/scripts/test-bank-prb07-reconciliation-rules-and-exceptions.js

async function main() {
  // Preconditions:
  // - B03 manual reconciliation works
  // - B04/B06 have some payment batch lines with bank_reference and/or references
  // - B02/B05 imported bank statement lines exist and are unreconciled
  //
  // Flow A: Rule setup
  // 1) Create rule: PAYMENT_BY_BANK_REFERENCE + AUTO_MATCH_PAYMENT_LINE
  // 2) Create rule: PAYMENT_BY_TEXT_AND_AMOUNT + AUTO_MATCH_PAYMENT_LINE (lower priority)
  // 3) Create rule: fallback QUEUE_EXCEPTION
  //
  // Flow B: Preview (read-only)
  // 4) POST /reconciliation/auto-preview
  //    -> returns action per line
  //    -> no statement line status changes
  //    -> no exceptions created
  //
  // Flow C: Apply
  // 5) POST /reconciliation/auto-apply
  //    -> exact single matches reconciled (B03 helper used)
  //    -> ambiguous/no-match create OPEN exceptions
  //    -> auto run log created
  //
  // Flow D: Exception queue lifecycle
  // 6) GET /reconciliation/exceptions -> OPEN items visible
  // 7) Assign one exception
  // 8) Resolve one exception manually
  // 9) Retry one exception after improving data/rule
  //
  // Flow E: Auto-close exception on reconciliation
  // 10) Manually reconcile a statement line with OPEN/ASSIGNED exception
  //     -> exception auto-closes RESOLVED
  //
  // Flow F: Idempotency / safety
  // 11) Re-run auto-apply with same run_request_id -> same auto run returned
  // 12) Already reconciled lines are skipped
  //
  // Permissions:
  // - bank.recon.rules.*, bank.recon.auto.run, bank.recon.exceptions.* enforced (403)
  console.log("PR-B07 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 15) `backend/package.json` updates

```json id="z6w4pc"
{
  "scripts": {
    "test:bank:prb07": "node backend/scripts/test-bank-prb07-reconciliation-rules-and-exceptions.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 16) API client — `frontend/src/api/bankReconciliationAutomation.js`

```js id="m8a0ty"
// frontend/src/api/bankReconciliationAutomation.js

import { apiFetch } from "./client.js"; // adapt

export function listBankReconciliationRules() {
  return apiFetch("/api/v1/bank/reconciliation/rules");
}

export function createBankReconciliationRule(payload) {
  return apiFetch("/api/v1/bank/reconciliation/rules", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function updateBankReconciliationRule(ruleId, payload) {
  return apiFetch(`/api/v1/bank/reconciliation/rules/${ruleId}`, {
    method: "PATCH",
    body: JSON.stringify(payload),
  });
}

export function previewBankAutoReconciliation(payload) {
  return apiFetch("/api/v1/bank/reconciliation/auto-preview", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function applyBankAutoReconciliation(payload) {
  return apiFetch("/api/v1/bank/reconciliation/auto-apply", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function listBankReconciliationExceptions(params = {}) {
  const qs = new URLSearchParams();
  Object.entries(params).forEach(([k, v]) => {
    if (v === undefined || v === null || v === "") return;
    qs.set(k, String(v));
  });
  const q = qs.toString();
  return apiFetch(`/api/v1/bank/reconciliation/exceptions${q ? `?${q}` : ""}`);
}

export function assignBankReconciliationException(exceptionId, payload = {}) {
  return apiFetch(
    `/api/v1/bank/reconciliation/exceptions/${exceptionId}/assign`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}

export function resolveBankReconciliationException(exceptionId, payload = {}) {
  return apiFetch(
    `/api/v1/bank/reconciliation/exceptions/${exceptionId}/resolve`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}

export function ignoreBankReconciliationException(exceptionId, payload = {}) {
  return apiFetch(
    `/api/v1/bank/reconciliation/exceptions/${exceptionId}/ignore`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}

export function retryBankReconciliationException(exceptionId) {
  return apiFetch(
    `/api/v1/bank/reconciliation/exceptions/${exceptionId}/retry`,
    {
      method: "POST",
    },
  );
}
```

---

## 17) `BankReconciliationPage.jsx` — key integration snippets only

### Add imports

```jsx id="q8em2r"
import {
  listBankReconciliationRules,
  createBankReconciliationRule,
  previewBankAutoReconciliation,
  applyBankAutoReconciliation,
  listBankReconciliationExceptions,
  assignBankReconciliationException,
  resolveBankReconciliationException,
  retryBankReconciliationException,
} from "../../api/bankReconciliationAutomation.js";
```

### Add state

```jsx id="b1u8ek"
const [rules, setRules] = useState([]);
const [autoPreview, setAutoPreview] = useState([]);
const [exceptions, setExceptions] = useState([]);
const [reconAutoErr, setReconAutoErr] = useState("");
```

### Load rules + exceptions

```jsx id="hl3m0u"
async function loadReconAutomation() {
  const [rulesRes, exRes] = await Promise.all([
    listBankReconciliationRules(),
    listBankReconciliationExceptions({ status: "OPEN", limit: 50 }),
  ]);
  setRules(rulesRes.items || []);
  setExceptions(exRes.items || []);
}
```

### Create a starter rule (example)

```jsx id="m9j4hd"
async function onCreateStarterRule() {
  try {
    setReconAutoErr("");
    await createBankReconciliationRule({
      rule_code: "PAYREF_EXACT_001",
      rule_name: "Payment by bank reference exact",
      priority: 10,
      scope_type: "GLOBAL",
      match_type: "PAYMENT_BY_BANK_REFERENCE",
      conditions: {
        debit_credit: "DEBIT",
        amount_tolerance: 0,
      },
      action_type: "AUTO_MATCH_PAYMENT_LINE",
      stop_on_match: true,
      status: "ACTIVE",
    });
    await loadReconAutomation();
  } catch (e) {
    setReconAutoErr(e.message || "Rule create failed");
  }
}
```

### Preview + apply auto reconciliation

```jsx id="zc6p5v"
async function onPreviewAutoRecon(bankAccountId) {
  try {
    setReconAutoErr("");
    const res = await previewBankAutoReconciliation({
      bank_account_id: bankAccountId,
      limit: 100,
    });
    setAutoPreview(res.items || []);
  } catch (e) {
    setReconAutoErr(e.message || "Preview failed");
  }
}

async function onApplyAutoRecon(bankAccountId) {
  try {
    setReconAutoErr("");
    await applyBankAutoReconciliation({
      bank_account_id: bankAccountId,
      limit: 100,
      run_request_id: `recon-${bankAccountId}-${Date.now()}`,
    });
    await load(); // existing B03 reconciliation page reload
    await loadReconAutomation();
  } catch (e) {
    setReconAutoErr(e.message || "Auto apply failed");
  }
}
```

### Exception actions

```jsx id="m9kg2y"
async function onAssignException(ex) {
  await assignBankReconciliationException(ex.id, {});
  await loadReconAutomation();
}

async function onResolveException(ex) {
  await resolveBankReconciliationException(ex.id, {
    resolution_code: "RESOLVED_MANUALLY",
    resolution_note: "Reviewed and handled",
  });
  await loadReconAutomation();
}

async function onRetryException(ex) {
  await retryBankReconciliationException(ex.id);
  await load(); // refresh statement lines
  await loadReconAutomation();
}
```

### Compact UI blocks (no full tables)

```jsx id="3sxm1g"
{
  /* Reconciliation Automation Panel */
}
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Reconciliation Automation</h2>

  {/* Buttons:
      - Create Starter Rule
      - Preview Auto-Reconcile
      - Apply Auto-Reconcile
  */}

  {reconAutoErr ? (
    <div className="text-sm text-red-600">{reconAutoErr}</div>
  ) : null}

  <div className="text-sm mt-2 space-y-1">
    {/* Rules summary:
        rule_code, priority, match_type, action_type, status
    */}
  </div>

  <div className="text-sm mt-3 space-y-1">
    {/* Auto preview compact rows:
        statement_line_id, action, matched_rule_code, confidence, reason
    */}
  </div>
</div>;

{
  /* Exception Queue Panel */
}
<div className="rounded border bg-white p-4 mt-4">
  <h2 className="font-medium mb-2">Reconciliation Exceptions</h2>

  {/* Per item actions:
      - Assign
      - Resolve
      - Retry
  */}

  <div className="text-sm space-y-1">
    {/* exception id, status, reason_code, amount, booking_date, description, occurrence_count */}
  </div>
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Can create/list/update reconciliation rules (priority + effective-dated)
- ✅ Auto-reconciliation preview returns deterministic actions without writing data
- ✅ Auto-reconciliation apply reconciles only safe single-target matches
- ✅ Auto-reconciliation uses B03 core reconcile helper (shared logic)
- ✅ Unmatched / ambiguous / failed items create/update exception queue entries
- ✅ Exception queue supports assign / resolve / ignore / retry
- ✅ Reconciled statement lines store metadata:

  - `reconciliation_method`
  - `reconciliation_rule_id`
  - `reconciliation_confidence`

- ✅ Open exceptions auto-close when line becomes reconciled
- ✅ Auto-run logs are stored and support idempotent `run_request_id`
- ✅ B03 manual reconciliation still works unchanged
- ✅ Permissions enforced (`bank.recon.*`)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:bank:prb07`

Should verify at least:

1. **Rules**

   - Create active rules with priorities
   - List returns correct order (priority asc)

2. **Preview**

   - Preview returns candidate actions
   - No statement lines are reconciled
   - No exceptions created during preview

3. **Apply**

   - Exact/safe matches get reconciled
   - Reconciliation metadata saved (`RULE_AUTO`, rule id, confidence)
   - B03 reconciliation record created

4. **Exception queue**

   - No-rule / ambiguous cases create OPEN exceptions
   - Repeat apply updates same exception (occurrence count / last_seen_at), not endless duplicates
   - Assign / resolve / ignore endpoints work

5. **Retry**

   - Retry runs engine again for exception context
   - If match is now possible, line reconciles and exception closes

6. **Idempotency**

   - Re-run `auto-apply` with same `run_request_id` returns same run row
   - Already reconciled lines are skipped safely

7. **Permissions**

   - `bank.recon.rules.read/create/update`
   - `bank.recon.auto.run`
   - `bank.recon.exceptions.read/assign/resolve/retry`
     all enforced (`403`)

---

## Tiny implementation notes (important)

- Start with a few practical rules first:

  1. **Bank reference exact → payment line**
  2. **Payroll text + amount → payment line**
  3. **Fallback queue exception**

- Don’t over-automate day one. Ambiguous matches should **always** queue exceptions.
- Later PRs can extend B07 with:

  - confidence thresholds
  - ML ranking (optional)
  - fee/charge auto-posting templates
  - rule simulation on historical data

---

Perfect — here’s **PR-B08** in the same format.

# PR-B08-A: Bank Fees / Charges / Interest Auto-Posting Templates + Reconciliation Targets

## Goal

Reduce manual reconciliation for common bank-originated items by adding **auto-post templates** for things like:

- ✅ Bank fees / charges
- ✅ Bank commission
- ✅ Bank interest income
- ✅ Other recurring bank-originated entries (rules + templates)

This PR gives you:

- ✅ Template master for bank auto-posting (effective-dated, scoped)
- ✅ B07 rule action support: `AUTO_POST_TEMPLATE`
- ✅ Auto-create GL journal from statement line (system-posted)
- ✅ Auto-reconcile statement line to GL journal via B03
- ✅ Idempotent auto-posting (no duplicate journals for same statement line)
- ✅ Exception queue fallback when template/posting fails

---

## Key design rule (important)

**B08 extends B07 + B03; it does not bypass them.**

Flow stays:

- **B02/B05** import statement lines
- **B07** rules decide action
- If action is `AUTO_POST_TEMPLATE`:

  1. **B08** creates GL journal from statement line using template
  2. **B03** reconciles statement line to that GL journal

- If posting fails → **B07 exception queue**

So reconciliation remains auditable and centralized.

---

## Important behavior rules

### 1) One auto-post per statement line (idempotent)

A statement line can only produce **one active auto-post journal** unless reversed.

### 2) Templates do not decide matching

**Rules match**, templates **post**.
(B07 = decision layer, B08 = posting layer)

### 3) Template posting is sign-driven

- **Outflow (`amount < 0`)** → typically `Dr Expense / Cr Bank`
- **Inflow (`amount > 0`)** → typically `Dr Bank / Cr Income`

Template controls the **counter account** and direction policy.

### 4) B03 reconciliation must still be written

Auto-posting alone is not enough. The statement line must be reconciled to the GL journal via B03 helper.

---

## Files to create

### Backend

- `backend/src/migrations/m048_bank_recon_autopost_templates.js`
- `backend/src/routes/bank.reconciliationPostingTemplates.js`
- `backend/src/routes/bank.reconciliationPostingTemplates.validators.js`
- `backend/src/services/bank.reconciliationPostingTemplates.service.js`
- `backend/src/services/bank.reconciliationAutoPosting.service.js`
- `backend/scripts/test-bank-prb08-autopost-templates.js`

### Frontend (short snippets only)

- `frontend/src/api/bankReconciliationPostingTemplates.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (important patches)

- `backend/src/services/bank.reconciliationEngine.service.js` _(B07 engine)_

  - add `AUTO_POST_TEMPLATE` action support

- `backend/src/services/bank.reconciliation.service.js` _(B03 core)_

  - add helper to reconcile statement line → GL journal entry

- `backend/src/services/gl.journals.service.js` _(or your actual GL posting service file)_

  - export reusable system journal create/post helper

### Frontend (short integration only)

- `frontend/src/pages/bank/BankReconciliationPage.jsx`

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m048_bank_recon_autopost_templates.js`

```js id="b08m34"
// backend/src/migrations/m048_bank_recon_autopost_templates.js

export default {
  key: "m048_bank_recon_autopost_templates",
  description: "m048_bank_recon_autopost_templates",
  async up(connection) {
    // Template master
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_reconciliation_posting_templates (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        template_code VARCHAR(50) NOT NULL,
        template_name VARCHAR(190) NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE', -- ACTIVE, PAUSED, DISABLED

        scope_type VARCHAR(20) NOT NULL DEFAULT 'GLOBAL', -- GLOBAL, BANK_ACCOUNT
        bank_account_id BIGINT UNSIGNED NULL,

        entry_kind VARCHAR(30) NOT NULL, -- BANK_FEE_EXPENSE, BANK_INTEREST_INCOME, BANK_MISC
        direction_policy VARCHAR(20) NOT NULL DEFAULT 'BOTH', -- OUTFLOW_ONLY, INFLOW_ONLY, BOTH

        counter_account_id BIGINT UNSIGNED NOT NULL, -- expense/income GL account
        tax_account_id BIGINT UNSIGNED NULL,         -- reserved for future split logic
        tax_mode VARCHAR(20) NOT NULL DEFAULT 'NONE', -- NONE (v1), future: INCLUDED/EXCLUDED
        tax_rate DECIMAL(9,4) NULL,

        currency_code CHAR(3) NULL, -- null = any
        max_amount_abs DECIMAL(18,2) NULL, -- optional safety threshold
        min_amount_abs DECIMAL(18,2) NULL,

        description_mode VARCHAR(20) NOT NULL DEFAULT 'USE_STATEMENT_TEXT', -- USE_STATEMENT_TEXT, FIXED_TEXT, PREFIXED
        fixed_description VARCHAR(255) NULL,
        description_prefix VARCHAR(100) NULL,

        journal_source_code VARCHAR(30) NOT NULL DEFAULT 'BANK_AUTO_POST',
        journal_doc_type VARCHAR(30) NOT NULL DEFAULT 'BANK_AUTO',

        effective_from DATE NULL,
        effective_to DATE NULL,

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_brpt_template_code (template_code),
        KEY idx_brpt_status (status),
        KEY idx_brpt_scope (scope_type, bank_account_id),
        KEY idx_brpt_effective (effective_from, effective_to)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Auto-posting traceability + idempotency
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_reconciliation_auto_postings (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_statement_line_id BIGINT UNSIGNED NOT NULL,
        bank_reconciliation_posting_template_id BIGINT UNSIGNED NOT NULL,
        journal_entry_id BIGINT UNSIGNED NOT NULL,

        status VARCHAR(20) NOT NULL DEFAULT 'POSTED', -- POSTED, REVERSED
        posted_amount DECIMAL(18,2) NOT NULL,
        currency_code CHAR(3) NOT NULL,

        reversal_journal_entry_id BIGINT UNSIGNED NULL,
        reversed_at DATETIME NULL,
        reverse_reason VARCHAR(255) NULL,

        payload_json JSON NULL,
        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_brap_statement_line_active (bank_statement_line_id, status),
        UNIQUE KEY uq_brap_statement_line (bank_statement_line_id),
        KEY idx_brap_template (bank_reconciliation_posting_template_id),
        KEY idx_brap_journal (journal_entry_id),

        CONSTRAINT fk_brap_statement_line
          FOREIGN KEY (bank_statement_line_id) REFERENCES bank_statement_lines(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_brap_template
          FOREIGN KEY (bank_reconciliation_posting_template_id) REFERENCES bank_reconciliation_posting_templates(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Optional metadata on statement lines
    await db
      .query(
        `
      ALTER TABLE bank_statement_lines
        ADD COLUMN auto_post_template_id BIGINT UNSIGNED NULL AFTER reconciliation_rule_id,
        ADD COLUMN auto_post_journal_entry_id BIGINT UNSIGNED NULL AFTER auto_post_template_id
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE bank_statement_lines
        ADD KEY idx_bsl_auto_post_template (auto_post_template_id),
        ADD KEY idx_bsl_auto_post_journal (auto_post_journal_entry_id)
    `,
      )
      .catch(() => {});
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS bank_reconciliation_auto_postings;`);
    await connection.execute(
      `DROP TABLE IF EXISTS bank_reconciliation_posting_templates;`,
    );
    // Optional strict down for ALTER columns omitted
  },
};
```

---

## 2) Validators — `backend/src/routes/bank.reconciliationPostingTemplates.validators.js`

```js id="b08val"
// backend/src/routes/bank.reconciliationPostingTemplates.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}
function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}
function normalizeDecimal(v) {
  if (v === undefined || v === null || v === "") return null;
  const n = Number(v);
  if (!Number.isFinite(n)) throw new Error(`Invalid number: ${v}`);
  return n;
}

function validateTemplateIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreateTemplateBody(body = {}) {
  return {
    template_code:
      normalizeString(body.template_code) ||
      (() => {
        throw new Error("template_code is required");
      })(),
    template_name:
      normalizeString(body.template_name) ||
      (() => {
        throw new Error("template_name is required");
      })(),
    status: String(body.status || "ACTIVE")
      .trim()
      .toUpperCase(),
    scope_type: String(body.scope_type || "GLOBAL")
      .trim()
      .toUpperCase(),
    bank_account_id: body.bank_account_id
      ? requirePositiveInt(body.bank_account_id, "bank_account_id")
      : null,

    entry_kind: String(body.entry_kind || "BANK_MISC")
      .trim()
      .toUpperCase(),
    direction_policy: String(body.direction_policy || "BOTH")
      .trim()
      .toUpperCase(),

    counter_account_id: requirePositiveInt(
      body.counter_account_id,
      "counter_account_id",
    ),
    tax_account_id: body.tax_account_id
      ? requirePositiveInt(body.tax_account_id, "tax_account_id")
      : null,
    tax_mode: String(body.tax_mode || "NONE")
      .trim()
      .toUpperCase(),
    tax_rate: normalizeDecimal(body.tax_rate),

    currency_code: normalizeString(body.currency_code)?.toUpperCase() || null,
    min_amount_abs: normalizeDecimal(body.min_amount_abs),
    max_amount_abs: normalizeDecimal(body.max_amount_abs),

    description_mode: String(body.description_mode || "USE_STATEMENT_TEXT")
      .trim()
      .toUpperCase(),
    fixed_description: normalizeString(body.fixed_description),
    description_prefix: normalizeString(body.description_prefix),

    journal_source_code: String(body.journal_source_code || "BANK_AUTO_POST")
      .trim()
      .toUpperCase(),
    journal_doc_type: String(body.journal_doc_type || "BANK_AUTO")
      .trim()
      .toUpperCase(),

    effective_from: normalizeString(body.effective_from),
    effective_to: normalizeString(body.effective_to),
  };
}

function validateUpdateTemplateBody(body = {}) {
  return {
    template_name:
      body.template_name !== undefined
        ? normalizeString(body.template_name)
        : undefined,
    status: body.status ? String(body.status).trim().toUpperCase() : null,
    counter_account_id:
      body.counter_account_id !== undefined
        ? requirePositiveInt(body.counter_account_id, "counter_account_id")
        : undefined,
    direction_policy: body.direction_policy
      ? String(body.direction_policy).trim().toUpperCase()
      : null,
    currency_code:
      body.currency_code !== undefined
        ? normalizeString(body.currency_code)?.toUpperCase() || null
        : undefined,
    min_amount_abs:
      body.min_amount_abs !== undefined
        ? normalizeDecimal(body.min_amount_abs)
        : undefined,
    max_amount_abs:
      body.max_amount_abs !== undefined
        ? normalizeDecimal(body.max_amount_abs)
        : undefined,
    description_mode: body.description_mode
      ? String(body.description_mode).trim().toUpperCase()
      : null,
    fixed_description:
      body.fixed_description !== undefined
        ? normalizeString(body.fixed_description)
        : undefined,
    description_prefix:
      body.description_prefix !== undefined
        ? normalizeString(body.description_prefix)
        : undefined,
    effective_from:
      body.effective_from !== undefined
        ? normalizeString(body.effective_from)
        : undefined,
    effective_to:
      body.effective_to !== undefined
        ? normalizeString(body.effective_to)
        : undefined,
  };
}

export default {
  validateTemplateIdParam,
  validateCreateTemplateBody,
  validateUpdateTemplateBody,
};
```

---

## 3) Template master service — `backend/src/services/bank.reconciliationPostingTemplates.service.js`

```js id="b08tmpsvc"
// backend/src/services/bank.reconciliationPostingTemplates.service.js

function parseJsonRow(row) {
  return row;
}

async function listPostingTemplates(db) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_posting_templates ORDER BY status='ACTIVE' DESC, id DESC`,
  );
  return rows.map(parseJsonRow);
}

async function getPostingTemplate(db, id) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_posting_templates WHERE id=? LIMIT 1`,
    [id],
  );
  return rows[0] || null;
}

async function createPostingTemplate(db, body, userId = null) {
  const [ins] = await db.query(
    `
    INSERT INTO bank_reconciliation_posting_templates
    (template_code, template_name, status, scope_type, bank_account_id, entry_kind, direction_policy,
     counter_account_id, tax_account_id, tax_mode, tax_rate, currency_code, min_amount_abs, max_amount_abs,
     description_mode, fixed_description, description_prefix, journal_source_code, journal_doc_type,
     effective_from, effective_to, created_by, updated_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      body.template_code,
      body.template_name,
      body.status || "ACTIVE",
      body.scope_type || "GLOBAL",
      body.bank_account_id || null,
      body.entry_kind,
      body.direction_policy || "BOTH",
      body.counter_account_id,
      body.tax_account_id || null,
      body.tax_mode || "NONE",
      body.tax_rate || null,
      body.currency_code || null,
      body.min_amount_abs || null,
      body.max_amount_abs || null,
      body.description_mode || "USE_STATEMENT_TEXT",
      body.fixed_description || null,
      body.description_prefix || null,
      body.journal_source_code || "BANK_AUTO_POST",
      body.journal_doc_type || "BANK_AUTO",
      body.effective_from || null,
      body.effective_to || null,
      userId,
      userId,
    ],
  );
  return getPostingTemplate(db, ins.insertId);
}

async function updatePostingTemplate(db, id, body, userId = null) {
  const current = await getPostingTemplate(db, id);
  if (!current) {
    const err = new Error("Posting template not found");
    err.statusCode = 404;
    throw err;
  }

  await db.query(
    `
    UPDATE bank_reconciliation_posting_templates
    SET
      template_name = COALESCE(?, template_name),
      status = COALESCE(?, status),
      counter_account_id = COALESCE(?, counter_account_id),
      direction_policy = COALESCE(?, direction_policy),
      currency_code = ?,
      min_amount_abs = ?,
      max_amount_abs = ?,
      description_mode = COALESCE(?, description_mode),
      fixed_description = ?,
      description_prefix = ?,
      effective_from = ?,
      effective_to = ?,
      updated_by = ?,
      updated_at = NOW()
    WHERE id = ?
    `,
    [
      body.template_name ?? null,
      body.status || null,
      body.counter_account_id ?? null,
      body.direction_policy || null,
      body.currency_code !== undefined
        ? body.currency_code
        : current.currency_code,
      body.min_amount_abs !== undefined
        ? body.min_amount_abs
        : current.min_amount_abs,
      body.max_amount_abs !== undefined
        ? body.max_amount_abs
        : current.max_amount_abs,
      body.description_mode || null,
      body.fixed_description !== undefined
        ? body.fixed_description
        : current.fixed_description,
      body.description_prefix !== undefined
        ? body.description_prefix
        : current.description_prefix,
      body.effective_from !== undefined
        ? body.effective_from
        : current.effective_from,
      body.effective_to !== undefined
        ? body.effective_to
        : current.effective_to,
      userId,
      id,
    ],
  );

  return getPostingTemplate(db, id);
}

export default {
  listPostingTemplates,
  getPostingTemplate,
  createPostingTemplate,
  updatePostingTemplate,
};
```

---

## 4) Auto-post service — `backend/src/services/bank.reconciliationAutoPosting.service.js`

```js id="b08autopost"
// backend/src/services/bank.reconciliationAutoPosting.service.js

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

function parseDate(d) {
  return String(d || "").slice(0, 10);
}

function isEffective(template, bookingDate) {
  const d = parseDate(bookingDate);
  if (template.effective_from && d < parseDate(template.effective_from))
    return false;
  if (template.effective_to && d > parseDate(template.effective_to))
    return false;
  return true;
}

function buildNarration(template, line) {
  const desc = String(line.description || line.reference || "").trim();
  const mode = String(
    template.description_mode || "USE_STATEMENT_TEXT",
  ).toUpperCase();

  if (mode === "FIXED_TEXT")
    return template.fixed_description || desc || "Bank auto-post";
  if (mode === "PREFIXED")
    return `${template.description_prefix || "Bank"} ${desc}`.trim();
  return desc || template.template_name || "Bank auto-post";
}

function validateTemplateAppliesToLine(template, line) {
  if (String(template.status).toUpperCase() !== "ACTIVE") {
    const err = new Error("Template is not active");
    err.statusCode = 400;
    throw err;
  }

  if (!isEffective(template, line.booking_date)) {
    const err = new Error("Template not effective for statement line date");
    err.statusCode = 400;
    throw err;
  }

  if (
    template.scope_type === "BANK_ACCOUNT" &&
    Number(template.bank_account_id) !== Number(line.bank_account_id)
  ) {
    const err = new Error("Template not scoped to this bank account");
    err.statusCode = 400;
    throw err;
  }

  const absAmount = amount2(Math.abs(line.amount));
  if (
    template.currency_code &&
    String(template.currency_code).toUpperCase() !==
      String(line.currency_code).toUpperCase()
  ) {
    const err = new Error("Template currency mismatch");
    err.statusCode = 400;
    throw err;
  }
  if (
    template.min_amount_abs != null &&
    absAmount < amount2(template.min_amount_abs)
  ) {
    const err = new Error("Statement amount below template minimum");
    err.statusCode = 400;
    throw err;
  }
  if (
    template.max_amount_abs != null &&
    absAmount > amount2(template.max_amount_abs)
  ) {
    const err = new Error("Statement amount above template maximum");
    err.statusCode = 400;
    throw err;
  }

  const dir = String(template.direction_policy || "BOTH").toUpperCase();
  if (dir === "OUTFLOW_ONLY" && Number(line.amount) >= 0) {
    const err = new Error("Template applies only to outflows");
    err.statusCode = 400;
    throw err;
  }
  if (dir === "INFLOW_ONLY" && Number(line.amount) <= 0) {
    const err = new Error("Template applies only to inflows");
    err.statusCode = 400;
    throw err;
  }

  if (String(template.tax_mode || "NONE").toUpperCase() !== "NONE") {
    const err = new Error("Tax split modes are not implemented yet in B08 v1");
    err.statusCode = 400;
    throw err;
  }
}

// IMPORTANT: adapt to your real GL service export
function getGlCreateAndPostHelper() {
  import svc from "./gl.journals.service.js";
  if (typeof svc.createAndPostSystemJournal !== "function") {
    const err = new Error(
      "GL helper export missing: createAndPostSystemJournal",
    );
    err.statusCode = 500;
    throw err;
  }
  return svc.createAndPostSystemJournal;
}

async function getBankAccountWithGl(db, bankAccountId) {
  // adapt field names to your B01 table
  const [rows] = await db.query(
    `SELECT * FROM bank_accounts WHERE id=? LIMIT 1`,
    [bankAccountId],
  );
  return rows[0] || null;
}

async function getStatementLine(db, statementLineId) {
  const [rows] = await db.query(
    `SELECT * FROM bank_statement_lines WHERE id=? LIMIT 1`,
    [statementLineId],
  );
  return rows[0] || null;
}

async function getTemplate(db, templateId) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_posting_templates WHERE id=? LIMIT 1`,
    [templateId],
  );
  return rows[0] || null;
}

async function previewAutoPostFromTemplate(
  db,
  { bank_statement_line_id, template_id },
) {
  const line = await getStatementLine(db, bank_statement_line_id);
  if (!line) {
    const err = new Error("Bank statement line not found");
    err.statusCode = 404;
    throw err;
  }

  const template = await getTemplate(db, template_id);
  if (!template) {
    const err = new Error("Posting template not found");
    err.statusCode = 404;
    throw err;
  }

  validateTemplateAppliesToLine(template, line);

  const bankAccount = await getBankAccountWithGl(db, line.bank_account_id);
  if (!bankAccount || !bankAccount.gl_account_id) {
    const err = new Error("Bank account GL mapping missing");
    err.statusCode = 400;
    throw err;
  }

  const absAmount = amount2(Math.abs(line.amount));
  const narration = buildNarration(template, line);

  let lines;
  if (Number(line.amount) < 0) {
    // OUTFLOW: Dr Counter / Cr Bank
    lines = [
      {
        account_id: Number(template.counter_account_id),
        dr_amount: absAmount,
        cr_amount: 0,
        memo: narration,
      },
      {
        account_id: Number(bankAccount.gl_account_id),
        dr_amount: 0,
        cr_amount: absAmount,
        memo: narration,
      },
    ];
  } else {
    // INFLOW: Dr Bank / Cr Counter (usually income)
    lines = [
      {
        account_id: Number(bankAccount.gl_account_id),
        dr_amount: absAmount,
        cr_amount: 0,
        memo: narration,
      },
      {
        account_id: Number(template.counter_account_id),
        dr_amount: 0,
        cr_amount: absAmount,
        memo: narration,
      },
    ];
  }

  return {
    bank_statement_line_id: line.id,
    template_id: template.id,
    journal_date: parseDate(line.booking_date),
    currency_code: line.currency_code,
    narration,
    gl_lines: lines,
  };
}

async function autoPostFromTemplate(
  db,
  { bank_statement_line_id, template_id, user_id = null },
) {
  const createAndPostSystemJournal = getGlCreateAndPostHelper();

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [slRows] = await q.query(
      `SELECT * FROM bank_statement_lines WHERE id=? LIMIT 1 FOR UPDATE`,
      [bank_statement_line_id],
    );
    const line = slRows[0];
    if (!line) {
      const err = new Error("Bank statement line not found");
      err.statusCode = 404;
      throw err;
    }

    const [existing] = await q.query(
      `SELECT * FROM bank_reconciliation_auto_postings WHERE bank_statement_line_id=? LIMIT 1`,
      [line.id],
    );
    if (existing[0]) {
      if (conn) await conn.commit();
      return { auto_posting: existing[0], idempotent: true };
    }

    const [tplRows] = await q.query(
      `SELECT * FROM bank_reconciliation_posting_templates WHERE id=? LIMIT 1`,
      [template_id],
    );
    const template = tplRows[0];
    if (!template) {
      const err = new Error("Posting template not found");
      err.statusCode = 404;
      throw err;
    }

    validateTemplateAppliesToLine(template, line);

    const bankAccount = await getBankAccountWithGl(q, line.bank_account_id);
    if (!bankAccount || !bankAccount.gl_account_id) {
      const err = new Error("Bank account GL mapping missing");
      err.statusCode = 400;
      throw err;
    }

    const preview = await previewAutoPostFromTemplate(q, {
      bank_statement_line_id: line.id,
      template_id: template.id,
    });

    // Create + post GL journal (adapt to your GL helper)
    const glRes = await createAndPostSystemJournal(q, {
      journal_date: preview.journal_date,
      source_module: "BANK",
      source_type: "BANK_AUTO_POST",
      source_ref: `BSL:${line.id}`,
      doc_type: template.journal_doc_type || "BANK_AUTO",
      currency_code: line.currency_code,
      description: preview.narration,
      lines: preview.gl_lines,
      created_by: user_id,
    });

    const journalEntryId = Number(glRes.journal_entry_id);

    const [ins] = await q.query(
      `
      INSERT INTO bank_reconciliation_auto_postings
      (bank_statement_line_id, bank_reconciliation_posting_template_id, journal_entry_id, status, posted_amount, currency_code, payload_json, created_by)
      VALUES (?, ?, ?, 'POSTED', ?, ?, ?, ?)
      `,
      [
        line.id,
        template.id,
        journalEntryId,
        amount2(Math.abs(line.amount)),
        String(line.currency_code).toUpperCase(),
        JSON.stringify({ entry_kind: template.entry_kind }),
        user_id,
      ],
    );

    await q
      .query(
        `
      UPDATE bank_statement_lines
      SET auto_post_template_id = ?,
          auto_post_journal_entry_id = ?,
          updated_at = NOW()
      WHERE id = ?
      `,
        [template.id, journalEntryId, line.id],
      )
      .catch(() => {});

    if (conn) await conn.commit();

    const [rows] = await db.query(
      `SELECT * FROM bank_reconciliation_auto_postings WHERE id=? LIMIT 1`,
      [ins.insertId],
    );
    return {
      auto_posting: rows[0],
      journal_entry_id: journalEntryId,
      idempotent: false,
    };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

export default {
  previewAutoPostFromTemplate,
  autoPostFromTemplate,
};
```

---

## 5) Routes — `backend/src/routes/bank.reconciliationPostingTemplates.js`

```js id="b08routes"
// backend/src/routes/bank.reconciliationPostingTemplates.js

import express from "express";
import svc from "../services/bank.reconciliationPostingTemplates.service.js";
import autoPostSvc from "../services/bank.reconciliationAutoPosting.service.js";
import { validateTemplateIdParam,
  validateCreateTemplateBody,
  validateUpdateTemplateBody, } from "./bank.reconciliationPostingTemplates.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/bank/reconciliation/posting-templates
router.get(
  "/reconciliation/posting-templates",
  requireAuth,
  requirePermission("bank.recon.postTemplates.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const items = await svc.listPostingTemplates(db);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/posting-templates
router.post(
  "/reconciliation/posting-templates",
  requireAuth,
  requirePermission("bank.recon.postTemplates.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateTemplateBody(req.body);
      const item = await svc.createPostingTemplate(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json(item);
    } catch (err) {
      next(err);
    }
  },
);

// PATCH /api/v1/bank/reconciliation/posting-templates/:id
router.patch(
  "/reconciliation/posting-templates/:id",
  requireAuth,
  requirePermission("bank.recon.postTemplates.update"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateTemplateIdParam(req.params);
      const body = validateUpdateTemplateBody(req.body);
      const item = await svc.updatePostingTemplate(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// Optional helper endpoint for UI/testing
// POST /api/v1/bank/reconciliation/posting-templates/:id/preview
router.post(
  "/reconciliation/posting-templates/:id/preview",
  requireAuth,
  requirePermission("bank.recon.postTemplates.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateTemplateIdParam(req.params);
      const statementLineId = Number(req.body?.bank_statement_line_id);
      if (!Number.isInteger(statementLineId) || statementLineId <= 0) {
        throw new Error("bank_statement_line_id must be positive integer");
      }
      const result = await autoPostSvc.previewAutoPostFromTemplate(db, {
        bank_statement_line_id: statementLineId,
        template_id: id,
      });
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 6) Patch B07 engine — `backend/src/services/bank.reconciliationEngine.service.js` (important)

> Add support for rule action `AUTO_POST_TEMPLATE`.

### A) Add B08 + B03 helpers

```js id="b08eng1"
// patch snippet near top of B07 engine service

function getB03ReconcileGlHelper() {
  import svc from "./bank.reconciliation.service.js";
  if (typeof svc.reconcileStatementLineToGlJournalEntry !== "function") {
    const err = new Error(
      "B03 reconcile GL helper export missing: reconcileStatementLineToGlJournalEntry",
    );
    err.statusCode = 500;
    throw err;
  }
  return svc.reconcileStatementLineToGlJournalEntry;
}

async function getB08AutoPostService() {
  return (await import("./bank.reconciliationAutoPosting.service.js")).default;
}
```

### B) In `evaluateLineAgainstRules(...)`, support `AUTO_POST_TEMPLATE`

```js id="b08eng2"
// patch snippet inside evaluateLineAgainstRules(...)

if (actionType === "AUTO_POST_TEMPLATE") {
  const actionPayload = parseJsonField(rule.action_payload_json, {});
  const templateId = Number(actionPayload.template_id || 0);

  if (!Number.isInteger(templateId) || templateId <= 0) {
    return {
      matched: true,
      rule,
      outcome: {
        action: "QUEUE_EXCEPTION",
        reason_code: "POLICY_BLOCKED",
        reason_message: "AUTO_POST_TEMPLATE rule missing template_id",
        confidence: 0.2,
      },
    };
  }

  return {
    matched: true,
    rule,
    outcome: {
      action: "AUTO_POST_TEMPLATE",
      template_id: templateId,
      confidence: 0.9,
    },
  };
}
```

### C) In `previewAutoReconciliation(...)`, return preview action

```js id="b08eng3"
// patch snippet inside preview loop (before final push)

if (ev.outcome.action === "AUTO_POST_TEMPLATE") matched += 1;
```

And in pushed preview object:

```js id="b08eng4"
// add fields in preview item
template_id: ev.outcome.template_id || null,
```

### D) In `applyAutoReconciliation(...)`, execute auto-post + reconcile

```js id="b08eng5"
// patch snippet inside applyAutoReconciliation(...)

const reconcileStatementLineToGlJournalEntry = getB03ReconcileGlHelper();
const { autoPostFromTemplate } = getB08AutoPostService();

// inside per-line loop, before QUEUE_EXCEPTION branch:
if (ev.outcome.action === "AUTO_POST_TEMPLATE") {
  matched += 1;

  const postRes = await autoPostFromTemplate(db, {
    bank_statement_line_id: line.id,
    template_id: ev.outcome.template_id,
    user_id: userId,
  });

  await reconcileStatementLineToGlJournalEntry(db, {
    bank_statement_line_id: line.id,
    journal_entry_id: postRes.journal_entry_id,
    method: "RULE_AUTO",
    matched_rule_id: ev.rule?.id || null,
    confidence: ev.outcome.confidence ?? null,
    user_id: userId,
  });

  reconciled += 1;
  continue;
}
```

---

## 7) Patch B03 core service — `backend/src/services/bank.reconciliation.service.js` (important)

> Add a helper to reconcile statement lines to GL journals (same pattern as payment lines).

```js id="b08b03"
// patch snippet inside B03 service

async function reconcileStatementLineToGlJournalEntry(
  db,
  {
    bank_statement_line_id,
    journal_entry_id,
    method = "MANUAL",
    matched_rule_id = null,
    confidence = null,
    user_id = null,
  },
) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [slRows] = await q.query(
      `SELECT * FROM bank_statement_lines WHERE id=? LIMIT 1 FOR UPDATE`,
      [bank_statement_line_id],
    );
    const sl = slRows[0];
    if (!sl) {
      const err = new Error("Bank statement line not found");
      err.statusCode = 404;
      throw err;
    }
    if (
      String(sl.reconciliation_status || "OPEN").toUpperCase() === "RECONCILED"
    ) {
      if (conn) await conn.commit();
      return { idempotent: true, statement_line_id: sl.id };
    }

    const [jeRows] = await q.query(
      `SELECT * FROM journal_entries WHERE id=? LIMIT 1 FOR UPDATE`,
      [journal_entry_id],
    );
    const je = jeRows[0];
    if (!je) {
      const err = new Error("Journal entry not found");
      err.statusCode = 404;
      throw err;
    }

    await q.query(
      `
      INSERT INTO bank_reconciliations
      (bank_statement_line_id, target_type, target_id, amount, currency_code, method, matched_rule_id, confidence, created_by)
      VALUES (?, 'GL_JOURNAL_ENTRY', ?, ?, ?, ?, ?, ?, ?)
      `,
      [
        sl.id,
        je.id,
        sl.amount,
        sl.currency_code,
        method,
        matched_rule_id,
        confidence,
        user_id,
      ],
    );

    await q.query(
      `
      UPDATE bank_statement_lines
      SET reconciliation_status='RECONCILED',
          reconciled_at=NOW(),
          reconciliation_method=?,
          reconciliation_rule_id=?,
          reconciliation_confidence=?,
          updated_at=NOW()
      WHERE id=?
      `,
      [method, matched_rule_id, confidence, sl.id],
    );

    await q
      .query(
        `
      UPDATE bank_reconciliation_exceptions
      SET status='RESOLVED',
          resolved_by=?,
          resolved_at=NOW(),
          resolution_code='RECONCILED',
          resolution_note='Auto-closed on reconciliation',
          updated_at=NOW()
      WHERE bank_statement_line_id=?
        AND status IN ('OPEN','ASSIGNED')
      `,
        [user_id, sl.id],
      )
      .catch(() => {});

    if (conn) await conn.commit();

    return {
      idempotent: false,
      statement_line_id: sl.id,
      journal_entry_id: je.id,
    };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

// export it
export default {
  // existing exports...
  reconcileStatementLineToGlJournalEntry,
};
```

---

## 8) Patch GL service — `backend/src/services/gl.journals.service.js` (important)

> Export a reusable helper B08 can call to create/post balanced journals.

```js id="b08gl"
// patch snippet in your GL journal service (adapt to your real service)

async function createAndPostSystemJournal(db, payload) {
  // payload:
  // {
  //   journal_date, source_module, source_type, source_ref,
  //   doc_type, currency_code, description, lines, created_by
  // }

  // Reuse your existing GL create + post logic here.
  // Keep this helper thin and delegate to existing validated flows.

  // Example expected return:
  // { journal_entry_id: 12345, posted: true }

  // If you already have createJournal(...) + postJournal(...), just wrap them:
  // const draft = await createJournal(db, ...)
  // await postJournal(db, draft.id, ...)
  // return { journal_entry_id: draft.id, posted: true }

  throw new Error(
    "Implement createAndPostSystemJournal by wrapping existing GL create/post functions",
  );
}

export default {
  // existing exports...
  createAndPostSystemJournal,
};
```

---

## 9) Mount route — `backend/src/index.js`

```js id="b08idx"
// backend/src/index.js
import bankReconciliationPostingTemplatesRoutes from "./routes/bank.reconciliationPostingTemplates.js";
// ...
app.use("/api/v1/bank", bankReconciliationPostingTemplatesRoutes);
```

---

## 10) Migration registry — `backend/src/migrations/index.js`

```js id="b08migidx"
// backend/src/migrations/index.js
import m048_bank_recon_autopost_templates from "./m048_bank_recon_autopost_templates.js";
export default [
  // ...
  m048_bank_recon_autopost_templates,
];
```

---

## 11) Seed permissions — `backend/src/seedCore.js`

```js id="b08perm"
// backend/src/seedCore.js
const BANK_B08_PERMISSIONS = [
  "bank.recon.postTemplates.read",
  "bank.recon.postTemplates.create",
  "bank.recon.postTemplates.update",
];

// merge into permission seed list
```

> Note: auto-run execution still uses existing `bank.recon.auto.run` from B07.

---

## 12) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/bank/reconciliation/posting-templates`
- `POST /api/v1/bank/reconciliation/posting-templates`
- `PATCH /api/v1/bank/reconciliation/posting-templates/{id}`
- `POST /api/v1/bank/reconciliation/posting-templates/{id}/preview`

Also document B07 rule action extension:

- `action_type = AUTO_POST_TEMPLATE`
- `action_payload.template_id`

And document new B03 reconciliation target:

- `target_type = GL_JOURNAL_ENTRY`

---

## 13) Backend smoke test — `backend/scripts/test-bank-prb08-autopost-templates.js`

```js id="b08smoke"
// backend/scripts/test-bank-prb08-autopost-templates.js

async function main() {
  // Preconditions:
  // - B03/B07 implemented
  // - GL service has reusable createAndPostSystemJournal helper
  // - bank_accounts have gl_account_id mapping
  // - unreconciled bank statement lines exist (fees / interest patterns)
  //
  // Flow A: Template setup
  // 1) Create template: BANK_FEE_EXPENSE (OUTFLOW_ONLY, counter_account_id=Bank Fees Expense)
  // 2) Create template: BANK_INTEREST_INCOME (INFLOW_ONLY, counter_account_id=Interest Income)
  //
  // Flow B: Rule setup (B07)
  // 3) Create rule "BANK FEE" text pattern -> action AUTO_POST_TEMPLATE(template fee)
  // 4) Create rule "INTEREST" text pattern -> action AUTO_POST_TEMPLATE(template interest)
  //
  // Flow C: Preview
  // 5) Auto-preview shows action=AUTO_POST_TEMPLATE and template_id for matching lines
  //    -> no GL journal created
  //    -> no reconciliation yet
  //
  // Flow D: Apply
  // 6) Auto-apply:
  //    -> creates GL journal for matched fee/interest lines
  //    -> creates bank_reconciliation_auto_postings row
  //    -> reconciles statement line to GL_JOURNAL_ENTRY via B03 helper
  //    -> statement line reconciliation metadata saved (RULE_AUTO + rule_id)
  //
  // Flow E: Idempotency
  // 7) Re-run auto-apply on same lines
  //    -> no duplicate GL journals for already auto-posted/reconciled lines
  //
  // Flow F: Error -> exception
  // 8) Remove bank account GL mapping (or invalid template scope)
  //    -> apply creates/updates exception queue item (APPLY_ERROR/POLICY_BLOCKED)
  //
  // Permissions:
  // - bank.recon.postTemplates.read/create/update enforced (403)
  // - bank.recon.auto.run still required for apply
  console.log("PR-B08 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 14) `backend/package.json` updates

```json id="b08pkg"
{
  "scripts": {
    "test:bank:prb08": "node backend/scripts/test-bank-prb08-autopost-templates.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 15) API client — `frontend/src/api/bankReconciliationPostingTemplates.js`

```js id="b08feapi"
// frontend/src/api/bankReconciliationPostingTemplates.js

import { apiFetch } from "./client.js"; // adapt

export function listBankReconciliationPostingTemplates() {
  return apiFetch("/api/v1/bank/reconciliation/posting-templates");
}

export function createBankReconciliationPostingTemplate(payload) {
  return apiFetch("/api/v1/bank/reconciliation/posting-templates", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function updateBankReconciliationPostingTemplate(templateId, payload) {
  return apiFetch(
    `/api/v1/bank/reconciliation/posting-templates/${templateId}`,
    {
      method: "PATCH",
      body: JSON.stringify(payload),
    },
  );
}

export function previewBankReconciliationPostingTemplate(
  templateId,
  bankStatementLineId,
) {
  return apiFetch(
    `/api/v1/bank/reconciliation/posting-templates/${templateId}/preview`,
    {
      method: "POST",
      body: JSON.stringify({ bank_statement_line_id: bankStatementLineId }),
    },
  );
}
```

---

## 16) `BankReconciliationPage.jsx` — key snippets only

### Add imports

```jsx id="b08feimp"
import {
  listBankReconciliationPostingTemplates,
  createBankReconciliationPostingTemplate,
  previewBankReconciliationPostingTemplate,
} from "../../api/bankReconciliationPostingTemplates.js";
```

### Add state

```jsx id="b08fest"
const [postingTemplates, setPostingTemplates] = useState([]);
const [autoPostPreview, setAutoPostPreview] = useState(null);
const [postTemplateErr, setPostTemplateErr] = useState("");
```

### Load templates

```jsx id="b08feload"
async function loadPostingTemplates() {
  const res = await listBankReconciliationPostingTemplates();
  setPostingTemplates(res.items || []);
}
```

### Create starter templates (examples)

```jsx id="b08fecreate"
async function onCreateStarterFeeTemplate() {
  try {
    setPostTemplateErr("");
    await createBankReconciliationPostingTemplate({
      template_code: "BANK_FEE_EXP_001",
      template_name: "Bank fee expense (generic)",
      entry_kind: "BANK_FEE_EXPENSE",
      direction_policy: "OUTFLOW_ONLY",
      counter_account_id: 6101, // replace with your actual GL account id
      description_mode: "PREFIXED",
      description_prefix: "Bank Fee:",
      status: "ACTIVE",
    });
    await loadPostingTemplates();
  } catch (e) {
    setPostTemplateErr(e.message || "Template create failed");
  }
}

async function onCreateStarterInterestTemplate() {
  try {
    setPostTemplateErr("");
    await createBankReconciliationPostingTemplate({
      template_code: "BANK_INT_INC_001",
      template_name: "Bank interest income (generic)",
      entry_kind: "BANK_INTEREST_INCOME",
      direction_policy: "INFLOW_ONLY",
      counter_account_id: 7201, // replace with your actual GL account id
      description_mode: "PREFIXED",
      description_prefix: "Bank Interest:",
      status: "ACTIVE",
    });
    await loadPostingTemplates();
  } catch (e) {
    setPostTemplateErr(e.message || "Template create failed");
  }
}
```

### Preview template against selected statement line (optional UX)

```jsx id="b08feprev"
async function onPreviewTemplate(templateId, statementLineId) {
  try {
    setPostTemplateErr("");
    const res = await previewBankReconciliationPostingTemplate(
      templateId,
      statementLineId,
    );
    setAutoPostPreview(res);
  } catch (e) {
    setPostTemplateErr(e.message || "Template preview failed");
  }
}
```

### Compact UI block

```jsx id="b08feui"
{
  /* Auto-Posting Templates Panel */
}
<div className="rounded border bg-white p-4 mt-4">
  <h2 className="font-medium mb-2">Auto-Posting Templates</h2>

  {/* Buttons:
      - Create Fee Template
      - Create Interest Template
      - Preview Template on Selected Statement Line
  */}

  {postTemplateErr ? (
    <div className="text-sm text-red-600">{postTemplateErr}</div>
  ) : null}

  <div className="text-sm mt-2 space-y-1">
    {/* template_code, template_name, entry_kind, direction_policy, counter_account_id, status */}
  </div>

  <div className="text-sm mt-3 space-y-1">
    {/* auto-post preview:
        journal_date, narration, gl_lines (2-line summary)
    */}
  </div>
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Can create/list/update bank reconciliation auto-post templates
- ✅ Templates support effective dates, scope, direction policy, amount/currency safety limits
- ✅ B07 rules can use `action_type = AUTO_POST_TEMPLATE` with `action_payload.template_id`
- ✅ Auto-preview shows template action without creating journals
- ✅ Auto-apply creates GL journal via reusable GL helper (system-posted)
- ✅ Auto-apply writes `bank_reconciliation_auto_postings` trace row (idempotent per statement line)
- ✅ Auto-apply reconciles statement line to `GL_JOURNAL_ENTRY` via B03 helper
- ✅ Reconciled statement line stores rule/method metadata (from B07/B03)
- ✅ Posting/template errors route to B07 exception queue (no silent failures)
- ✅ Permissions enforced (`bank.recon.postTemplates.*` + existing `bank.recon.auto.run`)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:bank:prb08`

Should verify at least:

1. **Template management**

   - Create fee and interest templates
   - Update template status/scope/limits
   - List templates returns expected fields

2. **Rule integration**

   - B07 rule with `AUTO_POST_TEMPLATE` returns preview action with `template_id`

3. **Auto-post apply**

   - Matching fee line creates GL journal (`Dr Fee Expense / Cr Bank`)
   - Matching interest line creates GL journal (`Dr Bank / Cr Interest Income`)
   - `bank_reconciliation_auto_postings` row created
   - B03 reconciliation row created with `target_type=GL_JOURNAL_ENTRY`

4. **Idempotency**

   - Re-run apply does not create duplicate journal for same statement line

5. **Safety**

   - Template direction mismatch (e.g., inflow line with outflow template) fails safely
   - Missing bank GL account mapping fails safely
   - Failures generate/refresh exception queue items

6. **Permissions**

   - `bank.recon.postTemplates.read/create/update` enforced (`403`)
   - `bank.recon.auto.run` still required for apply

---

## Tiny implementation notes (important)

- Start with **2 templates** only:

  1. `BANK_FEE_EXPENSE`
  2. `BANK_INTEREST_INCOME`

- Keep `tax_mode = NONE` in v1.
  Tax/VAT split for bank fees can be a later PR if needed.
- This PR makes B07 much stronger because many unmatched bank lines become auto-postable (not just payment-matching).

---

Perfect — let’s lock the numbering cleanly.

Here’s **PR-B08-B** as the **remaining part of B08** (returns / rejections / FX handling), while keeping your previous **B08-A** (fees/interest auto-post templates) intact.

# PR-B08-B: Payment Returns / Rejections / FX Difference Handling (Bank Side Completion)

## Goal

Complete the remaining **Bank B08** scope by adding:

- ✅ Payment return / rejection event handling (bank side)
- ✅ Return status tracking on payment batch lines (B04/B06-compatible)
- ✅ Difference handling for matched payments (fees / FX deltas)
- ✅ Auto-post GL adjustment journals for differences (via profiles)
- ✅ Reconciliation stays in B03 (source of truth)
- ✅ B07 rules can route lines to:

  - `PROCESS_PAYMENT_RETURN`
  - `AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE`

This PR complements:

- **B06** export/ack execution
- **B07** rules + exception queue
- **B08-A** standalone fee/interest auto-post templates

---

## Key design rule (important)

**B08-B handles bank-side outcomes and reconciliation deltas.**
It does **not** replace domain logic (Payroll/AP) for payable reopening.

That means:

- We **do** track returned/rejected payment execution and reconcile the bank line
- We **do** update payment batch line status/returned amounts
- We **do not** automatically reopen payroll/AP liabilities here (domain module follow-up can consume these events)

This keeps bank module generic and reusable.

---

## Important behavior rules

### 1) Returns/rejections are events, not silent status flips

Every detected return/rejection creates a trace row:

- who/when
- source (ack or statement)
- linked payment line
- amount
- reason/code

### 2) Difference handling is explicit

When a statement line matches a payment line but amount differs:

- exact match → normal B03 reconcile
- non-exact match → use a **difference profile** (fee/FX) if allowed
- otherwise → B07 exception

### 3) Difference posting is idempotent per statement line

A statement line can only create one active difference adjustment journal.

### 4) B03 still writes the reconciliation record

Even if a difference journal is posted, the bank statement line is still reconciled through B03.

---

## Files to create

### Backend

- `backend/src/migrations/m049_bank_returns_and_recon_differences.js`
- `backend/src/routes/bank.paymentReturns.js`
- `backend/src/routes/bank.paymentReturns.validators.js`
- `backend/src/routes/bank.reconciliationDifferenceProfiles.js`
- `backend/src/routes/bank.reconciliationDifferenceProfiles.validators.js`
- `backend/src/services/bank.paymentReturns.service.js`
- `backend/src/services/bank.reconciliationDifferenceProfiles.service.js`
- `backend/src/services/bank.reconciliationDifferences.service.js`
- `backend/scripts/test-bank-prb08b-returns-rejections-fx.js`

### Frontend (short snippets only)

- `frontend/src/api/bankPaymentReturns.js`
- `frontend/src/api/bankReconciliationDifferenceProfiles.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (important patches)

- `backend/src/services/bank.reconciliationEngine.service.js` _(B07 engine)_

  - add rule actions:

    - `PROCESS_PAYMENT_RETURN`
    - `AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE`

- `backend/src/services/bank.reconciliation.service.js` _(B03 core)_

  - allow reconciliation metadata for difference adjustments

- `backend/src/services/bank.paymentBatches.service.js` _(B04/B06 line statuses)_

  - support return statuses and returned amounts

- `backend/src/services/gl.journals.service.js` _(from B08-A)_

  - reuse `createAndPostSystemJournal`

### Frontend (short integration only)

- `frontend/src/pages/bank/BankReconciliationPage.jsx`

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m049_bank_returns_and_recon_differences.js`

```js id="b08bm35"
// backend/src/migrations/m049_bank_returns_and_recon_differences.js

export default {
  key: "m049_bank_returns_and_recon_differences",
  description: "m049_bank_returns_and_recon_differences",
  async up(connection) {
    // Extend payment batch line execution tracking (B04/B06)
    await db
      .query(
        `
      ALTER TABLE payment_batch_lines
        ADD COLUMN return_status VARCHAR(20) NULL AFTER ack_status,      -- RETURNED, PARTIALLY_RETURNED, REJECTED_POST_ACK
        ADD COLUMN returned_amount DECIMAL(18,2) NOT NULL DEFAULT 0 AFTER executed_amount,
        ADD COLUMN return_reason_code VARCHAR(50) NULL AFTER return_status,
        ADD COLUMN last_returned_at DATETIME NULL AFTER return_reason_code
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE payment_batch_lines
        ADD KEY idx_pbl_return_status (return_status)
    `,
      )
      .catch(() => {});

    // Statement-line reconciliation delta metadata
    await db
      .query(
        `
      ALTER TABLE bank_statement_lines
        ADD COLUMN reconciliation_difference_type VARCHAR(20) NULL AFTER reconciliation_confidence, -- FEE, FX
        ADD COLUMN reconciliation_difference_amount DECIMAL(18,2) NULL AFTER reconciliation_difference_type,
        ADD COLUMN reconciliation_difference_journal_entry_id BIGINT UNSIGNED NULL AFTER reconciliation_difference_amount
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE bank_statement_lines
        ADD KEY idx_bsl_diff_journal (reconciliation_difference_journal_entry_id)
    `,
      )
      .catch(() => {});

    // Return/rejection event log (bank-side trace)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_payment_return_events (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        event_request_id VARCHAR(190) NULL,
        source_type VARCHAR(20) NOT NULL, -- ACK, STATEMENT, MANUAL
        source_ref VARCHAR(190) NULL,     -- ack import row ref / statement line ref / manual note ref

        payment_batch_line_id BIGINT UNSIGNED NOT NULL,
        bank_statement_line_id BIGINT UNSIGNED NULL,
        bank_payment_ack_import_line_id BIGINT UNSIGNED NULL,

        event_type VARCHAR(30) NOT NULL, -- PAYMENT_RETURNED, PAYMENT_REJECTED, PAYMENT_REVERSAL
        event_status VARCHAR(20) NOT NULL DEFAULT 'CONFIRMED', -- DETECTED, CONFIRMED, IGNORED

        amount DECIMAL(18,2) NOT NULL,
        currency_code CHAR(3) NOT NULL,
        bank_reference VARCHAR(190) NULL,
        reason_code VARCHAR(50) NULL,
        reason_message VARCHAR(255) NULL,

        payload_json JSON NULL,
        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bpre_request_id (event_request_id),
        KEY idx_bpre_pbl (payment_batch_line_id),
        KEY idx_bpre_statement_line (bank_statement_line_id),
        KEY idx_bpre_event_type (event_type),

        CONSTRAINT fk_bpre_pbl
          FOREIGN KEY (payment_batch_line_id) REFERENCES payment_batch_lines(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_bpre_statement_line
          FOREIGN KEY (bank_statement_line_id) REFERENCES bank_statement_lines(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Difference profiles (fee/FX) for matched-payment amount deltas
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_reconciliation_difference_profiles (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        profile_code VARCHAR(50) NOT NULL,
        profile_name VARCHAR(190) NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE', -- ACTIVE, PAUSED, DISABLED

        scope_type VARCHAR(20) NOT NULL DEFAULT 'GLOBAL', -- GLOBAL, BANK_ACCOUNT
        bank_account_id BIGINT UNSIGNED NULL,

        difference_type VARCHAR(20) NOT NULL, -- FEE, FX
        direction_policy VARCHAR(20) NOT NULL DEFAULT 'BOTH', -- INCREASE_ONLY, DECREASE_ONLY, BOTH
        tolerance_mode VARCHAR(20) NOT NULL DEFAULT 'ABSOLUTE', -- ABSOLUTE, PERCENT (ABSOLUTE only in v1)
        max_abs_difference DECIMAL(18,2) NOT NULL DEFAULT 0,

        // For FEE: usually expense account
        expense_account_id BIGINT UNSIGNED NULL,

        // For FX: gain/loss accounts
        fx_gain_account_id BIGINT UNSIGNED NULL,
        fx_loss_account_id BIGINT UNSIGNED NULL,

        currency_code CHAR(3) NULL, -- optional safety
        description_prefix VARCHAR(100) NULL,

        effective_from DATE NULL,
        effective_to DATE NULL,

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_brdp_code (profile_code),
        KEY idx_brdp_status (status),
        KEY idx_brdp_scope (scope_type, bank_account_id),
        KEY idx_brdp_type (difference_type)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Difference adjustment trace (idempotent per statement line)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_reconciliation_difference_adjustments (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_statement_line_id BIGINT UNSIGNED NOT NULL,
        payment_batch_line_id BIGINT UNSIGNED NOT NULL,
        bank_reconciliation_difference_profile_id BIGINT UNSIGNED NOT NULL,

        difference_type VARCHAR(20) NOT NULL, -- FEE, FX
        difference_amount DECIMAL(18,2) NOT NULL,
        currency_code CHAR(3) NOT NULL,

        journal_entry_id BIGINT UNSIGNED NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'POSTED', -- POSTED, REVERSED

        payload_json JSON NULL,
        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_brda_statement_line (bank_statement_line_id),
        KEY idx_brda_payment_line (payment_batch_line_id),
        KEY idx_brda_profile (bank_reconciliation_difference_profile_id),
        KEY idx_brda_journal (journal_entry_id),

        CONSTRAINT fk_brda_statement_line
          FOREIGN KEY (bank_statement_line_id) REFERENCES bank_statement_lines(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_brda_payment_line
          FOREIGN KEY (payment_batch_line_id) REFERENCES payment_batch_lines(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT,

        CONSTRAINT fk_brda_profile
          FOREIGN KEY (bank_reconciliation_difference_profile_id) REFERENCES bank_reconciliation_difference_profiles(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(
      `DROP TABLE IF EXISTS bank_reconciliation_difference_adjustments;`,
    );
    await connection.execute(
      `DROP TABLE IF EXISTS bank_reconciliation_difference_profiles;`,
    );
    await connection.execute(`DROP TABLE IF EXISTS bank_payment_return_events;`);
    // Optional strict down for ALTER columns omitted
  },
};
```

---

## 2) Validators — `backend/src/routes/bank.paymentReturns.validators.js`

```js id="b08bretval"
// backend/src/routes/bank.paymentReturns.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}
function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}
function normalizeNumber(v, field) {
  const n = Number(v);
  if (!Number.isFinite(n)) throw new Error(`${field} must be a valid number`);
  return n;
}

function validateReturnEventIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateListReturnEventsQuery(query = {}) {
  return {
    event_type: normalizeString(query.event_type)?.toUpperCase() || null,
    event_status: normalizeString(query.event_status)?.toUpperCase() || null,
    payment_batch_id: query.payment_batch_id
      ? requirePositiveInt(query.payment_batch_id, "payment_batch_id")
      : null,
    limit: query.limit ? Math.min(500, Math.max(1, Number(query.limit))) : 100,
  };
}

function validateCreateManualReturnBody(body = {}) {
  return {
    event_request_id: normalizeString(body.event_request_id),
    payment_batch_line_id: requirePositiveInt(
      body.payment_batch_line_id,
      "payment_batch_line_id",
    ),
    bank_statement_line_id: body.bank_statement_line_id
      ? requirePositiveInt(
          body.bank_statement_line_id,
          "bank_statement_line_id",
        )
      : null,
    event_type: String(body.event_type || "PAYMENT_RETURNED")
      .trim()
      .toUpperCase(),
    amount: normalizeNumber(body.amount, "amount"),
    currency_code: String(body.currency_code || "")
      .trim()
      .toUpperCase(),
    bank_reference: normalizeString(body.bank_reference),
    reason_code: normalizeString(body.reason_code)?.toUpperCase() || null,
    reason_message: normalizeString(body.reason_message),
    source_type: "MANUAL",
    source_ref: normalizeString(body.source_ref),
  };
}

function validateIgnoreReturnEventBody(body = {}) {
  return {
    reason_message:
      normalizeString(body.reason_message) || "Ignored by reviewer",
  };
}

export default {
  validateReturnEventIdParam,
  validateListReturnEventsQuery,
  validateCreateManualReturnBody,
  validateIgnoreReturnEventBody,
};
```

---

## 3) Validators — `backend/src/routes/bank.reconciliationDifferenceProfiles.validators.js`

```js id="b08bdiffval"
// backend/src/routes/bank.reconciliationDifferenceProfiles.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}
function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}
function normalizeDecimal(v) {
  if (v === undefined || v === null || v === "") return null;
  const n = Number(v);
  if (!Number.isFinite(n)) throw new Error(`Invalid number: ${v}`);
  return n;
}

function validateProfileIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreateDifferenceProfileBody(body = {}) {
  return {
    profile_code:
      normalizeString(body.profile_code) ||
      (() => {
        throw new Error("profile_code is required");
      })(),
    profile_name:
      normalizeString(body.profile_name) ||
      (() => {
        throw new Error("profile_name is required");
      })(),
    status: String(body.status || "ACTIVE")
      .trim()
      .toUpperCase(),
    scope_type: String(body.scope_type || "GLOBAL")
      .trim()
      .toUpperCase(),
    bank_account_id: body.bank_account_id
      ? requirePositiveInt(body.bank_account_id, "bank_account_id")
      : null,

    difference_type:
      String(body.difference_type || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("difference_type is required");
      })(),
    direction_policy: String(body.direction_policy || "BOTH")
      .trim()
      .toUpperCase(),
    tolerance_mode: "ABSOLUTE",
    max_abs_difference: normalizeDecimal(body.max_abs_difference) ?? 0,

    expense_account_id: body.expense_account_id
      ? requirePositiveInt(body.expense_account_id, "expense_account_id")
      : null,
    fx_gain_account_id: body.fx_gain_account_id
      ? requirePositiveInt(body.fx_gain_account_id, "fx_gain_account_id")
      : null,
    fx_loss_account_id: body.fx_loss_account_id
      ? requirePositiveInt(body.fx_loss_account_id, "fx_loss_account_id")
      : null,

    currency_code: normalizeString(body.currency_code)?.toUpperCase() || null,
    description_prefix: normalizeString(body.description_prefix),

    effective_from: normalizeString(body.effective_from),
    effective_to: normalizeString(body.effective_to),
  };
}

function validateUpdateDifferenceProfileBody(body = {}) {
  return {
    profile_name:
      body.profile_name !== undefined
        ? normalizeString(body.profile_name)
        : undefined,
    status: body.status ? String(body.status).trim().toUpperCase() : null,
    max_abs_difference:
      body.max_abs_difference !== undefined
        ? normalizeDecimal(body.max_abs_difference)
        : undefined,
    expense_account_id:
      body.expense_account_id !== undefined
        ? body.expense_account_id
          ? requirePositiveInt(body.expense_account_id, "expense_account_id")
          : null
        : undefined,
    fx_gain_account_id:
      body.fx_gain_account_id !== undefined
        ? body.fx_gain_account_id
          ? requirePositiveInt(body.fx_gain_account_id, "fx_gain_account_id")
          : null
        : undefined,
    fx_loss_account_id:
      body.fx_loss_account_id !== undefined
        ? body.fx_loss_account_id
          ? requirePositiveInt(body.fx_loss_account_id, "fx_loss_account_id")
          : null
        : undefined,
    currency_code:
      body.currency_code !== undefined
        ? normalizeString(body.currency_code)?.toUpperCase() || null
        : undefined,
    effective_from:
      body.effective_from !== undefined
        ? normalizeString(body.effective_from)
        : undefined,
    effective_to:
      body.effective_to !== undefined
        ? normalizeString(body.effective_to)
        : undefined,
  };
}

export default {
  validateProfileIdParam,
  validateCreateDifferenceProfileBody,
  validateUpdateDifferenceProfileBody,
};
```

---

## 4) Service — `backend/src/services/bank.paymentReturns.service.js`

```js id="b08bretsvc"
// backend/src/services/bank.paymentReturns.service.js

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

async function listPaymentReturnEvents(db, filters = {}) {
  const where = [];
  const args = [];

  if (filters.event_type) {
    where.push(`e.event_type = ?`);
    args.push(filters.event_type);
  }
  if (filters.event_status) {
    where.push(`e.event_status = ?`);
    args.push(filters.event_status);
  }
  if (filters.payment_batch_id) {
    where.push(`pbl.payment_batch_id = ?`);
    args.push(filters.payment_batch_id);
  }

  const [rows] = await db.query(
    `
    SELECT
      e.*,
      pbl.payment_batch_id,
      pbl.status AS payment_line_status,
      pbl.return_status,
      pbl.returned_amount,
      sl.booking_date,
      sl.amount AS statement_amount,
      sl.description AS statement_description
    FROM bank_payment_return_events e
    JOIN payment_batch_lines pbl ON pbl.id = e.payment_batch_line_id
    LEFT JOIN bank_statement_lines sl ON sl.id = e.bank_statement_line_id
    ${where.length ? `WHERE ${where.join(" AND ")}` : ""}
    ORDER BY e.id DESC
    LIMIT ?
    `,
    [...args, filters.limit || 100],
  );
  return rows;
}

async function applyReturnEffectsToPaymentLine(q, paymentBatchLineId, event) {
  const [rows] = await q.query(
    `SELECT * FROM payment_batch_lines WHERE id=? LIMIT 1 FOR UPDATE`,
    [paymentBatchLineId],
  );
  const line = rows[0];
  if (!line) {
    const err = new Error("Payment batch line not found");
    err.statusCode = 404;
    throw err;
  }

  const currentReturned = amount2(line.returned_amount || 0);
  const lineAmount = amount2(Math.abs(line.amount || 0));
  const eventAmt = amount2(Math.abs(event.amount || 0));

  let newReturned = currentReturned;
  if (event.event_type === "PAYMENT_REJECTED") {
    // Rejected before actual paid settlement; keep returned_amount as-is (usually 0)
    newReturned = currentReturned;
  } else {
    if (currentReturned + eventAmt > lineAmount) {
      const err = new Error(
        `Return amount exceeds line amount for payment line ${line.id}`,
      );
      err.statusCode = 409;
      throw err;
    }
    newReturned = amount2(currentReturned + eventAmt);
  }

  let returnStatus = null;
  let lineStatus = line.status;

  if (event.event_type === "PAYMENT_REJECTED") {
    returnStatus = "REJECTED_POST_ACK";
    if (
      ["EXPORTED", "EXECUTED"].includes(String(line.status || "").toUpperCase())
    )
      lineStatus = "REJECTED";
  } else {
    returnStatus =
      newReturned >= lineAmount ? "RETURNED" : "PARTIALLY_RETURNED";

    if (
      newReturned >= lineAmount &&
      ["PAID", "PARTIALLY_PAID", "EXECUTED"].includes(
        String(line.status || "").toUpperCase(),
      )
    ) {
      lineStatus = "RETURNED";
    } else if (
      newReturned > 0 &&
      ["PAID", "EXECUTED"].includes(String(line.status || "").toUpperCase())
    ) {
      lineStatus = "PARTIALLY_RETURNED";
    }
  }

  await q.query(
    `
    UPDATE payment_batch_lines
    SET
      returned_amount = ?,
      return_status = ?,
      return_reason_code = ?,
      last_returned_at = NOW(),
      status = ?
    WHERE id = ?
    `,
    [newReturned, returnStatus, event.reason_code || null, lineStatus, line.id],
  );

  await q
    .query(
      `INSERT INTO payment_batch_line_audit (payment_batch_line_id, action, payload_json, acted_by)
     VALUES (?, ?, ?, ?)`,
      [
        line.id,
        "BANK_RETURN_APPLIED",
        JSON.stringify({
          event_type: event.event_type,
          amount: event.amount,
          currency_code: event.currency_code,
          return_status: returnStatus,
          returned_amount: newReturned,
        }),
        event.created_by || null,
      ],
    )
    .catch(() => {});
}

async function createPaymentReturnEvent(db, body, userId = null) {
  if (body.event_request_id) {
    const [existing] = await db.query(
      `SELECT * FROM bank_payment_return_events WHERE event_request_id=? LIMIT 1`,
      [body.event_request_id],
    );
    if (existing[0]) return { item: existing[0], idempotent: true };
  }

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [pblRows] = await q.query(
      `SELECT * FROM payment_batch_lines WHERE id=? LIMIT 1`,
      [body.payment_batch_line_id],
    );
    const pbl = pblRows[0];
    if (!pbl) {
      const err = new Error("Payment batch line not found");
      err.statusCode = 404;
      throw err;
    }

    if (
      String(pbl.currency_code || "").toUpperCase() !==
      String(body.currency_code || "").toUpperCase()
    ) {
      const err = new Error(
        "Currency mismatch between return event and payment line",
      );
      err.statusCode = 400;
      throw err;
    }

    const [ins] = await q.query(
      `
      INSERT INTO bank_payment_return_events
      (event_request_id, source_type, source_ref, payment_batch_line_id, bank_statement_line_id, event_type, event_status,
       amount, currency_code, bank_reference, reason_code, reason_message, payload_json, created_by)
      VALUES (?, ?, ?, ?, ?, ?, 'CONFIRMED', ?, ?, ?, ?, ?, ?, ?)
      `,
      [
        body.event_request_id || null,
        body.source_type || "MANUAL",
        body.source_ref || null,
        body.payment_batch_line_id,
        body.bank_statement_line_id || null,
        body.event_type,
        amount2(Math.abs(body.amount)),
        body.currency_code,
        body.bank_reference || null,
        body.reason_code || null,
        body.reason_message || null,
        JSON.stringify({ created_via: body.source_type || "MANUAL" }),
        userId,
      ],
    );

    const eventId = ins.insertId;
    const [eventRows] = await q.query(
      `SELECT * FROM bank_payment_return_events WHERE id=? LIMIT 1`,
      [eventId],
    );
    const event = eventRows[0];

    await applyReturnEffectsToPaymentLine(q, body.payment_batch_line_id, {
      ...event,
      created_by: userId,
    });

    if (conn) await conn.commit();

    return { item: event, idempotent: false };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function ignorePaymentReturnEvent(db, eventId, body, userId = null) {
  const [rows] = await db.query(
    `SELECT * FROM bank_payment_return_events WHERE id=? LIMIT 1`,
    [eventId],
  );
  const ev = rows[0];
  if (!ev) {
    const err = new Error("Payment return event not found");
    err.statusCode = 404;
    throw err;
  }

  if (String(ev.event_status) === "IGNORED") return ev;

  await db.query(
    `UPDATE bank_payment_return_events SET event_status='IGNORED', reason_message=?, created_by=COALESCE(created_by, ?) WHERE id=?`,
    [body.reason_message || ev.reason_message || "Ignored", userId, eventId],
  );

  const [updated] = await db.query(
    `SELECT * FROM bank_payment_return_events WHERE id=? LIMIT 1`,
    [eventId],
  );
  return updated[0];
}

export default {
  listPaymentReturnEvents,
  createPaymentReturnEvent,
  ignorePaymentReturnEvent,
};
```

---

## 5) Service — `backend/src/services/bank.reconciliationDifferenceProfiles.service.js`

```js id="b08bdiffprofilesvc"
// backend/src/services/bank.reconciliationDifferenceProfiles.service.js

async function listDifferenceProfiles(db) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_difference_profiles ORDER BY status='ACTIVE' DESC, id DESC`,
  );
  return rows;
}

async function getDifferenceProfile(db, id) {
  const [rows] = await db.query(
    `SELECT * FROM bank_reconciliation_difference_profiles WHERE id=? LIMIT 1`,
    [id],
  );
  return rows[0] || null;
}

async function createDifferenceProfile(db, body, userId = null) {
  const [ins] = await db.query(
    `
    INSERT INTO bank_reconciliation_difference_profiles
    (profile_code, profile_name, status, scope_type, bank_account_id, difference_type, direction_policy,
     tolerance_mode, max_abs_difference, expense_account_id, fx_gain_account_id, fx_loss_account_id,
     currency_code, description_prefix, effective_from, effective_to, created_by, updated_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, 'ABSOLUTE', ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      body.profile_code,
      body.profile_name,
      body.status || "ACTIVE",
      body.scope_type || "GLOBAL",
      body.bank_account_id || null,
      body.difference_type,
      body.direction_policy || "BOTH",
      body.max_abs_difference || 0,
      body.expense_account_id || null,
      body.fx_gain_account_id || null,
      body.fx_loss_account_id || null,
      body.currency_code || null,
      body.description_prefix || null,
      body.effective_from || null,
      body.effective_to || null,
      userId,
      userId,
    ],
  );
  return getDifferenceProfile(db, ins.insertId);
}

async function updateDifferenceProfile(db, id, body, userId = null) {
  const current = await getDifferenceProfile(db, id);
  if (!current) {
    const err = new Error("Difference profile not found");
    err.statusCode = 404;
    throw err;
  }

  await db.query(
    `
    UPDATE bank_reconciliation_difference_profiles
    SET
      profile_name = COALESCE(?, profile_name),
      status = COALESCE(?, status),
      max_abs_difference = ?,
      expense_account_id = ?,
      fx_gain_account_id = ?,
      fx_loss_account_id = ?,
      currency_code = ?,
      effective_from = ?,
      effective_to = ?,
      updated_by = ?,
      updated_at = NOW()
    WHERE id=?
    `,
    [
      body.profile_name ?? null,
      body.status || null,
      body.max_abs_difference !== undefined
        ? body.max_abs_difference
        : current.max_abs_difference,
      body.expense_account_id !== undefined
        ? body.expense_account_id
        : current.expense_account_id,
      body.fx_gain_account_id !== undefined
        ? body.fx_gain_account_id
        : current.fx_gain_account_id,
      body.fx_loss_account_id !== undefined
        ? body.fx_loss_account_id
        : current.fx_loss_account_id,
      body.currency_code !== undefined
        ? body.currency_code
        : current.currency_code,
      body.effective_from !== undefined
        ? body.effective_from
        : current.effective_from,
      body.effective_to !== undefined
        ? body.effective_to
        : current.effective_to,
      userId,
      id,
    ],
  );

  return getDifferenceProfile(db, id);
}

export default {
  listDifferenceProfiles,
  getDifferenceProfile,
  createDifferenceProfile,
  updateDifferenceProfile,
};
```

---

## 6) Service — `backend/src/services/bank.reconciliationDifferences.service.js`

```js id="b08bdiffsvc"
// backend/src/services/bank.reconciliationDifferences.service.js

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

function parseDate(v) {
  return String(v || "").slice(0, 10);
}

function isEffective(profile, bookingDate) {
  const d = parseDate(bookingDate);
  if (profile.effective_from && d < parseDate(profile.effective_from))
    return false;
  if (profile.effective_to && d > parseDate(profile.effective_to)) return false;
  return true;
}

function getGlCreateAndPostHelper() {
  import svc from "./gl.journals.service.js";
  if (typeof svc.createAndPostSystemJournal !== "function") {
    const err = new Error(
      "GL helper export missing: createAndPostSystemJournal",
    );
    err.statusCode = 500;
    throw err;
  }
  return svc.createAndPostSystemJournal;
}

async function getBankAccountWithGl(db, bankAccountId) {
  const [rows] = await db.query(
    `SELECT * FROM bank_accounts WHERE id=? LIMIT 1`,
    [bankAccountId],
  );
  return rows[0] || null;
}

async function applyDifferenceAdjustment(
  db,
  { bank_statement_line_id, payment_batch_line_id, profile_id, user_id = null },
) {
  const createAndPostSystemJournal = getGlCreateAndPostHelper();

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [existing] = await q.query(
      `SELECT * FROM bank_reconciliation_difference_adjustments WHERE bank_statement_line_id=? LIMIT 1`,
      [bank_statement_line_id],
    );
    if (existing[0]) {
      if (conn) await conn.commit();
      return { item: existing[0], idempotent: true };
    }

    const [slRows] = await q.query(
      `SELECT * FROM bank_statement_lines WHERE id=? LIMIT 1 FOR UPDATE`,
      [bank_statement_line_id],
    );
    const sl = slRows[0];
    if (!sl) {
      const err = new Error("Bank statement line not found");
      err.statusCode = 404;
      throw err;
    }

    const [pblRows] = await q.query(
      `SELECT * FROM payment_batch_lines WHERE id=? LIMIT 1 FOR UPDATE`,
      [payment_batch_line_id],
    );
    const pbl = pblRows[0];
    if (!pbl) {
      const err = new Error("Payment batch line not found");
      err.statusCode = 404;
      throw err;
    }

    const [profRows] = await q.query(
      `SELECT * FROM bank_reconciliation_difference_profiles WHERE id=? LIMIT 1`,
      [profile_id],
    );
    const profile = profRows[0];
    if (!profile) {
      const err = new Error("Difference profile not found");
      err.statusCode = 404;
      throw err;
    }

    if (String(profile.status) !== "ACTIVE")
      throw new Error("Difference profile is not active");
    if (!isEffective(profile, sl.booking_date))
      throw new Error("Difference profile is not effective for line date");
    if (
      profile.scope_type === "BANK_ACCOUNT" &&
      Number(profile.bank_account_id) !== Number(sl.bank_account_id)
    ) {
      throw new Error("Difference profile not scoped to this bank account");
    }
    if (
      profile.currency_code &&
      String(profile.currency_code) !== String(sl.currency_code)
    ) {
      throw new Error("Difference profile currency mismatch");
    }

    const expected = amount2(Math.abs(pbl.amount || 0));
    const actual = amount2(Math.abs(sl.amount || 0));
    const diff = amount2(actual - expected); // positive means bank amount bigger than payment line amount
    const absDiff = amount2(Math.abs(diff));

    if (absDiff <= 0) {
      const err = new Error("No difference to adjust");
      err.statusCode = 400;
      throw err;
    }

    if (absDiff > amount2(profile.max_abs_difference || 0)) {
      const err = new Error(
        `Difference ${absDiff} exceeds profile max ${profile.max_abs_difference}`,
      );
      err.statusCode = 409;
      throw err;
    }

    const bank = await getBankAccountWithGl(q, sl.bank_account_id);
    if (!bank || !bank.gl_account_id)
      throw new Error("Bank account GL mapping missing");

    const diffType = String(profile.difference_type || "").toUpperCase();
    const descPrefix =
      profile.description_prefix ||
      (diffType === "FX" ? "FX Diff:" : "Bank Diff:");
    const narration =
      `${descPrefix} ${sl.description || sl.reference || `Statement ${sl.id}`}`.trim();

    let glLines = [];

    if (diffType === "FEE") {
      if (!profile.expense_account_id)
        throw new Error("FEE profile missing expense_account_id");

      // Typical case: actual bank outflow > expected payment amount => extra fee charge on same statement line
      // delta recorded as Dr Fee Expense / Cr Bank for outflow side.
      // For opposite sign, reverse entry.
      if (diff > 0) {
        glLines = [
          {
            account_id: Number(profile.expense_account_id),
            dr_amount: absDiff,
            cr_amount: 0,
            memo: narration,
          },
          {
            account_id: Number(bank.gl_account_id),
            dr_amount: 0,
            cr_amount: absDiff,
            memo: narration,
          },
        ];
      } else {
        glLines = [
          {
            account_id: Number(bank.gl_account_id),
            dr_amount: absDiff,
            cr_amount: 0,
            memo: narration,
          },
          {
            account_id: Number(profile.expense_account_id),
            dr_amount: 0,
            cr_amount: absDiff,
            memo: narration,
          },
        ];
      }
    } else if (diffType === "FX") {
      if (!profile.fx_gain_account_id || !profile.fx_loss_account_id) {
        throw new Error("FX profile missing gain/loss account ids");
      }

      // Generic bank-side FX delta:
      // diff > 0 means statement absolute amount > expected absolute amount -> unfavorable on payment
      // diff < 0 -> favorable
      if (diff > 0) {
        // Loss: Dr FX Loss / Cr Bank (for outflow delta pattern)
        glLines = [
          {
            account_id: Number(profile.fx_loss_account_id),
            dr_amount: absDiff,
            cr_amount: 0,
            memo: narration,
          },
          {
            account_id: Number(bank.gl_account_id),
            dr_amount: 0,
            cr_amount: absDiff,
            memo: narration,
          },
        ];
      } else {
        // Gain: Dr Bank / Cr FX Gain
        glLines = [
          {
            account_id: Number(bank.gl_account_id),
            dr_amount: absDiff,
            cr_amount: 0,
            memo: narration,
          },
          {
            account_id: Number(profile.fx_gain_account_id),
            dr_amount: 0,
            cr_amount: absDiff,
            memo: narration,
          },
        ];
      }
    } else {
      throw new Error(`Unsupported difference_type: ${diffType}`);
    }

    const glRes = await createAndPostSystemJournal(q, {
      journal_date: parseDate(sl.booking_date),
      source_module: "BANK",
      source_type: "BANK_RECON_DIFF",
      source_ref: `BSL:${sl.id}|PBL:${pbl.id}`,
      doc_type: "BANK_DIFF",
      currency_code: sl.currency_code,
      description: narration,
      lines: glLines,
      created_by: user_id,
    });

    const [ins] = await q.query(
      `
      INSERT INTO bank_reconciliation_difference_adjustments
      (bank_statement_line_id, payment_batch_line_id, bank_reconciliation_difference_profile_id,
       difference_type, difference_amount, currency_code, journal_entry_id, status, payload_json, created_by)
      VALUES (?, ?, ?, ?, ?, ?, ?, 'POSTED', ?, ?)
      `,
      [
        sl.id,
        pbl.id,
        profile.id,
        diffType,
        diff,
        sl.currency_code,
        glRes.journal_entry_id,
        JSON.stringify({
          expected_amount_abs: expected,
          actual_amount_abs: actual,
        }),
        user_id,
      ],
    );

    await q
      .query(
        `
      UPDATE bank_statement_lines
      SET reconciliation_difference_type = ?,
          reconciliation_difference_amount = ?,
          reconciliation_difference_journal_entry_id = ?,
          updated_at = NOW()
      WHERE id = ?
      `,
        [diffType, diff, glRes.journal_entry_id, sl.id],
      )
      .catch(() => {});

    if (conn) await conn.commit();

    const [rows] = await db.query(
      `SELECT * FROM bank_reconciliation_difference_adjustments WHERE id=? LIMIT 1`,
      [ins.insertId],
    );
    return {
      item: rows[0],
      journal_entry_id: glRes.journal_entry_id,
      idempotent: false,
    };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

export default {
  applyDifferenceAdjustment,
};
```

---

## 7) Routes — `backend/src/routes/bank.paymentReturns.js`

```js id="b08bretroutes"
// backend/src/routes/bank.paymentReturns.js

import express from "express";
import svc from "../services/bank.paymentReturns.service.js";
import { validateReturnEventIdParam,
  validateListReturnEventsQuery,
  validateCreateManualReturnBody,
  validateIgnoreReturnEventBody, } from "./bank.paymentReturns.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/bank/payment-returns
router.get(
  "/payment-returns",
  requireAuth,
  requirePermission("bank.returns.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const q = validateListReturnEventsQuery(req.query);
      const items = await svc.listPaymentReturnEvents(db, q);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/payment-returns
router.post(
  "/payment-returns",
  requireAuth,
  requirePermission("bank.returns.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateManualReturnBody(req.body);
      const result = await svc.createPaymentReturnEvent(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/payment-returns/:id/ignore
router.post(
  "/payment-returns/:id/ignore",
  requireAuth,
  requirePermission("bank.returns.review"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateReturnEventIdParam(req.params);
      const body = validateIgnoreReturnEventBody(req.body);
      const item = await svc.ignorePaymentReturnEvent(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 8) Routes — `backend/src/routes/bank.reconciliationDifferenceProfiles.js`

```js id="b08bdiffroutes"
// backend/src/routes/bank.reconciliationDifferenceProfiles.js

import express from "express";
import svc from "../services/bank.reconciliationDifferenceProfiles.service.js";
import { validateProfileIdParam,
  validateCreateDifferenceProfileBody,
  validateUpdateDifferenceProfileBody, } from "./bank.reconciliationDifferenceProfiles.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/bank/reconciliation/difference-profiles
router.get(
  "/reconciliation/difference-profiles",
  requireAuth,
  requirePermission("bank.recon.diffProfiles.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const items = await svc.listDifferenceProfiles(db);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/bank/reconciliation/difference-profiles
router.post(
  "/reconciliation/difference-profiles",
  requireAuth,
  requirePermission("bank.recon.diffProfiles.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateDifferenceProfileBody(req.body);
      const item = await svc.createDifferenceProfile(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json(item);
    } catch (err) {
      next(err);
    }
  },
);

// PATCH /api/v1/bank/reconciliation/difference-profiles/:id
router.patch(
  "/reconciliation/difference-profiles/:id",
  requireAuth,
  requirePermission("bank.recon.diffProfiles.update"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateProfileIdParam(req.params);
      const body = validateUpdateDifferenceProfileBody(req.body);
      const item = await svc.updateDifferenceProfile(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 9) Patch B07 engine — `backend/src/services/bank.reconciliationEngine.service.js` (important)

> Extend B07 to support returns and amount-difference flows.

### A) Add helpers

```js id="b08beng1"
// patch snippet near top of B07 engine service

async function getPaymentReturnsService() {
  return (await import("./bank.paymentReturns.service.js")).default;
}

async function getReconciliationDifferencesService() {
  return (await import("./bank.reconciliationDifferences.service.js")).default;
}
```

### B) Add rule action support in `evaluateLineAgainstRules(...)`

#### `PROCESS_PAYMENT_RETURN`

```js id="b08beng2"
// patch snippet inside evaluateLineAgainstRules(...)

if (actionType === "PROCESS_PAYMENT_RETURN") {
  const actionPayload = parseJsonField(rule.action_payload_json, {});
  // target resolution still uses existing payment-line lookup logic
  const targets = await findPaymentBatchLineTargets(db, line, {
    ...rule,
    match_type: actionPayload.target_match_type || "PAYMENT_BY_BANK_REFERENCE",
    conditions_json: JSON.stringify({
      ...parseJsonField(rule.conditions_json, {}),
      ...(actionPayload.target_conditions || {}),
    }),
  });

  if (targets.length === 1) {
    return {
      matched: true,
      rule,
      outcome: {
        action: "PROCESS_PAYMENT_RETURN",
        target: targets[0],
        event_type: String(
          actionPayload.event_type || "PAYMENT_RETURNED",
        ).toUpperCase(),
        reason_code: String(
          actionPayload.reason_code || "BANK_RETURN",
        ).toUpperCase(),
        confidence: 0.9,
      },
    };
  }

  return {
    matched: true,
    rule,
    outcome: {
      action: "QUEUE_EXCEPTION",
      reason_code: targets.length > 1 ? "AMBIGUOUS_TARGET" : "NO_TARGET_FOUND",
      reason_message:
        targets.length > 1
          ? `Multiple payment line targets found (${targets.length}) for return`
          : "Return rule matched but no payment target found",
      confidence: 0.4,
      candidates: targets.map((t) => ({
        id: t.id,
        amount: t.amount,
        status: t.status,
      })),
    },
  };
}
```

#### `AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE`

```js id="b08beng3"
// patch snippet inside evaluateLineAgainstRules(...)

if (actionType === "AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE") {
  const actionPayload = parseJsonField(rule.action_payload_json, {});
  const profileId = Number(actionPayload.difference_profile_id || 0);

  const targets = await findPaymentBatchLineTargets(db, line, rule);
  if (targets.length !== 1) {
    return {
      matched: true,
      rule,
      outcome: {
        action: "QUEUE_EXCEPTION",
        reason_code:
          targets.length > 1 ? "AMBIGUOUS_TARGET" : "NO_TARGET_FOUND",
        reason_message:
          targets.length > 1
            ? `Multiple payment line targets found (${targets.length})`
            : "No payment target found",
        confidence: 0.4,
      },
    };
  }

  return {
    matched: true,
    rule,
    outcome: {
      action: "AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE",
      target: targets[0],
      difference_profile_id:
        Number.isInteger(profileId) && profileId > 0 ? profileId : null,
      confidence: 0.9,
    },
  };
}
```

### C) In preview output include new fields

```js id="b08beng4"
// add to preview item payload
event_type: ev.outcome.event_type || null,
difference_profile_id: ev.outcome.difference_profile_id || null,
```

### D) In `applyAutoReconciliation(...)`, execute new actions

```js id="b08beng5"
// patch snippet inside applyAutoReconciliation(...)

const { createPaymentReturnEvent } = getPaymentReturnsService();
const { applyDifferenceAdjustment } = getReconciliationDifferencesService();

// before QUEUE_EXCEPTION branch:

if (ev.outcome.action === "PROCESS_PAYMENT_RETURN") {
  matched += 1;

  await createPaymentReturnEvent(db, {
    event_request_id: `AUTO_RET|SL:${line.id}|RULE:${ev.rule?.id || "X"}`,
    payment_batch_line_id: ev.outcome.target.id,
    bank_statement_line_id: line.id,
    event_type: ev.outcome.event_type || "PAYMENT_RETURNED",
    amount: Math.abs(Number(line.amount || 0)),
    currency_code: line.currency_code,
    bank_reference: line.reference || null,
    reason_code: ev.outcome.reason_code || "BANK_RETURN",
    reason_message: "Auto-detected from bank reconciliation rule",
    source_type: "STATEMENT",
    source_ref: `SL:${line.id}`,
  }, userId);

  // Reconcile bank line to same payment line (return evidence)
  await reconcileStatementLineToPaymentBatchLine(db, {
    bank_statement_line_id: line.id,
    payment_batch_line_id: ev.outcome.target.id,
    method: "RULE_AUTO",
    matched_rule_id: ev.rule?.id || null,
    confidence: ev.outcome.confidence ?? null,
    user_id: userId,
  });

  reconciled += 1;
  continue;
}

if (ev.outcome.action === "AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE") {
  matched += 1;

  const target = ev.outcome.target;
  const expectedAbs = Math.abs(Number(target.amount || 0));
  const actualAbs = Math.abs(Number(line.amount || 0));

  // exact match -> normal reconcile
  if (Number(expectedAbs.toFixed(2)) === Number(actualAbs.toFixed(2))) {
    await reconcileStatementLineToPaymentBatchLine(db, {
      bank_statement_line_id: line.id,
      payment_batch_line_id: target.id,
      method: "RULE_AUTO",
      matched_rule_id: ev.rule?.id || null,
      confidence: ev.outcome.confidence ?? null,
      user_id: userId,
    });
    reconciled += 1;
    continue;
  }

  if (!ev.outcome.difference_profile_id) {
    await upsertExceptionForLine(db, line.id, {
      reason_code: "POLICY_BLOCKED",
      reason_message: "Difference detected but no difference profile configured",
      matched_rule_id: ev.rule?.id || null,
      severity: "HIGH",
    }, userId);
    exceptionCount += 1;
    continue;
  }

  const diffRes = await applyDifferenceAdjustment(db, {
    bank_statement_line_id: line.id,
    payment_batch_line_id: target.id,
    profile_id: ev.outcome.difference_profile_id,
    user_id: userId,
  });

  await reconcileStatementLineToPaymentBatchLine(db, {
    bank_statement_line_id: line.id,
    payment_batch_line_id: target.id,
    method: "RULE_AUTO",
    matched_rule_id: ev.rule?.id || null,
    confidence: ev.outcome.confidence ?? null,
    user_id: userId,
    difference_adjustment_journal_entry_id: diffRes.journal_entry_id, // optional metadata in B03 patch
  });

  reconciled += 1;
  continue;
}
```

---

## 10) Patch B03 core service — `backend/src/services/bank.reconciliation.service.js` (important)

> Extend existing payment-line reconciliation helper to optionally capture difference adjustment metadata.

```js id="b08bb03"
// patch snippet in reconcileStatementLineToPaymentBatchLine(...) signature

async function reconcileStatementLineToPaymentBatchLine(
  db,
  {
    bank_statement_line_id,
    payment_batch_line_id,
    method = "MANUAL",
    matched_rule_id = null,
    confidence = null,
    user_id = null,
    difference_adjustment_journal_entry_id = null, // NEW optional
  },
) {
  // existing logic...

  // after statement line reconcile update, optionally persist diff metadata
  if (difference_adjustment_journal_entry_id) {
    await q
      .query(
        `
      UPDATE bank_statement_lines
      SET reconciliation_difference_journal_entry_id = COALESCE(reconciliation_difference_journal_entry_id, ?),
          updated_at = NOW()
      WHERE id = ?
      `,
        [difference_adjustment_journal_entry_id, bank_statement_line_id],
      )
      .catch(() => {});
  }

  // in bank_reconciliation_audit payload include the difference journal id
}
```

---

## 11) Patch B04/B06 payment batch service — `backend/src/services/bank.paymentBatches.service.js` (important)

> Add/recognize return-aware statuses in list/detail summaries.

### Add support for these line statuses

- `RETURNED`
- `PARTIALLY_RETURNED`

### Add return metrics in batch summary

- `returned_line_count`
- `partially_returned_line_count`
- `total_returned_amount`

This keeps Payment Batch detail operational after B08-B.

---

## 12) Mount routes — `backend/src/index.js`

```js id="b08bidx"
// backend/src/index.js
import bankPaymentReturnsRoutes from "./routes/bank.paymentReturns.js";
import bankReconciliationDifferenceProfilesRoutes from "./routes/bank.reconciliationDifferenceProfiles.js";
// ...
app.use("/api/v1/bank", bankPaymentReturnsRoutes);
app.use("/api/v1/bank", bankReconciliationDifferenceProfilesRoutes);
```

---

## 13) Migration registry — `backend/src/migrations/index.js`

```js id="b08bmigidx"
// backend/src/migrations/index.js
import m049_bank_returns_and_recon_differences from "./m049_bank_returns_and_recon_differences.js";
export default [
  // ...
  m049_bank_returns_and_recon_differences,
];
```

---

## 14) Seed permissions — `backend/src/seedCore.js`

```js id="b08bperm"
// backend/src/seedCore.js
const BANK_B08B_PERMISSIONS = [
  "bank.returns.read",
  "bank.returns.create",
  "bank.returns.review",
  "bank.recon.diffProfiles.read",
  "bank.recon.diffProfiles.create",
  "bank.recon.diffProfiles.update",
];

// merge into permission seed list
```

> Auto engine execution still uses existing `bank.recon.auto.run`.

---

## 15) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

### Returns / rejections

- `GET /api/v1/bank/payment-returns`
- `POST /api/v1/bank/payment-returns`
- `POST /api/v1/bank/payment-returns/{id}/ignore`

### Difference profiles

- `GET /api/v1/bank/reconciliation/difference-profiles`
- `POST /api/v1/bank/reconciliation/difference-profiles`
- `PATCH /api/v1/bank/reconciliation/difference-profiles/{id}`

Also document new B07 rule actions:

- `PROCESS_PAYMENT_RETURN`
- `AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE`

And new rule action payload fields:

- `action_payload.event_type`
- `action_payload.difference_profile_id`

---

## 16) Backend smoke test — `backend/scripts/test-bank-prb08b-returns-rejections-fx.js`

```js id="b08bsmoke"
// backend/scripts/test-bank-prb08b-returns-rejections-fx.js

async function main() {
  // Preconditions:
  // - B06/B07/B08-A implemented
  // - B03 manual reconciliation works
  // - GL createAndPostSystemJournal helper exists
  // - Payment batch lines exist (some PAID/EXECUTED)
  // - Bank statement lines imported and unreconciled
  //
  // Flow A: Return event manual
  // 1) POST /bank/payment-returns (manual) for a payment_batch_line
  //    -> bank_payment_return_events row created
  //    -> payment_batch_line returned_amount / return_status updated
  //    -> line status can become PARTIALLY_RETURNED / RETURNED
  //
  // Flow B: Return rule automation
  // 2) Create B07 rule action PROCESS_PAYMENT_RETURN (match by bank ref/text)
  // 3) Auto-preview shows PROCESS_PAYMENT_RETURN
  // 4) Auto-apply creates return event + reconciles statement line to payment line
  //
  // Flow C: Difference profiles
  // 5) Create FEE difference profile (expense account, max diff)
  // 6) Create FX difference profile (gain/loss accounts, max diff)
  //
  // Flow D: Difference automation
  // 7) Create B07 rule action AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE(profile_id)
  // 8) Auto-apply on amount-different statement line:
  //    -> posts diff GL journal (FEE or FX)
  //    -> creates bank_reconciliation_difference_adjustments row
  //    -> reconciles statement line to payment line via B03
  //    -> statement line stores difference metadata
  //
  // Flow E: Safety / idempotency
  // 9) Re-run auto-apply same lines
  //    -> no duplicate return event (if same event_request_id path)
  //    -> no duplicate diff adjustment for same statement line
  // 10) Diff > profile max -> exception queue item
  // 11) Missing accounts/mappings -> exception queue item
  //
  // Permissions:
  // - bank.returns.*, bank.recon.diffProfiles.* enforced
  // - bank.recon.auto.run required for automation apply
  console.log("PR-B08-B smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 17) `backend/package.json` updates

```json id="b08bpkg"
{
  "scripts": {
    "test:bank:prb08b": "node backend/scripts/test-bank-prb08b-returns-rejections-fx.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 18) API client — `frontend/src/api/bankPaymentReturns.js`

```js id="b08bfeapi1"
// frontend/src/api/bankPaymentReturns.js

import { apiFetch } from "./client.js"; // adapt

export function listBankPaymentReturns(params = {}) {
  const qs = new URLSearchParams();
  Object.entries(params).forEach(([k, v]) => {
    if (v === undefined || v === null || v === "") return;
    qs.set(k, String(v));
  });
  const q = qs.toString();
  return apiFetch(`/api/v1/bank/payment-returns${q ? `?${q}` : ""}`);
}

export function createBankPaymentReturn(payload) {
  return apiFetch("/api/v1/bank/payment-returns", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function ignoreBankPaymentReturn(returnEventId, payload = {}) {
  return apiFetch(`/api/v1/bank/payment-returns/${returnEventId}/ignore`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}
```

---

## 19) API client — `frontend/src/api/bankReconciliationDifferenceProfiles.js`

```js id="b08bfeapi2"
// frontend/src/api/bankReconciliationDifferenceProfiles.js

import { apiFetch } from "./client.js"; // adapt

export function listBankReconciliationDifferenceProfiles() {
  return apiFetch("/api/v1/bank/reconciliation/difference-profiles");
}

export function createBankReconciliationDifferenceProfile(payload) {
  return apiFetch("/api/v1/bank/reconciliation/difference-profiles", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function updateBankReconciliationDifferenceProfile(profileId, payload) {
  return apiFetch(
    `/api/v1/bank/reconciliation/difference-profiles/${profileId}`,
    {
      method: "PATCH",
      body: JSON.stringify(payload),
    },
  );
}
```

---

## 20) `BankReconciliationPage.jsx` — key snippets only

### Add imports

```jsx id="b08bfeimp"
import {
  listBankPaymentReturns,
  createBankPaymentReturn,
  ignoreBankPaymentReturn,
} from "../../api/bankPaymentReturns.js";

import {
  listBankReconciliationDifferenceProfiles,
  createBankReconciliationDifferenceProfile,
} from "../../api/bankReconciliationDifferenceProfiles.js";
```

### Add state

```jsx id="b08bfestate"
const [paymentReturns, setPaymentReturns] = useState([]);
const [differenceProfiles, setDifferenceProfiles] = useState([]);
const [returnsErr, setReturnsErr] = useState("");
const [diffProfileErr, setDiffProfileErr] = useState("");
```

### Load panels

```jsx id="b08bfeload"
async function loadReturnsAndDiffProfiles() {
  const [retRes, diffRes] = await Promise.all([
    listBankPaymentReturns({ event_status: "CONFIRMED", limit: 50 }),
    listBankReconciliationDifferenceProfiles(),
  ]);

  setPaymentReturns(retRes.items || []);
  setDifferenceProfiles(diffRes.items || []);
}
```

### Create starter difference profiles (examples)

```jsx id="b08bfestarters"
async function onCreateStarterFeeDiffProfile() {
  try {
    setDiffProfileErr("");
    await createBankReconciliationDifferenceProfile({
      profile_code: "BANK_FEE_DIFF_001",
      profile_name: "Bank fee delta on matched payments",
      difference_type: "FEE",
      direction_policy: "INCREASE_ONLY",
      max_abs_difference: 50,
      expense_account_id: 6101, // replace
      description_prefix: "Bank Fee Diff:",
      status: "ACTIVE",
    });
    await loadReturnsAndDiffProfiles();
  } catch (e) {
    setDiffProfileErr(e.message || "Fee difference profile create failed");
  }
}

async function onCreateStarterFxDiffProfile() {
  try {
    setDiffProfileErr("");
    await createBankReconciliationDifferenceProfile({
      profile_code: "BANK_FX_DIFF_001",
      profile_name: "FX difference on matched payments",
      difference_type: "FX",
      direction_policy: "BOTH",
      max_abs_difference: 500,
      fx_gain_account_id: 7401, // replace
      fx_loss_account_id: 7801, // replace
      description_prefix: "FX Diff:",
      status: "ACTIVE",
    });
    await loadReturnsAndDiffProfiles();
  } catch (e) {
    setDiffProfileErr(e.message || "FX difference profile create failed");
  }
}
```

### Manual return create (optional fallback UX)

```jsx id="b08bfemanualret"
async function onCreateManualReturn(
  selectedPaymentBatchLineId,
  selectedStatementLine,
) {
  try {
    setReturnsErr("");
    await createBankPaymentReturn({
      event_request_id: `ret-${selectedPaymentBatchLineId}-${Date.now()}`,
      payment_batch_line_id: selectedPaymentBatchLineId,
      bank_statement_line_id: selectedStatementLine.id,
      event_type: "PAYMENT_RETURNED",
      amount: Math.abs(selectedStatementLine.amount),
      currency_code: selectedStatementLine.currency_code,
      bank_reference: selectedStatementLine.reference || "",
      reason_code: "BANK_RETURN",
      reason_message: "Manual bank return event",
    });
    await load();
    await loadReturnsAndDiffProfiles();
  } catch (e) {
    setReturnsErr(e.message || "Manual return create failed");
  }
}
```

### Compact UI blocks

```jsx id="b08bfeui"
{
  /* Payment Returns Panel */
}
<div className="rounded border bg-white p-4 mt-4">
  <h2 className="font-medium mb-2">Payment Returns / Rejections</h2>

  {/* Buttons:
      - Create Manual Return (fallback)
      - Ignore Return Event
  */}

  {returnsErr ? <div className="text-sm text-red-600">{returnsErr}</div> : null}

  <div className="text-sm mt-2 space-y-1">
    {/* return event summary:
        event_type, event_status, payment_batch_id, payment_batch_line_id, amount, reason_code, created_at
    */}
  </div>
</div>;

{
  /* Difference Profiles Panel */
}
<div className="rounded border bg-white p-4 mt-4">
  <h2 className="font-medium mb-2">
    Reconciliation Difference Profiles (Fee / FX)
  </h2>

  {/* Buttons:
      - Create Fee Diff Profile
      - Create FX Diff Profile
  */}

  {diffProfileErr ? (
    <div className="text-sm text-red-600">{diffProfileErr}</div>
  ) : null}

  <div className="text-sm mt-2 space-y-1">
    {/* profile_code, difference_type, max_abs_difference, linked accounts, status */}
  </div>
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Can create/list/ignore payment return/rejection events (bank-side trace)
- ✅ Creating a return event updates payment batch line return fields:

  - `return_status`
  - `returned_amount`
  - `last_returned_at`

- ✅ B07 rules can auto-detect returns with `PROCESS_PAYMENT_RETURN`
- ✅ Auto-detected return can reconcile bank statement line to payment batch line (B03)
- ✅ Can create/list/update reconciliation difference profiles for `FEE` and `FX`
- ✅ B07 rules can use `AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE`
- ✅ For matched-payment amount differences:

  - within profile tolerance → auto-post difference GL journal + reconcile
  - outside tolerance / invalid config → exception queue

- ✅ Difference adjustment is idempotent per statement line
- ✅ B03 remains source of truth for reconciliation record
- ✅ B04/B06 payment batch summaries show returned metrics
- ✅ Permissions enforced (`bank.returns.*`, `bank.recon.diffProfiles.*`, plus existing `bank.recon.auto.run`)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:bank:prb08b`

Should verify at least:

1. **Return events**

   - Manual return event can be created
   - `payment_batch_lines.returned_amount` increases safely
   - `return_status` becomes `PARTIALLY_RETURNED` / `RETURNED`
   - Over-return blocked

2. **Return rule automation**

   - B07 rule action `PROCESS_PAYMENT_RETURN` appears in preview
   - Auto-apply creates return event and reconciles statement line

3. **Difference profiles**

   - Create fee/FX difference profiles
   - Update profile tolerance/status/accounts
   - List returns correct fields

4. **Difference auto-post**

   - B07 rule action `AUTO_MATCH_PAYMENT_LINE_WITH_DIFFERENCE` works
   - FEE difference posts GL journal and creates `bank_reconciliation_difference_adjustments`
   - FX difference posts GL journal and creates adjustment trace
   - Statement line reconciles via B03 and stores difference metadata

5. **Safety / idempotency**

   - Same statement line does not create duplicate difference adjustment
   - Missing accounts or bad profile config → exception queue
   - Difference > max tolerance → exception queue

6. **Permissions**

   - `bank.returns.read/create/review`
   - `bank.recon.diffProfiles.read/create/update`
   - `bank.recon.auto.run`
     all enforced (`403`)

---

## Tiny implementation notes (important)

- **B08-A** (standalone fee/interest auto-post) and **B08-B** (return/rejection/difference handling) now complete your original B08 bucket cleanly.
- Keep B08-B generic: it updates **bank execution evidence** and **reconciliation**, while Payroll/AP can later consume return events to reopen liabilities if needed.
- This sets you up nicely for **B09** next (SoD / approvals / thresholds), since the operational risk points are now clearer:

  - manual return creation
  - exception overrides
  - rule/profile changes
  - auto-run execution

---

Perfect. This is the right next step.

With **B06 + B07 + B08-A + B08-B** in place, **B09** is where you add the **risk controls** that real ERP/SaaP systems rely on.

# PR-B09: Strong Approvals / SoD / Thresholds for Bank Operations

## Goal

Add a **bank governance layer** (approvals + maker-checker + thresholds) across high-risk bank actions:

- ✅ Payment batch approvals (before export/release)
- ✅ Reconciliation rule / template / difference-profile changes (config governance)
- ✅ Manual return/rejection creation (high-risk correction)
- ✅ Reconciliation exception overrides / force actions
- ✅ Auditable approval trail with policy snapshot
- ✅ Maker-checker and threshold enforcement (SoD)

This PR is the control layer on top of:

- **B04/B06** payment execution
- **B07** reconciliation automation rules
- **B08-A** auto-post templates
- **B08-B** returns / rejections / fee/FX differences

---

## Key design rule (important)

**B09 is a governance wrapper, not a replacement of business services.**

Business services still do the actual work (export file, reconcile line, create return event, save rule/profile), but:

- B09 decides **whether approval is required**
- If required, B09 creates an **approval request**
- The action is executed only after approval (or blocked if rejected)

This keeps your modules clean and reusable.

---

## Important behavior rules

### 1) Maker-checker (SoD)

If policy requires maker-checker:

- requester **cannot approve** their own request

### 2) Threshold-based approvals

Policies can require approvals based on:

- target type (payment batch / config change / manual return / exception override)
- amount thresholds
- bank account scope
- currency (optional)

### 3) Immutable approval snapshot

Approval request stores a **snapshot JSON** of:

- target state
- action payload
- policy used
- threshold values

So later audits can see **what was approved**, even if config changes afterward.

### 4) Idempotent approvals

Repeated approve calls from same user do not duplicate votes.
Request finalization is idempotent.

### 5) Config changes can be staged

For governed config (rules/templates/profiles):

- create/update can save the record in a **PENDING_APPROVAL** state
- record becomes **effective/active** only after approval

---

3# Files to create

### Backend

- `backend/src/migrations/m050_bank_governance_approvals_sod.js`
- `backend/src/routes/bank.approvalPolicies.js`
- `backend/src/routes/bank.approvalPolicies.validators.js`
- `backend/src/routes/bank.approvalRequests.js`
- `backend/src/routes/bank.approvalRequests.validators.js`
- `backend/src/services/bank.approvalPolicies.service.js`
- `backend/src/services/bank.approvals.service.js`
- `backend/src/services/bank.governance.service.js`
- `backend/scripts/test-bank-prb09-approvals-sod-thresholds.js`

### Frontend (short snippets only)

- `frontend/src/api/bankApprovalPolicies.js`
- `frontend/src/api/bankApprovalRequests.js`

---

3# Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (important patches)

- `backend/src/services/bank.paymentBatches.service.js`

  - block export/release unless approved (when policy applies)

- `backend/src/services/bank.reconciliationRules.service.js` _(or your B07 rule service file)_

  - create/update can enter `approval_state=PENDING_APPROVAL`

- `backend/src/services/bank.reconciliationPostingTemplates.service.js` _(B08-A)_

  - same governance hook

- `backend/src/services/bank.reconciliationDifferenceProfiles.service.js` _(B08-B)_

  - same governance hook

- `backend/src/services/bank.paymentReturns.service.js` _(B08-B)_

  - manual return creation may require approval

- `backend/src/services/bank.reconciliationExceptions.service.js` _(if you have one)_

  - override/force resolve may require approval

- `backend/src/services/bank.reconciliation.service.js`

  - manual force reconcile / override hooks can require approval

### Frontend (short integration only)

- `frontend/src/pages/bank/BankPaymentsPage.jsx`
- `frontend/src/pages/bank/BankReconciliationPage.jsx`
- (Optional) `frontend/src/pages/bank/BankGovernancePage.jsx`

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m050_bank_governance_approvals_sod.js`

```js
// backend/src/migrations/m050_bank_governance_approvals_sod.js

export default {
  key: "m050_bank_governance_approvals_sod",
  description: "m050_bank_governance_approvals_sod",
  async up(connection) {
    // Approval policies (thresholds + SoD rules)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_approval_policies (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        policy_code VARCHAR(50) NOT NULL,
        policy_name VARCHAR(190) NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE', -- ACTIVE, PAUSED, DISABLED

        target_type VARCHAR(40) NOT NULL, -- PAYMENT_BATCH, RECON_RULE, POST_TEMPLATE, DIFF_PROFILE, MANUAL_RETURN, RECON_EXCEPTION_OVERRIDE
        action_type VARCHAR(40) NOT NULL, -- SUBMIT_EXPORT, RELEASE, CREATE, UPDATE, OVERRIDE, FORCE_RECONCILE, etc

        scope_type VARCHAR(20) NOT NULL DEFAULT 'GLOBAL', -- GLOBAL, BANK_ACCOUNT
        bank_account_id BIGINT UNSIGNED NULL,

        currency_code CHAR(3) NULL,
        min_amount DECIMAL(18,2) NULL,
        max_amount DECIMAL(18,2) NULL,

        required_approvals INT NOT NULL DEFAULT 1,
        maker_checker_required TINYINT(1) NOT NULL DEFAULT 1,
        approver_permission_code VARCHAR(100) NOT NULL, -- e.g. bank.approvals.requests.approve.payment

        auto_execute_on_final_approval TINYINT(1) NOT NULL DEFAULT 1,

        effective_from DATE NULL,
        effective_to DATE NULL,

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bap_policy_code (policy_code),
        KEY idx_bap_target (target_type, action_type, status),
        KEY idx_bap_scope (scope_type, bank_account_id)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Approval requests (generic execution queue + audit shell)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_approval_requests (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        request_code VARCHAR(80) NOT NULL,
        request_key VARCHAR(190) NULL, -- idempotency key

        policy_id BIGINT UNSIGNED NOT NULL,
        target_type VARCHAR(40) NOT NULL,
        target_id BIGINT UNSIGNED NULL,
        action_type VARCHAR(40) NOT NULL,

        request_status VARCHAR(20) NOT NULL DEFAULT 'PENDING', -- PENDING, APPROVED, REJECTED, EXECUTED, FAILED, CANCELLED
        execution_status VARCHAR(20) NOT NULL DEFAULT 'NOT_EXECUTED', -- NOT_EXECUTED, EXECUTED, FAILED

        threshold_amount DECIMAL(18,2) NULL,
        currency_code CHAR(3) NULL,
        bank_account_id BIGINT UNSIGNED NULL,

        requested_by BIGINT UNSIGNED NOT NULL,
        submitted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        decision_due_at DATETIME NULL,

        approved_at DATETIME NULL,
        rejected_at DATETIME NULL,
        executed_at DATETIME NULL,
        executed_by BIGINT UNSIGNED NULL,

        target_snapshot_json JSON NOT NULL,
        action_payload_json JSON NULL,
        policy_snapshot_json JSON NOT NULL,
        execution_result_json JSON NULL,
        execution_error_text TEXT NULL,

        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bar_request_code (request_code),
        UNIQUE KEY uq_bar_request_key (request_key),
        KEY idx_bar_status (request_status, execution_status),
        KEY idx_bar_target (target_type, target_id, action_type),
        KEY idx_bar_requested_by (requested_by),

        CONSTRAINT fk_bar_policy
          FOREIGN KEY (policy_id) REFERENCES bank_approval_policies(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Approval decisions / votes
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS bank_approval_request_decisions (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        bank_approval_request_id BIGINT UNSIGNED NOT NULL,
        decided_by BIGINT UNSIGNED NOT NULL,
        decision VARCHAR(20) NOT NULL, -- APPROVE, REJECT
        decision_comment VARCHAR(500) NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_bard_request_user (bank_approval_request_id, decided_by),
        KEY idx_bard_request (bank_approval_request_id),
        KEY idx_bard_decision (decision),

        CONSTRAINT fk_bard_request
          FOREIGN KEY (bank_approval_request_id) REFERENCES bank_approval_requests(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Extend payment_batches with approval fields (B04/B06 gate)
    await db
      .query(
        `
      ALTER TABLE payment_batches
        ADD COLUMN approval_status VARCHAR(20) NOT NULL DEFAULT 'NOT_REQUIRED' AFTER status,
        ADD COLUMN approval_request_id BIGINT UNSIGNED NULL AFTER approval_status,
        ADD COLUMN approved_at DATETIME NULL AFTER approval_request_id,
        ADD COLUMN approved_by BIGINT UNSIGNED NULL AFTER approved_at
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE payment_batches
        ADD KEY idx_pb_approval_status (approval_status),
        ADD KEY idx_pb_approval_request (approval_request_id)
    `,
      )
      .catch(() => {});

    // Extend governed bank config tables with approval state
    await db
      .query(
        `
      ALTER TABLE bank_reconciliation_rules
        ADD COLUMN approval_state VARCHAR(20) NOT NULL DEFAULT 'APPROVED' AFTER status,
        ADD COLUMN approval_request_id BIGINT UNSIGNED NULL AFTER approval_state,
        ADD COLUMN version_no INT NOT NULL DEFAULT 1 AFTER approval_request_id
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE bank_reconciliation_posting_templates
        ADD COLUMN approval_state VARCHAR(20) NOT NULL DEFAULT 'APPROVED' AFTER status,
        ADD COLUMN approval_request_id BIGINT UNSIGNED NULL AFTER approval_state,
        ADD COLUMN version_no INT NOT NULL DEFAULT 1 AFTER approval_request_id
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE bank_reconciliation_difference_profiles
        ADD COLUMN approval_state VARCHAR(20) NOT NULL DEFAULT 'APPROVED' AFTER status,
        ADD COLUMN approval_request_id BIGINT UNSIGNED NULL AFTER approval_state,
        ADD COLUMN version_no INT NOT NULL DEFAULT 1 AFTER approval_request_id
    `,
      )
      .catch(() => {});

    // Optional: exception governance marker (for overrides)
    await db
      .query(
        `
      ALTER TABLE bank_reconciliation_exceptions
        ADD COLUMN override_approval_request_id BIGINT UNSIGNED NULL AFTER resolution_note
    `,
      )
      .catch(() => {});
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS bank_approval_request_decisions;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_approval_requests;`);
    await connection.execute(`DROP TABLE IF EXISTS bank_approval_policies;`);
    // Optional strict down for ALTER columns omitted
  },
};
```

---

## 2) Validators — `backend/src/routes/bank.approvalPolicies.validators.js`

```js
// backend/src/routes/bank.approvalPolicies.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}
function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}
function normalizeDecimal(v) {
  if (v === undefined || v === null || v === "") return null;
  const n = Number(v);
  if (!Number.isFinite(n)) throw new Error(`Invalid number: ${v}`);
  return n;
}

function validatePolicyIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreatePolicyBody(body = {}) {
  return {
    policy_code:
      normalizeString(body.policy_code) ||
      (() => {
        throw new Error("policy_code is required");
      })(),
    policy_name:
      normalizeString(body.policy_name) ||
      (() => {
        throw new Error("policy_name is required");
      })(),
    status: String(body.status || "ACTIVE")
      .trim()
      .toUpperCase(),

    target_type:
      String(body.target_type || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("target_type is required");
      })(),
    action_type:
      String(body.action_type || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("action_type is required");
      })(),

    scope_type: String(body.scope_type || "GLOBAL")
      .trim()
      .toUpperCase(),
    bank_account_id: body.bank_account_id
      ? requirePositiveInt(body.bank_account_id, "bank_account_id")
      : null,

    currency_code: normalizeString(body.currency_code)?.toUpperCase() || null,
    min_amount: normalizeDecimal(body.min_amount),
    max_amount: normalizeDecimal(body.max_amount),

    required_approvals: body.required_approvals
      ? requirePositiveInt(body.required_approvals, "required_approvals")
      : 1,
    maker_checker_required:
      body.maker_checker_required === undefined
        ? true
        : !!body.maker_checker_required,
    approver_permission_code:
      normalizeString(body.approver_permission_code) ||
      "bank.approvals.requests.approve",
    auto_execute_on_final_approval:
      body.auto_execute_on_final_approval === undefined
        ? true
        : !!body.auto_execute_on_final_approval,

    effective_from: normalizeString(body.effective_from),
    effective_to: normalizeString(body.effective_to),
  };
}

function validateUpdatePolicyBody(body = {}) {
  return {
    policy_name:
      body.policy_name !== undefined
        ? normalizeString(body.policy_name)
        : undefined,
    status: body.status ? String(body.status).trim().toUpperCase() : null,
    min_amount:
      body.min_amount !== undefined
        ? normalizeDecimal(body.min_amount)
        : undefined,
    max_amount:
      body.max_amount !== undefined
        ? normalizeDecimal(body.max_amount)
        : undefined,
    required_approvals:
      body.required_approvals !== undefined
        ? requirePositiveInt(body.required_approvals, "required_approvals")
        : undefined,
    maker_checker_required:
      body.maker_checker_required !== undefined
        ? !!body.maker_checker_required
        : undefined,
    approver_permission_code:
      body.approver_permission_code !== undefined
        ? normalizeString(body.approver_permission_code) || null
        : undefined,
    auto_execute_on_final_approval:
      body.auto_execute_on_final_approval !== undefined
        ? !!body.auto_execute_on_final_approval
        : undefined,
    effective_from:
      body.effective_from !== undefined
        ? normalizeString(body.effective_from)
        : undefined,
    effective_to:
      body.effective_to !== undefined
        ? normalizeString(body.effective_to)
        : undefined,
  };
}

export default {
  validatePolicyIdParam,
  validateCreatePolicyBody,
  validateUpdatePolicyBody,
};
```

---

## 3) Validators — `backend/src/routes/bank.approvalRequests.validators.js`

```js
// backend/src/routes/bank.approvalRequests.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}
function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function validateApprovalRequestIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateListApprovalRequestsQuery(query = {}) {
  return {
    request_status:
      normalizeString(query.request_status)?.toUpperCase() || null,
    target_type: normalizeString(query.target_type)?.toUpperCase() || null,
    action_type: normalizeString(query.action_type)?.toUpperCase() || null,
    mine_only: String(query.mine_only || "").toLowerCase() === "true",
    limit: query.limit ? Math.min(500, Math.max(1, Number(query.limit))) : 100,
  };
}

function validateSubmitApprovalRequestBody(body = {}) {
  return {
    request_key: normalizeString(body.request_key),
    target_type:
      String(body.target_type || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("target_type is required");
      })(),
    target_id: body.target_id
      ? requirePositiveInt(body.target_id, "target_id")
      : null,
    action_type:
      String(body.action_type || "")
        .trim()
        .toUpperCase() ||
      (() => {
        throw new Error("action_type is required");
      })(),
    bank_account_id: body.bank_account_id
      ? requirePositiveInt(body.bank_account_id, "bank_account_id")
      : null,
    threshold_amount:
      body.threshold_amount !== undefined
        ? Number(body.threshold_amount)
        : null,
    currency_code: normalizeString(body.currency_code)?.toUpperCase() || null,
    action_payload: body.action_payload || null,
  };
}

function validateDecisionBody(body = {}) {
  return {
    decision_comment: normalizeString(body.decision_comment),
  };
}

export default {
  validateApprovalRequestIdParam,
  validateListApprovalRequestsQuery,
  validateSubmitApprovalRequestBody,
  validateDecisionBody,
};
```

---

## 4) Policy service — `backend/src/services/bank.approvalPolicies.service.js`

```js
// backend/src/services/bank.approvalPolicies.service.js

async function listApprovalPolicies(db) {
  const [rows] = await db.query(
    `SELECT * FROM bank_approval_policies ORDER BY status='ACTIVE' DESC, id DESC`,
  );
  return rows;
}

async function getApprovalPolicy(db, id) {
  const [rows] = await db.query(
    `SELECT * FROM bank_approval_policies WHERE id=? LIMIT 1`,
    [id],
  );
  return rows[0] || null;
}

async function createApprovalPolicy(db, body, userId = null) {
  const [ins] = await db.query(
    `
    INSERT INTO bank_approval_policies
    (policy_code, policy_name, status, target_type, action_type, scope_type, bank_account_id,
     currency_code, min_amount, max_amount, required_approvals, maker_checker_required,
     approver_permission_code, auto_execute_on_final_approval, effective_from, effective_to, created_by, updated_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      body.policy_code,
      body.policy_name,
      body.status,
      body.target_type,
      body.action_type,
      body.scope_type,
      body.bank_account_id,
      body.currency_code,
      body.min_amount,
      body.max_amount,
      body.required_approvals,
      body.maker_checker_required ? 1 : 0,
      body.approver_permission_code,
      body.auto_execute_on_final_approval ? 1 : 0,
      body.effective_from,
      body.effective_to,
      userId,
      userId,
    ],
  );
  return getApprovalPolicy(db, ins.insertId);
}

async function updateApprovalPolicy(db, id, body, userId = null) {
  const cur = await getApprovalPolicy(db, id);
  if (!cur) {
    const err = new Error("Approval policy not found");
    err.statusCode = 404;
    throw err;
  }

  await db.query(
    `
    UPDATE bank_approval_policies
    SET
      policy_name = COALESCE(?, policy_name),
      status = COALESCE(?, status),
      min_amount = ?,
      max_amount = ?,
      required_approvals = ?,
      maker_checker_required = ?,
      approver_permission_code = ?,
      auto_execute_on_final_approval = ?,
      effective_from = ?,
      effective_to = ?,
      updated_by = ?,
      updated_at = NOW()
    WHERE id=?
    `,
    [
      body.policy_name ?? null,
      body.status || null,
      body.min_amount !== undefined ? body.min_amount : cur.min_amount,
      body.max_amount !== undefined ? body.max_amount : cur.max_amount,
      body.required_approvals !== undefined
        ? body.required_approvals
        : cur.required_approvals,
      body.maker_checker_required !== undefined
        ? body.maker_checker_required
          ? 1
          : 0
        : cur.maker_checker_required,
      body.approver_permission_code !== undefined
        ? body.approver_permission_code
        : cur.approver_permission_code,
      body.auto_execute_on_final_approval !== undefined
        ? body.auto_execute_on_final_approval
          ? 1
          : 0
        : cur.auto_execute_on_final_approval,
      body.effective_from !== undefined
        ? body.effective_from
        : cur.effective_from,
      body.effective_to !== undefined ? body.effective_to : cur.effective_to,
      userId,
      id,
    ],
  );

  return getApprovalPolicy(db, id);
}

export default {
  listApprovalPolicies,
  getApprovalPolicy,
  createApprovalPolicy,
  updateApprovalPolicy,
};
```

---

## 5) Governance resolver service — `backend/src/services/bank.governance.service.js`

> This is the **policy selection + gating helper** used by payment/recon services.

```js
// backend/src/services/bank.governance.service.js

function amount2(n) {
  if (n === null || n === undefined) return null;
  return Number(Number(n).toFixed(2));
}

function date10(v) {
  return String(v || "").slice(0, 10);
}

function isEffective(policy, today) {
  const d = date10(today || new Date().toISOString());
  if (policy.effective_from && d < date10(policy.effective_from)) return false;
  if (policy.effective_to && d > date10(policy.effective_to)) return false;
  return true;
}

function policyMatchesContext(policy, ctx) {
  if (String(policy.status) !== "ACTIVE") return false;
  if (!isEffective(policy)) return false;

  if (String(policy.target_type) !== String(ctx.target_type)) return false;
  if (String(policy.action_type) !== String(ctx.action_type)) return false;

  if (
    policy.scope_type === "BANK_ACCOUNT" &&
    Number(policy.bank_account_id) !== Number(ctx.bank_account_id || 0)
  )
    return false;

  if (
    policy.currency_code &&
    String(policy.currency_code) !== String(ctx.currency_code || "")
  )
    return false;

  const a = amount2(ctx.threshold_amount);
  if (
    policy.min_amount != null &&
    (a == null || a < amount2(policy.min_amount))
  )
    return false;
  if (
    policy.max_amount != null &&
    (a == null || a > amount2(policy.max_amount))
  )
    return false;

  return true;
}

async function findApplicableApprovalPolicy(db, ctx) {
  const [rows] = await db.query(
    `SELECT * FROM bank_approval_policies WHERE target_type=? AND action_type=? AND status='ACTIVE' ORDER BY scope_type='BANK_ACCOUNT' DESC, id DESC`,
    [ctx.target_type, ctx.action_type],
  );

  for (const p of rows) {
    if (policyMatchesContext(p, ctx)) return p;
  }
  return null;
}

async function evaluateApprovalNeed(db, ctx) {
  const policy = await findApplicableApprovalPolicy(db, ctx);
  if (!policy) {
    return { approval_required: false, policy: null };
  }
  return { approval_required: true, policy };
}

export default {
  findApplicableApprovalPolicy,
  evaluateApprovalNeed,
};
```

---

## 6) Approval requests service — `backend/src/services/bank.approvals.service.js`

> This handles:

- submit request
- approve/reject
- finalization
- optional auto-execution callback

```js
// backend/src/services/bank.approvals.service.js

import { evaluateApprovalNeed } from "./bank.governance.service.js";
function amount2(n) {
  return n == null ? null : Number(Number(n).toFixed(2));
}

function mkRequestCode() {
  return `BAR-${Date.now()}-${Math.floor(Math.random() * 10000)}`;
}

async function listApprovalRequests(db, filters = {}, userId = null) {
  const where = [];
  const args = [];

  if (filters.request_status) {
    where.push(`r.request_status=?`);
    args.push(filters.request_status);
  }
  if (filters.target_type) {
    where.push(`r.target_type=?`);
    args.push(filters.target_type);
  }
  if (filters.action_type) {
    where.push(`r.action_type=?`);
    args.push(filters.action_type);
  }
  if (filters.mine_only && userId) {
    where.push(`r.requested_by=?`);
    args.push(userId);
  }

  const [rows] = await db.query(
    `
    SELECT
      r.*,
      p.policy_code,
      p.policy_name,
      p.required_approvals,
      p.maker_checker_required,
      (SELECT COUNT(*) FROM bank_approval_request_decisions d WHERE d.bank_approval_request_id=r.id AND d.decision='APPROVE') AS approve_count,
      (SELECT COUNT(*) FROM bank_approval_request_decisions d WHERE d.bank_approval_request_id=r.id AND d.decision='REJECT') AS reject_count
    FROM bank_approval_requests r
    JOIN bank_approval_policies p ON p.id = r.policy_id
    ${where.length ? `WHERE ${where.join(" AND ")}` : ""}
    ORDER BY r.id DESC
    LIMIT ?
    `,
    [...args, filters.limit || 100],
  );
  return rows;
}

async function submitApprovalRequest(db, body, userId, buildTargetSnapshotFn) {
  // idempotency
  if (body.request_key) {
    const [existing] = await db.query(
      `SELECT * FROM bank_approval_requests WHERE request_key=? LIMIT 1`,
      [body.request_key],
    );
    if (existing[0]) return { item: existing[0], idempotent: true };
  }

  const targetSnapshot = await buildTargetSnapshotFn(db, body);

  const ctx = {
    target_type: body.target_type,
    action_type: body.action_type,
    bank_account_id:
      body.bank_account_id || targetSnapshot.bank_account_id || null,
    threshold_amount:
      body.threshold_amount ?? targetSnapshot.threshold_amount ?? null,
    currency_code: body.currency_code || targetSnapshot.currency_code || null,
  };

  const gov = await evaluateApprovalNeed(db, ctx);

  // If no approval policy matches, caller should execute directly
  if (!gov.approval_required) {
    return {
      approval_required: false,
      policy: null,
      item: null,
      idempotent: false,
    };
  }

  const policy = gov.policy;
  const requestCode = mkRequestCode();

  const [ins] = await db.query(
    `
    INSERT INTO bank_approval_requests
    (request_code, request_key, policy_id, target_type, target_id, action_type, request_status, execution_status,
     threshold_amount, currency_code, bank_account_id, requested_by, target_snapshot_json, action_payload_json, policy_snapshot_json)
    VALUES (?, ?, ?, ?, ?, ?, 'PENDING', 'NOT_EXECUTED', ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      requestCode,
      body.request_key || null,
      policy.id,
      body.target_type,
      body.target_id || null,
      body.action_type,
      amount2(ctx.threshold_amount),
      ctx.currency_code || null,
      ctx.bank_account_id || null,
      userId,
      JSON.stringify(targetSnapshot),
      JSON.stringify(body.action_payload || null),
      JSON.stringify({
        id: policy.id,
        policy_code: policy.policy_code,
        required_approvals: policy.required_approvals,
        maker_checker_required: !!policy.maker_checker_required,
        approver_permission_code: policy.approver_permission_code,
        auto_execute_on_final_approval: !!policy.auto_execute_on_final_approval,
      }),
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM bank_approval_requests WHERE id=? LIMIT 1`,
    [ins.insertId],
  );
  return { approval_required: true, policy, item: rows[0], idempotent: false };
}

// executionResolver executes the actual action after final approval
async function approveApprovalRequest(
  db,
  requestId,
  { userId, decisionComment = null, hasPermissionFn, executionResolver },
) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [rRows] = await q.query(
      `SELECT * FROM bank_approval_requests WHERE id=? LIMIT 1 FOR UPDATE`,
      [requestId],
    );
    const req = rRows[0];
    if (!req) {
      const err = new Error("Approval request not found");
      err.statusCode = 404;
      throw err;
    }
    if (req.request_status !== "PENDING") {
      if (conn) await conn.commit();
      return { item: req, idempotent: true };
    }

    const [pRows] = await q.query(
      `SELECT * FROM bank_approval_policies WHERE id=? LIMIT 1`,
      [req.policy_id],
    );
    const policy = pRows[0];
    if (!policy) throw new Error("Approval policy not found");

    if (typeof hasPermissionFn === "function") {
      const ok = await hasPermissionFn(
        policy.approver_permission_code,
        req,
        policy,
      );
      if (!ok) {
        const err = new Error(
          "Missing approver permission for this approval policy",
        );
        err.statusCode = 403;
        throw err;
      }
    }

    if (
      Number(policy.maker_checker_required) === 1 &&
      Number(req.requested_by) === Number(userId)
    ) {
      const err = new Error(
        "Maker-checker violation: requester cannot approve own request",
      );
      err.statusCode = 403;
      throw err;
    }

    // idempotent voter record
    await q.query(
      `
      INSERT INTO bank_approval_request_decisions
      (bank_approval_request_id, decided_by, decision, decision_comment)
      VALUES (?, ?, 'APPROVE', ?)
      ON DUPLICATE KEY UPDATE decision='APPROVE', decision_comment=VALUES(decision_comment)
      `,
      [req.id, userId, decisionComment],
    );

    const [countsRows] = await q.query(
      `SELECT
         SUM(CASE WHEN decision='APPROVE' THEN 1 ELSE 0 END) AS approve_count,
         SUM(CASE WHEN decision='REJECT' THEN 1 ELSE 0 END) AS reject_count
       FROM bank_approval_request_decisions
       WHERE bank_approval_request_id=?`,
      [req.id],
    );
    const counts = countsRows[0] || { approve_count: 0, reject_count: 0 };

    const enoughApprovals =
      Number(counts.approve_count || 0) >=
      Number(policy.required_approvals || 1);

    if (!enoughApprovals) {
      if (conn) await conn.commit();
      const [fresh] = await db.query(
        `SELECT * FROM bank_approval_requests WHERE id=? LIMIT 1`,
        [req.id],
      );
      return { item: fresh[0], finalized: false };
    }

    await q.query(
      `
      UPDATE bank_approval_requests
      SET request_status='APPROVED',
          approved_at=NOW(),
          updated_at=NOW()
      WHERE id=?
      `,
      [req.id],
    );

    let execResult = null;

    if (
      Number(policy.auto_execute_on_final_approval) === 1 &&
      typeof executionResolver === "function"
    ) {
      try {
        execResult = await executionResolver(q, req, policy, userId);

        await q.query(
          `
          UPDATE bank_approval_requests
          SET request_status='EXECUTED',
              execution_status='EXECUTED',
              executed_at=NOW(),
              executed_by=?,
              execution_result_json=?,
              updated_at=NOW()
          WHERE id=?
          `,
          [userId, JSON.stringify(execResult || {}), req.id],
        );
      } catch (execErr) {
        await q.query(
          `
          UPDATE bank_approval_requests
          SET execution_status='FAILED',
              execution_error_text=?,
              updated_at=NOW()
          WHERE id=?
          `,
          [String(execErr.message || execErr), req.id],
        );
        throw execErr;
      }
    }

    if (conn) await conn.commit();

    const [outRows] = await db.query(
      `SELECT * FROM bank_approval_requests WHERE id=? LIMIT 1`,
      [req.id],
    );
    return { item: outRows[0], finalized: true, execution_result: execResult };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function rejectApprovalRequest(
  db,
  requestId,
  { userId, decisionComment = null, hasPermissionFn },
) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [rRows] = await q.query(
      `SELECT * FROM bank_approval_requests WHERE id=? LIMIT 1 FOR UPDATE`,
      [requestId],
    );
    const req = rRows[0];
    if (!req) {
      const err = new Error("Approval request not found");
      err.statusCode = 404;
      throw err;
    }
    if (req.request_status !== "PENDING") {
      if (conn) await conn.commit();
      return { item: req, idempotent: true };
    }

    const [pRows] = await q.query(
      `SELECT * FROM bank_approval_policies WHERE id=? LIMIT 1`,
      [req.policy_id],
    );
    const policy = pRows[0];
    if (!policy) throw new Error("Approval policy not found");

    if (typeof hasPermissionFn === "function") {
      const ok = await hasPermissionFn(
        policy.approver_permission_code,
        req,
        policy,
      );
      if (!ok) {
        const err = new Error(
          "Missing approver permission for this approval policy",
        );
        err.statusCode = 403;
        throw err;
      }
    }

    await q.query(
      `
      INSERT INTO bank_approval_request_decisions
      (bank_approval_request_id, decided_by, decision, decision_comment)
      VALUES (?, ?, 'REJECT', ?)
      ON DUPLICATE KEY UPDATE decision='REJECT', decision_comment=VALUES(decision_comment)
      `,
      [req.id, userId, decisionComment],
    );

    await q.query(
      `UPDATE bank_approval_requests SET request_status='REJECTED', rejected_at=NOW(), updated_at=NOW() WHERE id=?`,
      [req.id],
    );

    if (conn) await conn.commit();

    const [outRows] = await db.query(
      `SELECT * FROM bank_approval_requests WHERE id=? LIMIT 1`,
      [req.id],
    );
    return { item: outRows[0], finalized: true };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

export default {
  listApprovalRequests,
  submitApprovalRequest,
  approveApprovalRequest,
  rejectApprovalRequest,
};
```

---

## 7) Routes — `backend/src/routes/bank.approvalPolicies.js`

```js
// backend/src/routes/bank.approvalPolicies.js

import express from "express";
import svc from "../services/bank.approvalPolicies.service.js";
import { validatePolicyIdParam,
  validateCreatePolicyBody,
  validateUpdatePolicyBody, } from "./bank.approvalPolicies.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

router.get(
  "/approvals/policies",
  requireAuth,
  requirePermission("bank.approvals.policies.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const items = await svc.listApprovalPolicies(db);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

router.post(
  "/approvals/policies",
  requireAuth,
  requirePermission("bank.approvals.policies.create"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreatePolicyBody(req.body);
      const item = await svc.createApprovalPolicy(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json(item);
    } catch (err) {
      next(err);
    }
  },
);

router.patch(
  "/approvals/policies/:id",
  requireAuth,
  requirePermission("bank.approvals.policies.update"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validatePolicyIdParam(req.params);
      const body = validateUpdatePolicyBody(req.body);
      const item = await svc.updateApprovalPolicy(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 8) Routes — `backend/src/routes/bank.approvalRequests.js`

```js
// backend/src/routes/bank.approvalRequests.js

import express from "express";
import svc from "../services/bank.approvals.service.js";
import { validateApprovalRequestIdParam,
  validateListApprovalRequestsQuery,
  validateSubmitApprovalRequestBody,
  validateDecisionBody, } from "./bank.approvalRequests.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
// TODO: wire this to your existing RBAC permission resolver/context.
const hasPermission = async (req, permCode) => {
  const assigned = Array.isArray(req.user?.permissions)
    ? req.user.permissions
    : [];
  return assigned.includes(permCode);
};
import { query } from "../db.js";
const router = express.Router();

// IMPORTANT: execution resolver should dispatch to business services
function getExecutionResolver() {
  import bankPaymentBatches from "../services/bank.paymentBatches.service.js";
  import reconRules from "../services/bank.reconciliationRules.service.js";
  import postTemplates from "../services/bank.reconciliationPostingTemplates.service.js";
  import diffProfiles from "../services/bank.reconciliationDifferenceProfiles.service.js";
  import paymentReturns from "../services/bank.paymentReturns.service.js";
  import reconExceptions from "../services/bank.reconciliationExceptions.service.js";
  return async function executionResolver(db, req, policy, approverUserId) {
    const target = JSON.parse(req.target_snapshot_json || "{}");
    const payload = JSON.parse(req.action_payload_json || "null");

    // adapt these names to your real service exports
    if (
      req.target_type === "PAYMENT_BATCH" &&
      req.action_type === "SUBMIT_EXPORT"
    ) {
      return bankPaymentBatches.executeApprovedExport(db, {
        payment_batch_id: req.target_id,
        approval_request_id: req.id,
        approved_by: approverUserId,
      });
    }

    if (req.target_type === "PAYMENT_BATCH" && req.action_type === "RELEASE") {
      return bankPaymentBatches.executeApprovedRelease(db, {
        payment_batch_id: req.target_id,
        approval_request_id: req.id,
        approved_by: approverUserId,
      });
    }

    if (
      req.target_type === "RECON_RULE" &&
      ["CREATE", "UPDATE"].includes(req.action_type)
    ) {
      return reconRules.activateApprovedRuleChange(db, {
        rule_id: req.target_id,
        approval_request_id: req.id,
        approved_by: approverUserId,
      });
    }

    if (
      req.target_type === "POST_TEMPLATE" &&
      ["CREATE", "UPDATE"].includes(req.action_type)
    ) {
      return postTemplates.activateApprovedPostingTemplateChange(db, {
        template_id: req.target_id,
        approval_request_id: req.id,
        approved_by: approverUserId,
      });
    }

    if (
      req.target_type === "DIFF_PROFILE" &&
      ["CREATE", "UPDATE"].includes(req.action_type)
    ) {
      return diffProfiles.activateApprovedDifferenceProfileChange(db, {
        profile_id: req.target_id,
        approval_request_id: req.id,
        approved_by: approverUserId,
      });
    }

    if (req.target_type === "MANUAL_RETURN" && req.action_type === "CREATE") {
      return paymentReturns.executeApprovedManualReturn(db, {
        approval_request_id: req.id,
        approved_by: approverUserId,
        payload,
      });
    }

    if (
      req.target_type === "RECON_EXCEPTION_OVERRIDE" &&
      req.action_type === "OVERRIDE"
    ) {
      return reconExceptions.executeApprovedExceptionOverride(db, {
        approval_request_id: req.id,
        approved_by: approverUserId,
        payload,
      });
    }

    throw new Error(
      `No execution handler for ${req.target_type}/${req.action_type}`,
    );
  };
}

router.get(
  "/approvals/requests",
  requireAuth,
  requirePermission("bank.approvals.requests.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const q = validateListApprovalRequestsQuery(req.query);
      const items = await svc.listApprovalRequests(db, q, req.user?.id ?? null);
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// Optional direct submit endpoint (useful for manual/override requests)
router.post(
  "/approvals/requests",
  requireAuth,
  requirePermission("bank.approvals.requests.submit"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateSubmitApprovalRequestBody(req.body);

      // generic snapshot builder fallback
      const result = await svc.submitApprovalRequest(
        db,
        body,
        req.user.id,
        async () => ({
          target_type: body.target_type,
          target_id: body.target_id,
          bank_account_id: body.bank_account_id,
          threshold_amount: body.threshold_amount,
          currency_code: body.currency_code,
          submitted_via: "API",
        }),
      );

      res.status(201).json(result);
    } catch (err) {
      next(err);
    }
  },
);

router.post(
  "/approvals/requests/:id/approve",
  requireAuth,
  requirePermission("bank.approvals.requests.approve"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateApprovalRequestIdParam(req.params);
      const body = validateDecisionBody(req.body);

      const item = await svc.approveApprovalRequest(db, id, {
        userId: req.user.id,
        decisionComment: body.decision_comment,
        hasPermissionFn: async (permCode) => hasPermission(req, permCode),
        executionResolver: getExecutionResolver(),
      });

      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

router.post(
  "/approvals/requests/:id/reject",
  requireAuth,
  requirePermission("bank.approvals.requests.reject"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateApprovalRequestIdParam(req.params);
      const body = validateDecisionBody(req.body);

      const item = await svc.rejectApprovalRequest(db, id, {
        userId: req.user.id,
        decisionComment: body.decision_comment,
        hasPermissionFn: async (permCode) => hasPermission(req, permCode),
      });

      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 9) Patch B04/B06 payment batches — `backend/src/services/bank.paymentBatches.service.js` (important)

### A) Add approval gate before export/release

```js
// patch snippet in export/release service methods

import { evaluateApprovalNeed } from "./bank.governance.service.js";
import approvalsSvc from "./bank.approvals.service.js";
// inside export/release flow before execution:
const gov = await evaluateApprovalNeed(db, {
  target_type: "PAYMENT_BATCH",
  action_type: "SUBMIT_EXPORT", // or RELEASE
  bank_account_id: batch.bank_account_id,
  threshold_amount: batch.total_amount,
  currency_code: batch.currency_code,
});

if (gov.approval_required) {
  // create/return approval request instead of exporting now
  const submitRes = await approvalsSvc.submitApprovalRequest(
    db,
    {
      request_key: `PB:${batch.id}|SUBMIT_EXPORT|v${batch.version_no || 1}`,
      target_type: "PAYMENT_BATCH",
      target_id: batch.id,
      action_type: "SUBMIT_EXPORT",
      bank_account_id: batch.bank_account_id,
      threshold_amount: batch.total_amount,
      currency_code: batch.currency_code,
      action_payload: { payment_batch_id: batch.id },
    },
    userId,
    async () => ({
      payment_batch_id: batch.id,
      batch_no: batch.batch_no,
      bank_account_id: batch.bank_account_id,
      threshold_amount: batch.total_amount,
      currency_code: batch.currency_code,
      line_count: batch.line_count,
      status: batch.status,
    }),
  );

  await db.query(
    `
    UPDATE payment_batches
    SET approval_status='PENDING',
        approval_request_id=?,
        updated_at=NOW()
    WHERE id=?
    `,
    [submitRes.item?.id || null, batch.id],
  );

  return {
    approval_required: true,
    approval_request: submitRes.item,
    exported: false,
  };
}
```

### B) Add execution methods for approval resolver

```js
// patch snippet in bank.paymentBatches.service.js

async function executeApprovedExport(
  db,
  { payment_batch_id, approval_request_id, approved_by },
) {
  // wrap your existing actual export implementation here (without re-triggering approval gate)
  // update batch approval fields
  await db.query(
    `UPDATE payment_batches SET approval_status='APPROVED', approved_at=NOW(), approved_by=?, approval_request_id=? WHERE id=?`,
    [approved_by, approval_request_id, payment_batch_id],
  );
  // then call internal export core
  return { payment_batch_id, exported: true };
}

async function executeApprovedRelease(
  db,
  { payment_batch_id, approval_request_id, approved_by },
) {
  await db.query(
    `UPDATE payment_batches SET approval_status='APPROVED', approved_at=NOW(), approved_by=?, approval_request_id=? WHERE id=?`,
    [approved_by, approval_request_id, payment_batch_id],
  );
  // then call internal release core
  return { payment_batch_id, released: true };
}

export default {
  // existing exports...
  executeApprovedExport,
  executeApprovedRelease,
};
```

---

## 10) Patch B07/B08 config services — approval-state staging (important)

Apply same pattern to:

- `bank.reconciliationRules.service.js`
- `bank.reconciliationPostingTemplates.service.js`
- `bank.reconciliationDifferenceProfiles.service.js`

### Example patch pattern (template service shown)

```js
// patch snippet in createPostingTemplate / updatePostingTemplate

import approvalsSvc from "./bank.approvals.service.js";
import { evaluateApprovalNeed } from "./bank.governance.service.js";
// after insert/update of template row:
const template = await getPostingTemplate(db, templateId);

const gov = await evaluateApprovalNeed(db, {
  target_type: "POST_TEMPLATE",
  action_type: "CREATE", // or UPDATE
  bank_account_id: template.bank_account_id || null,
  threshold_amount: null,
  currency_code: template.currency_code || null,
});

if (gov.approval_required) {
  const submitRes = await approvalsSvc.submitApprovalRequest(
    db,
    {
      request_key: `POST_TEMPLATE:${template.id}|${actionType}|v${template.version_no || 1}`,
      target_type: "POST_TEMPLATE",
      target_id: template.id,
      action_type, // CREATE / UPDATE
      bank_account_id: template.bank_account_id || null,
      currency_code: template.currency_code || null,
      action_payload: { template_id: template.id },
    },
    userId,
    async () => ({
      template_id: template.id,
      template_code: template.template_code,
      template_name: template.template_name,
      status: template.status,
      approval_state: "PENDING_APPROVAL",
      version_no: template.version_no,
    }),
  );

  await db.query(
    `
    UPDATE bank_reconciliation_posting_templates
    SET approval_state='PENDING_APPROVAL',
        approval_request_id=?,
        status=CASE WHEN status='ACTIVE' THEN 'PAUSED' ELSE status END,
        version_no=version_no+1,
        updated_at=NOW()
    WHERE id=?
    `,
    [submitRes.item.id, template.id],
  );

  return {
    ...template,
    approval_state: "PENDING_APPROVAL",
    approval_required: true,
    approval_request: submitRes.item,
  };
}

// no approval required -> keep APPROVED
```

### Add activation method for approval resolver

```js
// patch snippet in bank.reconciliationPostingTemplates.service.js

async function activateApprovedPostingTemplateChange(
  db,
  { template_id, approval_request_id, approved_by },
) {
  await db.query(
    `
    UPDATE bank_reconciliation_posting_templates
    SET approval_state='APPROVED',
        approval_request_id=?,
        status=CASE WHEN status='PAUSED' THEN 'ACTIVE' ELSE status END,
        updated_by=?,
        updated_at=NOW()
    WHERE id=?
    `,
    [approval_request_id, approved_by, template_id],
  );
  return { template_id, activated: true };
}

export default {
  // existing exports...
  activateApprovedPostingTemplateChange,
};
```

> Same shape for:

- `activateApprovedRuleChange(...)`
- `activateApprovedDifferenceProfileChange(...)`

---

## 11) Patch B08-B manual returns — `backend/src/services/bank.paymentReturns.service.js` (important)

### A) Create request instead of immediate return (when policy applies)

```js
// patch snippet in manual return create endpoint path (source_type='MANUAL')

import { evaluateApprovalNeed } from "./bank.governance.service.js";
import approvalsSvc from "./bank.approvals.service.js";
// before createPaymentReturnEvent execution for MANUAL:
const gov = await evaluateApprovalNeed(db, {
  target_type: "MANUAL_RETURN",
  action_type: "CREATE",
  bank_account_id: body.bank_account_id || null, // derive from payment batch / bank acct if available
  threshold_amount: Math.abs(Number(body.amount || 0)),
  currency_code: body.currency_code,
});

if (gov.approval_required) {
  const submitRes = await approvalsSvc.submitApprovalRequest(
    db,
    {
      request_key: body.event_request_id
        ? `MANUAL_RETURN:${body.event_request_id}`
        : null,
      target_type: "MANUAL_RETURN",
      action_type: "CREATE",
      target_id: null,
      bank_account_id: body.bank_account_id || null,
      threshold_amount: Math.abs(Number(body.amount || 0)),
      currency_code: body.currency_code,
      action_payload: body, // execution resolver will run actual create
    },
    userId,
    async () => ({
      source_type: "MANUAL",
      payment_batch_line_id: body.payment_batch_line_id,
      bank_statement_line_id: body.bank_statement_line_id || null,
      amount: Math.abs(Number(body.amount || 0)),
      currency_code: body.currency_code,
      reason_code: body.reason_code || null,
    }),
  );

  return {
    approval_required: true,
    approval_request: submitRes.item,
    created: false,
  };
}
```

### B) Execution method for approved manual return

```js
// patch snippet in bank.paymentReturns.service.js

async function executeApprovedManualReturn(
  db,
  { approval_request_id, approved_by, payload },
) {
  const body = payload || {};
  const res = await createPaymentReturnEvent(
    db,
    {
      ...body,
      source_type: "MANUAL",
      source_ref: `APPROVAL:${approval_request_id}`,
    },
    approved_by,
  );

  return {
    approval_request_id,
    payment_return_event_id: res.item.id,
    created: true,
  };
}

export default {
  // existing exports...
  executeApprovedManualReturn,
};
```

---

## 12) Patch exception override / force reconcile (important)

> If you have a dedicated exception service, put it there. If not, patch the B03/B07 exception resolution path.

### Pattern

```js
// patch snippet (conceptual) in bank.reconciliationExceptions.service.js

import { evaluateApprovalNeed } from "./bank.governance.service.js";
import approvalsSvc from "./bank.approvals.service.js";
async function requestOrExecuteExceptionOverride(db, body, userId) {
  const ex = await getException(db, body.exception_id);

  const gov = await evaluateApprovalNeed(db, {
    target_type: "RECON_EXCEPTION_OVERRIDE",
    action_type: "OVERRIDE",
    bank_account_id: ex.bank_account_id || null,
    threshold_amount: Math.abs(Number(ex.amount || 0)),
    currency_code: ex.currency_code || null,
  });

  if (gov.approval_required) {
    const submitRes = await approvalsSvc.submitApprovalRequest(
      db,
      {
        request_key: `EXC:${ex.id}|OVERRIDE|${Date.now()}`,
        target_type: "RECON_EXCEPTION_OVERRIDE",
        target_id: ex.id,
        action_type: "OVERRIDE",
        bank_account_id: ex.bank_account_id || null,
        threshold_amount: Math.abs(Number(ex.amount || 0)),
        currency_code: ex.currency_code || null,
        action_payload: body,
      },
      userId,
      async () => ({
        exception_id: ex.id,
        reason_code: ex.reason_code,
        amount: ex.amount,
        currency_code: ex.currency_code,
        requested_resolution_code: body.resolution_code,
      }),
    );

    await db
      .query(
        `UPDATE bank_reconciliation_exceptions SET override_approval_request_id=? WHERE id=?`,
        [submitRes.item.id, ex.id],
      )
      .catch(() => {});

    return { approval_required: true, approval_request: submitRes.item };
  }

  return executeExceptionOverride(db, body, userId);
}

async function executeApprovedExceptionOverride(
  db,
  { approval_request_id, approved_by, payload },
) {
  // call existing override logic
  return { approval_request_id, resolved: true };
}

export default {
  // existing exports...
  requestOrExecuteExceptionOverride,
  executeApprovedExceptionOverride,
};
```

---

## 13) Routes mounting — `backend/src/index.js`

```js
// backend/src/index.js
import bankApprovalPoliciesRoutes from "./routes/bank.approvalPolicies.js";
import bankApprovalRequestsRoutes from "./routes/bank.approvalRequests.js";
// ...
app.use("/api/v1/bank", bankApprovalPoliciesRoutes);
app.use("/api/v1/bank", bankApprovalRequestsRoutes);
```

---

## 14) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m050_bank_governance_approvals_sod from "./m050_bank_governance_approvals_sod.js";
export default [
  // ...
  m050_bank_governance_approvals_sod,
];
```

---

## 15) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const BANK_B09_PERMISSIONS = [
  "bank.approvals.policies.read",
  "bank.approvals.policies.create",
  "bank.approvals.policies.update",

  "bank.approvals.requests.read",
  "bank.approvals.requests.submit",
  "bank.approvals.requests.approve",
  "bank.approvals.requests.reject",

  // Optional fine-grained approver perms referenced by policy.approver_permission_code
  "bank.approvals.requests.approve.payment",
  "bank.approvals.requests.approve.reconConfig",
  "bank.approvals.requests.approve.reconOverride",
  "bank.approvals.requests.approve.manualReturn",
];

// merge into permission seed list
```

> Tip: Policies can reference fine-grained approver permissions so you can separate:

- payment approvers
- reconciliation config approvers
- exception override approvers

---

## 16) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

### Approval policies

- `GET /api/v1/bank/approvals/policies`
- `POST /api/v1/bank/approvals/policies`
- `PATCH /api/v1/bank/approvals/policies/{id}`

### Approval requests

- `GET /api/v1/bank/approvals/requests`
- `POST /api/v1/bank/approvals/requests`
- `POST /api/v1/bank/approvals/requests/{id}/approve`
- `POST /api/v1/bank/approvals/requests/{id}/reject`

Also document:

- `payment_batches.approval_status`
- `approval_state` on rule/template/diff-profile records
- request lifecycle: `PENDING -> APPROVED -> EXECUTED` or `REJECTED`

---

## 17) Backend smoke test — `backend/scripts/test-bank-prb09-approvals-sod-thresholds.js`

```js
// backend/scripts/test-bank-prb09-approvals-sod-thresholds.js

async function main() {
  // Preconditions:
  // - B06/B07/B08-A/B08-B implemented
  // - Approval policy/requests routes enabled
  //
  // Flow A: Policy setup
  // 1) Create policy: PAYMENT_BATCH / SUBMIT_EXPORT (threshold > 1000, maker-checker=true)
  // 2) Create policy: RECON_RULE / UPDATE (always require 1 approval)
  // 3) Create policy: MANUAL_RETURN / CREATE (always require 1 approval)
  //
  // Flow B: Payment batch approval gate
  // 4) Try export payment batch > threshold as preparer
  //    -> returns approval_required=true
  //    -> payment_batches.approval_status='PENDING'
  //    -> no export file generated yet
  //
  // 5) Maker attempts approve same request
  //    -> 403 maker-checker violation
  //
  // 6) Different approver approves
  //    -> approval request EXECUTED
  //    -> export runs via execution resolver
  //    -> payment batch approval_status='APPROVED'
  //
  // Flow C: Config governance (B07/B08)
  // 7) Update recon rule/template/diff profile
  //    -> record approval_state='PENDING_APPROVAL'
  //    -> approval request created
  //    -> automation engine ignores pending config (ensure listing/filters use approval_state='APPROVED')
  // 8) Approver approves
  //    -> approval request EXECUTED
  //    -> record approval_state='APPROVED'
  //
  // Flow D: Manual return governance
  // 9) Create manual return
  //    -> approval request created (not immediate return event)
  // 10) Approver approves
  //    -> bank_payment_return_events row created
  //    -> payment_batch_line returned fields updated
  //
  // Flow E: Exception override governance
  // 11) Attempt force resolve high-risk exception
  //    -> approval request created
  // 12) Approver rejects
  //    -> no override executed, exception remains open
  //
  // Flow F: Threshold and scope
  // 13) Payment batch below threshold (or on unscoped bank account)
  //    -> no approval required, action executes directly
  //
  // Flow G: Idempotency
  // 14) Re-submit same request_key
  //    -> same approval request returned
  // 15) Re-approve already executed request
  //    -> idempotent response
  //
  // Permissions:
  // - policy permissions enforced
  // - approval request permissions enforced
  // - policy.approver_permission_code enforced
  console.log("PR-B09 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 18) `backend/package.json` updates

```json
{
  "scripts": {
    "test:bank:prb09": "node backend/scripts/test-bank-prb09-approvals-sod-thresholds.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 19) API client — `frontend/src/api/bankApprovalPolicies.js`

```js
// frontend/src/api/bankApprovalPolicies.js

import { apiFetch } from "./client.js"; // adapt

export function listBankApprovalPolicies() {
  return apiFetch("/api/v1/bank/approvals/policies");
}

export function createBankApprovalPolicy(payload) {
  return apiFetch("/api/v1/bank/approvals/policies", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function updateBankApprovalPolicy(policyId, payload) {
  return apiFetch(`/api/v1/bank/approvals/policies/${policyId}`, {
    method: "PATCH",
    body: JSON.stringify(payload),
  });
}
```

---

## 20) API client — `frontend/src/api/bankApprovalRequests.js`

```js
// frontend/src/api/bankApprovalRequests.js

import { apiFetch } from "./client.js"; // adapt

export function listBankApprovalRequests(params = {}) {
  const qs = new URLSearchParams();
  Object.entries(params).forEach(([k, v]) => {
    if (v === undefined || v === null || v === "") return;
    qs.set(k, String(v));
  });
  const q = qs.toString();
  return apiFetch(`/api/v1/bank/approvals/requests${q ? `?${q}` : ""}`);
}

export function submitBankApprovalRequest(payload) {
  return apiFetch("/api/v1/bank/approvals/requests", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function approveBankApprovalRequest(requestId, payload = {}) {
  return apiFetch(`/api/v1/bank/approvals/requests/${requestId}/approve`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function rejectBankApprovalRequest(requestId, payload = {}) {
  return apiFetch(`/api/v1/bank/approvals/requests/${requestId}/reject`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}
```

---

## 21) `BankPaymentsPage.jsx` — key snippets only

### Add state for approval gate responses

```jsx
const [paymentApprovalInfo, setPaymentApprovalInfo] = useState(null);
const [approvalErr, setApprovalErr] = useState("");
```

### Handle export/release response that returns approval_required

```jsx
async function onExportPaymentBatch(batchId) {
  try {
    setApprovalErr("");
    const res = await exportPaymentBatch(batchId); // existing API
    if (res.approval_required) {
      setPaymentApprovalInfo(res.approval_request);
      // show "Pending Approval" badge on batch
      return;
    }
    // normal success path
    await loadPaymentBatches();
  } catch (e) {
    setApprovalErr(e.message || "Export failed");
  }
}
```

### Compact UI indicators

```jsx
{
  /* Payment Batch Approval Status */
}
<div className="text-sm">
  {/* Show badges:
      NOT_REQUIRED / PENDING / APPROVED
      and approval_request_id if present
  */}
</div>;
```

---

## 22) `BankReconciliationPage.jsx` — key snippets only

### Add approval queue panel for recon team

```jsx
import {
  listBankApprovalRequests,
  approveBankApprovalRequest,
  rejectBankApprovalRequest,
} from "../../api/bankApprovalRequests.js";

const [approvalQueue, setApprovalQueue] = useState([]);
const [approvalQueueErr, setApprovalQueueErr] = useState("");

async function loadApprovalQueue() {
  const res = await listBankApprovalRequests({
    request_status: "PENDING",
    // optionally filter target_type for recon team
  });
  setApprovalQueue(res.items || []);
}

async function onApproveRequest(requestId) {
  try {
    setApprovalQueueErr("");
    await approveBankApprovalRequest(requestId, {
      decision_comment: "Approved",
    });
    await loadApprovalQueue();
    await load(); // existing recon refresh
  } catch (e) {
    setApprovalQueueErr(e.message || "Approve failed");
  }
}
```

### Compact UI block

```jsx
<div className="rounded border bg-white p-4 mt-4">
  <h2 className="font-medium mb-2">Bank Approval Queue</h2>

  {/* List pending requests:
      request_code, target_type, action_type, threshold_amount, requested_by, submitted_at
      Buttons: Approve / Reject
  */}

  {approvalQueueErr ? (
    <div className="text-sm text-red-600">{approvalQueueErr}</div>
  ) : null}
</div>
```

---

## Acceptance criteria (repeat in PR)

- ✅ Can create/list/update bank approval policies (target/action/scope/threshold/SoD)
- ✅ Approval policies support:

  - target type + action type
  - bank-account scope
  - amount thresholds
  - currency filter
  - required approval count
  - maker-checker
  - approver permission code

- ✅ Payment batch export/release is blocked and converted into approval request when policy applies
- ✅ Maker cannot approve own request when maker-checker is enabled
- ✅ Final approval auto-executes underlying action (payment export/release, etc.)
- ✅ Recon config changes (rules/templates/diff-profiles) can be staged with `approval_state=PENDING_APPROVAL`
- ✅ Approved config changes become active only after approval execution
- ✅ Manual return creation can require approval and executes only after approval
- ✅ Exception override / force actions can require approval
- ✅ Approval requests are auditable with target snapshot + policy snapshot + decisions
- ✅ Idempotency works for request submission (`request_key`) and repeated approve/reject calls
- ✅ Permissions enforced:

  - policy admin perms
  - request read/submit/approve/reject
  - policy-specific approver permission code

- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:bank:prb09`

Should verify at least:

1. **Policy engine**

   - Policy matching by target/action
   - Threshold matching (above/below)
   - Scope matching by bank account
   - Currency matching

2. **Maker-checker**

   - Requester cannot approve own request
   - Different approver can approve

3. **Payment approvals**

   - Export/release creates approval request when policy applies
   - Action not executed before approval
   - Action executes after final approval
   - Batch approval fields updated

4. **Recon config approvals**

   - Rule/template/profile updates become `PENDING_APPROVAL`
   - Pending config not used by automation engine
   - Approval activates config

5. **Manual return / override approvals**

   - Manual return can be held pending approval
   - After approval, return event is created and line updated
   - Rejected override does not execute

6. **Audit + idempotency**

   - `bank_approval_requests` stores target/policy snapshots
   - duplicate `request_key` returns same request
   - repeated approve on executed request is idempotent

7. **Permissions**

   - `bank.approvals.policies.*`
   - `bank.approvals.requests.*`
   - policy-defined approver permission code
     all enforced (`403`)

---

## Tiny implementation notes (important)

- Start with **single-stage approvals** (one level, `required_approvals` supports 1+ unique approvers).
- You can add **multi-stage routing** later (e.g., Treasury Manager then Finance Director) without breaking this design.
- In B07/B08 list queries, make sure automation uses only:

  - `status='ACTIVE'`
  - `approval_state='APPROVED'`

That one filter prevents accidental use of pending config.

---

# PR-P07: Beneficiary Bank Master + Immutable Snapshots for Payroll Payments

## Goal

Add a proper **beneficiary bank master** for payroll and capture **immutable snapshots** when payroll liabilities enter the payment flow.

This PR gives you:

- ✅ Employee beneficiary bank master (can store multiple accounts, one primary)
- ✅ Effective-dated / auditable beneficiary records
- ✅ Immutable beneficiary snapshot at payroll payment-link creation
- ✅ Payment file/export path uses **snapshot**, not live employee bank data
- ✅ Historical safety (later master edits do **not** rewrite past payments)
- ✅ Clear blocking when beneficiary bank info is missing/invalid
- ✅ Snapshot visibility in payroll liability/payment APIs

---

## Important behavior rules

### 1) Snapshots are immutable

When a payroll liability is linked into a payment batch (P03 flow), system creates/attaches a **beneficiary bank snapshot**.

- Later changes to employee bank master **must not** affect:

  - existing payroll payment links
  - existing payment batches
  - payment file exports

---

### 2) Master is editable, history is preserved

Employee beneficiary bank records can change (new account, bank switch, IBAN correction), but:

- master changes are auditable
- prior snapshots remain unchanged

---

### 3) Payment generation always uses snapshot

B06 payment file generation (and any payment export preview) must read beneficiary details from:

- `payroll_liability_payment_links.beneficiary_bank_snapshot_id` (preferred)
- or copied snapshot data on payment line payload (if your B04 schema already stores it)

**Never** pull live employee bank details during export.

---

### 4) Missing beneficiary blocks payment-link creation

If an employee liability has no valid beneficiary bank master record:

- payroll payment linking should fail (or skip with explicit error if you support partial batching later)
- error must identify which liability/employee is missing setup

v1 recommendation: **fail the operation with a clear 409/400**.

---

### 5) One primary active beneficiary per employee+currency (v1)

For simplicity:

- one active **primary** account per employee per currency
- service enforces this (MySQL partial unique constraints are awkward)

---

## Files to create

## Backend

- `backend/src/migrations/m051_payroll_beneficiary_snapshots.js`
- `backend/src/routes/payroll.beneficiaries.js`
- `backend/src/routes/payroll.beneficiaries.validators.js`
- `backend/src/services/payroll.beneficiaries.service.js`
- `backend/scripts/test-payroll-prp07-beneficiary-snapshots.js`

## Frontend (short snippets only)

- `frontend/src/api/payrollBeneficiaries.js`

---

## Files to update

## Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

## Backend (important patches)

- `backend/src/services/payroll.payments.service.js` _(P03 payment-link creation path)_

  - resolve beneficiary master
  - create snapshot
  - store snapshot on `payroll_liability_payment_links`

- `backend/src/services/bank.paymentFiles.service.js` _(or your B06 export service)_

  - export from snapshot, not live master

- `backend/src/services/payroll.liabilities.service.js` _(optional list/detail enrichments)_

  - expose snapshot id / beneficiary status for UI

## Frontend (short integration only)

- `frontend/src/pages/payroll/PayrollEmployeesPage.jsx` _(or your employee/payroll master page)_
- `frontend/src/pages/payroll/PayrollLiabilitiesPage.jsx` _(show snapshot status)_
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m051_payroll_beneficiary_snapshots.js`

> Adjust migration number if your sequence has moved.

```js
// backend/src/migrations/m051_payroll_beneficiary_snapshots.js

export default {
  key: "m051_payroll_beneficiary_snapshots",
  description: "m051_payroll_beneficiary_snapshots",
  async up(connection) {
    // Employee beneficiary bank master (effective-dated)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_beneficiary_bank_accounts (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        employee_id BIGINT UNSIGNED NOT NULL,

        account_holder_name VARCHAR(190) NOT NULL,
        bank_name VARCHAR(190) NOT NULL,
        bank_branch_name VARCHAR(190) NULL,

        country_code CHAR(2) NULL,
        currency_code CHAR(3) NOT NULL,

        iban VARCHAR(64) NULL,
        account_number VARCHAR(64) NULL,
        routing_number VARCHAR(64) NULL,
        swift_bic VARCHAR(32) NULL,

        account_last4 VARCHAR(4) NULL,
        account_fingerprint VARCHAR(128) NULL, -- hash/fingerprint for dedupe

        is_primary TINYINT(1) NOT NULL DEFAULT 0,
        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE', -- ACTIVE, INACTIVE

        effective_from DATE NULL,
        effective_to DATE NULL,

        verification_status VARCHAR(20) NOT NULL DEFAULT 'UNVERIFIED', -- UNVERIFIED, VERIFIED
        source_type VARCHAR(20) NOT NULL DEFAULT 'MANUAL', -- MANUAL, IMPORT, PROVIDER
        external_ref VARCHAR(190) NULL,

        payload_json JSON NULL,

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_pbba_employee (employee_id),
        KEY idx_pbba_primary (employee_id, currency_code, is_primary, status),
        KEY idx_pbba_status (status),
        KEY idx_pbba_effective (effective_from, effective_to)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Audit trail for master changes
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_beneficiary_bank_account_audit (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        beneficiary_bank_account_id BIGINT UNSIGNED NOT NULL,
        employee_id BIGINT UNSIGNED NOT NULL,

        action VARCHAR(30) NOT NULL, -- CREATED, UPDATED, SET_PRIMARY, DEACTIVATED
        before_json JSON NULL,
        after_json JSON NULL,
        reason VARCHAR(255) NULL,

        acted_by BIGINT UNSIGNED NULL,
        acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_pbbaa_account (beneficiary_bank_account_id),
        KEY idx_pbbaa_employee (employee_id),
        KEY idx_pbbaa_action (action)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Immutable snapshots used by payroll payment links
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_beneficiary_bank_snapshots (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,

        employee_id BIGINT UNSIGNED NOT NULL,
        source_beneficiary_bank_account_id BIGINT UNSIGNED NULL,

        snapshot_hash VARCHAR(128) NOT NULL,
        currency_code CHAR(3) NOT NULL,

        account_holder_name VARCHAR(190) NOT NULL,
        bank_name VARCHAR(190) NOT NULL,
        bank_branch_name VARCHAR(190) NULL,

        country_code CHAR(2) NULL,
        iban VARCHAR(64) NULL,
        account_number VARCHAR(64) NULL,
        routing_number VARCHAR(64) NULL,
        swift_bic VARCHAR(32) NULL,
        account_last4 VARCHAR(4) NULL,

        verification_status VARCHAR(20) NOT NULL DEFAULT 'UNVERIFIED',
        payload_json JSON NULL,

        created_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_pbbs_hash (snapshot_hash),
        KEY idx_pbbs_employee (employee_id),
        KEY idx_pbbs_source (source_beneficiary_bank_account_id)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Link snapshot to payroll payment links (P03)
    await db
      .query(
        `
      ALTER TABLE payroll_liability_payment_links
        ADD COLUMN beneficiary_bank_snapshot_id BIGINT UNSIGNED NULL AFTER payroll_liability_id,
        ADD COLUMN beneficiary_snapshot_status VARCHAR(20) NOT NULL DEFAULT 'PENDING' AFTER beneficiary_bank_snapshot_id,
        ADD KEY idx_plpl_benef_snapshot (beneficiary_bank_snapshot_id)
    `,
      )
      .catch(() => {});

    // Optional FK if your table names/types align
    await db
      .query(
        `
      ALTER TABLE payroll_liability_payment_links
        ADD CONSTRAINT fk_plpl_beneficiary_snapshot
        FOREIGN KEY (beneficiary_bank_snapshot_id)
        REFERENCES payroll_beneficiary_bank_snapshots(id)
        ON UPDATE RESTRICT ON DELETE RESTRICT
    `,
      )
      .catch(() => {});
  },

  async down(connection) {
    await connection.execute(
      `DROP TABLE IF EXISTS payroll_beneficiary_bank_account_audit;`,
    );
    await connection.execute(`DROP TABLE IF EXISTS payroll_beneficiary_bank_snapshots;`);
    await connection.execute(`DROP TABLE IF EXISTS payroll_beneficiary_bank_accounts;`);
    // Optional strict down for ALTER on payroll_liability_payment_links omitted
  },
};
```

---

## 2) Validators — `backend/src/routes/payroll.beneficiaries.validators.js`

```js
// backend/src/routes/payroll.beneficiaries.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function requireCurrency(v, field = "currency_code") {
  const s = String(v || "")
    .trim()
    .toUpperCase();
  if (!/^[A-Z]{3}$/.test(s))
    throw new Error(`${field} must be 3-letter currency`);
  return s;
}

function validateEmployeeIdParam(params = {}) {
  return { employeeId: requirePositiveInt(params.employeeId, "employeeId") };
}

function validateBeneficiaryAccountIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreateBeneficiaryAccountBody(body = {}) {
  const account_holder_name = normalizeString(body.account_holder_name);
  const bank_name = normalizeString(body.bank_name);

  if (!account_holder_name) throw new Error("account_holder_name is required");
  if (!bank_name) throw new Error("bank_name is required");

  const iban = normalizeString(body.iban);
  const account_number = normalizeString(body.account_number);

  if (!iban && !account_number) {
    throw new Error("Either iban or account_number is required");
  }

  return {
    account_holder_name,
    bank_name,
    bank_branch_name: normalizeString(body.bank_branch_name),
    country_code: normalizeString(body.country_code)?.toUpperCase() || null,
    currency_code: requireCurrency(body.currency_code),
    iban,
    account_number,
    routing_number: normalizeString(body.routing_number),
    swift_bic: normalizeString(body.swift_bic)?.toUpperCase() || null,
    is_primary: !!body.is_primary,
    effective_from: normalizeString(body.effective_from),
    effective_to: normalizeString(body.effective_to),
    verification_status:
      normalizeString(body.verification_status)?.toUpperCase() || "UNVERIFIED",
    source_type: normalizeString(body.source_type)?.toUpperCase() || "MANUAL",
    external_ref: normalizeString(body.external_ref),
    reason: normalizeString(body.reason),
  };
}

function validateUpdateBeneficiaryAccountBody(body = {}) {
  return {
    account_holder_name: normalizeString(body.account_holder_name),
    bank_name: normalizeString(body.bank_name),
    bank_branch_name: normalizeString(body.bank_branch_name),
    country_code: normalizeString(body.country_code)?.toUpperCase() || null,
    currency_code: body.currency_code
      ? requireCurrency(body.currency_code)
      : null,
    iban: normalizeString(body.iban),
    account_number: normalizeString(body.account_number),
    routing_number: normalizeString(body.routing_number),
    swift_bic: normalizeString(body.swift_bic)?.toUpperCase() || null,
    status: normalizeString(body.status)?.toUpperCase() || null,
    verification_status:
      normalizeString(body.verification_status)?.toUpperCase() || null,
    effective_from: normalizeString(body.effective_from),
    effective_to: normalizeString(body.effective_to),
    external_ref: normalizeString(body.external_ref),
    reason: normalizeString(body.reason) || "Updated beneficiary bank account",
  };
}

function validateSetPrimaryBody(body = {}) {
  return {
    reason:
      normalizeString(body.reason) || "Set primary beneficiary bank account",
  };
}

export default {
  validateEmployeeIdParam,
  validateBeneficiaryAccountIdParam,
  validateCreateBeneficiaryAccountBody,
  validateUpdateBeneficiaryAccountBody,
  validateSetPrimaryBody,
};
```

---

## 3) Service — `backend/src/services/payroll.beneficiaries.service.js`

> This service does two jobs:
>
> 1. Manage employee beneficiary bank master
> 2. Create immutable snapshots for payroll payment links

```js
// backend/src/services/payroll.beneficiaries.service.js

import crypto from "crypto";
function normalizeUpper(v) {
  return v == null ? null : String(v).trim().toUpperCase();
}

function maskLast4FromAccountLike({ iban, account_number }) {
  const raw = String(iban || account_number || "").replace(/\s+/g, "");
  return raw ? raw.slice(-4) : null;
}

function fingerprintAccount({
  iban,
  account_number,
  routing_number,
  swift_bic,
  currency_code,
}) {
  const base = [
    String(iban || "")
      .replace(/\s+/g, "")
      .toUpperCase(),
    String(account_number || "").replace(/\s+/g, ""),
    String(routing_number || "").replace(/\s+/g, ""),
    String(swift_bic || "").toUpperCase(),
    String(currency_code || "").toUpperCase(),
  ].join("|");
  return crypto.createHash("sha256").update(base).digest("hex");
}

function snapshotHashFromRow(row) {
  // Snapshot identity (if same exact details, reuse snapshot row)
  const base = JSON.stringify({
    employee_id: Number(row.employee_id),
    currency_code: normalizeUpper(row.currency_code),
    account_holder_name: row.account_holder_name || "",
    bank_name: row.bank_name || "",
    bank_branch_name: row.bank_branch_name || "",
    country_code: normalizeUpper(row.country_code),
    iban: (row.iban || "").replace(/\s+/g, "").toUpperCase(),
    account_number: (row.account_number || "").replace(/\s+/g, ""),
    routing_number: (row.routing_number || "").replace(/\s+/g, ""),
    swift_bic: normalizeUpper(row.swift_bic),
    verification_status:
      normalizeUpper(row.verification_status) || "UNVERIFIED",
  });
  return crypto.createHash("sha256").update(base).digest("hex");
}

async function writeAudit(
  db,
  {
    account,
    action,
    before = null,
    after = null,
    reason = null,
    userId = null,
  },
) {
  await db.query(
    `
    INSERT INTO payroll_beneficiary_bank_account_audit
    (beneficiary_bank_account_id, employee_id, action, before_json, after_json, reason, acted_by)
    VALUES (?, ?, ?, ?, ?, ?, ?)
    `,
    [
      account.id,
      account.employee_id,
      action,
      before ? JSON.stringify(before) : null,
      after ? JSON.stringify(after) : null,
      reason || null,
      userId || null,
    ],
  );
}

async function listEmployeeBeneficiaryBankAccounts(db, employeeId) {
  const [rows] = await db.query(
    `
    SELECT *
    FROM payroll_beneficiary_bank_accounts
    WHERE employee_id=?
    ORDER BY is_primary DESC, status='ACTIVE' DESC, id DESC
    `,
    [employeeId],
  );
  return rows;
}

async function createEmployeeBeneficiaryBankAccount(
  db,
  employeeId,
  body,
  userId = null,
) {
  const account_last4 = maskLast4FromAccountLike(body);
  const account_fingerprint = fingerprintAccount(body);

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    if (body.is_primary) {
      await q.query(
        `
        UPDATE payroll_beneficiary_bank_accounts
        SET is_primary=0, updated_by=?, updated_at=NOW()
        WHERE employee_id=? AND currency_code=? AND status='ACTIVE'
        `,
        [userId, employeeId, body.currency_code],
      );
    }

    const [ins] = await q.query(
      `
      INSERT INTO payroll_beneficiary_bank_accounts
      (employee_id, account_holder_name, bank_name, bank_branch_name,
       country_code, currency_code, iban, account_number, routing_number, swift_bic,
       account_last4, account_fingerprint, is_primary, status,
       effective_from, effective_to, verification_status, source_type, external_ref, payload_json,
       created_by, updated_by)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'ACTIVE', ?, ?, ?, ?, ?, NULL, ?, ?)
      `,
      [
        employeeId,
        body.account_holder_name,
        body.bank_name,
        body.bank_branch_name || null,
        body.country_code || null,
        body.currency_code,
        body.iban || null,
        body.account_number || null,
        body.routing_number || null,
        body.swift_bic || null,
        account_last4,
        account_fingerprint,
        body.is_primary ? 1 : 0,
        body.effective_from || null,
        body.effective_to || null,
        body.verification_status,
        body.source_type,
        body.external_ref || null,
        userId,
        userId,
      ],
    );

    const [rows] = await q.query(
      `SELECT * FROM payroll_beneficiary_bank_accounts WHERE id=? LIMIT 1`,
      [ins.insertId],
    );
    const row = rows[0];

    await writeAudit(q, {
      account: row,
      action: "CREATED",
      after: row,
      reason: body.reason || "Created beneficiary bank account",
      userId,
    });

    if (conn) await conn.commit();
    return row;
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function updateBeneficiaryBankAccount(
  db,
  accountId,
  body,
  userId = null,
) {
  const [curRows] = await db.query(
    `SELECT * FROM payroll_beneficiary_bank_accounts WHERE id=? LIMIT 1`,
    [accountId],
  );
  const cur = curRows[0];
  if (!cur) {
    const err = new Error("Beneficiary bank account not found");
    err.statusCode = 404;
    throw err;
  }

  const next = {
    ...cur,
    ...Object.fromEntries(
      Object.entries(body).filter(([, v]) => v !== undefined),
    ),
  };

  const account_last4 = maskLast4FromAccountLike(next);
  const account_fingerprint = fingerprintAccount(next);

  await db.query(
    `
    UPDATE payroll_beneficiary_bank_accounts
    SET account_holder_name = COALESCE(?, account_holder_name),
        bank_name = COALESCE(?, bank_name),
        bank_branch_name = ?,
        country_code = ?,
        currency_code = COALESCE(?, currency_code),
        iban = ?,
        account_number = ?,
        routing_number = ?,
        swift_bic = ?,
        account_last4 = ?,
        account_fingerprint = ?,
        status = COALESCE(?, status),
        verification_status = COALESCE(?, verification_status),
        effective_from = ?,
        effective_to = ?,
        external_ref = ?,
        updated_by = ?,
        updated_at = NOW()
    WHERE id = ?
    `,
    [
      body.account_holder_name || null,
      body.bank_name || null,
      body.bank_branch_name ?? cur.bank_branch_name ?? null,
      body.country_code ?? cur.country_code ?? null,
      body.currency_code || null,
      body.iban ?? cur.iban ?? null,
      body.account_number ?? cur.account_number ?? null,
      body.routing_number ?? cur.routing_number ?? null,
      body.swift_bic ?? cur.swift_bic ?? null,
      account_last4,
      account_fingerprint,
      body.status || null,
      body.verification_status || null,
      body.effective_from ?? cur.effective_from ?? null,
      body.effective_to ?? cur.effective_to ?? null,
      body.external_ref ?? cur.external_ref ?? null,
      userId,
      accountId,
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM payroll_beneficiary_bank_accounts WHERE id=? LIMIT 1`,
    [accountId],
  );
  const updated = rows[0];

  await writeAudit(db, {
    account: updated,
    action: String(updated.status) === "INACTIVE" ? "DEACTIVATED" : "UPDATED",
    before: cur,
    after: updated,
    reason: body.reason,
    userId,
  });

  return updated;
}

async function setPrimaryBeneficiaryBankAccount(
  db,
  accountId,
  { reason },
  userId = null,
) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [rows] = await q.query(
      `SELECT * FROM payroll_beneficiary_bank_accounts WHERE id=? LIMIT 1 FOR UPDATE`,
      [accountId],
    );
    const row = rows[0];
    if (!row) {
      const err = new Error("Beneficiary bank account not found");
      err.statusCode = 404;
      throw err;
    }
    if (row.status !== "ACTIVE") {
      const err = new Error(
        "Only ACTIVE beneficiary bank account can be primary",
      );
      err.statusCode = 409;
      throw err;
    }

    await q.query(
      `
      UPDATE payroll_beneficiary_bank_accounts
      SET is_primary=0, updated_by=?, updated_at=NOW()
      WHERE employee_id=? AND currency_code=? AND status='ACTIVE'
      `,
      [userId, row.employee_id, row.currency_code],
    );

    await q.query(
      `
      UPDATE payroll_beneficiary_bank_accounts
      SET is_primary=1, updated_by=?, updated_at=NOW()
      WHERE id=?
      `,
      [userId, row.id],
    );

    const [updatedRows] = await q.query(
      `SELECT * FROM payroll_beneficiary_bank_accounts WHERE id=? LIMIT 1`,
      [row.id],
    );
    const updated = updatedRows[0];

    await writeAudit(q, {
      account: updated,
      action: "SET_PRIMARY",
      before: row,
      after: updated,
      reason,
      userId,
    });

    if (conn) await conn.commit();
    return updated;
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function resolvePrimaryBeneficiaryBankAccount(
  db,
  { employeeId, currencyCode, asOfDate = null },
) {
  const [rows] = await db.query(
    `
    SELECT *
    FROM payroll_beneficiary_bank_accounts
    WHERE employee_id=?
      AND currency_code=?
      AND status='ACTIVE'
      AND is_primary=1
      AND (effective_from IS NULL OR effective_from <= COALESCE(?, CURDATE()))
      AND (effective_to IS NULL OR effective_to >= COALESCE(?, CURDATE()))
    ORDER BY id DESC
    LIMIT 1
    `,
    [employeeId, currencyCode, asOfDate, asOfDate],
  );
  return rows[0] || null;
}

async function createOrGetBeneficiarySnapshotFromMaster(
  db,
  masterRow,
  userId = null,
) {
  const snapshot_hash = snapshotHashFromRow(masterRow);

  const [existing] = await db.query(
    `SELECT * FROM payroll_beneficiary_bank_snapshots WHERE snapshot_hash=? LIMIT 1`,
    [snapshot_hash],
  );
  if (existing[0]) return existing[0];

  const [ins] = await db.query(
    `
    INSERT INTO payroll_beneficiary_bank_snapshots
    (employee_id, source_beneficiary_bank_account_id, snapshot_hash, currency_code,
     account_holder_name, bank_name, bank_branch_name, country_code,
     iban, account_number, routing_number, swift_bic, account_last4,
     verification_status, payload_json, created_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      masterRow.employee_id,
      masterRow.id,
      snapshot_hash,
      masterRow.currency_code,
      masterRow.account_holder_name,
      masterRow.bank_name,
      masterRow.bank_branch_name || null,
      masterRow.country_code || null,
      masterRow.iban || null,
      masterRow.account_number || null,
      masterRow.routing_number || null,
      masterRow.swift_bic || null,
      masterRow.account_last4 || null,
      masterRow.verification_status || "UNVERIFIED",
      JSON.stringify({
        source_type: masterRow.source_type || "MANUAL",
        external_ref: masterRow.external_ref || null,
      }),
      userId,
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM payroll_beneficiary_bank_snapshots WHERE id=? LIMIT 1`,
    [ins.insertId],
  );
  return rows[0];
}

async function attachBeneficiarySnapshotToPaymentLink(
  db,
  {
    paymentLinkId,
    payrollLiabilityId,
    employeeId,
    currencyCode,
    asOfDate = null,
  },
  userId = null,
) {
  const master = await resolvePrimaryBeneficiaryBankAccount(db, {
    employeeId,
    currencyCode,
    asOfDate,
  });

  if (!master) {
    const err = new Error(
      `No active primary beneficiary bank account for employee ${employeeId} (${currencyCode})`,
    );
    err.statusCode = 409;
    err.code = "PAYROLL_BENEFICIARY_MISSING";
    throw err;
  }

  const snapshot = await createOrGetBeneficiarySnapshotFromMaster(
    db,
    master,
    userId,
  );

  await db.query(
    `
    UPDATE payroll_liability_payment_links
    SET beneficiary_bank_snapshot_id=?,
        beneficiary_snapshot_status='CAPTURED'
    WHERE id=?
    `,
    [snapshot.id, paymentLinkId],
  );

  return snapshot;
}

async function getBeneficiarySnapshotForLiability(db, liabilityId) {
  const [rows] = await db.query(
    `
    SELECT
      l.id AS payroll_liability_id,
      pl.id AS payment_link_id,
      pl.beneficiary_bank_snapshot_id,
      pl.beneficiary_snapshot_status,
      s.*
    FROM payroll_run_liabilities l
    LEFT JOIN payroll_liability_payment_links pl
      ON pl.payroll_liability_id = l.id
    LEFT JOIN payroll_beneficiary_bank_snapshots s
      ON s.id = pl.beneficiary_bank_snapshot_id
    WHERE l.id = ?
    ORDER BY pl.id DESC
    LIMIT 1
    `,
    [liabilityId],
  );
  return rows[0] || null;
}

export default {
  listEmployeeBeneficiaryBankAccounts,
  createEmployeeBeneficiaryBankAccount,
  updateBeneficiaryBankAccount,
  setPrimaryBeneficiaryBankAccount,
  resolvePrimaryBeneficiaryBankAccount,
  createOrGetBeneficiarySnapshotFromMaster,
  attachBeneficiarySnapshotToPaymentLink,
  getBeneficiarySnapshotForLiability,
};
```

---

## 4) Routes — `backend/src/routes/payroll.beneficiaries.js`

```js
// backend/src/routes/payroll.beneficiaries.js

import express from "express";
import svc from "../services/payroll.beneficiaries.service.js";
import { validateEmployeeIdParam,
  validateBeneficiaryAccountIdParam,
  validateCreateBeneficiaryAccountBody,
  validateUpdateBeneficiaryAccountBody,
  validateSetPrimaryBody, } from "./payroll.beneficiaries.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/payroll/employees/:employeeId/beneficiary-bank-accounts
router.get(
  "/employees/:employeeId/beneficiary-bank-accounts",
  requireAuth,
  requirePermission("payroll.beneficiary.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { employeeId } = validateEmployeeIdParam(req.params);
      const items = await svc.listEmployeeBeneficiaryBankAccounts(
        db,
        employeeId,
      );
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/employees/:employeeId/beneficiary-bank-accounts
router.post(
  "/employees/:employeeId/beneficiary-bank-accounts",
  requireAuth,
  requirePermission("payroll.beneficiary.write"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { employeeId } = validateEmployeeIdParam(req.params);
      const body = validateCreateBeneficiaryAccountBody(req.body);
      const item = await svc.createEmployeeBeneficiaryBankAccount(
        db,
        employeeId,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// PATCH /api/v1/payroll/beneficiary-bank-accounts/:id
router.patch(
  "/beneficiary-bank-accounts/:id",
  requireAuth,
  requirePermission("payroll.beneficiary.write"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateBeneficiaryAccountIdParam(req.params);
      const body = validateUpdateBeneficiaryAccountBody(req.body);
      const item = await svc.updateBeneficiaryBankAccount(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/beneficiary-bank-accounts/:id/set-primary
router.post(
  "/beneficiary-bank-accounts/:id/set-primary",
  requireAuth,
  requirePermission("payroll.beneficiary.set_primary"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateBeneficiaryAccountIdParam(req.params);
      const body = validateSetPrimaryBody(req.body);
      const item = await svc.setPrimaryBeneficiaryBankAccount(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/payroll/liabilities/:id/beneficiary-bank-snapshot
router.get(
  "/liabilities/:id/beneficiary-bank-snapshot",
  requireAuth,
  requirePermission("payroll.beneficiary.snapshot.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const id = Number(req.params.id);
      if (!Number.isInteger(id) || id <= 0)
        throw new Error("id must be positive integer");
      const item = await svc.getBeneficiarySnapshotForLiability(db, id);
      if (!item) return res.status(404).json({ error: "Snapshot not found" });
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 5) Patch P03 payment-link creation — `backend/src/services/payroll.payments.service.js` (important)

> This is the core P07 integration point.
> When you create payroll payment links (or assign liabilities into a payment batch), attach the snapshot.

### A) Attach snapshot during link creation

```js
// patch snippet in backend/src/services/payroll.payments.service.js

import payrollBeneficiariesSvc from "./payroll.beneficiaries.service.js";
// ...inside your existing "create payment links / batch from liabilities" flow:

// After INSERT payroll_liability_payment_links ... get linkId
// You likely already have: liability (with employee_id), run/currency, linkId

const snapshot =
  await payrollBeneficiariesSvc.attachBeneficiarySnapshotToPaymentLink(
    q, // transaction connection
    {
      paymentLinkId: linkId,
      payrollLiabilityId: liability.id,
      employeeId: liability.employee_id,
      currencyCode: liability.currency_code || run.currency_code,
      asOfDate: run.period_end || null,
    },
    userId,
  );

// If you also create bank payment_batch_lines here, include snapshot details in line payload:
await q.query(
  `
  UPDATE payment_batch_lines
  SET payload_json = JSON_SET(
    COALESCE(payload_json, JSON_OBJECT()),
    '$.payroll.beneficiary_snapshot_id', ?,
    '$.payroll.account_holder_name', ?,
    '$.payroll.bank_name', ?,
    '$.payroll.account_last4', ?
  )
  WHERE id = ?
  `,
  [
    snapshot.id,
    snapshot.account_holder_name,
    snapshot.bank_name,
    snapshot.account_last4,
    paymentBatchLineId,
  ],
);

// Optional: if your payment_batch_lines has explicit beneficiary columns, fill them too
```

### B) Clear error for missing beneficiary setup

```js
// patch behavior around attachBeneficiarySnapshotToPaymentLink(...)
try {
  // attach snapshot
} catch (err) {
  if (err.code === "PAYROLL_BENEFICIARY_MISSING") {
    // Return structured business error (preferred)
    err.statusCode = 409;
    err.details = {
      payroll_liability_id: liability.id,
      employee_id: liability.employee_id,
      currency_code: liability.currency_code || run.currency_code,
      action_required:
        "Set primary beneficiary bank account before creating payroll payment batch",
    };
  }
  throw err;
}
```

---

## 6) Patch B06 payment file export — `backend/src/services/bank.paymentFiles.service.js` (important)

> Payment export must use snapshot, not live employee master.

```js
// patch snippet in backend/src/services/bank.paymentFiles.service.js

async function buildPaymentFileRowsForBatch(db, paymentBatchId) {
  // Example join path (adapt to your schema/table names)
  const [rows] = await db.query(
    `
    SELECT
      pbl.*,
      pl.payroll_liability_id,
      pl.beneficiary_bank_snapshot_id,

      s.account_holder_name AS snap_account_holder_name,
      s.bank_name AS snap_bank_name,
      s.iban AS snap_iban,
      s.account_number AS snap_account_number,
      s.routing_number AS snap_routing_number,
      s.swift_bic AS snap_swift_bic,
      s.account_last4 AS snap_account_last4,
      s.currency_code AS snap_currency_code

    FROM payment_batch_lines pbl
    LEFT JOIN payroll_liability_payment_links pl
      ON pl.payment_batch_line_id = pbl.id
    LEFT JOIN payroll_beneficiary_bank_snapshots s
      ON s.id = pl.beneficiary_bank_snapshot_id
    WHERE pbl.payment_batch_id = ?
    ORDER BY pbl.id
    `,
    [paymentBatchId],
  );

  // For payroll-origin lines, require snapshot
  for (const row of rows) {
    const isPayrollLine =
      row.payroll_liability_id != null ||
      String(row.line_type || "").toUpperCase() === "PAYROLL";

    if (isPayrollLine && !row.beneficiary_bank_snapshot_id) {
      const err = new Error(
        `Missing beneficiary snapshot for payroll payment batch line ${row.id}`,
      );
      err.statusCode = 409;
      throw err;
    }

    // Build file row using snapshot fields (not employee master)
    // ...
  }

  return rows;
}
```

---

## 7) Patch payroll liabilities list/detail — `backend/src/services/payroll.liabilities.service.js` (optional but useful)

> Add snapshot visibility so UI can show “ready for payment / missing beneficiary”.

```js
// patch snippet in payroll.liabilities.service.js list query SELECT

pl.beneficiary_bank_snapshot_id,
pl.beneficiary_snapshot_status,
```

And expose a simple derived flag in response mapping:

- `beneficiary_ready_for_payment = !!beneficiary_bank_snapshot_id`

---

## 8) Mount route — `backend/src/index.js`

```js
// backend/src/index.js
import payrollBeneficiariesRoutes from "./routes/payroll.beneficiaries.js";
// ...
app.use("/api/v1/payroll", payrollBeneficiariesRoutes);
```

---

## 9) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m051_payroll_beneficiary_snapshots from "./m051_payroll_beneficiary_snapshots.js";
export default [
  // ...
  m051_payroll_beneficiary_snapshots,
];
```

---

## 10) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const PAYROLL_P07_PERMISSIONS = [
  "payroll.beneficiary.read",
  "payroll.beneficiary.write",
  "payroll.beneficiary.set_primary",
  "payroll.beneficiary.snapshot.read",
];

// merge into permission seed list
```

> If you want stricter SoD later, P08 can split “write” into prepare vs approve.

---

## 11) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/payroll/employees/{employeeId}/beneficiary-bank-accounts`
- `POST /api/v1/payroll/employees/{employeeId}/beneficiary-bank-accounts`
- `PATCH /api/v1/payroll/beneficiary-bank-accounts/{id}`
- `POST /api/v1/payroll/beneficiary-bank-accounts/{id}/set-primary`
- `GET /api/v1/payroll/liabilities/{id}/beneficiary-bank-snapshot`

Also document new fields on payroll payment link / liabilities payloads:

- `beneficiary_bank_snapshot_id`
- `beneficiary_snapshot_status`

---

## 12) Backend smoke test — `backend/scripts/test-payroll-prp07-beneficiary-snapshots.js`

```js
// backend/scripts/test-payroll-prp07-beneficiary-snapshots.js

async function main() {
  // Preconditions:
  // - P03 payroll payment-link creation exists
  // - B06 payment file/export service exists (or export preview path)
  //
  // Flow A: Master setup
  // 1) Create beneficiary bank account for employee E1 (USD), is_primary=true
  // 2) List accounts -> returns 1 primary account
  //
  // Flow B: Snapshot on payroll payment link creation
  // 3) Create payroll run + liabilities for E1
  // 4) Create payroll payment batch / links (P03)
  //    -> link gets beneficiary_bank_snapshot_id
  //    -> beneficiary_snapshot_status='CAPTURED'
  //
  // Flow C: Historical safety
  // 5) Update employee E1 master bank account (change IBAN/account)
  // 6) Export payment file for existing batch (B06)
  //    -> export still uses OLD snapshot values (not new master)
  //
  // Flow D: New payment uses new snapshot
  // 7) Create a new payroll liability/payment link after master change
  //    -> new link gets different snapshot id (if details changed)
  //
  // Flow E: Missing setup block
  // 8) Create liability for employee E2 with no primary beneficiary account
  // 9) Try create payroll payment links
  //    -> fails with 409 and clear action_required message
  //
  // Flow F: Primary switching
  // 10) Add second account for E1 and set-primary
  //     -> previous primary unset, new primary set
  //
  // Permissions:
  // - payroll.beneficiary.read/write/set_primary/snapshot.read enforced (403)
  console.log("PR-P07 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 13) `backend/package.json` updates

```json
{
  "scripts": {
    "test:payroll:prp07": "node backend/scripts/test-payroll-prp07-beneficiary-snapshots.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 14) API client — `frontend/src/api/payrollBeneficiaries.js`

```js
// frontend/src/api/payrollBeneficiaries.js

import { apiFetch } from "./client.js"; // adapt to your app

export function listEmployeeBeneficiaryBankAccounts(employeeId) {
  return apiFetch(
    `/api/v1/payroll/employees/${employeeId}/beneficiary-bank-accounts`,
  );
}

export function createEmployeeBeneficiaryBankAccount(employeeId, payload) {
  return apiFetch(
    `/api/v1/payroll/employees/${employeeId}/beneficiary-bank-accounts`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}

export function updateBeneficiaryBankAccount(accountId, payload) {
  return apiFetch(`/api/v1/payroll/beneficiary-bank-accounts/${accountId}`, {
    method: "PATCH",
    body: JSON.stringify(payload),
  });
}

export function setPrimaryBeneficiaryBankAccount(accountId, payload = {}) {
  return apiFetch(
    `/api/v1/payroll/beneficiary-bank-accounts/${accountId}/set-primary`,
    {
      method: "POST",
      body: JSON.stringify(payload),
    },
  );
}

export function getPayrollLiabilityBeneficiarySnapshot(liabilityId) {
  return apiFetch(
    `/api/v1/payroll/liabilities/${liabilityId}/beneficiary-bank-snapshot`,
  );
}
```

---

## 15) Employee/payroll master page snippet — `PayrollEmployeesPage.jsx` (or equivalent)

### Add imports

```jsx
import {
  listEmployeeBeneficiaryBankAccounts,
  createEmployeeBeneficiaryBankAccount,
  setPrimaryBeneficiaryBankAccount,
} from "../../api/payrollBeneficiaries.js";
```

### Minimal state

```jsx
const [beneficiaryAccounts, setBeneficiaryAccounts] = useState([]);
const [beneficiaryErr, setBeneficiaryErr] = useState("");
```

### Load + create + set primary

```jsx
async function loadBeneficiaries(employeeId) {
  try {
    setBeneficiaryErr("");
    const res = await listEmployeeBeneficiaryBankAccounts(employeeId);
    setBeneficiaryAccounts(res.items || []);
  } catch (e) {
    setBeneficiaryErr(e.message || "Failed to load beneficiary bank accounts");
  }
}

async function onAddBeneficiary(employeeId) {
  await createEmployeeBeneficiaryBankAccount(employeeId, {
    account_holder_name: "John Doe",
    bank_name: "ABC Bank",
    currency_code: "USD",
    iban: "TR00...", // or account_number
    swift_bic: "ABCDEF12",
    is_primary: true,
    verification_status: "VERIFIED",
    reason: "Initial payroll beneficiary setup",
  });
  await loadBeneficiaries(employeeId);
}

async function onSetPrimary(accountId, employeeId) {
  await setPrimaryBeneficiaryBankAccount(accountId, {
    reason: "Switch payroll payout account",
  });
  await loadBeneficiaries(employeeId);
}
```

### Compact UI (no full tables)

```jsx
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Payroll Beneficiary Bank Accounts</h2>

  {/* Show compact list:
      - bank_name
      - account_holder_name
      - currency_code
      - account_last4
      - is_primary badge
      - status / verification_status
      - actions: Set Primary, Edit
  */}

  {beneficiaryErr ? (
    <div className="text-sm text-red-600">{beneficiaryErr}</div>
  ) : null}
</div>
```

---

## 16) Liability page snippet — `PayrollLiabilitiesPage.jsx` (snapshot readiness)

### Show payment readiness / snapshot status

```jsx
{
  /* In liability card/row */
}
<div className="text-xs">
  Beneficiary snapshot:{" "}
  {liability.beneficiary_bank_snapshot_id ? (
    <span className="text-green-700">
      Ready (#{liability.beneficiary_bank_snapshot_id})
    </span>
  ) : (
    <span className="text-amber-700">Missing</span>
  )}
</div>;
```

### Optional snapshot detail viewer

```jsx
import { getPayrollLiabilityBeneficiarySnapshot } from "../../api/payrollBeneficiaries.js";

async function onViewBeneficiarySnapshot(liabilityId) {
  const res = await getPayrollLiabilityBeneficiarySnapshot(liabilityId);
  // show modal/card with snapshot fields:
  // account_holder_name, bank_name, account_last4, iban/account_number (masked in UI)
}
```

---

## Acceptance criteria (repeat in PR)

- ✅ Employee beneficiary bank master exists and supports multiple accounts
- ✅ One active primary beneficiary account can be set per employee/currency (service-enforced)
- ✅ Beneficiary master changes are auditable
- ✅ Payroll payment-link creation (P03 flow) captures immutable beneficiary snapshot
- ✅ `payroll_liability_payment_links` stores `beneficiary_bank_snapshot_id`
- ✅ Payment file/export (B06) uses snapshot values, not live employee bank master
- ✅ Updating beneficiary master after batch creation does **not** change previously created payment exports
- ✅ Missing beneficiary setup blocks payroll payment-link creation with clear error
- ✅ Liability/list APIs can expose beneficiary snapshot readiness
- ✅ Permissions enforced:

  - `payroll.beneficiary.read`
  - `payroll.beneficiary.write`
  - `payroll.beneficiary.set_primary`
  - `payroll.beneficiary.snapshot.read`

- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:payroll:prp07`

Should verify at least:

1. **Master setup**

   - Create beneficiary account for employee
   - Mark as primary
   - List returns primary + masked account info

2. **Snapshot capture**

   - Create payroll payment links (P03)
   - Links receive `beneficiary_bank_snapshot_id`
   - Snapshot row contains expected bank details

3. **Historical immutability**

   - Update employee beneficiary master
   - Existing payment batch export still uses original snapshot values

4. **New payments use new snapshot**

   - New payroll payment link after master change gets new snapshot (if details changed)

5. **Missing setup block**

   - Employee with no beneficiary master cannot enter payroll payment flow (`409`)

6. **Primary switching**

   - Setting a new primary unsets old primary for same employee/currency

7. **Permissions**

   - All new `payroll.beneficiary.*` permissions enforced (`403`)

---

## Tiny implementation notes (important)

- If you already store employee bank account on your employee master table, **don’t delete it yet**.
  P07 can coexist and gradually become the source of truth for payroll payouts.
- If you have encryption helpers, use them for `iban/account_number` fields (recommended).
  Even if not in v1, at least avoid exposing raw values in list endpoints/UI.
- This PR sets up **P08** nicely:

  - payroll close checklist can enforce “all payroll liabilities have beneficiary snapshots before payment run”
  - close lock can block finalization if beneficiary setup is incomplete

---

# PR-P08: Payroll Close Controls + Checklist + Period Locks

## Goal

Add a proper **Payroll Period Close** workflow with:

- ✅ Close checklist generation (system checks)
- ✅ Maker-checker close approval
- ✅ Period-level locks for payroll changes
- ✅ Reopen flow (controlled, auditable)
- ✅ Lock enforcement wired into P05/P06 flows
- ✅ Checklist checks for:

  - P05 correction safety (no open retro drafts / invalid run states)
  - P06 manual override pending requests
  - P07 beneficiary snapshot readiness

This PR gives you the operational controls mature ERPs use before saying:
**“Payroll for this period is closed.”**

---

## Important behavior rules

### 1) Close is period-based (entity + period)

Close applies to:

- `entity_id`
- `period_start`
- `period_end`

It is not just a run-level status.

That means the close process evaluates **all payroll runs/liabilities/overrides** in that period.

---

### 2) Close uses checklist first, then approval

Workflow:

1. **Prepare checklist** (system computes checks)
2. **Request close** (maker)
3. **Approve & close** (checker, different user)

This gives you auditability and reduces accidental closes.

---

### 3) Close creates locks (not just a label)

When a period is **CLOSED**, P08 enforces locks:

- Block **P05** correction actions in that period:

  - reversal
  - off-cycle run creation
  - retro finalize (and retro batch edits if tied to closed source/current period)

- Block **P06** manual settlement override requests/approvals for liabilities in that closed period _(configurable in lock flags; v1 default = blocked)_

---

### 4) Beneficiary snapshot readiness is checked before close (P07)

Before close is allowed, checklist must confirm:

- No payroll liabilities in payment flow are missing `beneficiary_bank_snapshot_id`

This prevents “closed payroll, but payment setup incomplete” situations.

---

### 5) Reopen is explicit and audited

Reopen is allowed only to authorized users, with a reason.

Reopen does **not** delete history — it creates audit trail and unlocks period for controlled corrections.

---

## Files to create

## Backend

- `backend/src/migrations/m052_payroll_close_controls.js`
- `backend/src/routes/payroll.close.js`
- `backend/src/routes/payroll.close.validators.js`
- `backend/src/services/payroll.close.service.js`
- `backend/scripts/test-payroll-prp08-close-controls-checklist-locks.js`

## Frontend (short snippets only)

- `frontend/src/api/payrollClose.js`

---

## Files to update

## Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

## Backend (important patches)

- `backend/src/services/payroll.corrections.service.js` _(P05 lock enforcement)_
- `backend/src/services/payroll.retro.service.js` _(P05 lock enforcement for retro)_
- `backend/src/services/payroll.settlementOverrides.service.js` _(P06 lock enforcement)_
- `backend/src/services/payroll.runs.service.js` _(optional shared lock helper use)_
- `backend/src/services/payroll.payments.service.js` _(optional close-precheck hook during batch build)_

## Frontend (short integration only)

- `frontend/src/pages/payroll/PayrollRunsPage.jsx` _(show period close status)_
- `frontend/src/pages/payroll/PayrollClosePage.jsx` _(optional dedicated page)_
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m052_payroll_close_controls.js`

> Adjust migration number if your sequence differs.

```js
// backend/src/migrations/m052_payroll_close_controls.js

export default {
  key: "m052_payroll_close_controls",
  description: "m052_payroll_close_controls",
  async up(connection) {
    // One close record per entity+period (can reopen/reclose by status transitions)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_period_closes (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,

        entity_id BIGINT UNSIGNED NOT NULL,
        period_start DATE NOT NULL,
        period_end DATE NOT NULL,

        status VARCHAR(20) NOT NULL DEFAULT 'DRAFT', -- DRAFT, READY, REQUESTED, CLOSED, REOPENED
        checklist_version INT NOT NULL DEFAULT 1,

        total_checks INT NOT NULL DEFAULT 0,
        passed_checks INT NOT NULL DEFAULT 0,
        failed_checks INT NOT NULL DEFAULT 0,
        warning_checks INT NOT NULL DEFAULT 0,

        // Lock flags activated on CLOSE
        lock_run_changes TINYINT(1) NOT NULL DEFAULT 0,        -- P05 corrections
        lock_manual_settlements TINYINT(1) NOT NULL DEFAULT 0, -- P06 manual overrides
        lock_payment_prep TINYINT(1) NOT NULL DEFAULT 0,       -- optional P03 link creation guard

        request_note VARCHAR(500) NULL,
        close_note VARCHAR(500) NULL,
        reopen_reason VARCHAR(500) NULL,

        request_idempotency_key VARCHAR(190) NULL,
        close_idempotency_key VARCHAR(190) NULL,

        prepared_by BIGINT UNSIGNED NULL,
        prepared_at DATETIME NULL,

        requested_by BIGINT UNSIGNED NULL,
        requested_at DATETIME NULL,

        approved_by BIGINT UNSIGNED NULL,
        approved_at DATETIME NULL,

        closed_by BIGINT UNSIGNED NULL,
        closed_at DATETIME NULL,

        reopened_by BIGINT UNSIGNED NULL,
        reopened_at DATETIME NULL,

        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_payroll_period_close_period (entity_id, period_start, period_end),
        UNIQUE KEY uq_ppc_request_idem (request_idempotency_key),
        UNIQUE KEY uq_ppc_close_idem (close_idempotency_key),
        KEY idx_ppc_status (status),
        KEY idx_ppc_period (period_start, period_end)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Computed checklist items (refreshable)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_period_close_checks (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        payroll_period_close_id BIGINT UNSIGNED NOT NULL,

        check_code VARCHAR(80) NOT NULL,
        check_name VARCHAR(190) NOT NULL,
        severity VARCHAR(10) NOT NULL DEFAULT 'ERROR', -- ERROR, WARN, INFO
        status VARCHAR(10) NOT NULL DEFAULT 'FAIL',    -- PASS, FAIL, WARN

        metric_value DECIMAL(18,2) NULL,
        metric_text VARCHAR(255) NULL,
        details_json JSON NULL,

        sort_order INT NOT NULL DEFAULT 100,

        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_ppcc_unique (payroll_period_close_id, check_code),
        KEY idx_ppcc_close (payroll_period_close_id),
        KEY idx_ppcc_status (status),

        CONSTRAINT fk_ppcc_close
          FOREIGN KEY (payroll_period_close_id) REFERENCES payroll_period_closes(id)
          ON UPDATE RESTRICT ON DELETE CASCADE
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Audit log
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_period_close_audit (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        payroll_period_close_id BIGINT UNSIGNED NOT NULL,

        action VARCHAR(30) NOT NULL, -- PREPARED, REQUESTED, CLOSED, REOPENED
        action_status VARCHAR(20) NOT NULL DEFAULT 'CONFIRMED',
        note VARCHAR(500) NULL,
        payload_json JSON NULL,

        acted_by BIGINT UNSIGNED NULL,
        acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_ppca_close (payroll_period_close_id),
        KEY idx_ppca_action (action),

        CONSTRAINT fk_ppca_close
          FOREIGN KEY (payroll_period_close_id) REFERENCES payroll_period_closes(id)
          ON UPDATE RESTRICT ON DELETE CASCADE
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS payroll_period_close_audit;`);
    await connection.execute(`DROP TABLE IF EXISTS payroll_period_close_checks;`);
    await connection.execute(`DROP TABLE IF EXISTS payroll_period_closes;`);
  },
};
```

---

## 2) Validators — `backend/src/routes/payroll.close.validators.js`

```js
// backend/src/routes/payroll.close.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function requireDate(v, field) {
  const s = String(v || "").trim();
  if (!/^\d{4}-\d{2}-\d{2}$/.test(s))
    throw new Error(`${field} must be YYYY-MM-DD`);
  return s;
}

function validateCloseIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validatePrepareCloseBody(body = {}) {
  return {
    entity_id: requirePositiveInt(body.entity_id, "entity_id"),
    period_start: requireDate(body.period_start, "period_start"),
    period_end: requireDate(body.period_end, "period_end"),
    lock_run_changes:
      body.lock_run_changes === undefined ? true : !!body.lock_run_changes,
    lock_manual_settlements:
      body.lock_manual_settlements === undefined
        ? true
        : !!body.lock_manual_settlements,
    lock_payment_prep:
      body.lock_payment_prep === undefined ? false : !!body.lock_payment_prep,
    note: normalizeString(body.note),
  };
}

function validateRequestCloseBody(body = {}) {
  return {
    note: normalizeString(body.note),
    request_idempotency_key: normalizeString(body.request_idempotency_key),
  };
}

function validateApproveCloseBody(body = {}) {
  return {
    note: normalizeString(body.note),
    close_idempotency_key: normalizeString(body.close_idempotency_key),
  };
}

function validateReopenBody(body = {}) {
  return {
    reason:
      normalizeString(body.reason) ||
      (() => {
        throw new Error("reason is required");
      })(),
  };
}

export default {
  validateCloseIdParam,
  validatePrepareCloseBody,
  validateRequestCloseBody,
  validateApproveCloseBody,
  validateReopenBody,
};
```

---

## 3) Service — `backend/src/services/payroll.close.service.js`

> Core responsibilities:
>
> - compute checklist
> - request/approve close (maker-checker)
> - reopen
> - expose lock checks for other services (P05/P06)

```js
// backend/src/services/payroll.close.service.js

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

async function writeAudit(
  db,
  closeId,
  action,
  payload,
  userId = null,
  note = null,
) {
  await db.query(
    `
    INSERT INTO payroll_period_close_audit
    (payroll_period_close_id, action, action_status, note, payload_json, acted_by)
    VALUES (?, ?, 'CONFIRMED', ?, ?, ?)
    `,
    [
      closeId,
      action,
      note || null,
      payload ? JSON.stringify(payload) : null,
      userId,
    ],
  );
}

async function getOrCreatePeriodClose(
  db,
  { entity_id, period_start, period_end },
) {
  const [rows] = await db.query(
    `
    SELECT * FROM payroll_period_closes
    WHERE entity_id=? AND period_start=? AND period_end=?
    LIMIT 1
    `,
    [entity_id, period_start, period_end],
  );
  if (rows[0]) return rows[0];

  const [ins] = await db.query(
    `
    INSERT INTO payroll_period_closes
    (entity_id, period_start, period_end, status)
    VALUES (?, ?, ?, 'DRAFT')
    `,
    [entity_id, period_start, period_end],
  );
  const [created] = await db.query(
    `SELECT * FROM payroll_period_closes WHERE id=?`,
    [ins.insertId],
  );
  return created[0];
}

async function listPayrollPeriodCloses(
  db,
  { entity_id = null, limit = 50 } = {},
) {
  const sql = entity_id
    ? `SELECT * FROM payroll_period_closes WHERE entity_id=? ORDER BY id DESC LIMIT ?`
    : `SELECT * FROM payroll_period_closes ORDER BY id DESC LIMIT ?`;
  const params = entity_id ? [entity_id, limit] : [limit];
  const [rows] = await db.query(sql, params);
  return rows;
}

async function getPayrollPeriodCloseDetail(db, closeId) {
  const [closeRows] = await db.query(
    `SELECT * FROM payroll_period_closes WHERE id=? LIMIT 1`,
    [closeId],
  );
  const close = closeRows[0];
  if (!close) {
    const err = new Error("Payroll period close not found");
    err.statusCode = 404;
    throw err;
  }

  const [checks] = await db.query(
    `SELECT * FROM payroll_period_close_checks WHERE payroll_period_close_id=? ORDER BY sort_order, id`,
    [closeId],
  );
  const [audit] = await db.query(
    `SELECT * FROM payroll_period_close_audit WHERE payroll_period_close_id=? ORDER BY id DESC`,
    [closeId],
  );

  return { close, checks, audit };
}

/**
 * Checklist computation (P05/P06/P07 aware)
 */
async function computeChecklist(db, { entity_id, period_start, period_end }) {
  // 1) Payroll runs in period
  const [[runStats]] = await db.query(
    `
    SELECT
      COUNT(*) AS run_count,
      SUM(CASE WHEN status IN ('DRAFT','FAILED') THEN 1 ELSE 0 END) AS draft_or_failed_runs,
      SUM(CASE WHEN status IN ('FINALIZED','POSTED','CLOSED') THEN 1 ELSE 0 END) AS finalized_like_runs,
      SUM(CASE WHEN posted_journal_entry_id IS NULL AND status IN ('FINALIZED','POSTED','CLOSED') THEN 1 ELSE 0 END) AS unposted_accrual_runs
    FROM payroll_runs
    WHERE entity_id = ?
      AND period_start = ?
      AND period_end = ?
    `,
    [entity_id, period_start, period_end],
  );

  // 2) Retro drafts touching this period (P05)
  const [[retroStats]] = await db
    .query(
      `
    SELECT
      COUNT(*) AS retro_draft_count
    FROM payroll_retro_batches
    WHERE status='DRAFT'
      AND entity_id = ?
      AND (
        (payroll_period_start = ? AND payroll_period_end = ?)
        OR (source_period_start = ? AND source_period_end = ?)
      )
    `,
      [entity_id, period_start, period_end, period_start, period_end],
    )
    .catch(() => [[{ retro_draft_count: 0 }]]); // if P05 table not yet present in lower envs

  // 3) Pending manual settlement override requests (P06)
  const [[overrideStats]] = await db
    .query(
      `
    SELECT
      COUNT(*) AS pending_override_count
    FROM payroll_liability_override_requests r
    INNER JOIN payroll_run_liabilities l ON l.id = r.payroll_liability_id
    INNER JOIN payroll_runs pr ON pr.id = l.run_id
    WHERE r.status='REQUESTED'
      AND pr.entity_id = ?
      AND pr.period_start = ?
      AND pr.period_end = ?
    `,
      [entity_id, period_start, period_end],
    )
    .catch(() => [[{ pending_override_count: 0 }]]);

  // 4) Beneficiary snapshot readiness (P07)
  const [[benefStats]] = await db
    .query(
      `
    SELECT
      COUNT(*) AS payment_flow_liability_count,
      SUM(CASE WHEN pl.id IS NOT NULL AND pl.beneficiary_bank_snapshot_id IS NULL THEN 1 ELSE 0 END) AS missing_beneficiary_snapshot_count
    FROM payroll_run_liabilities l
    INNER JOIN payroll_runs pr ON pr.id = l.run_id
    LEFT JOIN payroll_liability_payment_links pl ON pl.payroll_liability_id = l.id
    WHERE pr.entity_id = ?
      AND pr.period_start = ?
      AND pr.period_end = ?
      AND l.status IN ('IN_BATCH','PARTIALLY_PAID','PAID')
    `,
      [entity_id, period_start, period_end],
    )
    .catch(() => [
      [
        {
          payment_flow_liability_count: 0,
          missing_beneficiary_snapshot_count: 0,
        },
      ],
    ]);

  // 5) Optional payment sync exceptions (if table exists in your B07/B08 design later)
  // Keep as INFO/WARN placeholder for now
  const checks = [
    {
      check_code: "RUNS_NO_DRAFT_OR_FAILED",
      check_name: "No draft/failed payroll runs in period",
      severity: "ERROR",
      status:
        Number(runStats.draft_or_failed_runs || 0) === 0 ? "PASS" : "FAIL",
      metric_value: Number(runStats.draft_or_failed_runs || 0),
      metric_text: `${Number(runStats.draft_or_failed_runs || 0)} draft/failed runs`,
      sort_order: 10,
    },
    {
      check_code: "RUNS_ACCRUAL_POSTED",
      check_name: "Finalized payroll runs have accrual journal posting",
      severity: "ERROR",
      status:
        Number(runStats.unposted_accrual_runs || 0) === 0 ? "PASS" : "FAIL",
      metric_value: Number(runStats.unposted_accrual_runs || 0),
      metric_text: `${Number(runStats.unposted_accrual_runs || 0)} finalized runs missing posted_journal_entry_id`,
      sort_order: 20,
    },
    {
      check_code: "RETRO_DRAFTS_NONE",
      check_name: "No open retro draft batches affecting this period",
      severity: "ERROR",
      status: Number(retroStats.retro_draft_count || 0) === 0 ? "PASS" : "FAIL",
      metric_value: Number(retroStats.retro_draft_count || 0),
      metric_text: `${Number(retroStats.retro_draft_count || 0)} open retro drafts`,
      sort_order: 30,
    },
    {
      check_code: "MANUAL_OVERRIDE_REQUESTS_NONE",
      check_name: "No pending manual settlement override requests",
      severity: "ERROR",
      status:
        Number(overrideStats.pending_override_count || 0) === 0
          ? "PASS"
          : "FAIL",
      metric_value: Number(overrideStats.pending_override_count || 0),
      metric_text: `${Number(overrideStats.pending_override_count || 0)} pending override requests`,
      sort_order: 40,
    },
    {
      check_code: "BENEFICIARY_SNAPSHOTS_READY",
      check_name:
        "All payroll liabilities in payment flow have beneficiary snapshots",
      severity: "ERROR",
      status:
        Number(benefStats.missing_beneficiary_snapshot_count || 0) === 0
          ? "PASS"
          : "FAIL",
      metric_value: Number(benefStats.missing_beneficiary_snapshot_count || 0),
      metric_text: `${Number(benefStats.missing_beneficiary_snapshot_count || 0)} missing snapshots`,
      sort_order: 50,
      details_json: {
        payment_flow_liability_count: Number(
          benefStats.payment_flow_liability_count || 0,
        ),
      },
    },
    {
      check_code: "RUN_COUNT_INFO",
      check_name: "Payroll runs found in period",
      severity: "INFO",
      status: "PASS",
      metric_value: Number(runStats.run_count || 0),
      metric_text: `${Number(runStats.run_count || 0)} runs`,
      sort_order: 100,
    },
  ];

  return checks;
}

async function upsertChecklistRows(db, closeId, checks) {
  for (const c of checks) {
    await db.query(
      `
      INSERT INTO payroll_period_close_checks
      (payroll_period_close_id, check_code, check_name, severity, status, metric_value, metric_text, details_json, sort_order)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
      ON DUPLICATE KEY UPDATE
        check_name=VALUES(check_name),
        severity=VALUES(severity),
        status=VALUES(status),
        metric_value=VALUES(metric_value),
        metric_text=VALUES(metric_text),
        details_json=VALUES(details_json),
        sort_order=VALUES(sort_order),
        updated_at=NOW()
      `,
      [
        closeId,
        c.check_code,
        c.check_name,
        c.severity,
        c.status,
        c.metric_value ?? null,
        c.metric_text ?? null,
        c.details_json ? JSON.stringify(c.details_json) : null,
        c.sort_order ?? 100,
      ],
    );
  }
}

function summarizeChecks(checks) {
  const total = checks.length;
  const failed = checks.filter(
    (c) => c.severity === "ERROR" && c.status === "FAIL",
  ).length;
  const passed = checks.filter((c) => c.status === "PASS").length;
  const warning = checks.filter(
    (c) =>
      c.status === "WARN" || (c.severity === "WARN" && c.status !== "PASS"),
  ).length;
  return { total, failed, passed, warning };
}

async function preparePayrollPeriodClose(db, body, userId = null) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const close = await getOrCreatePeriodClose(q, body);

    if (close.status === "CLOSED") {
      const err = new Error(
        "Payroll period is already CLOSED. Reopen before preparing again.",
      );
      err.statusCode = 409;
      throw err;
    }

    const checks = await computeChecklist(q, body);
    await upsertChecklistRows(q, close.id, checks);

    const summary = summarizeChecks(checks);
    const nextStatus = summary.failed === 0 ? "READY" : "DRAFT";

    await q.query(
      `
      UPDATE payroll_period_closes
      SET status=?,
          lock_run_changes=?,
          lock_manual_settlements=?,
          lock_payment_prep=?,
          total_checks=?,
          passed_checks=?,
          failed_checks=?,
          warning_checks=?,
          prepared_by=?,
          prepared_at=NOW(),
          updated_at=NOW()
      WHERE id=?
      `,
      [
        nextStatus,
        body.lock_run_changes ? 1 : 0,
        body.lock_manual_settlements ? 1 : 0,
        body.lock_payment_prep ? 1 : 0,
        summary.total,
        summary.passed,
        summary.failed,
        summary.warning,
        userId,
        close.id,
      ],
    );

    await writeAudit(
      q,
      close.id,
      "PREPARED",
      {
        summary,
        lock_flags: {
          lock_run_changes: !!body.lock_run_changes,
          lock_manual_settlements: !!body.lock_manual_settlements,
          lock_payment_prep: !!body.lock_payment_prep,
        },
      },
      userId,
      body.note || "Prepared payroll close checklist",
    );

    if (conn) await conn.commit();
    return getPayrollPeriodCloseDetail(db, close.id);
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function requestPayrollPeriodClose(db, closeId, body, userId = null) {
  if (body.request_idempotency_key) {
    const [idem] = await db.query(
      `SELECT * FROM payroll_period_closes WHERE request_idempotency_key=? LIMIT 1`,
      [body.request_idempotency_key],
    );
    if (idem[0] && Number(idem[0].id) === Number(closeId)) {
      return getPayrollPeriodCloseDetail(db, closeId);
    }
  }

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [rows] = await q.query(
      `SELECT * FROM payroll_period_closes WHERE id=? LIMIT 1 FOR UPDATE`,
      [closeId],
    );
    const close = rows[0];
    if (!close) {
      const err = new Error("Payroll period close not found");
      err.statusCode = 404;
      throw err;
    }

    if (close.status === "CLOSED") {
      const err = new Error("Payroll period already CLOSED");
      err.statusCode = 409;
      throw err;
    }

    // Recompute checklist to avoid stale request
    const checks = await computeChecklist(q, close);
    await upsertChecklistRows(q, close.id, checks);
    const summary = summarizeChecks(checks);

    if (summary.failed > 0) {
      const err = new Error(
        "Cannot request close: checklist has failing ERROR checks",
      );
      err.statusCode = 409;
      err.details = { failed_checks: summary.failed };
      throw err;
    }

    await q.query(
      `
      UPDATE payroll_period_closes
      SET status='REQUESTED',
          request_note=?,
          request_idempotency_key=COALESCE(?, request_idempotency_key),
          total_checks=?,
          passed_checks=?,
          failed_checks=?,
          warning_checks=?,
          requested_by=?,
          requested_at=NOW(),
          updated_at=NOW()
      WHERE id=?
      `,
      [
        body.note || null,
        body.request_idempotency_key || null,
        summary.total,
        summary.passed,
        summary.failed,
        summary.warning,
        userId,
        close.id,
      ],
    );

    await writeAudit(
      q,
      close.id,
      "REQUESTED",
      { summary },
      userId,
      body.note || "Close requested",
    );

    if (conn) await conn.commit();
    return getPayrollPeriodCloseDetail(db, close.id);
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function approveAndClosePayrollPeriod(db, closeId, body, userId = null) {
  if (body.close_idempotency_key) {
    const [idem] = await db.query(
      `SELECT * FROM payroll_period_closes WHERE close_idempotency_key=? LIMIT 1`,
      [body.close_idempotency_key],
    );
    if (idem[0] && Number(idem[0].id) === Number(closeId)) {
      return getPayrollPeriodCloseDetail(db, closeId);
    }
  }

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [rows] = await q.query(
      `SELECT * FROM payroll_period_closes WHERE id=? LIMIT 1 FOR UPDATE`,
      [closeId],
    );
    const close = rows[0];
    if (!close) {
      const err = new Error("Payroll period close not found");
      err.statusCode = 404;
      throw err;
    }

    if (close.status === "CLOSED") {
      if (conn) await conn.commit();
      return getPayrollPeriodCloseDetail(db, close.id);
    }

    if (close.status !== "REQUESTED") {
      const err = new Error(
        `Close record must be REQUESTED before approval (current: ${close.status})`,
      );
      err.statusCode = 409;
      throw err;
    }

    if (
      close.requested_by &&
      userId &&
      Number(close.requested_by) === Number(userId)
    ) {
      const err = new Error(
        "Maker-checker violation: requester cannot approve/close the same payroll period",
      );
      err.statusCode = 403;
      throw err;
    }

    // Recompute checklist again at final close time
    const checks = await computeChecklist(q, close);
    await upsertChecklistRows(q, close.id, checks);
    const summary = summarizeChecks(checks);

    if (summary.failed > 0) {
      const err = new Error(
        "Cannot close payroll period: checklist has failing ERROR checks",
      );
      err.statusCode = 409;
      err.details = { failed_checks: summary.failed };
      throw err;
    }

    await q.query(
      `
      UPDATE payroll_period_closes
      SET status='CLOSED',
          close_note=?,
          close_idempotency_key=COALESCE(?, close_idempotency_key),
          total_checks=?,
          passed_checks=?,
          failed_checks=?,
          warning_checks=?,
          approved_by=?,
          approved_at=NOW(),
          closed_by=?,
          closed_at=NOW(),
          updated_at=NOW()
      WHERE id=?
      `,
      [
        body.note || null,
        body.close_idempotency_key || null,
        summary.total,
        summary.passed,
        summary.failed,
        summary.warning,
        userId,
        userId,
        close.id,
      ],
    );

    await writeAudit(
      q,
      close.id,
      "CLOSED",
      {
        summary,
        lock_flags: {
          lock_run_changes: !!close.lock_run_changes,
          lock_manual_settlements: !!close.lock_manual_settlements,
          lock_payment_prep: !!close.lock_payment_prep,
        },
      },
      userId,
      body.note || "Payroll period closed",
    );

    if (conn) await conn.commit();
    return getPayrollPeriodCloseDetail(db, close.id);
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function reopenPayrollPeriod(db, closeId, { reason }, userId = null) {
  const [rows] = await db.query(
    `SELECT * FROM payroll_period_closes WHERE id=? LIMIT 1`,
    [closeId],
  );
  const close = rows[0];
  if (!close) {
    const err = new Error("Payroll period close not found");
    err.statusCode = 404;
    throw err;
  }
  if (close.status !== "CLOSED") {
    const err = new Error(
      `Only CLOSED payroll periods can be reopened (current: ${close.status})`,
    );
    err.statusCode = 409;
    throw err;
  }

  await db.query(
    `
    UPDATE payroll_period_closes
    SET status='REOPENED',
        reopen_reason=?,
        reopened_by=?,
        reopened_at=NOW(),
        updated_at=NOW()
    WHERE id=?
    `,
    [reason, userId, closeId],
  );

  await writeAudit(db, closeId, "REOPENED", {}, userId, reason);

  return getPayrollPeriodCloseDetail(db, closeId);
}

/**
 * Shared lock check helper for P05/P06 services
 */
async function assertPayrollPeriodActionAllowed(
  db,
  { entityId, periodStart, periodEnd, actionType },
) {
  const [rows] = await db.query(
    `
    SELECT *
    FROM payroll_period_closes
    WHERE entity_id=? AND period_start=? AND period_end=?
    LIMIT 1
    `,
    [entityId, periodStart, periodEnd],
  );
  const close = rows[0];
  if (!close || close.status !== "CLOSED")
    return { allowed: true, close: close || null };

  const action = String(actionType || "").toUpperCase();
  const blocked =
    (action.startsWith("RUN_") && Number(close.lock_run_changes) === 1) ||
    (action.startsWith("MANUAL_SETTLEMENT_") &&
      Number(close.lock_manual_settlements) === 1) ||
    (action.startsWith("PAYMENT_PREP_") &&
      Number(close.lock_payment_prep) === 1);

  if (blocked) {
    const err = new Error(
      `Payroll period is CLOSED and locked for action ${action}`,
    );
    err.statusCode = 409;
    err.code = "PAYROLL_PERIOD_LOCKED";
    err.details = {
      payroll_period_close_id: close.id,
      entity_id: close.entity_id,
      period_start: close.period_start,
      period_end: close.period_end,
      action_type: action,
    };
    throw err;
  }

  return { allowed: true, close };
}

export default {
  listPayrollPeriodCloses,
  getPayrollPeriodCloseDetail,
  preparePayrollPeriodClose,
  requestPayrollPeriodClose,
  approveAndClosePayrollPeriod,
  reopenPayrollPeriod,
  assertPayrollPeriodActionAllowed,
};
```

---

## 4) Routes — `backend/src/routes/payroll.close.js`

```js
// backend/src/routes/payroll.close.js

import express from "express";
import svc from "../services/payroll.close.service.js";
import { validateCloseIdParam,
  validatePrepareCloseBody,
  validateRequestCloseBody,
  validateApproveCloseBody,
  validateReopenBody, } from "./payroll.close.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/payroll/period-closes
router.get(
  "/period-closes",
  requireAuth,
  requirePermission("payroll.close.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const entity_id = req.query.entity_id
        ? Number(req.query.entity_id)
        : null;
      const items = await svc.listPayrollPeriodCloses(db, {
        entity_id,
        limit: req.query.limit ? Number(req.query.limit) : 50,
      });
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/payroll/period-closes/:id
router.get(
  "/period-closes/:id",
  requireAuth,
  requirePermission("payroll.close.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateCloseIdParam(req.params);
      const item = await svc.getPayrollPeriodCloseDetail(db, id);
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/period-closes/prepare
router.post(
  "/period-closes/prepare",
  requireAuth,
  requirePermission("payroll.close.prepare"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validatePrepareCloseBody(req.body);
      const result = await svc.preparePayrollPeriodClose(
        db,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/period-closes/:id/request-close
router.post(
  "/period-closes/:id/request-close",
  requireAuth,
  requirePermission("payroll.close.request"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateCloseIdParam(req.params);
      const body = validateRequestCloseBody(req.body);
      const result = await svc.requestPayrollPeriodClose(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/period-closes/:id/approve-close
router.post(
  "/period-closes/:id/approve-close",
  requireAuth,
  requirePermission("payroll.close.approve"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateCloseIdParam(req.params);
      const body = validateApproveCloseBody(req.body);
      const result = await svc.approveAndClosePayrollPeriod(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/period-closes/:id/reopen
router.post(
  "/period-closes/:id/reopen",
  requireAuth,
  requirePermission("payroll.close.reopen"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateCloseIdParam(req.params);
      const body = validateReopenBody(req.body);
      const result = await svc.reopenPayrollPeriod(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 5) Patch P05 services — lock enforcement

### A) `backend/src/services/payroll.corrections.service.js`

Block reversal and off-cycle create when period is closed+locked.

```js
// patch snippet at top
import payrollCloseSvc from "./payroll.close.service.js";
// In reversePayrollRun(...) after sourceRun loaded:
await payrollCloseSvc.assertPayrollPeriodActionAllowed(q, {
  entityId: sourceRun.entity_id,
  periodStart: sourceRun.period_start,
  periodEnd: sourceRun.period_end,
  actionType: "RUN_REVERSAL",
});

// In createOffCycleRun(...) before creating run:
await payrollCloseSvc.assertPayrollPeriodActionAllowed(q, {
  entityId: body.entity_id,
  periodStart: body.payroll_period_start,
  periodEnd: body.payroll_period_end,
  actionType: "RUN_OFF_CYCLE_CREATE",
});
```

### B) `backend/src/services/payroll.retro.service.js`

Block retro edits/finalize when period is closed+locked.

```js
// patch snippet at top
import payrollCloseSvc from "./payroll.close.service.js";
// In createRetroBatch(...)
await payrollCloseSvc.assertPayrollPeriodActionAllowed(db, {
  entityId: body.entity_id,
  periodStart: body.payroll_period_start,
  periodEnd: body.payroll_period_end,
  actionType: "RUN_RETRO_CREATE",
});

// In addRetroBatchLines(...) after batch loaded:
await payrollCloseSvc.assertPayrollPeriodActionAllowed(db, {
  entityId: batch.entity_id,
  periodStart: batch.payroll_period_start,
  periodEnd: batch.payroll_period_end,
  actionType: "RUN_RETRO_EDIT",
});

// In finalizeRetroBatch(...) after batch loaded:
await payrollCloseSvc.assertPayrollPeriodActionAllowed(q, {
  entityId: batch.entity_id,
  periodStart: batch.payroll_period_start,
  periodEnd: batch.payroll_period_end,
  actionType: "RUN_RETRO_FINALIZE",
});
```

---

## 6) Patch P06 service — manual override lock enforcement

### `backend/src/services/payroll.settlementOverrides.service.js`

Block manual override request/approve/reject if period closed and `lock_manual_settlements=1`.

```js
// patch snippet at top
import payrollCloseSvc from "./payroll.close.service.js";
// In createManualSettlementRequest(...) after liab resolved
const [runRows] = await db.query(
  `SELECT entity_id, period_start, period_end FROM payroll_runs WHERE id=? LIMIT 1`,
  [liab.run_id],
);
const run = runRows[0];
await payrollCloseSvc.assertPayrollPeriodActionAllowed(db, {
  entityId: run.entity_id,
  periodStart: run.period_start,
  periodEnd: run.period_end,
  actionType: "MANUAL_SETTLEMENT_REQUEST",
});

// In approveApplyManualSettlementRequest(...) after liab resolved
const [runRows2] = await q.query(
  `SELECT entity_id, period_start, period_end FROM payroll_runs WHERE id=? LIMIT 1`,
  [liab.run_id],
);
const run2 = runRows2[0];
await payrollCloseSvc.assertPayrollPeriodActionAllowed(q, {
  entityId: run2.entity_id,
  periodStart: run2.period_start,
  periodEnd: run2.period_end,
  actionType: "MANUAL_SETTLEMENT_APPROVE",
});

// In rejectManualSettlementRequest(...) (same pattern, actionType "MANUAL_SETTLEMENT_REJECT")
```

> If you prefer reject to remain allowed after close (to clear pending requests), you can **allow REJECT** and only block request/approve.
> v1 stricter default is okay, but operationally allowing reject is often useful.

---

## 7) Optional patch P03 payment prep — payment link creation guard

If you enable `lock_payment_prep`, block creating new payment links/batches for closed period.

### `backend/src/services/payroll.payments.service.js`

```js
// patch snippet at top
import payrollCloseSvc from "./payroll.close.service.js";
// in createPayrollPaymentBatchFromRun(...) after run loaded
await payrollCloseSvc.assertPayrollPeriodActionAllowed(q, {
  entityId: run.entity_id,
  periodStart: run.period_start,
  periodEnd: run.period_end,
  actionType: "PAYMENT_PREP_CREATE_BATCH",
});
```

---

## 8) Mount route — `backend/src/index.js`

```js
// backend/src/index.js
import payrollCloseRoutes from "./routes/payroll.close.js";
// ...
app.use("/api/v1/payroll", payrollCloseRoutes);
```

---

## 9) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m052_payroll_close_controls from "./m052_payroll_close_controls.js";
export default [
  // ...
  m052_payroll_close_controls,
];
```

---

## 10) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const PAYROLL_P08_PERMISSIONS = [
  "payroll.close.read",
  "payroll.close.prepare",
  "payroll.close.request",
  "payroll.close.approve",
  "payroll.close.reopen",
];

// merge into permission seed list
```

---

## 11) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/payroll/period-closes`
- `GET /api/v1/payroll/period-closes/{id}`
- `POST /api/v1/payroll/period-closes/prepare`
- `POST /api/v1/payroll/period-closes/{id}/request-close`
- `POST /api/v1/payroll/period-closes/{id}/approve-close`
- `POST /api/v1/payroll/period-closes/{id}/reopen`

Also document checklist item schema:

- `check_code`
- `check_name`
- `severity`
- `status`
- `metric_value`
- `metric_text`
- `details_json`

And close lock flags:

- `lock_run_changes`
- `lock_manual_settlements`
- `lock_payment_prep`

---

## 12) Backend smoke test — `backend/scripts/test-payroll-prp08-close-controls-checklist-locks.js`

```js
// backend/scripts/test-payroll-prp08-close-controls-checklist-locks.js

async function main() {
  // Preconditions:
  // - P05/P06/P07 implemented
  //
  // Flow A: Prepare checklist (fail case)
  // 1) Create period with one failing condition (e.g. pending manual override request OR missing beneficiary snapshot)
  // 2) POST /payroll/period-closes/prepare
  //    -> close record created/updated
  //    -> checklist contains FAIL item(s)
  //    -> status remains DRAFT
  // 3) POST /request-close
  //    -> 409 blocked due to failing checklist
  //
  // Flow B: Fix issues and prepare again
  // 4) Resolve pending override / attach beneficiary snapshots
  // 5) POST /prepare again
  //    -> checklist all ERROR checks PASS
  //    -> status READY
  //
  // Flow C: Maker-checker close
  // 6) User A POST /request-close
  //    -> status REQUESTED
  // 7) User A POST /approve-close
  //    -> 403 maker-checker block
  // 8) User B POST /approve-close
  //    -> status CLOSED, lock flags active
  //
  // Flow D: Lock enforcement (P05)
  // 9) Try reverse payroll run in closed period
  //    -> 409 PAYROLL_PERIOD_LOCKED
  // 10) Try create off-cycle run in closed period
  //     -> 409 PAYROLL_PERIOD_LOCKED
  // 11) Try retro finalize in closed period
  //     -> 409 PAYROLL_PERIOD_LOCKED
  //
  // Flow E: Lock enforcement (P06)
  // 12) Try create manual settlement override request for liability in closed period
  //     -> 409 PAYROLL_PERIOD_LOCKED
  //
  // Flow F: Reopen
  // 13) POST /reopen with reason (authorized user)
  //     -> status REOPENED
  // 14) Retry one blocked P05 action
  //     -> now allowed (assuming business state valid)
  //
  // Flow G: Audit
  // 15) GET /period-closes/:id includes checklist + audit rows (PREPARED, REQUESTED, CLOSED, REOPENED)
  //
  // Permissions:
  // - payroll.close.read/prepare/request/approve/reopen enforced (403)
  console.log("PR-P08 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 13) `backend/package.json` updates

```json
{
  "scripts": {
    "test:payroll:prp08": "node backend/scripts/test-payroll-prp08-close-controls-checklist-locks.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 14) API client — `frontend/src/api/payrollClose.js`

```js
// frontend/src/api/payrollClose.js

import { apiFetch } from "./client.js"; // adapt to your app

export function listPayrollPeriodCloses(params = {}) {
  const qs = new URLSearchParams();
  Object.entries(params).forEach(([k, v]) => {
    if (v === undefined || v === null || v === "") return;
    qs.set(k, String(v));
  });
  const q = qs.toString();
  return apiFetch(`/api/v1/payroll/period-closes${q ? `?${q}` : ""}`);
}

export function getPayrollPeriodClose(id) {
  return apiFetch(`/api/v1/payroll/period-closes/${id}`);
}

export function preparePayrollPeriodClose(payload) {
  return apiFetch(`/api/v1/payroll/period-closes/prepare`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function requestPayrollPeriodClose(id, payload = {}) {
  return apiFetch(`/api/v1/payroll/period-closes/${id}/request-close`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function approvePayrollPeriodClose(id, payload = {}) {
  return apiFetch(`/api/v1/payroll/period-closes/${id}/approve-close`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function reopenPayrollPeriodClose(id, payload) {
  return apiFetch(`/api/v1/payroll/period-closes/${id}/reopen`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}
```

---

## 15) `PayrollRunsPage.jsx` — key period close badge snippet

```jsx
// Add close status badge for selected period/entity
<div className="text-sm">
  Payroll Period Close:{" "}
  {periodClose?.close?.status ? (
    <span className="px-2 py-0.5 rounded border">
      {periodClose.close.status}
    </span>
  ) : (
    <span className="text-amber-700">Not prepared</span>
  )}
</div>
```

---

## 16) Optional `PayrollClosePage.jsx` snippets (compact, no full page code)

### Imports/state

```jsx
import {
  preparePayrollPeriodClose,
  requestPayrollPeriodClose,
  approvePayrollPeriodClose,
  reopenPayrollPeriodClose,
  getPayrollPeriodClose,
} from "../../api/payrollClose.js";

const [closeDetail, setCloseDetail] = useState(null);
const [closeErr, setCloseErr] = useState("");
```

### Prepare checklist

```jsx
async function onPrepareClose() {
  try {
    setCloseErr("");
    const res = await preparePayrollPeriodClose({
      entity_id: selectedEntityId,
      period_start: periodStart,
      period_end: periodEnd,
      lock_run_changes: true,
      lock_manual_settlements: true,
      lock_payment_prep: false,
      note: "Prepare payroll close checklist",
    });
    setCloseDetail(res);
  } catch (e) {
    setCloseErr(e.message || "Prepare close failed");
  }
}
```

### Request / Approve / Reopen

```jsx
async function onRequestClose() {
  const closeId = closeDetail?.close?.id;
  if (!closeId) return;
  const res = await requestPayrollPeriodClose(closeId, {
    request_idempotency_key: `ppc-req-${closeId}`,
    note: "Ready for payroll close approval",
  });
  setCloseDetail(res);
}

async function onApproveClose() {
  const closeId = closeDetail?.close?.id;
  if (!closeId) return;
  const res = await approvePayrollPeriodClose(closeId, {
    close_idempotency_key: `ppc-close-${closeId}`,
    note: "Approved and closed",
  });
  setCloseDetail(res);
}

async function onReopenClose() {
  const closeId = closeDetail?.close?.id;
  if (!closeId) return;
  const res = await reopenPayrollPeriodClose(closeId, {
    reason: "Retro correction required after audit finding",
  });
  setCloseDetail(res);
}
```

### Checklist panel

```jsx
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Payroll Close Checklist</h2>

  {/* Show compact checklist items:
      - check_name
      - severity
      - status (PASS/FAIL)
      - metric_text
  */}

  {/* Summary chips:
      total_checks / passed_checks / failed_checks / warning_checks
  */}

  {closeErr ? <div className="text-sm text-red-600">{closeErr}</div> : null}
</div>
```

---

## Acceptance criteria (repeat in PR)

- ✅ Payroll period close records exist for entity + period
- ✅ System can prepare/refresh close checklist
- ✅ Checklist includes P05/P06/P07-aware checks:

  - no draft/failed payroll runs
  - accrual posting complete
  - no open retro drafts
  - no pending manual override requests
  - beneficiary snapshot readiness complete

- ✅ Close request is blocked if checklist has failing ERROR checks
- ✅ Close approval is maker-checker (requester cannot approve)
- ✅ Closing period activates lock flags
- ✅ P05 actions are blocked in locked closed period:

  - reversal
  - off-cycle
  - retro finalize/edit

- ✅ P06 manual override actions are blocked in locked closed period
- ✅ Reopen flow unlocks the period (audited)
- ✅ Period close audit trail is stored and queryable
- ✅ Permissions enforced:

  - `payroll.close.read`
  - `payroll.close.prepare`
  - `payroll.close.request`
  - `payroll.close.approve`
  - `payroll.close.reopen`

- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:payroll:prp08`

Should verify at least:

1. **Prepare checklist with failures**

   - Checklist generated
   - Failing checks shown
   - `request-close` blocked (`409`)

2. **Prepare checklist success**

   - All ERROR checks pass
   - Close record status becomes `READY`

3. **Maker-checker close**

   - User A requests close
   - User A cannot approve
   - User B approves -> status `CLOSED`

4. **Lock enforcement**

   - P05 reversal/off-cycle/retro actions blocked (`409 PAYROLL_PERIOD_LOCKED`)
   - P06 manual settlement override request/approve blocked

5. **Reopen**

   - Authorized user reopens with reason
   - Previously blocked P05 action becomes allowed again (business rules permitting)

6. **Audit + detail**

   - Detail endpoint returns checklist + audit events (`PREPARED`, `REQUESTED`, `CLOSED`, `REOPENED`)

7. **Permissions**

   - all `payroll.close.*` permissions enforced (`403`)

---

## Tiny implementation notes (important)

- This PR gives you a real **operational close**, not just run finalization.
- P08 intentionally checks **beneficiary snapshot readiness** (P07) before close, which is very practical for payroll ops.
- If you later want to allow **post-close settlement only** (while still blocking payroll corrections), keep:

  - `lock_run_changes = true`
  - `lock_manual_settlements = false`
  - and document that policy in your payroll SOP.

---

Awesome — here’s **PR-P09** in the same concrete format.

# PR-P09: Provider-Specific Payroll Adapters (Integration Layer + Import Pipeline)

## Goal

Add a **pluggable payroll provider adapter framework** so your app can ingest payroll results from different providers without rewriting your payroll subledger logic.

This PR gives you:

- ✅ Provider adapter registry (`provider_code -> adapter`)
- ✅ Entity-level provider connection/config
- ✅ External employee ID mapping to internal payroll employees
- ✅ Import preview → apply pipeline (idempotent)
- ✅ Raw payload audit storage + normalized canonical payload
- ✅ P08 lock enforcement on import apply (closed periods blocked)
- ✅ Traceability from payroll runs to provider import job
- ✅ One starter adapter (Generic CSV/JSON) + adapter contract for real providers later

---

## Important behavior rules

### 1) Adapter outputs a canonical format

Each provider adapter must normalize provider payload into a **canonical import DTO** your core payroll services understand.

Core payroll logic should not care if source is:

- CSV export
- JSON API
- Provider A
- Provider B

---

### 2) Preview first, apply second (idempotent)

Workflow:

1. **Preview import** (validate schema, map employees, compute totals/errors)
2. **Apply import** (creates/updates payroll run + liabilities)

Re-applying the same payload (same import key/hash) must be idempotent.

---

### 3) Raw payload is preserved for audit

Store:

- raw payload (JSON/text)
- normalized payload (canonical JSON)
- validation/mapping errors
- who previewed/applied
- applied payroll run id

This is essential for payroll auditability.

---

### 4) Employee matching is explicit (no silent guessing)

Provider rows must resolve to internal employees through:

- `payroll_employee_provider_refs` mapping table (preferred)
- optional fallback by employee code/email (explicit + visible in preview)

Unmatched employees block apply.

---

### 5) P08 close locks apply to provider imports

If payroll period is closed and `lock_run_changes=1`, importing payroll results into that period is blocked.

---

## Files to create

## Backend

- `backend/src/migrations/m053_payroll_provider_adapters.js`
- `backend/src/routes/payroll.providers.js`
- `backend/src/routes/payroll.providers.validators.js`
- `backend/src/services/payroll.providers.service.js`
- `backend/src/services/payroll.providers.registry.js`
- `backend/src/services/payroll.providers.adapters/base.adapter.js`
- `backend/src/services/payroll.providers.adapters/genericCsv.adapter.js`
- `backend/src/services/payroll.providers.adapters/genericJson.adapter.js`
- `backend/scripts/test-payroll-prp09-provider-adapters.js`

## Frontend (short snippets only)

- `frontend/src/api/payrollProviders.js`

---

## Files to update

## Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

## Backend (important patches)

- `backend/src/services/payroll.runs.service.js` _(helper for imported run create/upsert)_
- `backend/src/services/payroll.liabilities.service.js` _(helper to replace/build liabilities from normalized import)_
- `backend/src/services/payroll.close.service.js` _(P08 helper reused, no major change)_
- `backend/src/services/payroll.payments.service.js` _(optional: provider payment refs hook later)_
- `backend/src/services/payroll.employees.service.js` _(optional: expose provider refs in employee detail)_

## Frontend (short integration only)

- `frontend/src/pages/payroll/PayrollImportsPage.jsx` _(new page optional)_
- `frontend/src/pages/payroll/PayrollRunsPage.jsx` _(show source/provider import badge)_
- `frontend/src/i18n/messages.js` _(optional labels)_

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m053_payroll_provider_adapters.js`

```js
// backend/src/migrations/m053_payroll_provider_adapters.js

export default {
  key: "m053_payroll_provider_adapters",
  description: "m053_payroll_provider_adapters",
  async up(connection) {
    // Entity-level provider connection/config
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_provider_connections (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        entity_id BIGINT UNSIGNED NOT NULL,

        provider_code VARCHAR(40) NOT NULL,      -- GENERIC_CSV, GENERIC_JSON, ADP, SAP_PAYROLL, ...
        provider_name VARCHAR(120) NOT NULL,
        adapter_version VARCHAR(40) NOT NULL DEFAULT 'v1',

        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE', -- ACTIVE, INACTIVE
        is_default TINYINT(1) NOT NULL DEFAULT 0,

        settings_json JSON NULL,   -- column mappings, defaults, API options
        secrets_json JSON NULL,    -- if you store encrypted secrets later, keep encrypted blob here

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_ppc_entity (entity_id),
        KEY idx_ppc_status (status),
        KEY idx_ppc_provider (provider_code)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // External employee mapping (provider employee -> internal employee)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_employee_provider_refs (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        entity_id BIGINT UNSIGNED NOT NULL,
        employee_id BIGINT UNSIGNED NOT NULL,

        provider_code VARCHAR(40) NOT NULL,
        external_employee_id VARCHAR(120) NOT NULL,
        external_employee_code VARCHAR(120) NULL,

        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE',
        is_primary TINYINT(1) NOT NULL DEFAULT 1,

        payload_json JSON NULL,

        created_by BIGINT UNSIGNED NULL,
        updated_by BIGINT UNSIGNED NULL,
        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_pepr_provider_employee (entity_id, provider_code, external_employee_id),
        KEY idx_pepr_employee (employee_id),
        KEY idx_pepr_provider_code (provider_code)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Import job (preview/apply lifecycle)
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_provider_import_jobs (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        entity_id BIGINT UNSIGNED NOT NULL,
        payroll_provider_connection_id BIGINT UNSIGNED NOT NULL,

        provider_code VARCHAR(40) NOT NULL,
        adapter_version VARCHAR(40) NOT NULL,

        period_start DATE NOT NULL,
        period_end DATE NOT NULL,
        payroll_date DATE NULL,
        currency_code CHAR(3) NOT NULL,

        import_key VARCHAR(190) NULL,      -- optional user-supplied idempotency key
        raw_payload_hash VARCHAR(128) NOT NULL,
        normalized_payload_hash VARCHAR(128) NULL,

        source_format VARCHAR(20) NOT NULL, -- CSV, JSON
        source_filename VARCHAR(255) NULL,

        status VARCHAR(20) NOT NULL DEFAULT 'PREVIEWED',
        -- PREVIEWED, APPLYING, APPLIED, REJECTED, FAILED

        preview_summary_json JSON NULL,
        validation_errors_json JSON NULL,
        match_errors_json JSON NULL,

        raw_payload_text LONGTEXT NULL,    -- CSV text or raw JSON string (mask secrets)
        normalized_payload_json JSON NULL, -- canonical DTO used for apply

        applied_payroll_run_id BIGINT UNSIGNED NULL,
        applied_journal_entry_id BIGINT UNSIGNED NULL,

        requested_by BIGINT UNSIGNED NULL,  -- preview user (maker)
        requested_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        applied_by BIGINT UNSIGNED NULL,    -- apply user (checker)
        applied_at DATETIME NULL,

        idempotency_key VARCHAR(190) NULL,  -- apply idempotency
        failure_message VARCHAR(500) NULL,

        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_ppij_import_key (entity_id, provider_code, import_key),
        UNIQUE KEY uq_ppij_payload_hash (entity_id, provider_code, period_start, period_end, raw_payload_hash),
        UNIQUE KEY uq_ppij_apply_idem (idempotency_key),
        KEY idx_ppij_status (status),
        KEY idx_ppij_period (entity_id, period_start, period_end),

        CONSTRAINT fk_ppij_connection
          FOREIGN KEY (payroll_provider_connection_id) REFERENCES payroll_provider_connections(id)
          ON UPDATE RESTRICT ON DELETE RESTRICT
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Audit trail for import lifecycle
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS payroll_provider_import_audit (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        payroll_provider_import_job_id BIGINT UNSIGNED NOT NULL,

        action VARCHAR(30) NOT NULL, -- PREVIEWED, APPLY_STARTED, APPLIED, FAILED, REJECTED
        payload_json JSON NULL,
        note VARCHAR(500) NULL,

        acted_by BIGINT UNSIGNED NULL,
        acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_ppia_job (payroll_provider_import_job_id),
        KEY idx_ppia_action (action),

        CONSTRAINT fk_ppia_job
          FOREIGN KEY (payroll_provider_import_job_id) REFERENCES payroll_provider_import_jobs(id)
          ON UPDATE RESTRICT ON DELETE CASCADE
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    // Traceability on payroll_runs
    await db
      .query(
        `
      ALTER TABLE payroll_runs
        ADD COLUMN source_type VARCHAR(30) NOT NULL DEFAULT 'MANUAL' AFTER status,
        ADD COLUMN source_provider_code VARCHAR(40) NULL AFTER source_type,
        ADD COLUMN source_provider_import_job_id BIGINT UNSIGNED NULL AFTER source_provider_code,
        ADD KEY idx_payroll_runs_source_provider_import (source_provider_import_job_id)
    `,
      )
      .catch(() => {});

    await db
      .query(
        `
      ALTER TABLE payroll_runs
        ADD CONSTRAINT fk_payroll_runs_source_import_job
        FOREIGN KEY (source_provider_import_job_id)
        REFERENCES payroll_provider_import_jobs(id)
        ON UPDATE RESTRICT ON DELETE RESTRICT
    `,
      )
      .catch(() => {});
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS payroll_provider_import_audit;`);
    await connection.execute(`DROP TABLE IF EXISTS payroll_provider_import_jobs;`);
    await connection.execute(`DROP TABLE IF EXISTS payroll_employee_provider_refs;`);
    await connection.execute(`DROP TABLE IF EXISTS payroll_provider_connections;`);
    // optional strict ALTER down omitted
  },
};
```

---

## 2) Validators — `backend/src/routes/payroll.providers.validators.js`

```js
// backend/src/routes/payroll.providers.validators.js

function requirePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

function normalizeString(v) {
  if (v === undefined || v === null) return null;
  const s = String(v).trim();
  return s === "" ? null : s;
}

function requireDate(v, field) {
  const s = String(v || "").trim();
  if (!/^\d{4}-\d{2}-\d{2}$/.test(s))
    throw new Error(`${field} must be YYYY-MM-DD`);
  return s;
}

function requireCurrency(v) {
  const s = String(v || "")
    .trim()
    .toUpperCase();
  if (!/^[A-Z]{3}$/.test(s))
    throw new Error("currency_code must be 3-letter code");
  return s;
}

function validateConnectionIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateImportJobIdParam(params = {}) {
  return { id: requirePositiveInt(params.id, "id") };
}

function validateCreateConnectionBody(body = {}) {
  const provider_code = String(body.provider_code || "")
    .trim()
    .toUpperCase();
  if (!provider_code) throw new Error("provider_code is required");
  return {
    entity_id: requirePositiveInt(body.entity_id, "entity_id"),
    provider_code,
    provider_name: normalizeString(body.provider_name) || provider_code,
    adapter_version: normalizeString(body.adapter_version) || "v1",
    is_default: !!body.is_default,
    settings_json: body.settings_json || {},
    note: normalizeString(body.note),
  };
}

function validateUpdateConnectionBody(body = {}) {
  return {
    provider_name: normalizeString(body.provider_name),
    status: normalizeString(body.status)?.toUpperCase() || null,
    adapter_version: normalizeString(body.adapter_version),
    is_default: body.is_default === undefined ? undefined : !!body.is_default,
    settings_json: body.settings_json,
    note: normalizeString(body.note) || "Updated provider connection",
  };
}

function validatePreviewImportBody(body = {}) {
  const source_format = String(body.source_format || "")
    .trim()
    .toUpperCase();
  if (!["CSV", "JSON"].includes(source_format)) {
    throw new Error("source_format must be CSV or JSON");
  }

  return {
    payroll_provider_connection_id: requirePositiveInt(
      body.payroll_provider_connection_id,
      "payroll_provider_connection_id",
    ),
    period_start: requireDate(body.period_start, "period_start"),
    period_end: requireDate(body.period_end, "period_end"),
    payroll_date: body.payroll_date
      ? requireDate(body.payroll_date, "payroll_date")
      : null,
    currency_code: requireCurrency(body.currency_code),
    source_format,
    source_filename: normalizeString(body.source_filename),
    raw_payload_text:
      normalizeString(body.raw_payload_text) ||
      (() => {
        throw new Error("raw_payload_text is required");
      })(),
    import_key: normalizeString(body.import_key),
  };
}

function validateApplyImportBody(body = {}) {
  return {
    idempotency_key: normalizeString(body.idempotency_key),
    note: normalizeString(body.note),
    auto_post_accrual:
      body.auto_post_accrual === undefined ? false : !!body.auto_post_accrual,
    allow_same_user_apply: !!body.allow_same_user_apply, // default false (maker-checker)
  };
}

function validateCreateEmployeeProviderRefBody(body = {}) {
  return {
    entity_id: requirePositiveInt(body.entity_id, "entity_id"),
    employee_id: requirePositiveInt(body.employee_id, "employee_id"),
    provider_code: String(body.provider_code || "")
      .trim()
      .toUpperCase(),
    external_employee_id:
      normalizeString(body.external_employee_id) ||
      (() => {
        throw new Error("external_employee_id is required");
      })(),
    external_employee_code: normalizeString(body.external_employee_code),
  };
}

export default {
  validateConnectionIdParam,
  validateImportJobIdParam,
  validateCreateConnectionBody,
  validateUpdateConnectionBody,
  validatePreviewImportBody,
  validateApplyImportBody,
  validateCreateEmployeeProviderRefBody,
};
```

---

## 3) Adapter registry — `backend/src/services/payroll.providers.registry.js`

```js
// backend/src/services/payroll.providers.registry.js

import GenericCsvAdapter from "./payroll.providers.adapters/genericCsv.adapter.js";
import GenericJsonAdapter from "./payroll.providers.adapters/genericJson.adapter.js";
const ADAPTERS = {
  GENERIC_CSV: GenericCsvAdapter,
  GENERIC_JSON: GenericJsonAdapter,

  // future examples:
  // ADP: (await import("./payroll.providers.adapters/adp.adapter.js")).default,
  // SAP_PAYROLL: (await import("./payroll.providers.adapters/sapPayroll.adapter.js")).default,
};

function getPayrollProviderAdapter(
  providerCode,
  { settings = {}, adapterVersion = "v1" } = {},
) {
  const key = String(providerCode || "")
    .trim()
    .toUpperCase();
  const AdapterClass = ADAPTERS[key];
  if (!AdapterClass) {
    const err = new Error(`Unsupported payroll provider adapter: ${key}`);
    err.statusCode = 400;
    throw err;
  }
  return new AdapterClass({ settings, adapterVersion, providerCode: key });
}

function listSupportedPayrollProviders() {
  return Object.keys(ADAPTERS).map((code) => ({ provider_code: code }));
}

export default {
  getPayrollProviderAdapter,
  listSupportedPayrollProviders,
};
```

---

## 4) Base adapter contract — `backend/src/services/payroll.providers.adapters/base.adapter.js`

```js
// backend/src/services/payroll.providers.adapters/base.adapter.js

class BasePayrollProviderAdapter {
  constructor({ settings = {}, adapterVersion = "v1", providerCode }) {
    this.settings = settings;
    this.adapterVersion = adapterVersion;
    this.providerCode = providerCode;
  }

  /**
   * Parse raw payload text -> provider-specific structured object
   */
  parseRaw(rawPayloadText, { sourceFormat }) {
    throw new Error("parseRaw() not implemented");
  }

  /**
   * Validate provider payload shape and required fields
   * return { errors: [], warnings: [] }
   */
  validateSchema(_parsed) {
    return { errors: [], warnings: [] };
  }

  /**
   * Normalize provider data into canonical DTO
   *
   * Canonical DTO shape:
   * {
   *   run: { period_start, period_end, payroll_date, currency_code, source_ref, totals... },
   *   employees: [
   *     {
   *       external_employee_id,
   *       external_employee_code,
   *       employee_name,
   *       employee_email,
   *       cost_center_code,
   *       gross_amount,
   *       net_pay_amount,
   *       employer_tax_amount,
   *       employee_tax_amount,
   *       deductions_amount,
   *       earnings: [{ code, amount }],
   *       deductions: [{ code, amount }],
   *       taxes: [{ code, amount, payer_type }]
   *     }
   *   ],
   *   summary: {...}
   * }
   */
  normalizePayrollResults(_parsed, _ctx) {
    throw new Error("normalizePayrollResults() not implemented");
  }

  /**
   * Optional: normalize payment references / bank evidence (future P04/B06 integration)
   */
  normalizePaymentRefs(_parsed) {
    return { payment_refs: [] };
  }
}

export default BasePayrollProviderAdapter;
```

---

## 5) Starter adapters (generic CSV/JSON)

### `backend/src/services/payroll.providers.adapters/genericJson.adapter.js`

```js
// backend/src/services/payroll.providers.adapters/genericJson.adapter.js

import Base from "./base.adapter.js";
function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

class GenericJsonAdapter extends Base {
  parseRaw(rawPayloadText) {
    try {
      return JSON.parse(rawPayloadText);
    } catch (e) {
      const err = new Error("Invalid JSON payload");
      err.statusCode = 400;
      throw err;
    }
  }

  validateSchema(parsed) {
    const errors = [];
    if (!parsed || typeof parsed !== "object")
      errors.push("JSON payload must be an object");
    if (!Array.isArray(parsed.employees))
      errors.push("employees array is required");
    return { errors, warnings: [] };
  }

  normalizePayrollResults(parsed, ctx) {
    const employees = (parsed.employees || []).map((r) => ({
      external_employee_id: String(
        r.external_employee_id || r.employee_id || "",
      ).trim(),
      external_employee_code:
        String(r.external_employee_code || r.employee_code || "").trim() ||
        null,
      employee_name: String(r.employee_name || "").trim() || null,
      employee_email: String(r.employee_email || "").trim() || null,
      cost_center_code: String(r.cost_center_code || "").trim() || null,

      gross_amount: amount2(r.gross_amount),
      net_pay_amount: amount2(r.net_pay_amount),
      employer_tax_amount: amount2(r.employer_tax_amount),
      employee_tax_amount: amount2(r.employee_tax_amount),
      deductions_amount: amount2(r.deductions_amount),

      earnings: Array.isArray(r.earnings) ? r.earnings : [],
      deductions: Array.isArray(r.deductions) ? r.deductions : [],
      taxes: Array.isArray(r.taxes) ? r.taxes : [],
    }));

    return {
      run: {
        period_start: ctx.period_start,
        period_end: ctx.period_end,
        payroll_date: ctx.payroll_date,
        currency_code: ctx.currency_code,
        source_ref: parsed.source_ref || null,
      },
      employees,
      summary: {
        employee_count: employees.length,
        total_gross: amount2(employees.reduce((s, r) => s + r.gross_amount, 0)),
        total_net: amount2(employees.reduce((s, r) => s + r.net_pay_amount, 0)),
        total_employer_tax: amount2(
          employees.reduce((s, r) => s + r.employer_tax_amount, 0),
        ),
      },
    };
  }
}

export default GenericJsonAdapter;
```

### `backend/src/services/payroll.providers.adapters/genericCsv.adapter.js`

```js
// backend/src/services/payroll.providers.adapters/genericCsv.adapter.js

import Base from "./base.adapter.js";
/**
 * Minimal CSV parser for v1 (simple comma-separated, no quoted commas handling).
 * For production, replace with a robust CSV parser library.
 */
function parseCsvLines(text) {
  const lines = String(text || "")
    .trim()
    .split(/\r?\n/)
    .filter(Boolean);
  if (!lines.length) return [];
  const headers = lines[0].split(",").map((s) => s.trim());
  return lines.slice(1).map((line) => {
    const cols = line.split(",").map((s) => s.trim());
    const row = {};
    headers.forEach((h, i) => {
      row[h] = cols[i] ?? "";
    });
    return row;
  });
}

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

class GenericCsvAdapter extends Base {
  parseRaw(rawPayloadText) {
    return parseCsvLines(rawPayloadText);
  }

  validateSchema(parsedRows) {
    const errors = [];
    if (!Array.isArray(parsedRows)) errors.push("CSV rows must be an array");
    const sample = parsedRows[0] || {};
    const required = ["external_employee_id", "gross_amount", "net_pay_amount"];
    for (const k of required) {
      if (!(k in sample)) errors.push(`Missing CSV column: ${k}`);
    }
    return { errors, warnings: [] };
  }

  normalizePayrollResults(parsedRows, ctx) {
    const employees = parsedRows.map((r) => ({
      external_employee_id: String(r.external_employee_id || "").trim(),
      external_employee_code:
        String(r.external_employee_code || "").trim() || null,
      employee_name: String(r.employee_name || "").trim() || null,
      employee_email: String(r.employee_email || "").trim() || null,
      cost_center_code: String(r.cost_center_code || "").trim() || null,

      gross_amount: amount2(r.gross_amount),
      net_pay_amount: amount2(r.net_pay_amount),
      employer_tax_amount: amount2(r.employer_tax_amount),
      employee_tax_amount: amount2(r.employee_tax_amount),
      deductions_amount: amount2(r.deductions_amount),

      earnings: [],
      deductions: [],
      taxes: [],
    }));

    return {
      run: {
        period_start: ctx.period_start,
        period_end: ctx.period_end,
        payroll_date: ctx.payroll_date,
        currency_code: ctx.currency_code,
        source_ref: null,
      },
      employees,
      summary: {
        employee_count: employees.length,
        total_gross: amount2(employees.reduce((s, r) => s + r.gross_amount, 0)),
        total_net: amount2(employees.reduce((s, r) => s + r.net_pay_amount, 0)),
        total_employer_tax: amount2(
          employees.reduce((s, r) => s + r.employer_tax_amount, 0),
        ),
      },
    };
  }
}

export default GenericCsvAdapter;
```

---

## 6) Service — `backend/src/services/payroll.providers.service.js`

> Main jobs:
>
> - provider connection config
> - employee external refs
> - preview import
> - apply import (calls core payroll services)

```js
// backend/src/services/payroll.providers.service.js

import crypto from "crypto";
import { getPayrollProviderAdapter,
  listSupportedPayrollProviders, } from "./payroll.providers.registry.js";
import payrollCloseSvc from "./payroll.close.service.js";
import payrollRunsSvc from "./payroll.runs.service.js";
import payrollLiabilitiesSvc from "./payroll.liabilities.service.js";
// Optional later:
// import payrollPostingSvc from "./payroll.posting.service.js";

function sha256(v) {
  return crypto
    .createHash("sha256")
    .update(String(v || ""))
    .digest("hex");
}

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

async function writeImportAudit(
  db,
  jobId,
  action,
  payload = null,
  userId = null,
  note = null,
) {
  await db.query(
    `
    INSERT INTO payroll_provider_import_audit
    (payroll_provider_import_job_id, action, payload_json, note, acted_by)
    VALUES (?, ?, ?, ?, ?)
    `,
    [
      jobId,
      action,
      payload ? JSON.stringify(payload) : null,
      note || null,
      userId,
    ],
  );
}

async function listProviderConnections(db, { entity_id = null } = {}) {
  const [rows] = entity_id
    ? await db.query(
        `SELECT * FROM payroll_provider_connections WHERE entity_id=? ORDER BY is_default DESC, id DESC`,
        [entity_id],
      )
    : await db.query(
        `SELECT * FROM payroll_provider_connections ORDER BY id DESC`,
      );
  return rows;
}

async function createProviderConnection(db, body, userId = null) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;
  try {
    if (conn) await conn.beginTransaction();

    if (body.is_default) {
      await q.query(
        `UPDATE payroll_provider_connections SET is_default=0, updated_by=?, updated_at=NOW() WHERE entity_id=?`,
        [userId, body.entity_id],
      );
    }

    const [ins] = await q.query(
      `
      INSERT INTO payroll_provider_connections
      (entity_id, provider_code, provider_name, adapter_version, status, is_default, settings_json, created_by, updated_by)
      VALUES (?, ?, ?, ?, 'ACTIVE', ?, ?, ?, ?)
      `,
      [
        body.entity_id,
        body.provider_code,
        body.provider_name,
        body.adapter_version,
        body.is_default ? 1 : 0,
        JSON.stringify(body.settings_json || {}),
        userId,
        userId,
      ],
    );

    const [rows] = await q.query(
      `SELECT * FROM payroll_provider_connections WHERE id=? LIMIT 1`,
      [ins.insertId],
    );
    if (conn) await conn.commit();
    return rows[0];
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function updateProviderConnection(db, id, body, userId = null) {
  const [curRows] = await db.query(
    `SELECT * FROM payroll_provider_connections WHERE id=? LIMIT 1`,
    [id],
  );
  const cur = curRows[0];
  if (!cur) {
    const err = new Error("Payroll provider connection not found");
    err.statusCode = 404;
    throw err;
  }

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;
  try {
    if (conn) await conn.beginTransaction();

    if (body.is_default === true) {
      await q.query(
        `UPDATE payroll_provider_connections SET is_default=0, updated_by=?, updated_at=NOW() WHERE entity_id=?`,
        [userId, cur.entity_id],
      );
    }

    await q.query(
      `
      UPDATE payroll_provider_connections
      SET provider_name = COALESCE(?, provider_name),
          status = COALESCE(?, status),
          adapter_version = COALESCE(?, adapter_version),
          is_default = COALESCE(?, is_default),
          settings_json = COALESCE(?, settings_json),
          updated_by = ?,
          updated_at = NOW()
      WHERE id = ?
      `,
      [
        body.provider_name || null,
        body.status || null,
        body.adapter_version || null,
        body.is_default === undefined ? null : body.is_default ? 1 : 0,
        body.settings_json === undefined
          ? null
          : JSON.stringify(body.settings_json),
        userId,
        id,
      ],
    );

    const [rows] = await q.query(
      `SELECT * FROM payroll_provider_connections WHERE id=? LIMIT 1`,
      [id],
    );
    if (conn) await conn.commit();
    return rows[0];
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

async function createEmployeeProviderRef(db, body, userId = null) {
  const [ins] = await db.query(
    `
    INSERT INTO payroll_employee_provider_refs
    (entity_id, employee_id, provider_code, external_employee_id, external_employee_code, created_by, updated_by)
    VALUES (?, ?, ?, ?, ?, ?, ?)
    ON DUPLICATE KEY UPDATE
      employee_id = VALUES(employee_id),
      external_employee_code = VALUES(external_employee_code),
      updated_by = VALUES(updated_by),
      updated_at = NOW()
    `,
    [
      body.entity_id,
      body.employee_id,
      body.provider_code,
      body.external_employee_id,
      body.external_employee_code || null,
      userId,
      userId,
    ],
  );
  return { ok: true, insertId: ins.insertId || null };
}

async function listEmployeeProviderRefs(
  db,
  { entity_id, provider_code = null },
) {
  const [rows] = provider_code
    ? await db.query(
        `SELECT * FROM payroll_employee_provider_refs WHERE entity_id=? AND provider_code=? ORDER BY id DESC`,
        [entity_id, provider_code],
      )
    : await db.query(
        `SELECT * FROM payroll_employee_provider_refs WHERE entity_id=? ORDER BY id DESC`,
        [entity_id],
      );
  return rows;
}

async function resolveEmployeeMappings(
  db,
  { entityId, providerCode, employees },
) {
  if (!employees.length) return { employees: [], unmatched: [] };

  const ids = [
    ...new Set(employees.map((e) => e.external_employee_id).filter(Boolean)),
  ];
  if (!ids.length)
    return {
      employees,
      unmatched: employees.map((e) => ({
        ...e,
        reason: "missing external_employee_id",
      })),
    };

  const [rows] = await db.query(
    `
    SELECT *
    FROM payroll_employee_provider_refs
    WHERE entity_id=? AND provider_code=? AND external_employee_id IN (?)
      AND status='ACTIVE'
    `,
    [entityId, providerCode, ids],
  );

  const byExternalId = new Map(
    rows.map((r) => [String(r.external_employee_id), r]),
  );

  const mapped = [];
  const unmatched = [];

  for (const e of employees) {
    const ref = byExternalId.get(String(e.external_employee_id || ""));
    if (!ref) {
      unmatched.push({
        external_employee_id: e.external_employee_id,
        external_employee_code: e.external_employee_code || null,
        employee_name: e.employee_name || null,
        reason: "No payroll_employee_provider_refs mapping",
      });
      continue;
    }

    mapped.push({
      ...e,
      employee_id: Number(ref.employee_id),
      mapping_ref_id: Number(ref.id),
    });
  }

  return { employees: mapped, unmatched };
}

function buildPreviewSummary({
  normalized,
  mappedEmployees,
  unmatched,
  schemaErrors,
  schemaWarnings,
}) {
  return {
    employee_count_in_payload: normalized.employees.length,
    employee_count_mapped: mappedEmployees.length,
    employee_count_unmatched: unmatched.length,
    total_gross: amount2(normalized.summary?.total_gross || 0),
    total_net: amount2(normalized.summary?.total_net || 0),
    total_employer_tax: amount2(normalized.summary?.total_employer_tax || 0),
    schema_error_count: schemaErrors.length,
    schema_warning_count: schemaWarnings.length,
    apply_blocked: schemaErrors.length > 0 || unmatched.length > 0,
  };
}

async function previewProviderImport(db, body, userId = null) {
  const [connRows] = await db.query(
    `SELECT * FROM payroll_provider_connections WHERE id=? LIMIT 1`,
    [body.payroll_provider_connection_id],
  );
  const connection = connRows[0];
  if (!connection) {
    const err = new Error("Payroll provider connection not found");
    err.statusCode = 404;
    throw err;
  }
  if (connection.status !== "ACTIVE") {
    const err = new Error("Payroll provider connection is not ACTIVE");
    err.statusCode = 409;
    throw err;
  }

  const adapter = getPayrollProviderAdapter(connection.provider_code, {
    settings: connection.settings_json || {},
    adapterVersion: connection.adapter_version,
  });

  const rawHash = sha256(body.raw_payload_text);

  // payload dedupe per period+provider
  const [existing] = await db.query(
    `
    SELECT * FROM payroll_provider_import_jobs
    WHERE entity_id=? AND provider_code=? AND period_start=? AND period_end=? AND raw_payload_hash=?
    LIMIT 1
    `,
    [
      connection.entity_id,
      connection.provider_code,
      body.period_start,
      body.period_end,
      rawHash,
    ],
  );
  if (existing[0]) {
    return { job: existing[0], idempotent_preview: true };
  }

  const parsed = adapter.parseRaw(body.raw_payload_text, {
    sourceFormat: body.source_format,
  });
  const schema = adapter.validateSchema(parsed);
  const normalized = adapter.normalizePayrollResults(parsed, {
    period_start: body.period_start,
    period_end: body.period_end,
    payroll_date: body.payroll_date,
    currency_code: body.currency_code,
  });

  const mapping = await resolveEmployeeMappings(db, {
    entityId: connection.entity_id,
    providerCode: connection.provider_code,
    employees: normalized.employees || [],
  });

  // attach employee_id on preview payload
  const normalizedForApply = {
    ...normalized,
    employees: mapping.employees,
  };

  const previewSummary = buildPreviewSummary({
    normalized,
    mappedEmployees: mapping.employees,
    unmatched: mapping.unmatched,
    schemaErrors: schema.errors || [],
    schemaWarnings: schema.warnings || [],
  });

  const normalizedHash = sha256(JSON.stringify(normalizedForApply));

  const [ins] = await db.query(
    `
    INSERT INTO payroll_provider_import_jobs
    (entity_id, payroll_provider_connection_id, provider_code, adapter_version,
     period_start, period_end, payroll_date, currency_code,
     import_key, raw_payload_hash, normalized_payload_hash,
     source_format, source_filename, status,
     preview_summary_json, validation_errors_json, match_errors_json,
     raw_payload_text, normalized_payload_json, requested_by)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'PREVIEWED', ?, ?, ?, ?, ?, ?)
    `,
    [
      connection.entity_id,
      connection.id,
      connection.provider_code,
      connection.adapter_version,
      body.period_start,
      body.period_end,
      body.payroll_date || null,
      body.currency_code,
      body.import_key || null,
      rawHash,
      normalizedHash,
      body.source_format,
      body.source_filename || null,
      JSON.stringify(previewSummary),
      JSON.stringify(schema.errors || []),
      JSON.stringify(mapping.unmatched || []),
      body.raw_payload_text,
      JSON.stringify(normalizedForApply),
      userId,
    ],
  );

  await writeImportAudit(
    db,
    ins.insertId,
    "PREVIEWED",
    {
      preview_summary: previewSummary,
      warnings: schema.warnings || [],
    },
    userId,
    "Previewed payroll provider import",
  );

  const [rows] = await db.query(
    `SELECT * FROM payroll_provider_import_jobs WHERE id=? LIMIT 1`,
    [ins.insertId],
  );

  return {
    job: rows[0],
    preview_summary: previewSummary,
    schema_warnings: schema.warnings || [],
    unmatched_employees: mapping.unmatched || [],
    idempotent_preview: false,
  };
}

async function getProviderImportJobDetail(db, jobId) {
  const [rows] = await db.query(
    `SELECT * FROM payroll_provider_import_jobs WHERE id=? LIMIT 1`,
    [jobId],
  );
  const job = rows[0];
  if (!job) {
    const err = new Error("Payroll provider import job not found");
    err.statusCode = 404;
    throw err;
  }
  const [audit] = await db.query(
    `SELECT * FROM payroll_provider_import_audit WHERE payroll_provider_import_job_id=? ORDER BY id DESC`,
    [jobId],
  );
  return { job, audit };
}

async function applyProviderImport(db, jobId, body, userId = null) {
  if (body.idempotency_key) {
    const [idem] = await db.query(
      `SELECT * FROM payroll_provider_import_jobs WHERE idempotency_key=? LIMIT 1`,
      [body.idempotency_key],
    );
    if (
      idem[0] &&
      Number(idem[0].id) === Number(jobId) &&
      idem[0].status === "APPLIED"
    ) {
      return getProviderImportJobDetail(db, jobId);
    }
  }

  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const [jobRows] = await q.query(
      `SELECT * FROM payroll_provider_import_jobs WHERE id=? LIMIT 1 FOR UPDATE`,
      [jobId],
    );
    const job = jobRows[0];
    if (!job) {
      const err = new Error("Payroll provider import job not found");
      err.statusCode = 404;
      throw err;
    }

    if (job.status === "APPLIED") {
      if (conn) await conn.commit();
      return getProviderImportJobDetail(db, jobId);
    }

    if (!["PREVIEWED", "FAILED"].includes(job.status)) {
      const err = new Error(
        `Import job status ${job.status} cannot be applied`,
      );
      err.statusCode = 409;
      throw err;
    }

    if (
      !body.allow_same_user_apply &&
      job.requested_by &&
      userId &&
      Number(job.requested_by) === Number(userId)
    ) {
      const err = new Error(
        "Maker-checker violation: preview user cannot apply same import job",
      );
      err.statusCode = 403;
      throw err;
    }

    const previewSummary = job.preview_summary_json || {};
    const validationErrors = job.validation_errors_json || [];
    const matchErrors = job.match_errors_json || [];

    if (
      (validationErrors?.length || 0) > 0 ||
      (matchErrors?.length || 0) > 0 ||
      previewSummary.apply_blocked
    ) {
      const err = new Error(
        "Import apply blocked: preview has validation/matching errors",
      );
      err.statusCode = 409;
      throw err;
    }

    // P08 lock check
    await payrollCloseSvc.assertPayrollPeriodActionAllowed(q, {
      entityId: job.entity_id,
      periodStart: job.period_start,
      periodEnd: job.period_end,
      actionType: "RUN_IMPORT_APPLY",
    });

    await q.query(
      `
      UPDATE payroll_provider_import_jobs
      SET status='APPLYING',
          idempotency_key = COALESCE(?, idempotency_key),
          updated_at=NOW()
      WHERE id=?
      `,
      [body.idempotency_key || null, job.id],
    );

    await writeImportAudit(
      q,
      job.id,
      "APPLY_STARTED",
      null,
      userId,
      body.note || "Applying payroll import",
    );

    const normalized = job.normalized_payload_json || {};
    const employees = Array.isArray(normalized.employees)
      ? normalized.employees
      : [];

    // Core helper 1: create/upsert payroll run as imported source
    const run = await payrollRunsSvc.createOrUpdateImportedPayrollRun(q, {
      entity_id: job.entity_id,
      period_start: job.period_start,
      period_end: job.period_end,
      payroll_date: job.payroll_date,
      currency_code: job.currency_code,
      source_type: "PROVIDER_IMPORT",
      source_provider_code: job.provider_code,
      source_provider_import_job_id: job.id,
      provider_summary: normalized.summary || {},
      requested_by: userId,
    });

    // Core helper 2: build/replace liabilities from normalized import
    const liabResult =
      await payrollLiabilitiesSvc.replaceRunLiabilitiesFromProviderImport(q, {
        run_id: run.id,
        entity_id: job.entity_id,
        currency_code: job.currency_code,
        employees,
        provider_code: job.provider_code,
        import_job_id: job.id,
        source_period_start: job.period_start,
        source_period_end: job.period_end,
        user_id: userId,
      });

    // Optional: auto-post accrual
    let appliedJournalEntryId = null;
    // if (body.auto_post_accrual) {
    //   const postRes = await payrollPostingSvc.postPayrollRunAccrual(q, run.id, { userId });
    //   appliedJournalEntryId = postRes.journal_entry_id;
    // }

    await q.query(
      `
      UPDATE payroll_provider_import_jobs
      SET status='APPLIED',
          applied_payroll_run_id=?,
          applied_journal_entry_id=?,
          applied_by=?,
          applied_at=NOW(),
          failure_message=NULL,
          updated_at=NOW()
      WHERE id=?
      `,
      [run.id, appliedJournalEntryId, userId, job.id],
    );

    await writeImportAudit(
      q,
      job.id,
      "APPLIED",
      {
        payroll_run_id: run.id,
        liabilities_created: liabResult.created_count || 0,
        liabilities_updated: liabResult.updated_count || 0,
      },
      userId,
      body.note || "Applied payroll provider import",
    );

    if (conn) await conn.commit();
    return getProviderImportJobDetail(db, job.id);
  } catch (err) {
    if (conn) {
      try {
        await q.query(
          `UPDATE payroll_provider_import_jobs SET status='FAILED', failure_message=?, updated_at=NOW() WHERE id=?`,
          [String(err.message || "Import apply failed").slice(0, 500), jobId],
        );
        await writeImportAudit(
          q,
          jobId,
          "FAILED",
          { error: err.message },
          userId,
          "Apply failed",
        );
        await conn.commit();
      } catch (_) {
        try {
          await conn.rollback();
        } catch (__) {}
      }
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

export default {
  listSupportedPayrollProviders,
  listProviderConnections,
  createProviderConnection,
  updateProviderConnection,
  createEmployeeProviderRef,
  listEmployeeProviderRefs,
  previewProviderImport,
  getProviderImportJobDetail,
  applyProviderImport,
};
```

---

## 7) Routes — `backend/src/routes/payroll.providers.js`

```js
// backend/src/routes/payroll.providers.js

import express from "express";
import svc from "../services/payroll.providers.service.js";
import { validateConnectionIdParam,
  validateImportJobIdParam,
  validateCreateConnectionBody,
  validateUpdateConnectionBody,
  validatePreviewImportBody,
  validateApplyImportBody,
  validateCreateEmployeeProviderRefBody, } from "./payroll.providers.validators.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

// GET /api/v1/payroll/providers
router.get(
  "/providers",
  requireAuth,
  requirePermission("payroll.provider.read"),
  async (req, res, next) => {
    try {
      res.json({ items: svc.listSupportedPayrollProviders() });
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/payroll/provider-connections
router.get(
  "/provider-connections",
  requireAuth,
  requirePermission("payroll.provider.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const entity_id = req.query.entity_id
        ? Number(req.query.entity_id)
        : null;
      const items = await svc.listProviderConnections(db, { entity_id });
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/provider-connections
router.post(
  "/provider-connections",
  requireAuth,
  requirePermission("payroll.provider.write"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateConnectionBody(req.body);
      const item = await svc.createProviderConnection(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// PATCH /api/v1/payroll/provider-connections/:id
router.patch(
  "/provider-connections/:id",
  requireAuth,
  requirePermission("payroll.provider.write"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateConnectionIdParam(req.params);
      const body = validateUpdateConnectionBody(req.body);
      const item = await svc.updateProviderConnection(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/employee-provider-refs
router.post(
  "/employee-provider-refs",
  requireAuth,
  requirePermission("payroll.provider.mapping.write"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validateCreateEmployeeProviderRefBody(req.body);
      const result = await svc.createEmployeeProviderRef(
        db,
        body,
        req.user?.id ?? null,
      );
      res.status(201).json(result);
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/payroll/employee-provider-refs?entity_id=...&provider_code=...
router.get(
  "/employee-provider-refs",
  requireAuth,
  requirePermission("payroll.provider.mapping.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const entity_id = Number(req.query.entity_id);
      if (!Number.isInteger(entity_id) || entity_id <= 0)
        throw new Error("entity_id is required");
      const provider_code = req.query.provider_code
        ? String(req.query.provider_code).toUpperCase()
        : null;
      const items = await svc.listEmployeeProviderRefs(db, {
        entity_id,
        provider_code,
      });
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/provider-imports/preview
router.post(
  "/provider-imports/preview",
  requireAuth,
  requirePermission("payroll.provider.import.preview"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const body = validatePreviewImportBody(req.body);
      const result = await svc.previewProviderImport(
        db,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/payroll/provider-imports/:id
router.get(
  "/provider-imports/:id",
  requireAuth,
  requirePermission("payroll.provider.import.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateImportJobIdParam(req.params);
      const item = await svc.getProviderImportJobDetail(db, id);
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/provider-imports/:id/apply
router.post(
  "/provider-imports/:id/apply",
  requireAuth,
  requirePermission("payroll.provider.import.apply"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateImportJobIdParam(req.params);
      const body = validateApplyImportBody(req.body);
      const result = await svc.applyProviderImport(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 8) Patch `payroll.runs.service.js` — imported run helper (important)

> Add a helper so P09 doesn’t duplicate run creation logic.

```js
// patch snippet in backend/src/services/payroll.runs.service.js

async function createOrUpdateImportedPayrollRun(db, payload) {
  // Try find existing run by source_provider_import_job_id first
  if (payload.source_provider_import_job_id) {
    const [existing] = await db.query(
      `SELECT * FROM payroll_runs WHERE source_provider_import_job_id=? LIMIT 1`,
      [payload.source_provider_import_job_id],
    );
    if (existing[0]) return existing[0];
  }

  // Create imported run (adapt fields to your payroll_runs schema)
  const [ins] = await db.query(
    `
    INSERT INTO payroll_runs
    (entity_id, period_start, period_end, payroll_date, currency_code,
     status, source_type, source_provider_code, source_provider_import_job_id,
     created_by, updated_by)
    VALUES (?, ?, ?, ?, ?, 'FINALIZED', ?, ?, ?, ?, ?)
    `,
    [
      payload.entity_id,
      payload.period_start,
      payload.period_end,
      payload.payroll_date || payload.period_end,
      payload.currency_code,
      payload.source_type || "PROVIDER_IMPORT",
      payload.source_provider_code || null,
      payload.source_provider_import_job_id || null,
      payload.requested_by || null,
      payload.requested_by || null,
    ],
  );

  const [rows] = await db.query(
    `SELECT * FROM payroll_runs WHERE id=? LIMIT 1`,
    [ins.insertId],
  );
  return rows[0];
}

export default {
  // ...existing exports
  createOrUpdateImportedPayrollRun,
};
```

---

## 9) Patch `payroll.liabilities.service.js` — provider import helper (important)

> P09 should reuse your liability model and statuses, not invent a parallel path.

```js
// patch snippet in backend/src/services/payroll.liabilities.service.js

function amount2(n) {
  return Number(Number(n || 0).toFixed(2));
}

async function replaceRunLiabilitiesFromProviderImport(
  db,
  {
    run_id,
    currency_code,
    employees,
    provider_code,
    import_job_id,
    user_id = null,
  },
) {
  // v1 strategy: replace imported liabilities for the run (safe/idempotent for provider imports)
  // If your schema distinguishes employee net vs tax liabilities, adapt this split carefully.

  // Optional: delete only if run source_type=PROVIDER_IMPORT and not in payment flow
  await db
    .query(
      `
    DELETE FROM payroll_run_liabilities
    WHERE run_id = ?
      AND status IN ('OPEN', 'IN_BATCH', 'PARTIALLY_PAID', 'PAID', 'POSTED')
    `,
      [run_id],
    )
    .catch(() => {
      // if delete is unsafe in your flow, replace with soft-rebuild approach
    });

  let created_count = 0;

  for (const e of employees) {
    // 1) Employee net pay liability (payable to employee)
    if (amount2(e.net_pay_amount) > 0) {
      await db.query(
        `
        INSERT INTO payroll_run_liabilities
        (run_id, employee_id, liability_type, status,
         amount, settled_amount, outstanding_amount, currency_code,
         source_ref, created_by, updated_by)
        VALUES (?, ?, 'EMPLOYEE_NET_PAY', 'OPEN', ?, 0, ?, ?, ?, ?, ?)
        `,
        [
          run_id,
          e.employee_id,
          amount2(e.net_pay_amount),
          amount2(e.net_pay_amount),
          currency_code,
          `PROVIDER:${provider_code}|JOB:${import_job_id}|EMP:${e.external_employee_id}`,
          user_id,
          user_id,
        ],
      );
      created_count += 1;
    }

    // 2) Statutory liability (employee+employer taxes) - simplified v1 aggregate
    const statutory =
      amount2(e.employee_tax_amount) + amount2(e.employer_tax_amount);
    if (amount2(statutory) > 0) {
      await db.query(
        `
        INSERT INTO payroll_run_liabilities
        (run_id, employee_id, liability_type, status,
         amount, settled_amount, outstanding_amount, currency_code,
         source_ref, created_by, updated_by)
        VALUES (?, ?, 'STATUTORY_PAYABLE', 'OPEN', ?, 0, ?, ?, ?, ?, ?)
        `,
        [
          run_id,
          e.employee_id,
          amount2(statutory),
          amount2(statutory),
          currency_code,
          `PROVIDER:${provider_code}|JOB:${import_job_id}|EMP:${e.external_employee_id}`,
          user_id,
          user_id,
        ],
      );
      created_count += 1;
    }
  }

  // Optional: write payroll liability audit summary row if you already have payroll_liability_audit
  return { created_count, updated_count: 0 };
}

export default {
  // ...existing exports
  replaceRunLiabilitiesFromProviderImport,
};
```

> If your existing P03 liability generator already has a more precise breakdown, use that instead of the simplified insert logic above.

---

## 10) Mount route — `backend/src/index.js`

```js
// backend/src/index.js
import payrollProvidersRoutes from "./routes/payroll.providers.js";
// ...
app.use("/api/v1/payroll", payrollProvidersRoutes);
```

---

## 11) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m053_payroll_provider_adapters from "./m053_payroll_provider_adapters.js";
export default [
  // ...
  m053_payroll_provider_adapters,
];
```

---

## 12) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const PAYROLL_P09_PERMISSIONS = [
  "payroll.provider.read",
  "payroll.provider.write",
  "payroll.provider.mapping.read",
  "payroll.provider.mapping.write",
  "payroll.provider.import.read",
  "payroll.provider.import.preview",
  "payroll.provider.import.apply",
];

// merge into permission seed list
```

---

## 13) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/payroll/providers`
- `GET /api/v1/payroll/provider-connections`
- `POST /api/v1/payroll/provider-connections`
- `PATCH /api/v1/payroll/provider-connections/{id}`
- `GET /api/v1/payroll/employee-provider-refs`
- `POST /api/v1/payroll/employee-provider-refs`
- `POST /api/v1/payroll/provider-imports/preview`
- `GET /api/v1/payroll/provider-imports/{id}`
- `POST /api/v1/payroll/provider-imports/{id}/apply`

Also document canonical preview/apply response fields:

- `preview_summary_json`
- `validation_errors_json`
- `match_errors_json`
- `applied_payroll_run_id`
- `status`

---

## 14) Backend smoke test — `backend/scripts/test-payroll-prp09-provider-adapters.js`

```js
// backend/scripts/test-payroll-prp09-provider-adapters.js

async function main() {
  // Preconditions:
  // - P08 close controls implemented
  // - payroll_runs + payroll_run_liabilities services support import helpers
  //
  // Flow A: Provider setup
  // 1) Create provider connection (GENERIC_JSON) for entity E1
  // 2) Create payroll_employee_provider_refs mappings for employees
  //
  // Flow B: Preview import (success)
  // 3) POST /provider-imports/preview with valid JSON payload
  //    -> PREVIEWED job created
  //    -> preview summary totals present
  //    -> no validation/match errors
  //
  // Flow C: Preview import (unmatched employee block)
  // 4) Preview payload containing one unmapped external_employee_id
  //    -> preview created
  //    -> match_errors_json has item(s)
  //    -> apply_blocked=true
  // 5) POST /apply on that job
  //    -> 409 blocked
  //
  // Flow D: Apply import (maker-checker)
  // 6) User A previews valid payload
  // 7) User A tries apply -> 403 (default maker-checker)
  // 8) User B applies -> APPLIED
  //    -> payroll run created with source_type='PROVIDER_IMPORT'
  //    -> source_provider_import_job_id set
  //    -> payroll liabilities created
  //
  // Flow E: Apply idempotency
  // 9) Re-apply same job with same idempotency_key
  //    -> returns existing applied result, no duplicate run/liabilities
  //
  // Flow F: Payload hash dedupe
  // 10) Preview exact same payload/provider/period again
  //     -> idempotent preview returns existing job
  //
  // Flow G: P08 lock enforcement
  // 11) Close the payroll period (P08)
  // 12) Preview another import for same period (preview may succeed)
  // 13) Apply import -> 409 PAYROLL_PERIOD_LOCKED
  //
  // Permissions:
  // - payroll.provider.* permissions enforced (403)
  console.log("PR-P09 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 15) `backend/package.json` updates

```json
{
  "scripts": {
    "test:payroll:prp09": "node backend/scripts/test-payroll-prp09-provider-adapters.js"
  }
}
```

---

## Frontend (short version — key matching parts only)

## 16) API client — `frontend/src/api/payrollProviders.js`

```js
// frontend/src/api/payrollProviders.js

import { apiFetch } from "./client.js"; // adapt to your app

export function listPayrollProviders() {
  return apiFetch("/api/v1/payroll/providers");
}

export function listPayrollProviderConnections(params = {}) {
  const qs = new URLSearchParams();
  Object.entries(params).forEach(([k, v]) => {
    if (v === undefined || v === null || v === "") return;
    qs.set(k, String(v));
  });
  const q = qs.toString();
  return apiFetch(`/api/v1/payroll/provider-connections${q ? `?${q}` : ""}`);
}

export function createPayrollProviderConnection(payload) {
  return apiFetch("/api/v1/payroll/provider-connections", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function previewPayrollProviderImport(payload) {
  return apiFetch("/api/v1/payroll/provider-imports/preview", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function getPayrollProviderImportJob(id) {
  return apiFetch(`/api/v1/payroll/provider-imports/${id}`);
}

export function applyPayrollProviderImport(id, payload = {}) {
  return apiFetch(`/api/v1/payroll/provider-imports/${id}/apply`, {
    method: "POST",
    body: JSON.stringify(payload),
  });
}

export function createPayrollEmployeeProviderRef(payload) {
  return apiFetch("/api/v1/payroll/employee-provider-refs", {
    method: "POST",
    body: JSON.stringify(payload),
  });
}
```

---

## 17) `PayrollImportsPage.jsx` snippets (compact)

### Imports/state

```jsx
import {
  listPayrollProviderConnections,
  previewPayrollProviderImport,
  applyPayrollProviderImport,
  getPayrollProviderImportJob,
} from "../../api/payrollProviders.js";

const [connections, setConnections] = useState([]);
const [previewJob, setPreviewJob] = useState(null);
const [previewErr, setPreviewErr] = useState("");
```

### Preview action

```jsx
async function onPreviewImport() {
  try {
    setPreviewErr("");
    const res = await previewPayrollProviderImport({
      payroll_provider_connection_id: selectedConnectionId,
      period_start: periodStart,
      period_end: periodEnd,
      payroll_date: payrollDate,
      currency_code: "USD",
      source_format: "JSON",
      source_filename: "payroll_export.json",
      raw_payload_text: rawPayloadText, // textarea
      import_key: `prov-${selectedConnectionId}-${periodStart}-${periodEnd}`,
    });
    setPreviewJob(res);
  } catch (e) {
    setPreviewErr(e.message || "Preview failed");
  }
}
```

### Apply action

```jsx
async function onApplyImport() {
  const jobId = previewJob?.job?.id;
  if (!jobId) return;

  const res = await applyPayrollProviderImport(jobId, {
    idempotency_key: `apply-${jobId}`,
    note: "Apply provider payroll import",
    auto_post_accrual: false,
  });

  setPreviewJob(res);
}
```

### Compact UI notes

```jsx
<div className="rounded border bg-white p-4">
  <h2 className="font-medium mb-2">Payroll Provider Import</h2>

  {/* Sections:
      1) Provider connection selector
      2) Period fields (start/end/payroll_date/currency)
      3) Raw payload textarea (JSON/CSV)
      4) Preview button
      5) Preview summary chips:
         - employee_count_mapped / unmatched
         - total_gross / total_net
         - apply_blocked
      6) Error lists:
         - validation_errors_json
         - match_errors_json
      7) Apply button (disabled if apply_blocked)
  */}

  {previewErr ? <div className="text-sm text-red-600">{previewErr}</div> : null}
</div>
```

---

## 18) `PayrollRunsPage.jsx` — source badge snippet

```jsx
{
  /* In payroll run row/card */
}
<div className="text-xs">
  Source:{" "}
  {run.source_type === "PROVIDER_IMPORT" ? (
    <span className="text-blue-700">
      {run.source_provider_code || "Provider Import"}
      {run.source_provider_import_job_id
        ? ` (Import #${run.source_provider_import_job_id})`
        : ""}
    </span>
  ) : (
    <span>Manual</span>
  )}
</div>;
```

---

## Acceptance criteria (repeat in PR)

- ✅ Payroll provider adapter registry exists and supports pluggable adapters
- ✅ Entity-level payroll provider connections can be created/updated
- ✅ External employee → internal employee mapping table exists
- ✅ Provider import preview parses and validates raw payload
- ✅ Preview produces normalized canonical payload and summary totals
- ✅ Unmatched employees are surfaced and block apply
- ✅ Import apply is idempotent and auditable
- ✅ Applied import creates/updates payroll run with source traceability:

  - `source_type='PROVIDER_IMPORT'`
  - `source_provider_code`
  - `source_provider_import_job_id`

- ✅ Applied import creates payroll liabilities in existing payroll subledger tables
- ✅ P08 close lock blocks provider import apply for closed/locked periods
- ✅ Maker-checker apply is enforced by default (preview user cannot apply same job)
- ✅ Permissions enforced:

  - `payroll.provider.read/write`
  - `payroll.provider.mapping.read/write`
  - `payroll.provider.import.read/preview/apply`

- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:payroll:prp09`

Should verify at least:

1. **Provider setup**

   - Create provider connection
   - Create employee mapping refs

2. **Preview success**

   - Valid payload previews successfully
   - Summary totals computed
   - No matching/validation blockers

3. **Preview blocked by unmatched employees**

   - Unmatched provider employee appears in preview
   - Apply blocked with `409`

4. **Apply import (maker-checker)**

   - Preview by User A
   - User A cannot apply (`403`) by default
   - User B applies successfully
   - Payroll run + liabilities created

5. **Idempotency**

   - Re-apply same job with same idempotency key returns existing result
   - No duplicate run/liabilities

6. **Payload dedupe**

   - Re-preview same payload for same provider/period returns idempotent preview

7. **P08 lock**

   - Closed period blocks import apply (`409 PAYROLL_PERIOD_LOCKED`)

8. **Permissions**

   - all `payroll.provider.*` permissions enforced (`403`)

---

## Tiny implementation notes (important)

- P09 is intentionally **integration-first**, not a payroll calculation engine.
- The adapter contract is the key design win: once it’s stable, adding a new provider becomes mostly a mapping project.
- Later enhancements (optional):

  - encrypted secrets + API pull jobs
  - provider webhook ingestion
  - provider-specific payment reference normalization into P04/B06 reconciliation
  - mapping UI for earnings/deduction/tax codes to GL and cost centers

---

Perfect. Here’s the **post-P09 cleanup / final hardening PR set** to close the **Bank + Payroll** roadmap in a production-ready way.

# Post-P09 Hardening PR Series (Bank + Payroll)

These are **cross-module** PRs (not only Bank or Payroll).
They focus on:

- security
- reliability
- performance
- operations
- controls
- maintainability

---

## Global rules for all hardening PRs (repeat in each PR)

- **No silent behavior change** to posted accounting data
- All migrations are **additive / non-destructive**
- All new jobs/actions are **idempotent**
- All new approvals/actions are **audited**
- OpenAPI updated for any new endpoints
- Smoke test script added for each PR
- Backward compatibility preserved for existing Bxx / Pxx endpoints

---

# PR-H01: Sensitive Data Security (Encryption, Masking, Retention)

## Goal

Protect sensitive data across **Bank** and **Payroll provider** integrations by introducing:

- ✅ Encryption-at-rest for secrets (API keys, tokens, SFTP credentials, webhook secrets)
- ✅ Consistent masking/redaction in API responses and logs
- ✅ Raw payload retention controls (mask / purge)
- ✅ Audit trail for sensitive-data lifecycle actions
- ✅ Boot-time encryption config validation (fail fast in non-dev)

---

## Important behavior rules

### 1) Never return secrets in API responses

Even if a record contains secrets, responses should return:

- masked values only (`"****abcd"`)
- or flags (`has_secrets: true`)

No plaintext secret should leave backend APIs.

---

### 2) Encrypt before DB write

Services must encrypt secrets before persisting to DB.

- Storage format: envelope encryption payload
- Keep key version (`kid`) for rotation support
- Decrypt only inside backend service layer when needed

---

### 3) Raw payload retention is controlled and auditable

For import/feed/webhook payloads:

- `ACTIVE` = raw payload available (restricted)
- `MASKED` = raw payload redacted, hashes + metadata preserved
- `PURGED` = raw payload removed, hashes + audit preserved

Mask/purge actions must write an audit row.

---

### 4) Additive migration only

Do not break existing records:

- keep old plaintext columns temporarily if they exist
- add encrypted columns and migrate service writes first
- optional later cleanup PR can drop plaintext columns after backfill

---

## Files to create

### Backend

- `backend/src/migrations/m054_sensitive_data_security.js`
- `backend/src/utils/cryptoEnvelope.js`
- `backend/src/utils/redaction.js`
- `backend/scripts/test-hardening-prh01-sensitive-data.js`

---

## Files to update

### Backend

- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (patch services)

- `backend/src/services/payroll.providers.service.js` _(P09 patch)_
- `backend/src/services/bank.providers.service.js` _(or your actual B05 provider connection service name)_
- `backend/src/services/bank.webhooks.service.js` _(or equivalent)_
- `backend/src/services/bank.paymentExports.service.js` _(or equivalent)_

### Backend (optional route patch if you expose retention actions)

- `backend/src/routes/payroll.providers.js`
- `backend/src/routes/payroll.providers.validators.js`

> For Bank files: adapt filenames to your B05/B06 implementation names. The important part is applying the **same encryption + masking + redaction pattern**.

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m054_sensitive_data_security.js`

> This migration is **additive** and defensive (uses `catch` for optional bank tables if names differ in your repo).

```js
// backend/src/migrations/m054_sensitive_data_security.js

export default {
  key: "m054_sensitive_data_security",
  description: "m054_sensitive_data_security",
  async up(connection) {
    // ---- Payroll provider connections (P09) ----
    // Keep old secrets_json for transition; add encrypted envelope columns.
    await db
      .query(
        `
        ALTER TABLE payroll_provider_connections
          ADD COLUMN secrets_encrypted_json LONGTEXT NULL AFTER settings_json,
          ADD COLUMN secrets_key_version VARCHAR(40) NULL AFTER secrets_encrypted_json,
          ADD COLUMN secrets_migrated_at DATETIME NULL AFTER secrets_key_version
      `,
      )
      .catch(() => {});

    // Raw payload retention status on payroll imports (P09)
    await db
      .query(
        `
        ALTER TABLE payroll_provider_import_jobs
          ADD COLUMN raw_payload_retention_status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE' AFTER raw_payload_text,
          ADD COLUMN raw_payload_masked_at DATETIME NULL AFTER raw_payload_retention_status,
          ADD COLUMN raw_payload_purged_at DATETIME NULL AFTER raw_payload_masked_at,
          ADD COLUMN raw_payload_redaction_note VARCHAR(500) NULL AFTER raw_payload_purged_at
      `,
      )
      .catch(() => {});

    await db
      .query(
        `
        ALTER TABLE payroll_provider_import_jobs
          ADD KEY idx_ppij_raw_payload_retention_status (raw_payload_retention_status)
      `,
      )
      .catch(() => {});

    // ---- Optional Bank tables (adapt to your actual B05/B06/B07 schema names) ----
    // Example: bank provider connections
    await db
      .query(
        `
        ALTER TABLE bank_provider_connections
          ADD COLUMN secrets_encrypted_json LONGTEXT NULL AFTER settings_json,
          ADD COLUMN secrets_key_version VARCHAR(40) NULL AFTER secrets_encrypted_json,
          ADD COLUMN secrets_migrated_at DATETIME NULL AFTER secrets_key_version
      `,
      )
      .catch(() => {});

    // Example: bank webhook endpoints / configs
    await db
      .query(
        `
        ALTER TABLE bank_webhook_endpoints
          ADD COLUMN secret_encrypted_json LONGTEXT NULL AFTER webhook_secret,
          ADD COLUMN secret_key_version VARCHAR(40) NULL AFTER secret_encrypted_json
      `,
      )
      .catch(() => {});

    // Example: bank feed event raw payload retention
    await db
      .query(
        `
        ALTER TABLE bank_feed_events
          ADD COLUMN raw_payload_retention_status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE' AFTER raw_payload_text,
          ADD COLUMN raw_payload_masked_at DATETIME NULL AFTER raw_payload_retention_status,
          ADD COLUMN raw_payload_purged_at DATETIME NULL AFTER raw_payload_masked_at
      `,
      )
      .catch(() => {});

    await db
      .query(
        `
        ALTER TABLE bank_webhook_events
          ADD COLUMN raw_payload_retention_status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE' AFTER raw_payload_text,
          ADD COLUMN raw_payload_masked_at DATETIME NULL AFTER raw_payload_retention_status,
          ADD COLUMN raw_payload_purged_at DATETIME NULL AFTER raw_payload_masked_at
      `,
      )
      .catch(() => {});

    // ---- Generic audit for sensitive data lifecycle ----
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS sensitive_data_audit (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        module_code VARCHAR(40) NOT NULL,       -- PAYROLL, BANK
        object_type VARCHAR(60) NOT NULL,       -- PROVIDER_CONNECTION, IMPORT_JOB, WEBHOOK_EVENT, ...
        object_id BIGINT UNSIGNED NOT NULL,

        action VARCHAR(30) NOT NULL,            -- ENCRYPTED_WRITE, MASKED_PAYLOAD, PURGED_PAYLOAD, BACKFILL_MIGRATED
        payload_json JSON NULL,
        note VARCHAR(500) NULL,

        acted_by BIGINT UNSIGNED NULL,
        acted_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        KEY idx_sda_obj (module_code, object_type, object_id),
        KEY idx_sda_action (action),
        KEY idx_sda_acted_at (acted_at)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS sensitive_data_audit;`);
    // Strict down for ALTERs intentionally omitted for dev safety
  },
};
```

---

## 2) Encryption utility — `backend/src/utils/cryptoEnvelope.js`

> AES-256-GCM envelope encryption with key version support.

### Env vars used

- `APP_ENCRYPTION_KEYS_JSON`
  Example:

  ```json
  { "v1": "base64-32-byte-key-here", "v2": "base64-32-byte-key-here" }
  ```

- `APP_ENCRYPTION_ACTIVE_KEY_VERSION` (e.g. `v1`)
- `NODE_ENV`

```js
// backend/src/utils/cryptoEnvelope.js

import crypto from "crypto";
function parseKeysFromEnv() {
  const raw = process.env.APP_ENCRYPTION_KEYS_JSON || "{}";
  let parsed;
  try {
    parsed = JSON.parse(raw);
  } catch (e) {
    throw new Error("APP_ENCRYPTION_KEYS_JSON must be valid JSON");
  }

  const out = {};
  for (const [kid, base64Key] of Object.entries(parsed || {})) {
    const key = Buffer.from(String(base64Key || ""), "base64");
    if (key.length !== 32) {
      throw new Error(
        `Encryption key ${kid} must be 32 bytes (base64-decoded)`,
      );
    }
    out[kid] = key;
  }
  return out;
}

function getKeyMaterial() {
  const keys = parseKeysFromEnv();
  const activeKid = String(
    process.env.APP_ENCRYPTION_ACTIVE_KEY_VERSION || "",
  ).trim();

  if (!activeKid) {
    throw new Error("APP_ENCRYPTION_ACTIVE_KEY_VERSION is required");
  }
  if (!keys[activeKid]) {
    throw new Error(`Active encryption key version not found: ${activeKid}`);
  }

  return { keys, activeKid, activeKey: keys[activeKid] };
}

function encryptJson(value) {
  const { activeKid, activeKey } = getKeyMaterial();

  const iv = crypto.randomBytes(12); // GCM recommended 12 bytes
  const cipher = crypto.createCipheriv("aes-256-gcm", activeKey, iv);

  const plaintext = Buffer.from(JSON.stringify(value ?? {}), "utf8");
  const ciphertext = Buffer.concat([cipher.update(plaintext), cipher.final()]);
  const tag = cipher.getAuthTag();

  return {
    alg: "AES-256-GCM",
    kid: activeKid,
    iv_b64: iv.toString("base64"),
    tag_b64: tag.toString("base64"),
    ct_b64: ciphertext.toString("base64"),
    enc_at: new Date().toISOString(),
  };
}

function decryptJson(envelope) {
  if (!envelope || typeof envelope !== "object") return {};

  const { keys } = getKeyMaterial();
  const key = keys[envelope.kid];
  if (!key) {
    throw new Error(`Missing decryption key for kid=${envelope.kid}`);
  }

  const iv = Buffer.from(String(envelope.iv_b64 || ""), "base64");
  const tag = Buffer.from(String(envelope.tag_b64 || ""), "base64");
  const ciphertext = Buffer.from(String(envelope.ct_b64 || ""), "base64");

  const decipher = crypto.createDecipheriv("aes-256-gcm", key, iv);
  decipher.setAuthTag(tag);

  const plaintext = Buffer.concat([
    decipher.update(ciphertext),
    decipher.final(),
  ]);
  return JSON.parse(plaintext.toString("utf8"));
}

function serializeEnvelope(envelope) {
  return JSON.stringify(envelope || null);
}

function parseEnvelopeText(text) {
  if (!text) return null;
  try {
    return JSON.parse(String(text));
  } catch (_) {
    return null;
  }
}

function assertEncryptionConfigured() {
  const env = String(process.env.NODE_ENV || "development");
  if (["production", "staging"].includes(env)) {
    // Throws if invalid/missing
    getKeyMaterial();
  }
}

export default {
  encryptJson,
  decryptJson,
  serializeEnvelope,
  parseEnvelopeText,
  assertEncryptionConfigured,
};
```

---

## 3) Redaction utility — `backend/src/utils/redaction.js`

> Use this for logs, audit payloads, and API responses.

```js
// backend/src/utils/redaction.js

const DEFAULT_SENSITIVE_KEYS = [
  "password",
  "secret",
  "token",
  "api_key",
  "apikey",
  "access_token",
  "refresh_token",
  "client_secret",
  "private_key",
  "webhook_secret",
  "authorization",
  "iban",
  "account_number",
  "routing_number",
];

function maskString(value, { keepEnd = 4 } = {}) {
  const s = String(value || "");
  if (!s) return "";
  if (s.length <= keepEnd) return "*".repeat(s.length);
  return `${"*".repeat(Math.max(4, s.length - keepEnd))}${s.slice(-keepEnd)}`;
}

function looksSensitiveKey(key) {
  const k = String(key || "").toLowerCase();
  return DEFAULT_SENSITIVE_KEYS.some((frag) => k.includes(frag));
}

function redactValueByKey(key, value) {
  if (value === null || value === undefined) return value;

  if (typeof value === "string") {
    if (looksSensitiveKey(key)) return maskString(value);
    return value;
  }

  if (typeof value === "number" || typeof value === "boolean") {
    return looksSensitiveKey(key) ? "***" : value;
  }

  if (Array.isArray(value)) {
    return value.map((v) => redactValueByKey(key, v));
  }

  if (typeof value === "object") {
    return redactObject(value);
  }

  return value;
}

function redactObject(input) {
  if (!input || typeof input !== "object") return input;
  if (Array.isArray(input)) return input.map(redactObject);

  const out = {};
  for (const [k, v] of Object.entries(input)) {
    if (looksSensitiveKey(k)) {
      if (typeof v === "string") out[k] = maskString(v);
      else out[k] = "***";
      continue;
    }
    out[k] = typeof v === "object" && v !== null ? redactObject(v) : v;
  }
  return out;
}

function redactRawPayloadText(text, { maxLen = 4000 } = {}) {
  const s = String(text || "");
  if (!s) return s;

  // Try JSON redaction first
  try {
    const json = JSON.parse(s);
    const redacted = redactObject(json);
    const out = JSON.stringify(redacted);
    return out.length > maxLen ? `${out.slice(0, maxLen)}...[TRUNCATED]` : out;
  } catch (_) {
    // fallback text masking (best-effort)
    let out = s
      .replace(/(authorization\s*[:=]\s*)(.+)/gi, "$1***")
      .replace(/(token\s*[:=]\s*)(.+)/gi, "$1***")
      .replace(/(secret\s*[:=]\s*)(.+)/gi, "$1***");

    if (out.length > maxLen) out = `${out.slice(0, maxLen)}...[TRUNCATED]`;
    return out;
  }
}

export default {
  maskString,
  redactObject,
  redactRawPayloadText,
};
```

---

## 4) Patch `payroll.providers.service.js` (P09) — encrypt secrets + mask responses + payload retention

> Keep your P09 service. Apply these **targeted changes**.

### A) Add imports

```js
import { encryptJson,
  decryptJson,
  serializeEnvelope,
  parseEnvelopeText, } from "../utils/cryptoEnvelope.js";
import { redactObject, redactRawPayloadText } from "../utils/redaction.js";
```

---

### B) Add helpers inside service

```js
async function writeSensitiveDataAudit(
  db,
  {
    moduleCode,
    objectType,
    objectId,
    action,
    payload = null,
    note = null,
    userId = null,
  },
) {
  await db.query(
    `
    INSERT INTO sensitive_data_audit
    (module_code, object_type, object_id, action, payload_json, note, acted_by)
    VALUES (?, ?, ?, ?, ?, ?, ?)
    `,
    [
      moduleCode,
      objectType,
      objectId,
      action,
      payload ? JSON.stringify(payload) : null,
      note,
      userId,
    ],
  );
}

function maskSecretsForApi(row) {
  if (!row) return row;
  const out = { ...row };

  // Never expose encrypted blob
  delete out.secrets_encrypted_json;

  // Never expose plaintext legacy secrets_json
  if ("secrets_json" in out) {
    out.secrets_json = out.secrets_json ? { _masked: true } : null;
  }

  out.has_secrets = !!(row.secrets_encrypted_json || row.secrets_json);
  return out;
}

function getConnectionSecretsDecrypted(row) {
  // Prefer encrypted blob
  const env = parseEnvelopeText(row?.secrets_encrypted_json);
  if (env) return decryptJson(env);

  // Legacy fallback for transition (plaintext)
  if (row?.secrets_json && typeof row.secrets_json === "object") {
    return row.secrets_json;
  }
  if (row?.secrets_json && typeof row.secrets_json === "string") {
    try {
      return JSON.parse(row.secrets_json);
    } catch (_) {
      return {};
    }
  }

  return {};
}
```

---

### C) Patch create/update provider connection to encrypt `secrets_json`

> If your P09 route body doesn’t yet accept `secrets_json`, add it (optional).
> If you already have it in settings/admin flows, encrypt here.

#### Create patch (inside `createProviderConnection(...)`)

```js
const secretsEnvelope = body.secrets_json
  ? encryptJson(body.secrets_json)
  : null;

const [ins] = await q.query(
  `
  INSERT INTO payroll_provider_connections
  (entity_id, provider_code, provider_name, adapter_version, status, is_default,
   settings_json, secrets_encrypted_json, secrets_key_version, created_by, updated_by)
  VALUES (?, ?, ?, ?, 'ACTIVE', ?, ?, ?, ?, ?, ?)
  `,
  [
    body.entity_id,
    body.provider_code,
    body.provider_name,
    body.adapter_version,
    body.is_default ? 1 : 0,
    JSON.stringify(body.settings_json || {}),
    secretsEnvelope ? serializeEnvelope(secretsEnvelope) : null,
    secretsEnvelope ? secretsEnvelope.kid : null,
    userId,
    userId,
  ],
);

// Optional: legacy plaintext column cleanup (if exists in schema and you used it before)
await q
  .query(
    `UPDATE payroll_provider_connections SET secrets_json = NULL, secrets_migrated_at = NOW() WHERE id = ?`,
    [ins.insertId],
  )
  .catch(() => {});

await writeSensitiveDataAudit(q, {
  moduleCode: "PAYROLL",
  objectType: "PROVIDER_CONNECTION",
  objectId: ins.insertId,
  action: "ENCRYPTED_WRITE",
  payload: {
    provider_code: body.provider_code,
    has_secrets: !!secretsEnvelope,
  },
  note: "Provider connection created with encrypted secrets",
  userId,
});
```

#### Update patch (inside `updateProviderConnection(...)`)

```js
let secretsEnvelope = null;
let updateSecrets = false;

if (body.secrets_json !== undefined) {
  updateSecrets = true;
  secretsEnvelope = body.secrets_json ? encryptJson(body.secrets_json) : null;
}

await q.query(
  `
  UPDATE payroll_provider_connections
  SET provider_name = COALESCE(?, provider_name),
      status = COALESCE(?, status),
      adapter_version = COALESCE(?, adapter_version),
      is_default = COALESCE(?, is_default),
      settings_json = COALESCE(?, settings_json),
      secrets_encrypted_json = CASE WHEN ? THEN ? ELSE secrets_encrypted_json END,
      secrets_key_version = CASE WHEN ? THEN ? ELSE secrets_key_version END,
      secrets_migrated_at = CASE WHEN ? THEN NOW() ELSE secrets_migrated_at END,
      updated_by = ?,
      updated_at = NOW()
  WHERE id = ?
  `,
  [
    body.provider_name || null,
    body.status || null,
    body.adapter_version || null,
    body.is_default === undefined ? null : body.is_default ? 1 : 0,
    body.settings_json === undefined
      ? null
      : JSON.stringify(body.settings_json),
    updateSecrets ? 1 : 0,
    updateSecrets
      ? secretsEnvelope
        ? serializeEnvelope(secretsEnvelope)
        : null
      : null,
    updateSecrets ? 1 : 0,
    updateSecrets ? (secretsEnvelope ? secretsEnvelope.kid : null) : null,
    updateSecrets ? 1 : 0,
    userId,
    id,
  ],
);

// Clear legacy plaintext if updated
if (updateSecrets) {
  await q
    .query(
      `UPDATE payroll_provider_connections SET secrets_json = NULL WHERE id = ?`,
      [id],
    )
    .catch(() => {});
}

if (updateSecrets) {
  await writeSensitiveDataAudit(q, {
    moduleCode: "PAYROLL",
    objectType: "PROVIDER_CONNECTION",
    objectId: id,
    action: "ENCRYPTED_WRITE",
    payload: { has_secrets: !!secretsEnvelope },
    note: "Provider connection secrets rotated/updated",
    userId,
  });
}
```

---

### D) Patch list/get responses to mask secrets

```js
// In listProviderConnections(...)
return rows.map(maskSecretsForApi);

// In any get-connection-by-id endpoint/service
return maskSecretsForApi(row);
```

---

### E) Use decrypted secrets only internally (example usage)

```js
// In preview/apply or provider API pull methods, when adapter/provider client needs credentials:
const providerSecrets = getConnectionSecretsDecrypted(connection);

// NEVER log raw providerSecrets
// If logging config:
logger.info("Provider connection loaded", {
  connection_id: connection.id,
  provider_code: connection.provider_code,
  secrets: redactObject(providerSecrets),
});
```

---

### F) Add raw payload retention actions (mask / purge)

> These support H01 retention control for payroll provider imports.

```js
async function maskPayrollProviderImportRawPayload(
  db,
  jobId,
  { reason = "Manual mask" } = {},
  userId = null,
) {
  const [rows] = await db.query(
    `SELECT id, raw_payload_text, raw_payload_retention_status FROM payroll_provider_import_jobs WHERE id=? LIMIT 1`,
    [jobId],
  );
  const job = rows[0];
  if (!job) {
    const err = new Error("Payroll provider import job not found");
    err.statusCode = 404;
    throw err;
  }

  if (job.raw_payload_retention_status === "PURGED") {
    const err = new Error("Raw payload already purged");
    err.statusCode = 409;
    throw err;
  }

  const redacted = redactRawPayloadText(job.raw_payload_text || "");

  await db.query(
    `
    UPDATE payroll_provider_import_jobs
    SET raw_payload_text = ?,
        raw_payload_retention_status = 'MASKED',
        raw_payload_masked_at = NOW(),
        raw_payload_redaction_note = ?
    WHERE id = ?
    `,
    [redacted, reason, jobId],
  );

  await writeSensitiveDataAudit(db, {
    moduleCode: "PAYROLL",
    objectType: "IMPORT_JOB",
    objectId: jobId,
    action: "MASKED_PAYLOAD",
    payload: { previous_status: job.raw_payload_retention_status || "ACTIVE" },
    note: reason,
    userId,
  });

  const [updated] = await db.query(
    `SELECT * FROM payroll_provider_import_jobs WHERE id=? LIMIT 1`,
    [jobId],
  );
  return updated[0];
}

async function purgePayrollProviderImportRawPayload(
  db,
  jobId,
  { reason = "Manual purge" } = {},
  userId = null,
) {
  const [rows] = await db.query(
    `SELECT id, raw_payload_retention_status FROM payroll_provider_import_jobs WHERE id=? LIMIT 1`,
    [jobId],
  );
  const job = rows[0];
  if (!job) {
    const err = new Error("Payroll provider import job not found");
    err.statusCode = 404;
    throw err;
  }

  if (job.raw_payload_retention_status === "PURGED") {
    return job; // idempotent
  }

  await db.query(
    `
    UPDATE payroll_provider_import_jobs
    SET raw_payload_text = NULL,
        raw_payload_retention_status = 'PURGED',
        raw_payload_purged_at = NOW(),
        raw_payload_redaction_note = ?
    WHERE id = ?
    `,
    [reason, jobId],
  );

  await writeSensitiveDataAudit(db, {
    moduleCode: "PAYROLL",
    objectType: "IMPORT_JOB",
    objectId: jobId,
    action: "PURGED_PAYLOAD",
    payload: { previous_status: job.raw_payload_retention_status || "ACTIVE" },
    note: reason,
    userId,
  });

  const [updated] = await db.query(
    `SELECT * FROM payroll_provider_import_jobs WHERE id=? LIMIT 1`,
    [jobId],
  );
  return updated[0];
}
```

Export them:

```js
export default {
  // ...existing exports
  maskPayrollProviderImportRawPayload,
  purgePayrollProviderImportRawPayload,
};
```

---

## 5) Patch `payroll.providers.validators.js` (optional H01 additions)

### A) Allow secrets on create/update (if you want admin API to set them)

```js
// in validateCreateConnectionBody(...)
secrets_json: body.secrets_json || undefined,
```

```js
// in validateUpdateConnectionBody(...)
secrets_json: body.secrets_json, // undefined = no change, null = clear
```

### B) Add retention action validator

```js
function validateRetentionActionBody(body = {}) {
  const reason = String(body.reason || "").trim() || "Manual retention action";
  return { reason };
}
```

Export it.

---

## 6) Patch `payroll.providers.js` route — add payload mask/purge endpoints (optional but recommended)

> If you want H01 controls exposed now (good for admin ops).

### Add import

```js
import { validateRetentionActionBody, } from "./payroll.providers.validators.js";
```

### Add routes

```js
// POST /api/v1/payroll/provider-imports/:id/mask-raw-payload
router.post(
  "/provider-imports/:id/mask-raw-payload",
  requireAuth,
  requirePermission("payroll.provider.import.retention.manage"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateImportJobIdParam(req.params);
      const body = validateRetentionActionBody(req.body);
      const item = await svc.maskPayrollProviderImportRawPayload(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/payroll/provider-imports/:id/purge-raw-payload
router.post(
  "/provider-imports/:id/purge-raw-payload",
  requireAuth,
  requirePermission("payroll.provider.import.retention.manage"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const { id } = validateImportJobIdParam(req.params);
      const body = validateRetentionActionBody(req.body);
      const item = await svc.purgePayrollProviderImportRawPayload(
        db,
        id,
        body,
        req.user?.id ?? null,
      );
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);
```

---

## 7) Bank service patches (B05/B06/B07/B08) — same pattern (important)

> Your exact filenames may differ. Apply the **same pattern** used in payroll providers.

### A) Encrypt bank connection/payment export/webhook secrets

In your bank provider connection / export profile service:

```js
import { encryptJson,
  decryptJson,
  serializeEnvelope,
  parseEnvelopeText, } from "../utils/cryptoEnvelope.js";
import { redactObject } from "../utils/redaction.js";
// write:
const env = body.secrets_json ? encryptJson(body.secrets_json) : null;
row.secrets_encrypted_json = serializeEnvelope(env);
row.secrets_key_version = env.kid;

// read internal:
const secrets = decryptJson(parseEnvelopeText(row.secrets_encrypted_json));

// api response:
delete row.secrets_encrypted_json;
delete row.webhook_secret;
row.has_secrets = true;
```

### B) Redact webhook/feed payloads before logging

In webhook/feed services:

```js
logger.info("Bank webhook received", {
  endpoint_id,
  headers: redactObject(req.headers),
  payload: redactObject(req.body),
});
```

### C) Add raw payload mask/purge methods for bank events (same as payroll import jobs)

For tables like:

- `bank_webhook_events`
- `bank_feed_events`

Add methods:

- `maskBankWebhookEventRawPayload(id)`
- `purgeBankWebhookEventRawPayload(id)`
- `maskBankFeedEventRawPayload(id)`
- `purgeBankFeedEventRawPayload(id)`

And write `sensitive_data_audit` rows with:

- `module_code = 'BANK'`
- `object_type = 'WEBHOOK_EVENT' | 'FEED_EVENT'`

---

## 8) Boot-time config validation — `backend/src/index.js`

> Fail fast in non-dev if encryption config is missing.

```js
// backend/src/index.js
import { assertEncryptionConfigured } from "./utils/cryptoEnvelope.js";
// Before app.listen(...)
assertEncryptionConfigured();
```

Optional dev warning:

```js
if (process.env.NODE_ENV !== "production") {
  try {
    assertEncryptionConfigured();
  } catch (e) {
    console.warn(
      "[WARN] Encryption not fully configured (dev mode):",
      e.message,
    );
  }
}
```

---

## 9) Migration registry — `backend/src/migrations/index.js`

```js
// backend/src/migrations/index.js
import m054_sensitive_data_security from "./m054_sensitive_data_security.js";
export default [
  // ...
  m054_sensitive_data_security,
];
```

---

## 10) Seed permissions — `backend/src/seedCore.js`

```js
// backend/src/seedCore.js
const HARDENING_H01_PERMISSIONS = [
  "payroll.provider.import.retention.manage",
  "bank.integration.retention.manage",
  "security.sensitive_data.audit.read",
];

// merge into permission seed list
```

> If you add admin audit endpoints later, `security.sensitive_data.audit.read` is ready.

---

## 11) OpenAPI generation — `backend/scripts/generate-openapi.js`

### Update existing schemas/responses

For provider/bank connection responses:

- do **not** expose raw secrets
- include:

  - `has_secrets: boolean`
  - `secrets_key_version` (optional)
  - masked/placeholder `secrets_json` if you keep field for compatibility

### Register new payroll retention endpoints (if added)

- `POST /api/v1/payroll/provider-imports/{id}/mask-raw-payload`
- `POST /api/v1/payroll/provider-imports/{id}/purge-raw-payload`

Document retention statuses:

- `ACTIVE`
- `MASKED`
- `PURGED`

---

## 12) Backend smoke test — `backend/scripts/test-hardening-prh01-sensitive-data.js`

```js
// backend/scripts/test-hardening-prh01-sensitive-data.js

async function main() {
  // Preconditions:
  // - P09 implemented
  // - APP_ENCRYPTION_KEYS_JSON + APP_ENCRYPTION_ACTIVE_KEY_VERSION set
  //
  // Flow A: Payroll provider connection secret encryption
  // 1) Create provider connection with secrets_json
  // 2) DB row has secrets_encrypted_json populated
  // 3) API/service list response does NOT return plaintext secrets
  // 4) Internal decrypt helper returns original secret values
  //
  // Flow B: Payroll import raw payload retention controls
  // 5) Create preview import job with raw_payload_text
  // 6) POST mask-raw-payload
  //    -> raw_payload_retention_status = MASKED
  //    -> raw_payload_text is redacted
  //    -> audit row written (MASKED_PAYLOAD)
  // 7) POST purge-raw-payload
  //    -> raw_payload_retention_status = PURGED
  //    -> raw_payload_text = NULL
  //    -> audit row written (PURGED_PAYLOAD)
  // 8) Re-purge same row -> idempotent / no break
  //
  // Flow C: Bank secret storage pattern (if B05 tables/services exist)
  // 9) Create/update bank provider connection or export profile with secrets
  //    -> encrypted blob stored
  //    -> API response masked
  //
  // Flow D: Boot config validation
  // 10) Simulate production env without encryption keys
  //     -> assertEncryptionConfigured throws
  //
  // Permissions:
  // - payroll.provider.import.retention.manage enforced (403)
  //
  console.log("PR-H01 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 13) `backend/package.json` updates

```json
{
  "scripts": {
    "test:hardening:prh01": "node backend/scripts/test-hardening-prh01-sensitive-data.js"
  }
}
```

---

## Acceptance criteria (repeat in PR)

- ✅ Secrets for payroll provider integrations are encrypted at rest
- ✅ Bank integration secrets use same encryption pattern (adapted to B05/B06 services)
- ✅ API responses never return plaintext secrets
- ✅ Redaction utility is used for logs/audit payloads
- ✅ Payroll provider import raw payloads support:

  - `ACTIVE`
  - `MASKED`
  - `PURGED`

- ✅ Mask/purge actions write `sensitive_data_audit` rows
- ✅ Boot fails fast in non-dev if encryption config is missing/invalid
- ✅ Migration is additive and backward compatible (legacy plaintext columns can remain temporarily)
- ✅ Permissions enforced for retention actions
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:hardening:prh01`

Should verify at least:

1. **Encryption-at-rest**

   - `secrets_encrypted_json` is stored
   - `secrets_key_version` is set
   - plaintext secret not returned from API

2. **Internal decryption**

   - backend service can decrypt and use secret internally

3. **Mask raw payload**

   - import job raw payload becomes redacted
   - retention status becomes `MASKED`
   - audit row written

4. **Purge raw payload**

   - import job raw payload becomes `NULL`
   - retention status becomes `PURGED`
   - audit row written

5. **Idempotent purge**

   - repeated purge call does not fail or corrupt data

6. **Permissions**

   - `payroll.provider.import.retention.manage` enforced (`403`)

7. **Boot validation**

   - missing/invalid encryption env throws in production/staging mode

---

## Tiny implementation notes (important)

- This PR **does not** require immediate backfill of old plaintext secret rows.
  You can add a small follow-up migration/script later to migrate legacy `secrets_json` → `secrets_encrypted_json`.

- H01 intentionally introduces **key versioning** now, so future rotation is easy:

  - write with active key
  - read with row’s `kid`
  - later add “re-encrypt all” job

- H07 (retention/archival) will later automate mask/purge schedules.
  H01 just gives you the **safe primitives** and audit trail.

---

Perfect — here is **PR-H02** in the same concrete format.

# PR-H02: Jobs + Retry Engine (Idempotent Background Processing Backbone)

## Goal

Create a reusable **background jobs + retry engine** for long-running and failure-prone operations across **Bank** and **Payroll**.

This PR gives you:

- ✅ Generic job queue table + attempt history
- ✅ Idempotent enqueue (`idempotency_key`)
- ✅ Retry with backoff (`FAILED_RETRYABLE -> QUEUED`)
- ✅ Dead-letter behavior (`FAILED_FINAL`)
- ✅ Row-lock safe worker claim/run flow
- ✅ Admin endpoints to inspect/requeue/cancel jobs
- ✅ Starter handlers for Bank + Payroll
- ✅ Optional async mode hooks for existing Bxx / Pxx flows

---

## Important behavior rules

### 1) Enqueue is idempotent

If the same job is enqueued again with the same:

- `queue_name`
- `idempotency_key`

…it should return the existing job, not create a duplicate.

---

### 2) Worker claims jobs safely (no double execution)

Workers must claim jobs using DB row locking (`FOR UPDATE`) so two workers cannot run the same job at once.

---

### 3) Retries are controlled and auditable

On handler failure:

- if retryable and attempts remain → set `FAILED_RETRYABLE`, schedule `run_after_at`
- if not retryable or attempts exhausted → set `FAILED_FINAL`

Every attempt writes a job attempt row.

---

### 4) Handlers remain domain-safe

Jobs should call existing Bank/Payroll services (B05/B06/B07/B08/P09) — not duplicate business logic.

This PR adds the execution backbone, not new accounting behavior.

---

### 5) Sensitive data is redacted in errors/logs

Use H01 redaction helpers when writing job error payloads / logs.

---

## Files to create

### Backend

- `backend/src/migrations/m055_job_engine.js`
- `backend/src/services/jobs.service.js`
- `backend/src/services/jobHandlers/index.js`
- `backend/src/services/jobHandlers/bankFeedPull.handler.js`
- `backend/src/services/jobHandlers/bankWebhookProcess.handler.js`
- `backend/src/services/jobHandlers/paymentSyncRetry.handler.js`
- `backend/src/services/jobHandlers/payrollImportApply.handler.js`
- `backend/src/routes/jobs.admin.js`
- `backend/scripts/run-jobs-worker.js`
- `backend/scripts/test-hardening-prh02-job-engine.js`

---

## Files to update

### Backend

- `backend/src/migrations/index.js`
- `backend/src/index.js`
- `backend/src/seedCore.js`
- `backend/scripts/generate-openapi.js`
- `backend/package.json`

### Backend (patch existing services to enqueue jobs)

- `backend/src/services/payroll.providers.service.js` _(P09 async apply option)_
- `backend/src/services/bank.providers.service.js` _(or your B05 feed service)_
- `backend/src/services/bank.webhooks.service.js` _(optional deferred processing)_
- `backend/src/services/bank.reconciliation.service.js` _(or B07/B08 sync retry enqueue)_

> Adapt Bank filenames to your actual Bxx implementation names.

---

## Concrete skeletons

## 1) Migration — `backend/src/migrations/m055_job_engine.js`

```js id="wmql9n"
// backend/src/migrations/m055_job_engine.js

export default {
  key: "m055_job_engine",
  description: "m055_job_engine",
  async up(connection) {
    await connection.execute(`
      CREATE TABLE IF NOT EXISTS app_jobs (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,

        queue_name VARCHAR(60) NOT NULL,          -- bank.integrations, payroll.imports, ops.default
        module_code VARCHAR(40) NOT NULL,         -- BANK, PAYROLL, OPS
        job_type VARCHAR(60) NOT NULL,            -- BANK_FEED_PULL, PAYROLL_IMPORT_APPLY, ...

        status VARCHAR(20) NOT NULL DEFAULT 'QUEUED',
        -- QUEUED, RUNNING, SUCCEEDED, FAILED_RETRYABLE, FAILED_FINAL, CANCELLED

        priority INT NOT NULL DEFAULT 100,        -- lower = sooner
        run_after_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,

        idempotency_key VARCHAR(190) NULL,
        payload_json JSON NULL,
        payload_hash VARCHAR(128) NULL,

        attempt_count INT NOT NULL DEFAULT 0,
        max_attempts INT NOT NULL DEFAULT 5,

        locked_by VARCHAR(120) NULL,
        locked_at DATETIME NULL,

        started_at DATETIME NULL,
        finished_at DATETIME NULL,

        last_error_code VARCHAR(80) NULL,
        last_error_message VARCHAR(500) NULL,
        last_error_json JSON NULL,

        result_json JSON NULL,

        created_by BIGINT UNSIGNED NULL,
        cancelled_by BIGINT UNSIGNED NULL,
        cancelled_at DATETIME NULL,

        created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

        PRIMARY KEY (id),
        UNIQUE KEY uq_app_jobs_queue_idem (queue_name, idempotency_key),
        KEY idx_app_jobs_sched (status, run_after_at, priority, id),
        KEY idx_app_jobs_type (module_code, job_type),
        KEY idx_app_jobs_locked (locked_at)
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);

    await connection.execute(`
      CREATE TABLE IF NOT EXISTS app_job_attempts (
        id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
        app_job_id BIGINT UNSIGNED NOT NULL,

        attempt_no INT NOT NULL,
        worker_id VARCHAR(120) NOT NULL,

        status VARCHAR(20) NOT NULL,  -- RUNNING, SUCCEEDED, FAILED_RETRYABLE, FAILED_FINAL
        started_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
        finished_at DATETIME NULL,

        error_code VARCHAR(80) NULL,
        error_message VARCHAR(500) NULL,
        error_json JSON NULL,

        result_json JSON NULL,

        PRIMARY KEY (id),
        UNIQUE KEY uq_app_job_attempt_no (app_job_id, attempt_no),
        KEY idx_app_job_attempts_job (app_job_id),
        KEY idx_app_job_attempts_status (status),

        CONSTRAINT fk_app_job_attempts_job
          FOREIGN KEY (app_job_id) REFERENCES app_jobs(id)
          ON UPDATE RESTRICT ON DELETE CASCADE
      ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    `);
  },

  async down(connection) {
    await connection.execute(`DROP TABLE IF EXISTS app_job_attempts;`);
    await connection.execute(`DROP TABLE IF EXISTS app_jobs;`);
  },
};
```

---

## 2) Job handlers registry — `backend/src/services/jobHandlers/index.js`

```js id="8sp6o9"
// backend/src/services/jobHandlers/index.js

import bankFeedPullHandler from "./bankFeedPull.handler.js";
import bankWebhookProcessHandler from "./bankWebhookProcess.handler.js";
import paymentSyncRetryHandler from "./paymentSyncRetry.handler.js";
import payrollImportApplyHandler from "./payrollImportApply.handler.js";
const HANDLERS = {
  BANK_FEED_PULL: bankFeedPullHandler,
  BANK_WEBHOOK_PROCESS: bankWebhookProcessHandler,
  PAYMENT_SYNC_RETRY: paymentSyncRetryHandler,
  PAYROLL_IMPORT_APPLY: payrollImportApplyHandler,
};

function getJobHandler(jobType) {
  const h = HANDLERS[String(jobType || "").toUpperCase()];
  if (!h) {
    const err = new Error(`Unsupported job type: ${jobType}`);
    err.statusCode = 400;
    err.errorCode = "JOB_HANDLER_UNSUPPORTED";
    err.retryable = false;
    throw err;
  }
  return h;
}

export default {
  getJobHandler,
};
```

---

## 3) Starter handlers

> These call your existing domain services. Names are placeholders — adapt to your actual files.

### A) `bankFeedPull.handler.js`

```js id="6n6t7y"
// backend/src/services/jobHandlers/bankFeedPull.handler.js

// Adapt to your actual B05 service:
import bankProvidersSvc from "../bank.providers.service.js";
export default {
  /**
   * payload example:
   * {
   *   provider_connection_id: 12,
   *   from_date: "2026-02-01",
   *   to_date: "2026-02-25",
   *   triggered_by: 1001
   * }
   */
  async run({ db, payload, job }) {
    const res = await bankProvidersSvc.pullBankFeedForConnection(
      db,
      {
        provider_connection_id: payload.provider_connection_id,
        from_date: payload.from_date,
        to_date: payload.to_date,
        source: "JOB_ENGINE",
        job_id: job.id,
      },
      payload.triggered_by || null,
    );

    return {
      ok: true,
      imported_statement_lines: res.imported_statement_lines || 0,
      provider_connection_id: payload.provider_connection_id,
    };
  },
};
```

### B) `bankWebhookProcess.handler.js`

```js id="2r6ql5"
// backend/src/services/jobHandlers/bankWebhookProcess.handler.js

// Adapt to your actual webhook service:
import bankWebhooksSvc from "../bank.webhooks.service.js";
export default {
  /**
   * payload example:
   * { webhook_event_id: 987, triggered_by: 1001 }
   */
  async run({ db, payload, job }) {
    const res = await bankWebhooksSvc.processWebhookEvent(
      db,
      payload.webhook_event_id,
      {
        source: "JOB_ENGINE",
        job_id: job.id,
        user_id: payload.triggered_by || null,
      },
    );

    return {
      ok: true,
      webhook_event_id: payload.webhook_event_id,
      status: res.status || "processed",
    };
  },
};
```

### C) `paymentSyncRetry.handler.js`

```js id="e6x9s7"
// backend/src/services/jobHandlers/paymentSyncRetry.handler.js

// Adapt to your actual B07/P04 sync service name:
import paymentSyncSvc from "../bank.reconciliation.service.js";
export default {
  /**
   * payload example:
   * { payment_batch_id: 55, mode: "RETRY_FAILED_LINES", triggered_by: 1001 }
   */
  async run({ db, payload, job }) {
    const res = await paymentSyncSvc.retryPaymentBatchSync(
      db,
      {
        payment_batch_id: payload.payment_batch_id,
        mode: payload.mode || "RETRY_FAILED_LINES",
        source: "JOB_ENGINE",
        job_id: job.id,
      },
      payload.triggered_by || null,
    );

    return {
      ok: true,
      payment_batch_id: payload.payment_batch_id,
      retried_count: res.retried_count || 0,
      success_count: res.success_count || 0,
      failed_count: res.failed_count || 0,
    };
  },
};
```

### D) `payrollImportApply.handler.js`

```js id="m1wt4h"
// backend/src/services/jobHandlers/payrollImportApply.handler.js

import payrollProvidersSvc from "../payroll.providers.service.js";
export default {
  /**
   * payload example:
   * {
   *   import_job_id: 123,
   *   acting_user_id: 2002,
   *   apply_note: "Async apply",
   *   allow_same_user_apply: false
   * }
   */
  async run({ db, payload, job }) {
    const res = await payrollProvidersSvc.applyProviderImport(
      db,
      payload.import_job_id,
      {
        idempotency_key: `JOB:${job.id}|PAYROLL_IMPORT_APPLY`,
        note: payload.apply_note || "Async payroll import apply",
        auto_post_accrual: !!payload.auto_post_accrual,
        allow_same_user_apply: !!payload.allow_same_user_apply,
      },
      payload.acting_user_id || null,
    );

    return {
      ok: true,
      import_job_id: payload.import_job_id,
      applied_payroll_run_id: res?.job?.applied_payroll_run_id || null,
    };
  },
};
```

---

## 4) Jobs service — `backend/src/services/jobs.service.js`

> Core engine: enqueue, list, claim, run, retry, cancel, requeue.

```js id="q4tc0q"
// backend/src/services/jobs.service.js

import crypto from "crypto";
import { getJobHandler } from "./jobHandlers.js";
import { redactObject } from "../utils/redaction.js";
function hashPayload(obj) {
  return crypto
    .createHash("sha256")
    .update(JSON.stringify(obj || {}))
    .digest("hex");
}

function nowDate() {
  return new Date();
}

function addSeconds(date, sec) {
  return new Date(date.getTime() + sec * 1000);
}

function computeRetryDelaySeconds(attemptNo, job) {
  // Exponential backoff with cap, plus optional job payload override
  const base = Number(job?.payload_json?.retry_base_seconds || 30);
  const max = Number(job?.payload_json?.retry_max_seconds || 3600);
  const n = Math.max(1, Number(attemptNo || 1));
  const delay = Math.min(max, base * Math.pow(2, Math.max(0, n - 1)));
  return Math.floor(delay);
}

function toStatusTerminal(status) {
  return ["SUCCEEDED", "FAILED_FINAL", "CANCELLED"].includes(
    String(status || ""),
  );
}

function normalizeJobType(s) {
  return String(s || "")
    .trim()
    .toUpperCase();
}

async function enqueueJob(db, spec, userId = null) {
  const queue_name = String(spec.queue_name || "ops.default").trim();
  const module_code = String(spec.module_code || "OPS")
    .trim()
    .toUpperCase();
  const job_type = normalizeJobType(spec.job_type);
  if (!job_type) throw new Error("job_type is required");

  const payload = spec.payload || {};
  const idempotency_key =
    spec.idempotency_key === undefined
      ? null
      : String(spec.idempotency_key || "").trim() || null;

  const payload_hash = hashPayload(payload);
  const priority = Number.isInteger(spec.priority) ? spec.priority : 100;
  const max_attempts = Number.isInteger(spec.max_attempts)
    ? spec.max_attempts
    : 5;
  const run_after_at = spec.run_after_at || new Date();

  if (idempotency_key) {
    const [existing] = await db.query(
      `SELECT * FROM app_jobs WHERE queue_name=? AND idempotency_key=? LIMIT 1`,
      [queue_name, idempotency_key],
    );
    if (existing[0]) {
      return { job: existing[0], idempotent: true };
    }
  }

  const [ins] = await db.query(
    `
    INSERT INTO app_jobs
    (queue_name, module_code, job_type, status, priority, run_after_at,
     idempotency_key, payload_json, payload_hash, max_attempts, created_by)
    VALUES (?, ?, ?, 'QUEUED', ?, ?, ?, ?, ?, ?, ?)
    `,
    [
      queue_name,
      module_code,
      job_type,
      priority,
      run_after_at,
      idempotency_key,
      JSON.stringify(payload),
      payload_hash,
      max_attempts,
      userId,
    ],
  );

  const [rows] = await db.query(`SELECT * FROM app_jobs WHERE id=? LIMIT 1`, [
    ins.insertId,
  ]);
  return { job: rows[0], idempotent: false };
}

async function listJobs(db, filters = {}) {
  const where = [];
  const params = [];

  if (filters.status) {
    where.push(`status = ?`);
    params.push(String(filters.status).toUpperCase());
  }
  if (filters.module_code) {
    where.push(`module_code = ?`);
    params.push(String(filters.module_code).toUpperCase());
  }
  if (filters.job_type) {
    where.push(`job_type = ?`);
    params.push(String(filters.job_type).toUpperCase());
  }

  const limit = Math.min(200, Math.max(1, Number(filters.limit || 50)));

  const sql = `
    SELECT *
    FROM app_jobs
    ${where.length ? `WHERE ${where.join(" AND ")}` : ""}
    ORDER BY
      CASE status
        WHEN 'RUNNING' THEN 0
        WHEN 'FAILED_RETRYABLE' THEN 1
        WHEN 'QUEUED' THEN 2
        ELSE 3
      END,
      created_at DESC
    LIMIT ${limit}
  `;

  const [rows] = await db.query(sql, params);
  return rows;
}

async function getJob(db, id) {
  const [rows] = await db.query(`SELECT * FROM app_jobs WHERE id=? LIMIT 1`, [
    id,
  ]);
  const job = rows[0];
  if (!job) {
    const err = new Error("Job not found");
    err.statusCode = 404;
    throw err;
  }

  const [attempts] = await db.query(
    `SELECT * FROM app_job_attempts WHERE app_job_id=? ORDER BY attempt_no DESC`,
    [id],
  );

  return { job, attempts };
}

async function cancelJob(db, id, userId = null) {
  const [rows] = await db.query(`SELECT * FROM app_jobs WHERE id=? LIMIT 1`, [
    id,
  ]);
  const job = rows[0];
  if (!job) {
    const err = new Error("Job not found");
    err.statusCode = 404;
    throw err;
  }
  if (toStatusTerminal(job.status)) return job;
  if (job.status === "RUNNING") {
    const err = new Error("Cannot cancel a RUNNING job");
    err.statusCode = 409;
    throw err;
  }

  await db.query(
    `
    UPDATE app_jobs
    SET status='CANCELLED', cancelled_by=?, cancelled_at=NOW(), finished_at=NOW()
    WHERE id=?
    `,
    [userId, id],
  );

  const [updated] = await db.query(
    `SELECT * FROM app_jobs WHERE id=? LIMIT 1`,
    [id],
  );
  return updated[0];
}

async function requeueJob(db, id, userId = null) {
  const [rows] = await db.query(`SELECT * FROM app_jobs WHERE id=? LIMIT 1`, [
    id,
  ]);
  const job = rows[0];
  if (!job) {
    const err = new Error("Job not found");
    err.statusCode = 404;
    throw err;
  }
  if (!["FAILED_FINAL", "FAILED_RETRYABLE", "CANCELLED"].includes(job.status)) {
    const err = new Error(`Job status ${job.status} cannot be requeued`);
    err.statusCode = 409;
    throw err;
  }

  await db.query(
    `
    UPDATE app_jobs
    SET status='QUEUED',
        run_after_at=NOW(),
        locked_by=NULL,
        locked_at=NULL,
        started_at=NULL,
        finished_at=NULL,
        last_error_code=NULL,
        last_error_message=NULL,
        last_error_json=NULL,
        cancelled_by=NULL,
        cancelled_at=NULL,
        updated_at=NOW()
    WHERE id=?
    `,
    [id],
  );

  const [updated] = await db.query(
    `SELECT * FROM app_jobs WHERE id=? LIMIT 1`,
    [id],
  );
  return updated[0];
}

async function claimNextRunnableJob(db, { workerId, queueNames = [] }) {
  const conn = db.getConnection ? await db.getConnection() : null;
  const q = conn || db;

  try {
    if (conn) await conn.beginTransaction();

    const queueFilterSql =
      queueNames.length > 0
        ? `AND queue_name IN (${queueNames.map(() => "?").join(",")})`
        : "";
    const queueParams = queueNames.length > 0 ? queueNames : [];

    const [rows] = await q.query(
      `
      SELECT *
      FROM app_jobs
      WHERE status IN ('QUEUED', 'FAILED_RETRYABLE')
        AND run_after_at <= NOW()
        AND (locked_at IS NULL OR locked_at < DATE_SUB(NOW(), INTERVAL 15 MINUTE))
        ${queueFilterSql}
      ORDER BY priority ASC, run_after_at ASC, id ASC
      LIMIT 1
      FOR UPDATE
      `,
      queueParams,
    );

    const job = rows[0];
    if (!job) {
      if (conn) await conn.commit();
      return null;
    }

    await q.query(
      `
      UPDATE app_jobs
      SET status='RUNNING',
          locked_by=?,
          locked_at=NOW(),
          started_at=COALESCE(started_at, NOW()),
          attempt_count = attempt_count + 1,
          updated_at=NOW()
      WHERE id=?
      `,
      [workerId, job.id],
    );

    const attemptNo = Number(job.attempt_count || 0) + 1;

    await q.query(
      `
      INSERT INTO app_job_attempts
      (app_job_id, attempt_no, worker_id, status, started_at)
      VALUES (?, ?, ?, 'RUNNING', NOW())
      `,
      [job.id, attemptNo, workerId],
    );

    const [claimedRows] = await q.query(
      `SELECT * FROM app_jobs WHERE id=? LIMIT 1`,
      [job.id],
    );

    if (conn) await conn.commit();

    return { job: claimedRows[0], attempt_no: attemptNo };
  } catch (err) {
    if (conn) {
      try {
        await conn.rollback();
      } catch (_) {}
    }
    throw err;
  } finally {
    if (conn) conn.release();
  }
}

function classifyJobError(err) {
  const retryable =
    err?.retryable === true ||
    (err?.statusCode &&
      [408, 429, 500, 502, 503, 504].includes(Number(err.statusCode)));

  return {
    retryable,
    errorCode: String(err?.errorCode || "JOB_EXECUTION_ERROR"),
    errorMessage: String(err?.message || "Job execution failed").slice(0, 500),
    errorJson: redactObject({
      statusCode: err?.statusCode || null,
      retryable,
      details: err?.details || null,
    }),
  };
}

async function completeJobSuccess(db, { jobId, attemptNo, result }) {
  await db.query(
    `
    UPDATE app_jobs
    SET status='SUCCEEDED',
        finished_at=NOW(),
        locked_by=NULL,
        locked_at=NULL,
        result_json=?,
        last_error_code=NULL,
        last_error_message=NULL,
        last_error_json=NULL,
        updated_at=NOW()
    WHERE id=?
    `,
    [JSON.stringify(redactObject(result || {})), jobId],
  );

  await db.query(
    `
    UPDATE app_job_attempts
    SET status='SUCCEEDED',
        finished_at=NOW(),
        result_json=?
    WHERE app_job_id=? AND attempt_no=?
    `,
    [JSON.stringify(redactObject(result || {})), jobId, attemptNo],
  );
}

async function completeJobFailure(db, { job, attemptNo, errInfo }) {
  const attempts = Number(job.attempt_count || 0);
  const maxAttempts = Number(job.max_attempts || 5);
  const canRetry = errInfo.retryable && attempts < maxAttempts;

  let nextStatus = canRetry ? "FAILED_RETRYABLE" : "FAILED_FINAL";
  let runAfterAt = null;

  if (canRetry) {
    const delaySec = computeRetryDelaySeconds(attemptNo, job);
    runAfterAt = addSeconds(nowDate(), delaySec);
  }

  await db.query(
    `
    UPDATE app_jobs
    SET status=?,
        run_after_at = COALESCE(?, run_after_at),
        finished_at = CASE WHEN ?='FAILED_FINAL' THEN NOW() ELSE NULL END,
        locked_by=NULL,
        locked_at=NULL,
        last_error_code=?,
        last_error_message=?,
        last_error_json=?,
        updated_at=NOW()
    WHERE id=?
    `,
    [
      nextStatus,
      runAfterAt,
      nextStatus,
      errInfo.errorCode,
      errInfo.errorMessage,
      JSON.stringify(errInfo.errorJson || {}),
      job.id,
    ],
  );

  await db.query(
    `
    UPDATE app_job_attempts
    SET status=?,
        finished_at=NOW(),
        error_code=?,
        error_message=?,
        error_json=?
    WHERE app_job_id=? AND attempt_no=?
    `,
    [
      nextStatus,
      errInfo.errorCode,
      errInfo.errorMessage,
      JSON.stringify(errInfo.errorJson || {}),
      job.id,
      attemptNo,
    ],
  );
}

async function runClaimedJob(db, claimed, { workerId }) {
  const job = claimed.job;
  const attemptNo = claimed.attempt_no;
  const payload = job.payload_json || {};

  try {
    const handler = getJobHandler(job.job_type);
    const result = await handler.run({
      db,
      payload,
      job,
      workerId,
      attemptNo,
    });

    await completeJobSuccess(db, {
      jobId: job.id,
      attemptNo,
      result,
    });

    return { ok: true, job_id: job.id, status: "SUCCEEDED", result };
  } catch (err) {
    const errInfo = classifyJobError(err);

    // refresh current job row because attempt_count was incremented on claim
    const [fresh] = await db.query(
      `SELECT * FROM app_jobs WHERE id=? LIMIT 1`,
      [job.id],
    );

    await completeJobFailure(db, {
      job: fresh[0] || job,
      attemptNo,
      errInfo,
    });

    return {
      ok: false,
      job_id: job.id,
      status: errInfo.retryable ? "FAILED_RETRYABLE" : "FAILED_FINAL",
      error: errInfo,
    };
  }
}

async function runOneAvailableJob(
  db,
  { workerId = "worker-1", queueNames = [] } = {},
) {
  const claimed = await claimNextRunnableJob(db, { workerId, queueNames });
  if (!claimed) return { ok: true, idle: true };
  return runClaimedJob(db, claimed, { workerId });
}

export default {
  enqueueJob,
  listJobs,
  getJob,
  cancelJob,
  requeueJob,
  claimNextRunnableJob,
  runClaimedJob,
  runOneAvailableJob,
};
```

---

## 5) Admin routes — `backend/src/routes/jobs.admin.js`

```js id="0x74ja"
// backend/src/routes/jobs.admin.js

import express from "express";
import jobsSvc from "../services/jobs.service.js";
// replace with your actual helpers
import { requireAuth } from "../middleware/auth.js";
import { requirePermission } from "../middleware/rbac.js";
import { query } from "../db.js";
const router = express.Router();

function parsePositiveInt(v, field) {
  const n = Number(v);
  if (!Number.isInteger(n) || n <= 0)
    throw new Error(`${field} must be positive integer`);
  return n;
}

// GET /api/v1/jobs
router.get(
  "/",
  requireAuth,
  requirePermission("ops.jobs.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const items = await jobsSvc.listJobs(db, {
        status: req.query.status,
        module_code: req.query.module_code,
        job_type: req.query.job_type,
        limit: req.query.limit,
      });
      res.json({ items });
    } catch (err) {
      next(err);
    }
  },
);

// GET /api/v1/jobs/:id
router.get(
  "/:id",
  requireAuth,
  requirePermission("ops.jobs.read"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const id = parsePositiveInt(req.params.id, "id");
      const item = await jobsSvc.getJob(db, id);
      res.json(item);
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/jobs/:id/cancel
router.post(
  "/:id/cancel",
  requireAuth,
  requirePermission("ops.jobs.manage"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const id = parsePositiveInt(req.params.id, "id");
      const item = await jobsSvc.cancelJob(db, id, req.user?.id ?? null);
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/jobs/:id/requeue
router.post(
  "/:id/requeue",
  requireAuth,
  requirePermission("ops.jobs.manage"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const id = parsePositiveInt(req.params.id, "id");
      const item = await jobsSvc.requeueJob(db, id, req.user?.id ?? null);
      res.json({ item });
    } catch (err) {
      next(err);
    }
  },
);

// POST /api/v1/jobs/run-once
router.post(
  "/run-once",
  requireAuth,
  requirePermission("ops.jobs.run"),
  async (req, res, next) => {
    try {
      const db = { query }; // adapt to your service signature
      const workerId = `http-${req.user?.id || "system"}`;
      const queueNames = Array.isArray(req.body?.queue_names)
        ? req.body.queue_names
        : [];
      const result = await jobsSvc.runOneAvailableJob(db, {
        workerId,
        queueNames,
      });
      res.json(result);
    } catch (err) {
      next(err);
    }
  },
);

export default router;
```

---

## 6) Worker runner script — `backend/scripts/run-jobs-worker.js`

```js id="6g57z1"
// backend/scripts/run-jobs-worker.js

/**
 * Minimal worker loop.
 * Adapt db bootstrap to your project (shared DB pool import).
 */

import os from "os";
import jobsSvc from "../src/services/jobs.service.js";
import { createDbPool } from "../src/db.js"; // adapt if needed

async function sleep(ms) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

async function main() {
  const db = await createDbPool(); // adapt
  const workerId = `worker:${os.hostname()}:${process.pid}`;
  const pollMs = Number(process.env.JOBS_WORKER_POLL_MS || 2000);

  console.log(`[jobs-worker] started workerId=${workerId} pollMs=${pollMs}`);

  while (true) {
    try {
      const result = await jobsSvc.runOneAvailableJob(db, {
        workerId,
        queueNames: process.env.JOBS_WORKER_QUEUES
          ? String(process.env.JOBS_WORKER_QUEUES)
              .split(",")
              .map((s) => s.trim())
              .filter(Boolean)
          : [],
      });

      if (result.idle) {
        await sleep(pollMs);
      } else {
        console.log("[jobs-worker] job result", {
          job_id: result.job_id,
          status: result.status,
          ok: result.ok,
        });
      }
    } catch (err) {
      console.error("[jobs-worker] loop error", err.message);
      await sleep(pollMs);
    }
  }
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 7) Patch `payroll.providers.service.js` (P09) — optional async apply enqueue

> Add a helper that enqueues payroll import apply as a job instead of applying inline.

### Add import

```js id="y9vk4y"
import jobsSvc from "./jobs.service.js";
```

### Add helper

```js id="t5zq4w"
async function enqueueProviderImportApplyJob(
  db,
  importJobId,
  body,
  userId = null,
) {
  // Reuse existing P09 checks lightly (job existence, etc.) if you want.
  // Full maker-checker + lock checks still happen inside applyProviderImport when job executes.

  return jobsSvc.enqueueJob(
    db,
    {
      queue_name: "payroll.imports",
      module_code: "PAYROLL",
      job_type: "PAYROLL_IMPORT_APPLY",
      priority: 50,
      idempotency_key:
        body.idempotency_key || `PAYROLL_IMPORT_APPLY:${importJobId}`,
      max_attempts: 5,
      payload: {
        import_job_id: importJobId,
        acting_user_id: userId,
        apply_note: body.note || "Queued payroll provider import apply",
        auto_post_accrual: !!body.auto_post_accrual,
        allow_same_user_apply: !!body.allow_same_user_apply,
        retry_base_seconds: 30,
        retry_max_seconds: 1800,
      },
    },
    userId,
  );
}
```

### Export it

```js id="0ghv66"
export default {
  // ...existing exports
  enqueueProviderImportApplyJob,
};
```

> If you want, you can also add an **async route mode**:
> `POST /api/v1/payroll/provider-imports/:id/apply?async=1` → enqueue job and return `{job}`.

---

## 8) Bank service patches (B05/B06/B07/B08) — enqueue hooks

> Adapt to your actual service names.

### A) Queue bank feed pull (B05)

```js id="g8ncbs"
// in bank.providers.service.js (or your B05 feed service)
import jobsSvc from "./jobs.service.js";
async function enqueueBankFeedPull(db, payload, userId = null) {
  return jobsSvc.enqueueJob(
    db,
    {
      queue_name: "bank.integrations",
      module_code: "BANK",
      job_type: "BANK_FEED_PULL",
      priority: 40,
      idempotency_key:
        payload.idempotency_key ||
        `BANK_FEED_PULL:${payload.provider_connection_id}:${payload.from_date}:${payload.to_date}`,
      max_attempts: 6,
      payload: {
        provider_connection_id: payload.provider_connection_id,
        from_date: payload.from_date,
        to_date: payload.to_date,
        triggered_by: userId,
        retry_base_seconds: 60,
        retry_max_seconds: 3600,
      },
    },
    userId,
  );
}
```

### B) Queue webhook processing (B05/B07)

```js id="1vi9f7"
// in bank.webhooks.service.js
async function enqueueWebhookProcessing(db, webhookEventId, userId = null) {
  return jobsSvc.enqueueJob(
    db,
    {
      queue_name: "bank.integrations",
      module_code: "BANK",
      job_type: "BANK_WEBHOOK_PROCESS",
      priority: 20,
      idempotency_key: `BANK_WEBHOOK_PROCESS:${webhookEventId}`,
      max_attempts: 8,
      payload: {
        webhook_event_id: webhookEventId,
        triggered_by: userId,
        retry_base_seconds: 15,
        retry_max_seconds: 900,
      },
    },
    userId,
  );
}
```

### C) Queue payment sync retry (B07/B08/P04 edge sync)

```js id="dvhl9s"
// in bank.reconciliation.service.js (or equivalent)
async function enqueuePaymentSyncRetry(db, paymentBatchId, userId = null) {
  return jobsSvc.enqueueJob(
    db,
    {
      queue_name: "bank.reconciliation",
      module_code: "BANK",
      job_type: "PAYMENT_SYNC_RETRY",
      priority: 60,
      idempotency_key: `PAYMENT_SYNC_RETRY:${paymentBatchId}`,
      max_attempts: 5,
      payload: {
        payment_batch_id: paymentBatchId,
        mode: "RETRY_FAILED_LINES",
        triggered_by: userId,
        retry_base_seconds: 120,
        retry_max_seconds: 1800,
      },
    },
    userId,
  );
}
```

---

## 9) Mount route — `backend/src/index.js`

```js id="hqb38x"
// backend/src/index.js
import jobsAdminRoutes from "./routes/jobs.admin.js";
// ...
app.use("/api/v1/jobs", jobsAdminRoutes);
```

### Optional worker bootstrap in API process (dev only)

```js id="u7xdiw"
// Optional: don't do this in production API process unless you want a single-node simple setup
if (process.env.JOBS_INLINE_WORKER === "1") {
  import jobsSvc from "./services/jobs.service.js";
  const workerId = `inline-api:${process.pid}`;
  setInterval(() => {
    jobsSvc
      .runOneAvailableJob(app.locals.db || global.db, { workerId })
      .catch(() => {});
  }, 2000);
}
```

> Recommended: run `backend/scripts/run-jobs-worker.js` as a separate process instead.

---

## 10) Migration registry — `backend/src/migrations/index.js`

```js id="vx7d4b"
// backend/src/migrations/index.js
import m055_job_engine from "./m055_job_engine.js";
export default [
  // ...
  m055_job_engine,
];
```

---

## 11) Seed permissions — `backend/src/seedCore.js`

```js id="snb4ve"
// backend/src/seedCore.js
const HARDENING_H02_PERMISSIONS = [
  "ops.jobs.read",
  "ops.jobs.manage",
  "ops.jobs.run",
];

// merge into permission seed list
```

---

## 12) OpenAPI generation — `backend/scripts/generate-openapi.js`

Register these paths:

- `GET /api/v1/jobs`
- `GET /api/v1/jobs/{id}`
- `POST /api/v1/jobs/{id}/cancel`
- `POST /api/v1/jobs/{id}/requeue`
- `POST /api/v1/jobs/run-once`

Document job statuses:

- `QUEUED`
- `RUNNING`
- `SUCCEEDED`
- `FAILED_RETRYABLE`
- `FAILED_FINAL`
- `CANCELLED`

Document job fields:

- `id`
- `queue_name`
- `module_code`
- `job_type`
- `status`
- `attempt_count`
- `max_attempts`
- `run_after_at`
- `last_error_code`
- `last_error_message`
- `result_json`

---

## 13) Backend smoke test — `backend/scripts/test-hardening-prh02-job-engine.js`

```js id="x9pqyt"
// backend/scripts/test-hardening-prh02-job-engine.js

async function main() {
  // Preconditions:
  // - H01 redaction utility exists
  // - P09 / Bank services exist or use stub handlers for smoke
  //
  // Flow A: Enqueue idempotency
  // 1) Enqueue job with queue_name + idempotency_key
  // 2) Enqueue same again
  //    -> returns existing job (idempotent)
  //
  // Flow B: Successful execution
  // 3) Enqueue a stub/success job (or real handler with safe fixture)
  // 4) Run worker once
  //    -> job status SUCCEEDED
  //    -> attempt row written
  //    -> result_json populated
  //
  // Flow C: Retryable failure
  // 5) Enqueue a job whose handler fails with retryable=true
  // 6) Run worker once
  //    -> job status FAILED_RETRYABLE
  //    -> run_after_at in future
  // 7) Simulate next attempt (advance run_after or wait)
  //    -> eventually succeeds (or retries)
  //
  // Flow D: Final failure / dead-letter
  // 8) Enqueue job that always fails non-retryable
  // 9) Run worker
  //    -> job status FAILED_FINAL
  //
  // Flow E: Requeue / cancel admin actions
  // 10) Requeue FAILED_FINAL job -> QUEUED
  // 11) Cancel queued job -> CANCELLED
  //
  // Flow F: Payroll import apply job integration (if P09 available)
  // 12) Enqueue PAYROLL_IMPORT_APPLY for a valid previewed import
  // 13) Worker runs -> import applied
  //
  // Permissions:
  // - ops.jobs.read/manage/run enforced (403)
  console.log("PR-H02 smoke test placeholder");
}

main().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

---

## 14) `backend/package.json` updates

```json id="8m94ya"
{
  "scripts": {
    "jobs:worker": "node backend/scripts/run-jobs-worker.js",
    "test:hardening:prh02": "node backend/scripts/test-hardening-prh02-job-engine.js"
  }
}
```

---

## Acceptance criteria (repeat in PR)

- ✅ Generic job queue tables exist (`app_jobs`, `app_job_attempts`)
- ✅ Job enqueue supports idempotency (`queue_name + idempotency_key`)
- ✅ Worker claims jobs safely with DB locking (no double-run)
- ✅ Retryable failures move to `FAILED_RETRYABLE` with scheduled retry
- ✅ Non-retryable/exhausted jobs move to `FAILED_FINAL`
- ✅ Every execution attempt is recorded in `app_job_attempts`
- ✅ Admin APIs support list/get/requeue/cancel/run-once
- ✅ H01 redaction is used for job error/result payload safety
- ✅ Starter handlers exist for Bank + Payroll:

  - `BANK_FEED_PULL`
  - `BANK_WEBHOOK_PROCESS`
  - `PAYMENT_SYNC_RETRY`
  - `PAYROLL_IMPORT_APPLY`

- ✅ Existing Bank/Payroll services can enqueue jobs (hooks added)
- ✅ OpenAPI updated
- ✅ Smoke test script exists and runs

---

## Smoke test expectations (explicit)

## `npm run test:hardening:prh02`

Should verify at least:

1. **Enqueue idempotency**

   - duplicate enqueue returns same job

2. **Successful execution**

   - job runs and becomes `SUCCEEDED`
   - attempt row written
   - result stored

3. **Retry behavior**

   - retryable error becomes `FAILED_RETRYABLE`
   - `run_after_at` is scheduled
   - next run can succeed

4. **Dead-letter behavior**

   - non-retryable (or max attempts exceeded) becomes `FAILED_FINAL`

5. **Admin actions**

   - `requeue` works for failed/cancelled jobs
   - `cancel` works for queued jobs
   - `run-once` triggers worker execution

6. **Permissions**

   - `ops.jobs.read`
   - `ops.jobs.manage`
   - `ops.jobs.run`
     all enforced (`403`)

7. **(Optional integration) Payroll import apply**

   - queued `PAYROLL_IMPORT_APPLY` job calls P09 apply and succeeds

---

## Tiny implementation notes (important)

- H02 gives you the **execution backbone**; H05 will surface this in ops dashboards, and H07 will add retention/cleanup for old job logs.
- Keep handlers thin. The real logic should stay in your Bank/Payroll services.
- If you later add Redis/SQS/etc., keep this DB engine as a fallback/reference implementation — the handler contract can remain the same.

---

# PR-H03: Performance + Indexing + Pagination Hardening

## Goal

Make large datasets fast and stable:

- bank statements
- reconciliation matches/exceptions
- payroll liabilities/settlements
- provider imports/audit logs

## Scope

- Add missing indexes
- Convert list endpoints to cursor pagination where needed
- Add sort-safe query patterns
- Add `EXPLAIN`-verified hot path checks

## Files

### Create

- `backend/src/migrations/m056_performance_indexes.js`
- `backend/scripts/test-hardening-prh03-query-performance.js`
- `docs/specs/perf-hotpaths-bank-payroll.md`

### Update

- `backend/src/routes/bank*.js` list endpoints
- `backend/src/routes/payroll*.js` list endpoints
- `backend/src/services/*` query methods
- `backend/package.json`

## Key index examples

- Bank:

  - `bank_statement_lines(account_id, statement_date, id)`
  - `payment_batch_lines(payment_batch_id, status, reconciliation_status)`
  - exceptions by `status, queue_owner, created_at`

- Payroll:

  - `payroll_run_liabilities(run_id, status, outstanding_amount)`
  - `payroll_liability_settlements(payroll_liability_id, settled_at)`
  - `payroll_provider_import_jobs(entity_id, period_start, period_end, status)`
  - `payroll_period_closes(entity_id, period_start, period_end, status)`

## Acceptance

- ✅ Large list endpoints support pagination consistently
- ✅ No full-table scans on main operational queries
- ✅ Query latency improved on seeded large dataset
- ✅ Sorting/filtering combinations remain correct

## Smoke test

`npm run test:hardening:prh03`

- seed big sample data
- run hot-path queries
- verify response shape + pagination tokens

---

# PR-H04: Unified Approval Policy Engine (Thresholds, SoD, Multi-step)

## Goal

Centralize approval rules for **Bank + Payroll** instead of scattering permission checks.

## Scope

Build a reusable approval policy engine for:

- Bank payment batches (B09)
- Bank exception write-offs / force matches
- Payroll manual settlement overrides (P06)
- Payroll period close / reopen (P08)
- Payroll provider import apply (P09) for high-value payrolls

## Files

### Create

- `backend/src/migrations/m057_approval_policy_engine.js`
- `backend/src/services/approvalPolicies.service.js`
- `backend/src/routes/approvalPolicies.js`
- `backend/scripts/test-hardening-prh04-approval-policies.js`

### Update

- `bank.approvals.service.js`
- `payroll.settlementOverrides.service.js`
- `payroll.close.service.js`
- `payroll.providers.service.js`
- `seedCore.js`
- `generate-openapi.js`

## Policy examples

- “Payroll manual override > 5,000 requires 2 approvers”
- “Bank payment batch > 50,000 needs Treasury + Finance”
- “Reopen closed payroll period requires CFO role”
- “Preview user cannot apply import” (existing) + threshold escalation

## Acceptance

- ✅ Approval thresholds are configurable
- ✅ Multi-step approvals supported
- ✅ SoD enforced centrally
- ✅ Existing B09/P06/P08/P09 flows call policy engine
- ✅ Policy decisions are auditable

## Smoke test

`npm run test:hardening:prh04`

- create policy
- attempt action below threshold (passes)
- above threshold (extra approval required)
- same-user approve blocked (SoD)

---

# PR-H05: Operations Dashboard APIs (KPIs, SLAs, Health)

## Goal

Expose operational visibility so you can run this like a real SaaS/SaaP product.

## Scope

Add read-only dashboard endpoints for:

- Bank reconciliation status
- Payment batch execution health
- Payroll import pipeline health
- Payroll period close status
- Queue/job health (from H02)

## Files

### Create

- `backend/src/routes/ops.dashboard.js`
- `backend/src/services/ops.dashboard.service.js`
- `backend/scripts/test-hardening-prh05-ops-dashboard.js`

### Update

- `backend/src/index.js`
- `generate-openapi.js`
- `frontend/src/api/opsDashboard.js` (short)
- `frontend/src/pages/OpsDashboardPage.jsx` (optional compact snippets)
- `backend/package.json`

## Suggested endpoints

- `GET /api/v1/ops/bank/reconciliation-summary`
- `GET /api/v1/ops/bank/payment-batches-health`
- `GET /api/v1/ops/payroll/import-health`
- `GET /api/v1/ops/payroll/close-status`
- `GET /api/v1/ops/jobs/health`

## KPI examples

- unmatched statement lines
- exception aging buckets
- failed exports / retries pending
- payroll imports previewed vs applied
- closed periods vs open periods
- failed-final jobs count

## Acceptance

- ✅ Ops endpoints aggregate real data correctly
- ✅ SLA/aging metrics available
- ✅ Filters by entity/date work
- ✅ No write capability on ops endpoints

## Smoke test

`npm run test:hardening:prh05`

- seed mixed statuses
- verify KPI totals and aging buckets

---

# PR-H06: Unified Exception Workbench (Bank + Payroll Settlement Exceptions)

## Goal

Consolidate operational exceptions into one consistent workflow.

## Scope

### Bank

- returns / rejections / fees / FX exceptions (from B08)
- unmatched reconciliation queue (from B07)

### Payroll

- payment sync exceptions (P04/P06 edge cases)
- import failures/match errors (P09)
- close checklist blockers (P08) surfaced operationally

## Files

### Create

- `backend/src/migrations/m058_exception_workbench.js`
- `backend/src/routes/exceptions.workbench.js`
- `backend/src/services/exceptions.workbench.service.js`
- `backend/scripts/test-hardening-prh06-exception-workbench.js`

### Update

- Bank exception services (write into unified table or unified view)
- Payroll provider/payments/close services (emit exceptions)
- `generate-openapi.js`
- `seedCore.js`
- frontend exception pages (compact snippets only)

## Common exception model

- `exception_type`
- `module` (`BANK`, `PAYROLL`)
- `severity`
- `status` (`OPEN`, `IN_REVIEW`, `RESOLVED`, `IGNORED`)
- `owner_user_id`
- `source_ref`
- `payload_json`
- `resolution_action`
- `resolved_by/at`

## Acceptance

- ✅ Bank and payroll exceptions visible in one queue
- ✅ Ownership + status workflow works
- ✅ Resolution actions audited
- ✅ Existing module-specific exception logic preserved but normalized

## Smoke test

`npm run test:hardening:prh06`

- create bank + payroll exceptions
- claim/resolve/reopen
- verify audit + filtering

---

# PR-H07: Data Retention, Archival, and Export Snapshots

## Goal

Control database growth and improve audit/export readiness.

## Scope

- Retention policies for:

  - raw bank feed payloads
  - payroll raw imports
  - webhook logs
  - job execution logs

- Archival tables or cold-storage export hooks
- Immutable audit export snapshots for a closed period

## Files

### Create

- `backend/src/migrations/m059_data_retention_archival.js`
- `backend/src/services/retentionPolicies.service.js`
- `backend/src/routes/retention.admin.js`
- `backend/src/services/exportSnapshots.service.js`
- `backend/scripts/test-hardening-prh07-retention-archival.js`

### Update

- H01/H02/H05 services (retention hooks)
- `generate-openapi.js`
- `package.json`

## Example retention policies

- Raw provider payload text: keep 90 days, then mask
- Webhook raw payloads: keep 30 days
- Job logs: keep 180 days
- Keep audit rows forever (or export before purge)

## Acceptance

- ✅ Retention policies configurable
- ✅ Purge/mask jobs are safe + auditable
- ✅ Closed-period export snapshot can be generated (metadata + hashes)
- ✅ No deletion of core accounting records

## Smoke test

`npm run test:hardening:prh07`

- apply retention policy
- run purge/mask
- verify core records untouched, audit preserved

---

# PR-H08: Release Gate + End-to-End Regression Pack (Bank + Payroll)

## Goal

Finish with a strong CI gate so future changes don’t break bank/payroll contracts.

## Scope

Create an E2E regression suite covering the whole backbone:

### Bank flow

- payment batch create → approve → export → settlement sync → reconciliation → exception handling

### Payroll flow

- provider import preview/apply → liabilities → payment linkage → partial settlement/manual override → period close

### Cross-flow

- closed-period lock enforcement
- approval thresholds
- retries/jobs
- idempotency

## Files

### Create

- `backend/scripts/test-e2e-bank-payroll-release-gate.js`
- `backend/scripts/fixtures/bank-payroll-e2e-fixtures.js`
- `.github/workflows/bank-payroll-release-gate.yml` _(if not already split)_
- `docs/specs/bank-payroll-regression-matrix.md`

### Update

- `backend/package.json`
- existing CI workflow(s)

## Acceptance

- ✅ CI runs deterministic E2E scenarios
- ✅ Idempotency + lock + SoD regressions covered
- ✅ Failure output points to stage (import, settlement, close, etc.)
- ✅ Release gate blocks broken merges

## Smoke test

`npm run test:e2e:bank-payroll`

- full seeded scenario passes end-to-end

---

# Recommended execution order

1. **PR-H01** — Security first (secrets/payload handling)
2. **PR-H02** — Job/retry backbone
3. **PR-H03** — Performance/indexing
4. **PR-H04** — Unified approval policy engine
5. **PR-H05** — Ops dashboards
6. **PR-H06** — Unified exception workbench
7. **PR-H07** — Retention/archival/export
8. **PR-H08** — Full release gate regression pack

---

# Optional final bonus PR (if you want)

## PR-H09: Tenant/Entity Isolation Hardening

If you plan multi-entity/multi-tenant usage seriously:

- row-level scoping helpers
- mandatory entity filters in services
- entity-bound id validation
- cross-entity access tests

(This is very valuable if the app will grow beyond single-company admin usage.)

---

If you want, I can now write **PR-H01** in the same full concrete format (migration skeleton + service snippets + exact acceptance + smoke test), just like the B/P PRs.

Perfect — here is **PR-H01** in the same concrete format.

# TEST THEM IF THEY THOSE MISTAKES EXIST.

Common integration mistakes to avoid

These are the ones that usually break this chain:

1. Status naming mismatch between B03/B04 and P04

P04 sync depends on batch/line/reconciliation evidence. If your actual columns differ, only adjust the P04 evidence query, not the payroll logic.

2. Missing idempotency keys

You need idempotency on:

statement import (B02)

payment batch creation (B04 / P03)

payroll sync apply settlement rows (P04)

3. Payroll mapping gaps in P02

P03 liability build depends on payable mappings from P02. If one payable mapping is missing, liability build/payment prep will break.

4. Not checking audit rows

Audit trails are part of the product quality here, not “optional nice-to-have.”

Recommended “merge gates” (practical)

Only merge each PR if these pass:

Schema stable

Smoke test script added

Permission seed updated

OpenAPI updated

Idempotency confirmed

Audit rows confirmed

---

## Follow-Up Integration PR Steps (Post H09)

These are the practical integration PRs that became unblocked after completing PR-B01..B09, PR-P01..P09, and PR-H01..H09.

Reference context docs:

- `01-PR_STEPS CARI.md`
- `02-PR-STEPS_CONTRACTS_PERIDOTS GELECEK YILLARA AIT GGELİRLER GIDERLER.md`
- `03-PR_FOLLOW_UPS_OF_CONTRACTS_PERIDOS.md`
- `05-gelir gider thaakkukları.md`

### Integration tracker

- [x] PR-I01 Main Release Gate Bridge (include bank-payroll gate in `test:release-gate`) (implemented)
- [x] PR-I02 Bank Route Alias + UX Compatibility (`/app/banka-hesaplari` -> `/app/banka-tanimla`) (implemented)
- [x] PR-I03 Bank Connector Provider Pack (real adapters beyond `MOCK_OB`) (implemented)
- [x] PR-I04 Secrets Backfill + Re-Encryption Job (legacy plaintext -> encrypted envelope) (implemented)
- [x] PR-I05 Retention Scheduler (true `SCHEDULED` policy execution loop) (implemented)
- [x] PR-I06 Contracts/Periods Integration with Bank + Payroll flows (future-year accrual chain) (implemented)
- [x] PR-I07 Unified Final Gate (core + contracts/revenue + bank/payroll in one orchestrator) (implemented)

---

### PR-I01: Main Release Gate Bridge

Goal:

- Make bank-payroll gate part of the default release-gate orchestrator.

Update:

- `backend/scripts/test-release-gate.js`
- `backend/package.json`

Acceptance:

- `npm run test:release-gate` executes:
  - `test:release-gate:core`
  - `test:contracts-revenue-gate`
  - `test:e2e:bank-payroll`
- Add optional skip env (example): `RELEASE_GATE_SKIP_BANK_PAYROLL=1`.

---

### PR-I02: Bank Route Alias + UX Compatibility

Goal:

- Add route alias for naming continuity without changing canonical path.

Update:

- `frontend/src/App.jsx`
- `frontend/src/layouts/sidebarConfig.js` (only if needed for redirects/legacy menu)
- `frontend/src/i18n/messages.js` (optional label)

Acceptance:

- `/app/banka-hesaplari` redirects to `/app/banka-tanimla`.
- Permission behavior remains identical to canonical route.

---

### PR-I03: Bank Connector Provider Pack

Goal:

- Replace single mock bank adapter with pluggable real providers.

Create/Update:

- `backend/src/services/bankConnectorAdapters/*.adapter.js`
- `backend/src/services/bankConnectorAdapters/index.js`
- optional provider-specific tests under `backend/scripts/`

Acceptance:

- At least one non-mock adapter is runnable in integration mode.
- Existing `MOCK_OB` path remains for deterministic test runs.

Implementation notes:

- Added `SANDBOX_OB` HTTP adapter and registry wiring.
- Added smoke script: `backend/scripts/test-bank-pri03-provider-pack.js` (`npm run test:bank:pri03`).

---

### PR-I04: Secrets Backfill + Re-Encryption Job

Goal:

- Migrate any legacy plaintext secrets to encrypted envelope model.

Create/Update:

- migration/script for one-time backfill
- optional job handler for rotation/re-encrypt-all
- audit writes for each migrated secret row

Acceptance:

- No active connector/provider rows rely on plaintext secret columns.
- Read/write paths remain backward compatible during migration window.

Implementation notes:

- Added migration service: `backend/src/services/secretsMigration.service.js`
  - payroll provider legacy plaintext backfill (`secrets_json` -> encrypted envelope)
  - provider + bank connector key rotation re-encryption
  - per-row `sensitive_data_audit` writes
- Added background job handler: `SECRETS_BACKFILL_REENCRYPT`
  - `backend/src/services/jobHandlers/secretsBackfillReencrypt.handler.js`
- Added one-time operational script:
  - `npm run job:secrets:migrate`
  - script: `backend/scripts/secrets-backfill-reencrypt.js`
- Added PR-I04 smoke/integration test:
  - `npm run test:integration:pri04`
  - script: `backend/scripts/test-integration-pri04-secrets-backfill-reencrypt.js`

---

### PR-I05: Retention Scheduler

Goal:

- Run retention policies automatically in `SCHEDULED` mode.

Create/Update:

- scheduler loop (cron/polling) that enqueues `DATA_RETENTION_RUN`
- worker integration docs and env settings

Acceptance:

- Due policies are enqueued without manual API trigger.
- Idempotency and run-history integrity preserved.

Implementation notes:

- Added retention scheduler service:
  - `backend/src/services/retentionScheduler.service.js`
  - scans active policies, evaluates due windows from `config_json`, enqueues `DATA_RETENTION_RUN`
- Added scheduler scripts:
  - one-shot tick: `npm run job:retention:schedule-due`
  - polling loop: `npm run jobs:retention:scheduler`
  - files:
    - `backend/scripts/retention-schedule-due-policies.js`
    - `backend/scripts/run-retention-scheduler.js`
- Extended `DATA_RETENTION_RUN` handler to honor payload `trigger_mode` (defaults to `JOB`):
  - scheduled enqueues now produce retention runs with `trigger_mode='SCHEDULED'`
  - file: `backend/src/services/jobHandlers/dataRetentionRun.handler.js`
- Added PR-I05 integration smoke:
  - `npm run test:integration:pri05`
  - file: `backend/scripts/test-integration-pri05-retention-scheduler.js`
- Added ops/env documentation:
  - `docs/specs/retention-scheduler.md`

---

### PR-I06: Contracts/Periods Integration with Bank + Payroll

Goal:

- Connect contract-period accrual flows ("gelecek yillara ait gelirler/giderler") to bank/payroll execution evidence.

Scope:

- contract billing/revrec outputs become traceable inputs to payment/reconciliation lifecycle
- consistent period-close behavior across contracts + payroll + bank evidence
- explicit link strategy for reversals/corrections across modules

Reference:

- `02-PR-STEPS_CONTRACTS_PERIDOTS GELECEK YILLARA AIT GGELİRLER GIDERLER.md`
- `03-PR_FOLLOW_UPS_OF_CONTRACTS_PERIDOS.md`

Acceptance:

- End-to-end test covers contract-period accrual -> payment prep -> settlement/reconciliation -> close checks.

Implementation notes:

- Added integration chain script:
  - `backend/scripts/test-integration-pri06-contracts-periods-bank-payroll.js`
  - runs strict staged chain:
    - contracts period/revrec generation: `test-contracts-pr22-revrec-generation.js`
    - accrual lifecycle settle/reverse: `test-revenue-pr17c.js`
    - payroll payment prep from liabilities: `test-payroll-prp03-liabilities-payment-prep.js`
    - settlement/reconciliation evidence sync: `test-payroll-prp04-payment-settlement-sync.js`
    - payroll close controls/checklist/locks: `test-payroll-prp08-close-controls-checklist-locks.js`
- Added npm alias:
  - `npm run test:integration:pri06`

---

### PR-I07: Unified Final Gate

Goal:

- Run all major module gates from one top-level command.

Update:

- `backend/scripts/test-release-gate.js`
- CI workflows

Acceptance:

- Unified gate can run all chains with optional skip flags per module family.
- Failure output remains stage-specific and actionable.

Implementation notes:

- Upgraded `backend/scripts/test-release-gate.js` to a staged orchestrator with explicit stage IDs:
  - `CORE` -> `test:release-gate:core`
  - `CONTRACTS_REVENUE` -> `test:contracts-revenue-gate`
  - `BANK_PAYROLL` -> `test:e2e:bank-payroll`
  - `INTEGRATION_PRI06` -> `test:integration:pri06`
- Added optional gate controls:
  - family skip flags:
    - `RELEASE_GATE_SKIP_CORE`
    - `RELEASE_GATE_SKIP_CONTRACTS_REVENUE`
    - `RELEASE_GATE_SKIP_BANK_PAYROLL`
    - `RELEASE_GATE_SKIP_INTEGRATION_PRI06`
  - stage selection flags:
    - `RELEASE_GATE_ONLY_STAGES` (CSV)
    - `RELEASE_GATE_SKIP_STAGES` (CSV)
    - `RELEASE_GATE_DRY_RUN`
- Improved failure diagnostics:
  - failed stage ID + script are printed explicitly
  - actionable rerun hint uses `RELEASE_GATE_ONLY_STAGES=<STAGE_ID>`
  - final summary prints per-stage duration/status.
- Updated CI workflow:
  - `.github/workflows/backend-release-gate.yml` now exposes `workflow_dispatch` inputs mapped to unified gate env flags.

